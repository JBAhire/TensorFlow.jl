# Autogenerated on 2019-02-20T16:49:23.66

module Ops
import TensorFlow
const tf = TensorFlow
"""
     reduce_join(inputs, reduction_indices; keep_dims=false, separator=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reduce_join(inputs_, reduction_indices_; name=nothing, keep_dims=nothing, separator=nothing)
            local desc
            tf.with_op_name(name, "ReduceJoin") do 
                desc = tf.NodeDescription("ReduceJoin")
                inputs_ = convert(Tensor{String}, inputs_)
                reduction_indices_ = convert(Tensor{Int32}, reduction_indices_)
                tf.add_input(desc, inputs_)
                tf.add_input(desc, reduction_indices_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
                if separator !== nothing
                    desc["separator"] = Base.String(separator)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reduce_join(inputs_::tf.TensorHandle, reduction_indices_::tf.TensorHandle; name=nothing, keep_dims=nothing, separator=nothing)
        desc = tf.EagerOp("ReduceJoin")
        tf.add_input(desc, inputs_)
        tf.add_input(desc, reduction_indices_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        if separator !== nothing
            desc["separator"] = Base.String(separator)
        end
        (tf.execute(desc))[1]
    end
end


"""
     reduce_dataset(input_dataset, initial_state, other_arguments; use_inter_op_parallelism=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reduce_dataset(input_dataset_, initial_state_, other_arguments_; name=nothing, f=nothing, Tstate=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, use_inter_op_parallelism=nothing)
            local desc
            tf.with_op_name(name, "ReduceDataset") do 
                desc = tf.NodeDescription("ReduceDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                initial_state_ = [convert(Tensor{Any}, x) for x = initial_state_]
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, initial_state_)
                tf.add_input(desc, other_arguments_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if Tstate !== nothing
                    desc["Tstate"] = map(Base.identity, Tstate)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if use_inter_op_parallelism !== nothing
                    desc["use_inter_op_parallelism"] = Base.Bool(use_inter_op_parallelism)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reduce_dataset(input_dataset_::tf.TensorHandle, initial_state_::tf.TensorHandle, other_arguments_::tf.TensorHandle; name=nothing, f=nothing, Tstate=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, use_inter_op_parallelism=nothing)
        desc = tf.EagerOp("ReduceDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, initial_state_)
        tf.add_input(desc, other_arguments_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if Tstate !== nothing
            desc["Tstate"] = map(Base.identity, Tstate)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if use_inter_op_parallelism !== nothing
            desc["use_inter_op_parallelism"] = Base.Bool(use_inter_op_parallelism)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_from_tensor(tensor, element_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_from_tensor(tensor_, element_shape_; name=nothing, element_dtype=nothing, shape_type=nothing)
            local desc
            tf.with_op_name(name, "TensorListFromTensor") do 
                desc = tf.NodeDescription("TensorListFromTensor")
                tensor_ = convert(Tensor{Any}, tensor_)
                element_shape_ = convert(Tensor{Any}, element_shape_)
                (tensor_,) = tf.tf_promote(tensor_)
                (element_shape_,) = tf.tf_promote(element_shape_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, element_shape_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
                if shape_type !== nothing
                    desc["shape_type"] = Base.identity(shape_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_from_tensor(tensor_::tf.TensorHandle, element_shape_::tf.TensorHandle; name=nothing, element_dtype=nothing, shape_type=nothing)
        desc = tf.EagerOp("TensorListFromTensor")
        tf.add_input(desc, tensor_)
        tf.add_input(desc, element_shape_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        if shape_type !== nothing
            desc["shape_type"] = Base.identity(shape_type)
        end
        desc["element_dtype"] = tf.data_type(tensor_)
        desc["shape_type"] = tf.data_type(element_shape_)
        (tf.execute(desc))[1]
    end
end


"""
     extract_jpeg_shape(contents; output_type=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function extract_jpeg_shape(contents_; name=nothing, output_type=nothing)
            local desc
            tf.with_op_name(name, "ExtractJpegShape") do 
                desc = tf.NodeDescription("ExtractJpegShape")
                contents_ = convert(Tensor{String}, contents_)
                tf.add_input(desc, contents_)
                if output_type !== nothing
                    desc["output_type"] = Base.identity(output_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function extract_jpeg_shape(contents_::tf.TensorHandle; name=nothing, output_type=nothing)
        desc = tf.EagerOp("ExtractJpegShape")
        tf.add_input(desc, contents_)
        if output_type !== nothing
            desc["output_type"] = Base.identity(output_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     svd(input; compute_uv=true, full_matrices=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function svd(input_; name=nothing, compute_uv=nothing, full_matrices=nothing)
            local desc
            tf.with_op_name(name, "Svd") do 
                desc = tf.NodeDescription("Svd")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if compute_uv !== nothing
                    desc["compute_uv"] = Base.Bool(compute_uv)
                end
                if full_matrices !== nothing
                    desc["full_matrices"] = Base.Bool(full_matrices)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function svd(input_::tf.TensorHandle; name=nothing, compute_uv=nothing, full_matrices=nothing)
        desc = tf.EagerOp("Svd")
        tf.add_input(desc, input_)
        if compute_uv !== nothing
            desc["compute_uv"] = Base.Bool(compute_uv)
        end
        if full_matrices !== nothing
            desc["full_matrices"] = Base.Bool(full_matrices)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     iterator_get_next_sync(iterator)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function iterator_get_next_sync(iterator_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "IteratorGetNextSync") do 
                desc = tf.NodeDescription("IteratorGetNextSync")
                iterator_ = convert(Tensor{Any}, iterator_)
                tf.add_input(desc, iterator_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function iterator_get_next_sync(iterator_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("IteratorGetNextSync")
        tf.add_input(desc, iterator_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     ref_enter(data; is_constant=false, parallel_iterations=10)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ref_enter(data_; name=nothing, frame_name=nothing, is_constant=nothing, parallel_iterations=nothing)
            local desc
            tf.with_op_name(name, "RefEnter") do 
                desc = tf.NodeDescription("RefEnter")
                data_ = convert(Tensor{Any}, data_)
                (data_,) = tf.tf_promote(data_)
                tf.add_input(desc, data_)
                if frame_name !== nothing
                    desc["frame_name"] = Base.String(frame_name)
                end
                if is_constant !== nothing
                    desc["is_constant"] = Base.Bool(is_constant)
                end
                if parallel_iterations !== nothing
                    desc["parallel_iterations"] = Base.Int(parallel_iterations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ref_enter(data_::tf.TensorHandle; name=nothing, frame_name=nothing, is_constant=nothing, parallel_iterations=nothing)
        desc = tf.EagerOp("RefEnter")
        tf.add_input(desc, data_)
        if frame_name !== nothing
            desc["frame_name"] = Base.String(frame_name)
        end
        if is_constant !== nothing
            desc["is_constant"] = Base.Bool(is_constant)
        end
        if parallel_iterations !== nothing
            desc["parallel_iterations"] = Base.Int(parallel_iterations)
        end
        desc["T"] = tf.data_type(data_)
        (tf.execute(desc))[1]
    end
end


"""
     erf(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function erf(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Erf") do 
                desc = tf.NodeDescription("Erf")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function erf(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Erf")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     lookup_table_export_v2(table_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lookup_table_export_v2(table_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "LookupTableExportV2") do 
                desc = tf.NodeDescription("LookupTableExportV2")
                table_handle_ = convert(Tensor{Any}, table_handle_)
                tf.add_input(desc, table_handle_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function lookup_table_export_v2(table_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LookupTableExportV2")
        tf.add_input(desc, table_handle_)
        tf.execute(desc)
    end
end


"""
     round(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function round(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Round") do 
                desc = tf.NodeDescription("Round")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function round(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Round")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     outfeed_dequeue(; device_ordinal=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function outfeed_dequeue(; name=nothing, dtype=nothing, shape=nothing, device_ordinal=nothing)
            local desc
            tf.with_op_name(name, "OutfeedDequeue") do 
                desc = tf.NodeDescription("OutfeedDequeue")
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
                if device_ordinal !== nothing
                    desc["device_ordinal"] = Base.Int(device_ordinal)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function outfeed_dequeue(; name=nothing, dtype=nothing, shape=nothing, device_ordinal=nothing)
        desc = tf.EagerOp("OutfeedDequeue")
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        if device_ordinal !== nothing
            desc["device_ordinal"] = Base.Int(device_ordinal)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_forest_tree_is_initialized_op(tree_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_forest_tree_is_initialized_op(tree_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorForestTreeIsInitializedOp") do 
                desc = tf.NodeDescription("TensorForestTreeIsInitializedOp")
                tree_handle_ = convert(Tensor{Any}, tree_handle_)
                tf.add_input(desc, tree_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_forest_tree_is_initialized_op(tree_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorForestTreeIsInitializedOp")
        tf.add_input(desc, tree_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     merge(inputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function merge(inputs_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "Merge") do 
                desc = tf.NodeDescription("Merge")
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                (inputs_,) = tf.tf_promote(inputs_)
                tf.add_input(desc, inputs_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function merge(inputs_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("Merge")
        tf.add_input(desc, inputs_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(inputs_)
        tf.execute(desc)
    end
end


"""
     histogram_fixed_width(values, value_range, nbins; dtype=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function histogram_fixed_width(values_, value_range_, nbins_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "HistogramFixedWidth") do 
                desc = tf.NodeDescription("HistogramFixedWidth")
                values_ = convert(Tensor{Any}, values_)
                value_range_ = convert(Tensor{Any}, value_range_)
                nbins_ = convert(Tensor{Int32}, nbins_)
                (values_, value_range_) = tf.tf_promote(values_, value_range_)
                tf.add_input(desc, values_)
                tf.add_input(desc, value_range_)
                tf.add_input(desc, nbins_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function histogram_fixed_width(values_::tf.TensorHandle, value_range_::tf.TensorHandle, nbins_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("HistogramFixedWidth")
        tf.add_input(desc, values_)
        tf.add_input(desc, value_range_)
        tf.add_input(desc, nbins_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["T"] = tf.data_type(values_)
        desc["T"] = tf.data_type(value_range_)
        (tf.execute(desc))[1]
    end
end


"""
     asin(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function asin(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Asin") do 
                desc = tf.NodeDescription("Asin")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function asin(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Asin")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     any(input, reduction_indices; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function any(input_, reduction_indices_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "Any") do 
                desc = tf.NodeDescription("Any")
                input_ = convert(Tensor{Bool}, input_)
                reduction_indices_ = convert(Tensor{Int32}, reduction_indices_)
                reduction_indices_ = reduction_indices_ - convert(tf.Tensor{eltype(reduction_indices_)}, 1)
                (reduction_indices_,) = tf.tf_promote(reduction_indices_)
                tf.add_input(desc, input_)
                tf.add_input(desc, reduction_indices_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function any(input_::tf.TensorHandle, reduction_indices_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("Any")
        tf.add_input(desc, input_)
        tf.add_input(desc, reduction_indices_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["Tidx"] = tf.data_type(reduction_indices_)
        (tf.execute(desc))[1]
    end
end


"""
     rsqrt_grad(y, dy)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function rsqrt_grad(y_, dy_; name=nothing)
            local desc
            tf.with_op_name(name, "RsqrtGrad") do 
                desc = tf.NodeDescription("RsqrtGrad")
                y_ = convert(Tensor{Any}, y_)
                dy_ = convert(Tensor{Any}, dy_)
                (y_, dy_) = tf.tf_promote(y_, dy_)
                tf.add_input(desc, y_)
                tf.add_input(desc, dy_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function rsqrt_grad(y_::tf.TensorHandle, dy_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RsqrtGrad")
        tf.add_input(desc, y_)
        tf.add_input(desc, dy_)
        desc["T"] = tf.data_type(y_)
        desc["T"] = tf.data_type(dy_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_scatter(handle, indices, value, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_scatter(handle_, indices_, value_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayScatter") do 
                desc = tf.NodeDescription("TensorArrayScatter")
                handle_ = convert(Tensor{String}, handle_)
                indices_ = convert(Tensor{Int32}, indices_)
                value_ = convert(Tensor{Any}, value_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, value_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_scatter(handle_::tf.TensorHandle, indices_::tf.TensorHandle, value_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArrayScatter")
        tf.add_input(desc, handle_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, value_)
        tf.add_input(desc, flow_in_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     dynamic_partition(data, partitions)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function dynamic_partition(data_, partitions_; name=nothing, num_partitions=nothing)
            local desc
            tf.with_op_name(name, "DynamicPartition") do 
                desc = tf.NodeDescription("DynamicPartition")
                data_ = convert(Tensor{Any}, data_)
                partitions_ = convert(Tensor{Int32}, partitions_)
                (data_,) = tf.tf_promote(data_)
                tf.add_input(desc, data_)
                tf.add_input(desc, partitions_)
                if num_partitions !== nothing
                    desc["num_partitions"] = Base.Int(num_partitions)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:num_partitions
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function dynamic_partition(data_::tf.TensorHandle, partitions_::tf.TensorHandle; name=nothing, num_partitions=nothing)
        desc = tf.EagerOp("DynamicPartition")
        tf.add_input(desc, data_)
        tf.add_input(desc, partitions_)
        if num_partitions !== nothing
            desc["num_partitions"] = Base.Int(num_partitions)
        end
        desc["T"] = tf.data_type(data_)
        tf.execute(desc)
    end
end


"""
     experimental_private_thread_pool_dataset(input_dataset, num_threads)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_private_thread_pool_dataset(input_dataset_, num_threads_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalPrivateThreadPoolDataset") do 
                desc = tf.NodeDescription("ExperimentalPrivateThreadPoolDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                num_threads_ = convert(Tensor{Int64}, num_threads_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, num_threads_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_private_thread_pool_dataset(input_dataset_::tf.TensorHandle, num_threads_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalPrivateThreadPoolDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, num_threads_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     reader_serialize_state(reader_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_serialize_state(reader_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderSerializeState") do 
                desc = tf.NodeDescription("ReaderSerializeState")
                reader_handle_ = convert(Tensor{String}, reader_handle_)
                tf.add_input(desc, reader_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reader_serialize_state(reader_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderSerializeState")
        tf.add_input(desc, reader_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     right_shift(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function right_shift(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "RightShift") do 
                desc = tf.NodeDescription("RightShift")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function right_shift(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RightShift")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     avg_pool3d(input; data_format=NDHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function avg_pool3d(input_; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "AvgPool3D") do 
                desc = tf.NodeDescription("AvgPool3D")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function avg_pool3d(input_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("AvgPool3D")
        tf.add_input(desc, input_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     encode_png(image; compression=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function encode_png(image_; name=nothing, compression=nothing)
            local desc
            tf.with_op_name(name, "EncodePng") do 
                desc = tf.NodeDescription("EncodePng")
                image_ = convert(Tensor{UInt8}, image_)
                (image_,) = tf.tf_promote(image_)
                tf.add_input(desc, image_)
                if compression !== nothing
                    desc["compression"] = Base.Int(compression)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function encode_png(image_::tf.TensorHandle; name=nothing, compression=nothing)
        desc = tf.EagerOp("EncodePng")
        tf.add_input(desc, image_)
        if compression !== nothing
            desc["compression"] = Base.Int(compression)
        end
        desc["T"] = tf.data_type(image_)
        (tf.execute(desc))[1]
    end
end


"""
     debug_identity(input; device_name=, tensor_name=, debug_urls=Int64[], gated_grpc=false)

Debug Identity Op.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function debug_identity(input_; name=nothing, device_name=nothing, tensor_name=nothing, debug_urls=nothing, gated_grpc=nothing)
            local desc
            tf.with_op_name(name, "DebugIdentity") do 
                desc = tf.NodeDescription("DebugIdentity")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if device_name !== nothing
                    desc["device_name"] = Base.String(device_name)
                end
                if tensor_name !== nothing
                    desc["tensor_name"] = Base.String(tensor_name)
                end
                if debug_urls !== nothing
                    desc["debug_urls"] = map(Base.identity, debug_urls)
                end
                if gated_grpc !== nothing
                    desc["gated_grpc"] = Base.Bool(gated_grpc)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function debug_identity(input_::tf.TensorHandle; name=nothing, device_name=nothing, tensor_name=nothing, debug_urls=nothing, gated_grpc=nothing)
        desc = tf.EagerOp("DebugIdentity")
        tf.add_input(desc, input_)
        if device_name !== nothing
            desc["device_name"] = Base.String(device_name)
        end
        if tensor_name !== nothing
            desc["tensor_name"] = Base.String(tensor_name)
        end
        if debug_urls !== nothing
            desc["debug_urls"] = map(Base.identity, debug_urls)
        end
        if gated_grpc !== nothing
            desc["gated_grpc"] = Base.Bool(gated_grpc)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     imag(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function imag(input_; name=nothing)
            local desc
            tf.with_op_name(name, "Imag") do 
                desc = tf.NodeDescription("Imag")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function imag(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Imag")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_sparse_apply_ftrl_v2(var, accum, linear, grad, indices, lr, l1, l2, l2_shrinkage, lr_power; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_sparse_apply_ftrl_v2(var_, accum_, linear_, grad_, indices_, lr_, l1_, l2_, l2_shrinkage_, lr_power_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceSparseApplyFtrlV2") do 
                desc = tf.NodeDescription("ResourceSparseApplyFtrlV2")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                linear_ = convert(Tensor{Any}, linear_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                l2_shrinkage_ = convert(Tensor{Any}, l2_shrinkage_)
                lr_power_ = convert(Tensor{Any}, lr_power_)
                (grad_, lr_, l1_, l2_, l2_shrinkage_, lr_power_) = tf.tf_promote(grad_, lr_, l1_, l2_, l2_shrinkage_, lr_power_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, linear_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, l2_shrinkage_)
                tf.add_input(desc, lr_power_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_sparse_apply_ftrl_v2(var_::tf.TensorHandle, accum_::tf.TensorHandle, linear_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, l2_shrinkage_::tf.TensorHandle, lr_power_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceSparseApplyFtrlV2")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, linear_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, l2_shrinkage_)
        tf.add_input(desc, lr_power_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(l2_shrinkage_)
        desc["T"] = tf.data_type(lr_power_)
        (tf.execute(desc))[1]
    end
end


"""
     stage_clear(; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stage_clear(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "StageClear") do 
                desc = tf.NodeDescription("StageClear")
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stage_clear(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("StageClear")
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sign(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sign(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Sign") do 
                desc = tf.NodeDescription("Sign")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sign(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Sign")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     population_count(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function population_count(x_; name=nothing)
            local desc
            tf.with_op_name(name, "PopulationCount") do 
                desc = tf.NodeDescription("PopulationCount")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function population_count(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("PopulationCount")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     neg(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function neg(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Neg") do 
                desc = tf.NodeDescription("Neg")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function neg(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Neg")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     anonymous_iterator()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function anonymous_iterator(; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "AnonymousIterator") do 
                desc = tf.NodeDescription("AnonymousIterator")
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function anonymous_iterator(; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("AnonymousIterator")
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_reduce_sum(input_indices, input_values, input_shape, reduction_axes; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_reduce_sum(input_indices_, input_values_, input_shape_, reduction_axes_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "SparseReduceSum") do 
                desc = tf.NodeDescription("SparseReduceSum")
                input_indices_ = convert(Tensor{Int64}, input_indices_)
                input_values_ = convert(Tensor{Any}, input_values_)
                input_shape_ = convert(Tensor{Int64}, input_shape_)
                reduction_axes_ = convert(Tensor{Int32}, reduction_axes_)
                (input_values_,) = tf.tf_promote(input_values_)
                tf.add_input(desc, input_indices_)
                tf.add_input(desc, input_values_)
                tf.add_input(desc, input_shape_)
                tf.add_input(desc, reduction_axes_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_reduce_sum(input_indices_::tf.TensorHandle, input_values_::tf.TensorHandle, input_shape_::tf.TensorHandle, reduction_axes_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("SparseReduceSum")
        tf.add_input(desc, input_indices_)
        tf.add_input(desc, input_values_)
        tf.add_input(desc, input_shape_)
        tf.add_input(desc, reduction_axes_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["T"] = tf.data_type(input_values_)
        (tf.execute(desc))[1]
    end
end


"""
     filter_dataset(input_dataset, other_arguments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function filter_dataset(input_dataset_, other_arguments_; name=nothing, predicate=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "FilterDataset") do 
                desc = tf.NodeDescription("FilterDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, other_arguments_)
                if predicate !== nothing
                    desc["predicate"] = Base.identity(predicate)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function filter_dataset(input_dataset_::tf.TensorHandle, other_arguments_::tf.TensorHandle; name=nothing, predicate=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("FilterDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, other_arguments_)
        if predicate !== nothing
            desc["predicate"] = Base.identity(predicate)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     string_length(input; unit=BYTE)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function string_length(input_; name=nothing, unit=nothing)
            local desc
            tf.with_op_name(name, "StringLength") do 
                desc = tf.NodeDescription("StringLength")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
                if unit !== nothing
                    desc["unit"] = Base.String(unit)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function string_length(input_::tf.TensorHandle; name=nothing, unit=nothing)
        desc = tf.EagerOp("StringLength")
        tf.add_input(desc, input_)
        if unit !== nothing
            desc["unit"] = Base.String(unit)
        end
        (tf.execute(desc))[1]
    end
end


"""
     conv3d(input, filter; data_format=NDHWC, dilations=[1, 1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function conv3d(input_, filter_; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "Conv3D") do 
                desc = tf.NodeDescription("Conv3D")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                (input_, filter_) = tf.tf_promote(input_, filter_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function conv3d(input_::tf.TensorHandle, filter_::tf.TensorHandle; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
        desc = tf.EagerOp("Conv3D")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(filter_)
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_adagrad_parameters(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_adagrad_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingAdagradParameters") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingAdagradParameters")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_adagrad_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingAdagradParameters")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     optional_has_value(optional)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function optional_has_value(optional_; name=nothing)
            local desc
            tf.with_op_name(name, "OptionalHasValue") do 
                desc = tf.NodeDescription("OptionalHasValue")
                optional_ = convert(Tensor{Any}, optional_)
                tf.add_input(desc, optional_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function optional_has_value(optional_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("OptionalHasValue")
        tf.add_input(desc, optional_)
        (tf.execute(desc))[1]
    end
end


"""
     apply_adam(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad; use_locking=false, use_nesterov=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_adam(var_, m_, v_, beta1_power_, beta2_power_, lr_, beta1_, beta2_, epsilon_, grad_; name=nothing, use_locking=nothing, use_nesterov=nothing)
            local desc
            tf.with_op_name(name, "ApplyAdam") do 
                desc = tf.NodeDescription("ApplyAdam")
                var_ = convert(Tensor{Any}, var_)
                m_ = convert(Tensor{Any}, m_)
                v_ = convert(Tensor{Any}, v_)
                beta1_power_ = convert(Tensor{Any}, beta1_power_)
                beta2_power_ = convert(Tensor{Any}, beta2_power_)
                lr_ = convert(Tensor{Any}, lr_)
                beta1_ = convert(Tensor{Any}, beta1_)
                beta2_ = convert(Tensor{Any}, beta2_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                (var_, m_, v_, beta1_power_, beta2_power_, lr_, beta1_, beta2_, epsilon_, grad_) = tf.tf_promote(var_, m_, v_, beta1_power_, beta2_power_, lr_, beta1_, beta2_, epsilon_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, m_)
                tf.add_input(desc, v_)
                tf.add_input(desc, beta1_power_)
                tf.add_input(desc, beta2_power_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, beta1_)
                tf.add_input(desc, beta2_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if use_nesterov !== nothing
                    desc["use_nesterov"] = Base.Bool(use_nesterov)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_adam(var_::tf.TensorHandle, m_::tf.TensorHandle, v_::tf.TensorHandle, beta1_power_::tf.TensorHandle, beta2_power_::tf.TensorHandle, lr_::tf.TensorHandle, beta1_::tf.TensorHandle, beta2_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing, use_nesterov=nothing)
        desc = tf.EagerOp("ApplyAdam")
        tf.add_input(desc, var_)
        tf.add_input(desc, m_)
        tf.add_input(desc, v_)
        tf.add_input(desc, beta1_power_)
        tf.add_input(desc, beta2_power_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, beta1_)
        tf.add_input(desc, beta2_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if use_nesterov !== nothing
            desc["use_nesterov"] = Base.Bool(use_nesterov)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(m_)
        desc["T"] = tf.data_type(v_)
        desc["T"] = tf.data_type(beta1_power_)
        desc["T"] = tf.data_type(beta2_power_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(beta1_)
        desc["T"] = tf.data_type(beta2_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     cudnn_rnn_params_to_canonical(num_layers, num_units, input_size, params; rnn_mode=lstm, input_mode=linear_input, direction=unidirectional, dropout=?, seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cudnn_rnn_params_to_canonical(num_layers_, num_units_, input_size_, params_; name=nothing, num_params=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "CudnnRNNParamsToCanonical") do 
                desc = tf.NodeDescription("CudnnRNNParamsToCanonical")
                num_layers_ = convert(Tensor{Int32}, num_layers_)
                num_units_ = convert(Tensor{Int32}, num_units_)
                input_size_ = convert(Tensor{Int32}, input_size_)
                params_ = convert(Tensor{Any}, params_)
                (params_,) = tf.tf_promote(params_)
                tf.add_input(desc, num_layers_)
                tf.add_input(desc, num_units_)
                tf.add_input(desc, input_size_)
                tf.add_input(desc, params_)
                if num_params !== nothing
                    desc["num_params"] = Base.Int(num_params)
                end
                if rnn_mode !== nothing
                    desc["rnn_mode"] = Base.String(rnn_mode)
                end
                if input_mode !== nothing
                    desc["input_mode"] = Base.String(input_mode)
                end
                if direction !== nothing
                    desc["direction"] = Base.String(direction)
                end
                if dropout !== nothing
                    desc["dropout"] = Base.identity(dropout)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function cudnn_rnn_params_to_canonical(num_layers_::tf.TensorHandle, num_units_::tf.TensorHandle, input_size_::tf.TensorHandle, params_::tf.TensorHandle; name=nothing, num_params=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("CudnnRNNParamsToCanonical")
        tf.add_input(desc, num_layers_)
        tf.add_input(desc, num_units_)
        tf.add_input(desc, input_size_)
        tf.add_input(desc, params_)
        if num_params !== nothing
            desc["num_params"] = Base.Int(num_params)
        end
        if rnn_mode !== nothing
            desc["rnn_mode"] = Base.String(rnn_mode)
        end
        if input_mode !== nothing
            desc["input_mode"] = Base.String(input_mode)
        end
        if direction !== nothing
            desc["direction"] = Base.String(direction)
        end
        if dropout !== nothing
            desc["dropout"] = Base.identity(dropout)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        desc["T"] = tf.data_type(params_)
        tf.execute(desc)
    end
end


"""
     irfft3d(input, fft_length)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function irfft3d(input_, fft_length_; name=nothing)
            local desc
            tf.with_op_name(name, "IRFFT3D") do 
                desc = tf.NodeDescription("IRFFT3D")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                fft_length_ = convert(Tensor{Int32}, fft_length_)
                tf.add_input(desc, input_)
                tf.add_input(desc, fft_length_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function irfft3d(input_::tf.TensorHandle, fft_length_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IRFFT3D")
        tf.add_input(desc, input_)
        tf.add_input(desc, fft_length_)
        (tf.execute(desc))[1]
    end
end


"""
     angle(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function angle(input_; name=nothing)
            local desc
            tf.with_op_name(name, "Angle") do 
                desc = tf.NodeDescription("Angle")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function angle(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Angle")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_forest_tree_resource_handle_op(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_forest_tree_resource_handle_op(; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "TensorForestTreeResourceHandleOp") do 
                desc = tf.NodeDescription("TensorForestTreeResourceHandleOp")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_forest_tree_resource_handle_op(; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("TensorForestTreeResourceHandleOp")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     learned_unigram_candidate_sampler(true_classes; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function learned_unigram_candidate_sampler(true_classes_; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, range_max=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "LearnedUnigramCandidateSampler") do 
                desc = tf.NodeDescription("LearnedUnigramCandidateSampler")
                true_classes_ = convert(Tensor{Int64}, true_classes_)
                tf.add_input(desc, true_classes_)
                if num_true !== nothing
                    desc["num_true"] = Base.Int(num_true)
                end
                if num_sampled !== nothing
                    desc["num_sampled"] = Base.Int(num_sampled)
                end
                if unique !== nothing
                    desc["unique"] = Base.Bool(unique)
                end
                if range_max !== nothing
                    desc["range_max"] = Base.Int(range_max)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function learned_unigram_candidate_sampler(true_classes_::tf.TensorHandle; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, range_max=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("LearnedUnigramCandidateSampler")
        tf.add_input(desc, true_classes_)
        if num_true !== nothing
            desc["num_true"] = Base.Int(num_true)
        end
        if num_sampled !== nothing
            desc["num_sampled"] = Base.Int(num_sampled)
        end
        if unique !== nothing
            desc["unique"] = Base.Bool(unique)
        end
        if range_max !== nothing
            desc["range_max"] = Base.Int(range_max)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        tf.execute(desc)
    end
end


"""
     _arg()

A graph node which represents an argument to a function.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _arg(; name=nothing, index=nothing)
            local desc
            tf.with_op_name(name, "_Arg") do 
                desc = tf.NodeDescription("_Arg")
                if index !== nothing
                    desc["index"] = Base.Int(index)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _arg(; name=nothing, index=nothing)
        desc = tf.EagerOp("_Arg")
        if index !== nothing
            desc["index"] = Base.Int(index)
        end
        (tf.execute(desc))[1]
    end
end


"""
     matrix_square_root(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_square_root(input_; name=nothing)
            local desc
            tf.with_op_name(name, "MatrixSquareRoot") do 
                desc = tf.NodeDescription("MatrixSquareRoot")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_square_root(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MatrixSquareRoot")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_dense_cwise_mul(sp_indices, sp_values, sp_shape, dense)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_dense_cwise_mul(sp_indices_, sp_values_, sp_shape_, dense_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseDenseCwiseMul") do 
                desc = tf.NodeDescription("SparseDenseCwiseMul")
                sp_indices_ = convert(Tensor{Int64}, sp_indices_)
                sp_values_ = convert(Tensor{Any}, sp_values_)
                sp_shape_ = convert(Tensor{Int64}, sp_shape_)
                dense_ = convert(Tensor{Any}, dense_)
                (sp_values_, dense_) = tf.tf_promote(sp_values_, dense_)
                tf.add_input(desc, sp_indices_)
                tf.add_input(desc, sp_values_)
                tf.add_input(desc, sp_shape_)
                tf.add_input(desc, dense_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_dense_cwise_mul(sp_indices_::tf.TensorHandle, sp_values_::tf.TensorHandle, sp_shape_::tf.TensorHandle, dense_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseDenseCwiseMul")
        tf.add_input(desc, sp_indices_)
        tf.add_input(desc, sp_values_)
        tf.add_input(desc, sp_shape_)
        tf.add_input(desc, dense_)
        desc["T"] = tf.data_type(sp_values_)
        desc["T"] = tf.data_type(dense_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_concat_v3(handle, flow_in; element_shape_except0=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_concat_v3(handle_, flow_in_; name=nothing, dtype=nothing, element_shape_except0=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayConcatV3") do 
                desc = tf.NodeDescription("TensorArrayConcatV3")
                handle_ = convert(Tensor{Any}, handle_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, flow_in_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if element_shape_except0 !== nothing
                    desc["element_shape_except0"] = Base.identity(element_shape_except0)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function tensor_array_concat_v3(handle_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, dtype=nothing, element_shape_except0=nothing)
        desc = tf.EagerOp("TensorArrayConcatV3")
        tf.add_input(desc, handle_)
        tf.add_input(desc, flow_in_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if element_shape_except0 !== nothing
            desc["element_shape_except0"] = Base.identity(element_shape_except0)
        end
        tf.execute(desc)
    end
end


"""
     unicode_script(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unicode_script(input_; name=nothing)
            local desc
            tf.with_op_name(name, "UnicodeScript") do 
                desc = tf.NodeDescription("UnicodeScript")
                input_ = convert(Tensor{Int32}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unicode_script(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("UnicodeScript")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_cholesky_grad(l, grad)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_cholesky_grad(l_, grad_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchCholeskyGrad") do 
                desc = tf.NodeDescription("BatchCholeskyGrad")
                l_ = convert(Tensor{Any}, l_)
                grad_ = convert(Tensor{Any}, grad_)
                (l_, grad_) = tf.tf_promote(l_, grad_)
                tf.add_input(desc, l_)
                tf.add_input(desc, grad_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_cholesky_grad(l_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchCholeskyGrad")
        tf.add_input(desc, l_)
        tf.add_input(desc, grad_)
        desc["T"] = tf.data_type(l_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     mean(input, reduction_indices; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mean(input_, reduction_indices_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "Mean") do 
                desc = tf.NodeDescription("Mean")
                input_ = convert(Tensor{Any}, input_)
                reduction_indices_ = convert(Tensor{Int32}, reduction_indices_)
                reduction_indices_ = reduction_indices_ - convert(tf.Tensor{eltype(reduction_indices_)}, 1)
                (input_,) = tf.tf_promote(input_)
                (reduction_indices_,) = tf.tf_promote(reduction_indices_)
                tf.add_input(desc, input_)
                tf.add_input(desc, reduction_indices_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mean(input_::tf.TensorHandle, reduction_indices_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("Mean")
        tf.add_input(desc, input_)
        tf.add_input(desc, reduction_indices_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tidx"] = tf.data_type(reduction_indices_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_fft(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_fft(input_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchFFT") do 
                desc = tf.NodeDescription("BatchFFT")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_fft(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchFFT")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     sin(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sin(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Sin") do 
                desc = tf.NodeDescription("Sin")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sin(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Sin")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_ensemble_resource_handle_op(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_ensemble_resource_handle_op(; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesEnsembleResourceHandleOp") do 
                desc = tf.NodeDescription("BoostedTreesEnsembleResourceHandleOp")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_ensemble_resource_handle_op(; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("BoostedTreesEnsembleResourceHandleOp")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     quantized_max_pool(input, min_input, max_input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_max_pool(input_, min_input_, max_input_; name=nothing, ksize=nothing, strides=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "QuantizedMaxPool") do 
                desc = tf.NodeDescription("QuantizedMaxPool")
                input_ = convert(Tensor{Any}, input_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_max_pool(input_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing)
        desc = tf.EagerOp("QuantizedMaxPool")
        tf.add_input(desc, input_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     ordered_map_stage(key, indices, values; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ordered_map_stage(key_, indices_, values_; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, fake_dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "OrderedMapStage") do 
                desc = tf.NodeDescription("OrderedMapStage")
                key_ = convert(Tensor{Int64}, key_)
                indices_ = convert(Tensor{Int32}, indices_)
                values_ = [convert(Tensor{Any}, x) for x = values_]
                tf.add_input(desc, key_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, values_)
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if fake_dtypes !== nothing
                    desc["fake_dtypes"] = map(Base.identity, fake_dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ordered_map_stage(key_::tf.TensorHandle, indices_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, fake_dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("OrderedMapStage")
        tf.add_input(desc, key_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, values_)
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if fake_dtypes !== nothing
            desc["fake_dtypes"] = map(Base.identity, fake_dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     partitioned_call(args; config=, config_proto=, executor_type=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function partitioned_call(args_; name=nothing, Tin=nothing, Tout=nothing, f=nothing, config=nothing, config_proto=nothing, executor_type=nothing)
            local desc
            tf.with_op_name(name, "PartitionedCall") do 
                desc = tf.NodeDescription("PartitionedCall")
                args_ = [convert(Tensor{Any}, x) for x = args_]
                tf.add_input(desc, args_)
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if config !== nothing
                    desc["config"] = Base.String(config)
                end
                if config_proto !== nothing
                    desc["config_proto"] = Base.String(config_proto)
                end
                if executor_type !== nothing
                    desc["executor_type"] = Base.String(executor_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function partitioned_call(args_::tf.TensorHandle; name=nothing, Tin=nothing, Tout=nothing, f=nothing, config=nothing, config_proto=nothing, executor_type=nothing)
        desc = tf.EagerOp("PartitionedCall")
        tf.add_input(desc, args_)
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if config !== nothing
            desc["config"] = Base.String(config)
        end
        if config_proto !== nothing
            desc["config_proto"] = Base.String(config_proto)
        end
        if executor_type !== nothing
            desc["executor_type"] = Base.String(executor_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_apply_adagrad(var, accum, lr, grad, indices; use_locking=false, update_slots=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_apply_adagrad(var_, accum_, lr_, grad_, indices_; name=nothing, use_locking=nothing, update_slots=nothing)
            local desc
            tf.with_op_name(name, "SparseApplyAdagrad") do 
                desc = tf.NodeDescription("SparseApplyAdagrad")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (var_, accum_, lr_, grad_) = tf.tf_promote(var_, accum_, lr_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if update_slots !== nothing
                    desc["update_slots"] = Base.Bool(update_slots)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_apply_adagrad(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing, update_slots=nothing)
        desc = tf.EagerOp("SparseApplyAdagrad")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if update_slots !== nothing
            desc["update_slots"] = Base.Bool(update_slots)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     decode_proto_v2(bytes; descriptor_source=local://, message_format=binary, sanitize=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_proto_v2(bytes_; name=nothing, message_type=nothing, field_names=nothing, output_types=nothing, descriptor_source=nothing, message_format=nothing, sanitize=nothing)
            local desc
            tf.with_op_name(name, "DecodeProtoV2") do 
                desc = tf.NodeDescription("DecodeProtoV2")
                bytes_ = convert(Tensor{String}, bytes_)
                tf.add_input(desc, bytes_)
                if message_type !== nothing
                    desc["message_type"] = Base.String(message_type)
                end
                if field_names !== nothing
                    desc["field_names"] = map(Base.identity, field_names)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if descriptor_source !== nothing
                    desc["descriptor_source"] = Base.String(descriptor_source)
                end
                if message_format !== nothing
                    desc["message_format"] = Base.String(message_format)
                end
                if sanitize !== nothing
                    desc["sanitize"] = Base.Bool(sanitize)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function decode_proto_v2(bytes_::tf.TensorHandle; name=nothing, message_type=nothing, field_names=nothing, output_types=nothing, descriptor_source=nothing, message_format=nothing, sanitize=nothing)
        desc = tf.EagerOp("DecodeProtoV2")
        tf.add_input(desc, bytes_)
        if message_type !== nothing
            desc["message_type"] = Base.String(message_type)
        end
        if field_names !== nothing
            desc["field_names"] = map(Base.identity, field_names)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if descriptor_source !== nothing
            desc["descriptor_source"] = Base.String(descriptor_source)
        end
        if message_format !== nothing
            desc["message_format"] = Base.String(message_format)
        end
        if sanitize !== nothing
            desc["sanitize"] = Base.Bool(sanitize)
        end
        tf.execute(desc)
    end
end


"""
     betainc(a, b, x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function betainc(a_, b_, x_; name=nothing)
            local desc
            tf.with_op_name(name, "Betainc") do 
                desc = tf.NodeDescription("Betainc")
                a_ = convert(Tensor{Any}, a_)
                b_ = convert(Tensor{Any}, b_)
                x_ = convert(Tensor{Any}, x_)
                (a_, b_, x_) = tf.tf_promote(a_, b_, x_)
                tf.add_input(desc, a_)
                tf.add_input(desc, b_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function betainc(a_::tf.TensorHandle, b_::tf.TensorHandle, x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Betainc")
        tf.add_input(desc, a_)
        tf.add_input(desc, b_)
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(a_)
        desc["T"] = tf.data_type(b_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     guarantee_const(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function guarantee_const(input_; name=nothing)
            local desc
            tf.with_op_name(name, "GuaranteeConst") do 
                desc = tf.NodeDescription("GuaranteeConst")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function guarantee_const(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("GuaranteeConst")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     decode_bmp(contents; channels=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_bmp(contents_; name=nothing, channels=nothing)
            local desc
            tf.with_op_name(name, "DecodeBmp") do 
                desc = tf.NodeDescription("DecodeBmp")
                contents_ = convert(Tensor{String}, contents_)
                tf.add_input(desc, contents_)
                if channels !== nothing
                    desc["channels"] = Base.Int(channels)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function decode_bmp(contents_::tf.TensorHandle; name=nothing, channels=nothing)
        desc = tf.EagerOp("DecodeBmp")
        tf.add_input(desc, contents_)
        if channels !== nothing
            desc["channels"] = Base.Int(channels)
        end
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_bucketize(float_values, bucket_boundaries)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_bucketize(float_values_, bucket_boundaries_; name=nothing, num_features=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesBucketize") do 
                desc = tf.NodeDescription("BoostedTreesBucketize")
                float_values_ = [convert(Tensor{Float32}, x) for x = float_values_]
                bucket_boundaries_ = [convert(Tensor{Float32}, x) for x = bucket_boundaries_]
                tf.add_input(desc, float_values_)
                tf.add_input(desc, bucket_boundaries_)
                if num_features !== nothing
                    desc["num_features"] = Base.Int(num_features)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:num_features
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function boosted_trees_bucketize(float_values_::tf.TensorHandle, bucket_boundaries_::tf.TensorHandle; name=nothing, num_features=nothing)
        desc = tf.EagerOp("BoostedTreesBucketize")
        tf.add_input(desc, float_values_)
        tf.add_input(desc, bucket_boundaries_)
        if num_features !== nothing
            desc["num_features"] = Base.Int(num_features)
        end
        tf.execute(desc)
    end
end


"""
     shutdown_distributed_tpu()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function shutdown_distributed_tpu(; name=nothing)
            local desc
            tf.with_op_name(name, "ShutdownDistributedTPU") do 
                desc
                tf.NodeDescription("ShutdownDistributedTPU")
            end
            tf.Tensor(tf.Operation(desc))
        end
    function shutdown_distributed_tpu(; name=nothing)
        desc = tf.EagerOp("ShutdownDistributedTPU")
        (tf.execute(desc))[1]
    end
end


"""
     experimental_stats_aggregator_summary(iterator)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_stats_aggregator_summary(iterator_; name=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalStatsAggregatorSummary") do 
                desc = tf.NodeDescription("ExperimentalStatsAggregatorSummary")
                iterator_ = convert(Tensor{Any}, iterator_)
                tf.add_input(desc, iterator_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_stats_aggregator_summary(iterator_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ExperimentalStatsAggregatorSummary")
        tf.add_input(desc, iterator_)
        (tf.execute(desc))[1]
    end
end


"""
     timestamp()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function timestamp(; name=nothing)
            local desc
            tf.with_op_name(name, "Timestamp") do 
                desc
                tf.NodeDescription("Timestamp")
            end
            tf.Tensor(tf.Operation(desc))
        end
    function timestamp(; name=nothing)
        desc = tf.EagerOp("Timestamp")
        (tf.execute(desc))[1]
    end
end


"""
     matrix_exponential(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_exponential(input_; name=nothing)
            local desc
            tf.with_op_name(name, "MatrixExponential") do 
                desc = tf.NodeDescription("MatrixExponential")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_exponential(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MatrixExponential")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     size(input; out_type=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function size(input_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "Size") do 
                desc = tf.NodeDescription("Size")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function size(input_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("Size")
        tf.add_input(desc, input_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     add_n(inputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function add_n(inputs_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "AddN") do 
                desc = tf.NodeDescription("AddN")
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                (inputs_,) = tf.tf_promote(inputs_)
                tf.add_input(desc, inputs_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function add_n(inputs_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("AddN")
        tf.add_input(desc, inputs_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(inputs_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_segment_sum(data, indices, segment_ids)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_segment_sum(data_, indices_, segment_ids_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSegmentSum") do 
                desc = tf.NodeDescription("SparseSegmentSum")
                data_ = convert(Tensor{Any}, data_)
                indices_ = convert(Tensor{Int32}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                segment_ids_ = convert(Tensor{Int32}, segment_ids_)
                (data_,) = tf.tf_promote(data_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, data_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, segment_ids_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_segment_sum(data_::tf.TensorHandle, indices_::tf.TensorHandle, segment_ids_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSegmentSum")
        tf.add_input(desc, data_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, segment_ids_)
        desc["T"] = tf.data_type(data_)
        desc["Tidx"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_dataset(input_dataset, batch_size)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_dataset(input_dataset_, batch_size_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "BatchDataset") do 
                desc = tf.NodeDescription("BatchDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                batch_size_ = convert(Tensor{Int64}, batch_size_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, batch_size_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_dataset(input_dataset_::tf.TensorHandle, batch_size_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("BatchDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, batch_size_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     record_input(; file_random_seed=301, file_shuffle_shift_ratio=?, file_buffer_size=10000, file_parallelism=16, batch_size=32, compression_type=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function record_input(; name=nothing, file_pattern=nothing, file_random_seed=nothing, file_shuffle_shift_ratio=nothing, file_buffer_size=nothing, file_parallelism=nothing, batch_size=nothing, compression_type=nothing)
            local desc
            tf.with_op_name(name, "RecordInput") do 
                desc = tf.NodeDescription("RecordInput")
                if file_pattern !== nothing
                    desc["file_pattern"] = Base.String(file_pattern)
                end
                if file_random_seed !== nothing
                    desc["file_random_seed"] = Base.Int(file_random_seed)
                end
                if file_shuffle_shift_ratio !== nothing
                    desc["file_shuffle_shift_ratio"] = Base.identity(file_shuffle_shift_ratio)
                end
                if file_buffer_size !== nothing
                    desc["file_buffer_size"] = Base.Int(file_buffer_size)
                end
                if file_parallelism !== nothing
                    desc["file_parallelism"] = Base.Int(file_parallelism)
                end
                if batch_size !== nothing
                    desc["batch_size"] = Base.Int(batch_size)
                end
                if compression_type !== nothing
                    desc["compression_type"] = Base.String(compression_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function record_input(; name=nothing, file_pattern=nothing, file_random_seed=nothing, file_shuffle_shift_ratio=nothing, file_buffer_size=nothing, file_parallelism=nothing, batch_size=nothing, compression_type=nothing)
        desc = tf.EagerOp("RecordInput")
        if file_pattern !== nothing
            desc["file_pattern"] = Base.String(file_pattern)
        end
        if file_random_seed !== nothing
            desc["file_random_seed"] = Base.Int(file_random_seed)
        end
        if file_shuffle_shift_ratio !== nothing
            desc["file_shuffle_shift_ratio"] = Base.identity(file_shuffle_shift_ratio)
        end
        if file_buffer_size !== nothing
            desc["file_buffer_size"] = Base.Int(file_buffer_size)
        end
        if file_parallelism !== nothing
            desc["file_parallelism"] = Base.Int(file_parallelism)
        end
        if batch_size !== nothing
            desc["batch_size"] = Base.Int(batch_size)
        end
        if compression_type !== nothing
            desc["compression_type"] = Base.String(compression_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     queue_dequeue_up_to_v2(handle, n; timeout_ms=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_dequeue_up_to_v2(handle_, n_; name=nothing, component_types=nothing, timeout_ms=nothing)
            local desc
            tf.with_op_name(name, "QueueDequeueUpToV2") do 
                desc = tf.NodeDescription("QueueDequeueUpToV2")
                handle_ = convert(Tensor{Any}, handle_)
                n_ = convert(Tensor{Int32}, n_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, n_)
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if timeout_ms !== nothing
                    desc["timeout_ms"] = Base.Int(timeout_ms)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_dequeue_up_to_v2(handle_::tf.TensorHandle, n_::tf.TensorHandle; name=nothing, component_types=nothing, timeout_ms=nothing)
        desc = tf.EagerOp("QueueDequeueUpToV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, n_)
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if timeout_ms !== nothing
            desc["timeout_ms"] = Base.Int(timeout_ms)
        end
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingProximalAdagradParametersGradAccumDebug") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingProximalAdagradParametersGradAccumDebug")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingProximalAdagradParametersGradAccumDebug")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     load_tpu_embedding_rms_prop_parameters_grad_accum_debug(parameters, ms, mom, gradient_accumulators; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_rms_prop_parameters_grad_accum_debug(parameters_, ms_, mom_, gradient_accumulators_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingRMSPropParametersGradAccumDebug") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingRMSPropParametersGradAccumDebug")
                parameters_ = convert(Tensor{Float32}, parameters_)
                ms_ = convert(Tensor{Float32}, ms_)
                mom_ = convert(Tensor{Float32}, mom_)
                gradient_accumulators_ = convert(Tensor{Float32}, gradient_accumulators_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, ms_)
                tf.add_input(desc, mom_)
                tf.add_input(desc, gradient_accumulators_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_rms_prop_parameters_grad_accum_debug(parameters_::tf.TensorHandle, ms_::tf.TensorHandle, mom_::tf.TensorHandle, gradient_accumulators_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingRMSPropParametersGradAccumDebug")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, ms_)
        tf.add_input(desc, mom_)
        tf.add_input(desc, gradient_accumulators_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     serialize_tensor(tensor)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function serialize_tensor(tensor_; name=nothing)
            local desc
            tf.with_op_name(name, "SerializeTensor") do 
                desc = tf.NodeDescription("SerializeTensor")
                tensor_ = convert(Tensor{Any}, tensor_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, tensor_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function serialize_tensor(tensor_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SerializeTensor")
        tf.add_input(desc, tensor_)
        desc["T"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     mul(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mul(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Mul") do 
                desc = tf.NodeDescription("Mul")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mul(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Mul")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     softmax_cross_entropy_with_logits(features, labels)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function softmax_cross_entropy_with_logits(features_, labels_; name=nothing)
            local desc
            tf.with_op_name(name, "SoftmaxCrossEntropyWithLogits") do 
                desc = tf.NodeDescription("SoftmaxCrossEntropyWithLogits")
                features_ = convert(Tensor{Any}, features_)
                labels_ = convert(Tensor{Any}, labels_)
                (features_, labels_) = tf.tf_promote(features_, labels_)
                tf.add_input(desc, features_)
                tf.add_input(desc, labels_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function softmax_cross_entropy_with_logits(features_::tf.TensorHandle, labels_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SoftmaxCrossEntropyWithLogits")
        tf.add_input(desc, features_)
        tf.add_input(desc, labels_)
        desc["T"] = tf.data_type(features_)
        desc["T"] = tf.data_type(labels_)
        tf.execute(desc)
    end
end


"""
     resource_scatter_div(resource, indices, updates)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_scatter_div(resource_, indices_, updates_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "ResourceScatterDiv") do 
                desc = tf.NodeDescription("ResourceScatterDiv")
                resource_ = convert(Tensor{Any}, resource_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (updates_,) = tf.tf_promote(updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_scatter_div(resource_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("ResourceScatterDiv")
        tf.add_input(desc, resource_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["Tindices"] = tf.data_type(indices_)
        desc["dtype"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     fixed_length_record_dataset_v2(filenames, header_bytes, record_bytes, footer_bytes, buffer_size, compression_type)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fixed_length_record_dataset_v2(filenames_, header_bytes_, record_bytes_, footer_bytes_, buffer_size_, compression_type_; name=nothing)
            local desc
            tf.with_op_name(name, "FixedLengthRecordDatasetV2") do 
                desc = tf.NodeDescription("FixedLengthRecordDatasetV2")
                filenames_ = convert(Tensor{String}, filenames_)
                header_bytes_ = convert(Tensor{Int64}, header_bytes_)
                record_bytes_ = convert(Tensor{Int64}, record_bytes_)
                footer_bytes_ = convert(Tensor{Int64}, footer_bytes_)
                buffer_size_ = convert(Tensor{Int64}, buffer_size_)
                compression_type_ = convert(Tensor{String}, compression_type_)
                tf.add_input(desc, filenames_)
                tf.add_input(desc, header_bytes_)
                tf.add_input(desc, record_bytes_)
                tf.add_input(desc, footer_bytes_)
                tf.add_input(desc, buffer_size_)
                tf.add_input(desc, compression_type_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fixed_length_record_dataset_v2(filenames_::tf.TensorHandle, header_bytes_::tf.TensorHandle, record_bytes_::tf.TensorHandle, footer_bytes_::tf.TensorHandle, buffer_size_::tf.TensorHandle, compression_type_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("FixedLengthRecordDatasetV2")
        tf.add_input(desc, filenames_)
        tf.add_input(desc, header_bytes_)
        tf.add_input(desc, record_bytes_)
        tf.add_input(desc, footer_bytes_)
        tf.add_input(desc, buffer_size_)
        tf.add_input(desc, compression_type_)
        (tf.execute(desc))[1]
    end
end


"""
     skip_dataset(input_dataset, count)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function skip_dataset(input_dataset_, count_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "SkipDataset") do 
                desc = tf.NodeDescription("SkipDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                count_ = convert(Tensor{Int64}, count_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, count_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function skip_dataset(input_dataset_::tf.TensorHandle, count_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("SkipDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, count_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     cosh(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cosh(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Cosh") do 
                desc = tf.NodeDescription("Cosh")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cosh(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Cosh")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     fused_batch_norm_v2(x, scale, offset, mean, variance; epsilon=?, data_format=NHWC, is_training=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fused_batch_norm_v2(x_, scale_, offset_, mean_, variance_; name=nothing, U=nothing, epsilon=nothing, data_format=nothing, is_training=nothing)
            local desc
            tf.with_op_name(name, "FusedBatchNormV2") do 
                desc = tf.NodeDescription("FusedBatchNormV2")
                x_ = convert(Tensor{Any}, x_)
                scale_ = convert(Tensor{Any}, scale_)
                offset_ = convert(Tensor{Any}, offset_)
                mean_ = convert(Tensor{Any}, mean_)
                variance_ = convert(Tensor{Any}, variance_)
                (scale_, offset_, mean_, variance_) = tf.tf_promote(scale_, offset_, mean_, variance_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
                tf.add_input(desc, scale_)
                tf.add_input(desc, offset_)
                tf.add_input(desc, mean_)
                tf.add_input(desc, variance_)
                if U !== nothing
                    desc["U"] = Base.identity(U)
                end
                if epsilon !== nothing
                    desc["epsilon"] = Base.identity(epsilon)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if is_training !== nothing
                    desc["is_training"] = Base.Bool(is_training)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:5
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function fused_batch_norm_v2(x_::tf.TensorHandle, scale_::tf.TensorHandle, offset_::tf.TensorHandle, mean_::tf.TensorHandle, variance_::tf.TensorHandle; name=nothing, U=nothing, epsilon=nothing, data_format=nothing, is_training=nothing)
        desc = tf.EagerOp("FusedBatchNormV2")
        tf.add_input(desc, x_)
        tf.add_input(desc, scale_)
        tf.add_input(desc, offset_)
        tf.add_input(desc, mean_)
        tf.add_input(desc, variance_)
        if U !== nothing
            desc["U"] = Base.identity(U)
        end
        if epsilon !== nothing
            desc["epsilon"] = Base.identity(epsilon)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if is_training !== nothing
            desc["is_training"] = Base.Bool(is_training)
        end
        desc["T"] = tf.data_type(x_)
        desc["U"] = tf.data_type(scale_)
        desc["U"] = tf.data_type(offset_)
        desc["U"] = tf.data_type(mean_)
        desc["U"] = tf.data_type(variance_)
        tf.execute(desc)
    end
end


"""
     tensor_array_split(handle, value, lengths, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_split(handle_, value_, lengths_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArraySplit") do 
                desc = tf.NodeDescription("TensorArraySplit")
                handle_ = convert(Tensor{String}, handle_)
                value_ = convert(Tensor{Any}, value_)
                lengths_ = convert(Tensor{Int64}, lengths_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, value_)
                tf.add_input(desc, lengths_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_split(handle_::tf.TensorHandle, value_::tf.TensorHandle, lengths_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArraySplit")
        tf.add_input(desc, handle_)
        tf.add_input(desc, value_)
        tf.add_input(desc, lengths_)
        tf.add_input(desc, flow_in_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     ctc_loss(inputs, labels_indices, labels_values, sequence_length; preprocess_collapse_repeated=false, ctc_merge_repeated=true, ignore_longer_outputs_than_inputs=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ctc_loss(inputs_, labels_indices_, labels_values_, sequence_length_; name=nothing, preprocess_collapse_repeated=nothing, ctc_merge_repeated=nothing, ignore_longer_outputs_than_inputs=nothing)
            local desc
            tf.with_op_name(name, "CTCLoss") do 
                desc = tf.NodeDescription("CTCLoss")
                inputs_ = convert(Tensor{Float32}, inputs_)
                labels_indices_ = convert(Tensor{Int64}, labels_indices_)
                labels_values_ = convert(Tensor{Int32}, labels_values_)
                sequence_length_ = convert(Tensor{Int32}, sequence_length_)
                tf.add_input(desc, inputs_)
                tf.add_input(desc, labels_indices_)
                tf.add_input(desc, labels_values_)
                tf.add_input(desc, sequence_length_)
                if preprocess_collapse_repeated !== nothing
                    desc["preprocess_collapse_repeated"] = Base.Bool(preprocess_collapse_repeated)
                end
                if ctc_merge_repeated !== nothing
                    desc["ctc_merge_repeated"] = Base.Bool(ctc_merge_repeated)
                end
                if ignore_longer_outputs_than_inputs !== nothing
                    desc["ignore_longer_outputs_than_inputs"] = Base.Bool(ignore_longer_outputs_than_inputs)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function ctc_loss(inputs_::tf.TensorHandle, labels_indices_::tf.TensorHandle, labels_values_::tf.TensorHandle, sequence_length_::tf.TensorHandle; name=nothing, preprocess_collapse_repeated=nothing, ctc_merge_repeated=nothing, ignore_longer_outputs_than_inputs=nothing)
        desc = tf.EagerOp("CTCLoss")
        tf.add_input(desc, inputs_)
        tf.add_input(desc, labels_indices_)
        tf.add_input(desc, labels_values_)
        tf.add_input(desc, sequence_length_)
        if preprocess_collapse_repeated !== nothing
            desc["preprocess_collapse_repeated"] = Base.Bool(preprocess_collapse_repeated)
        end
        if ctc_merge_repeated !== nothing
            desc["ctc_merge_repeated"] = Base.Bool(ctc_merge_repeated)
        end
        if ignore_longer_outputs_than_inputs !== nothing
            desc["ignore_longer_outputs_than_inputs"] = Base.Bool(ignore_longer_outputs_than_inputs)
        end
        tf.execute(desc)
    end
end


"""
     quantized_reshape(tensor, shape, input_min, input_max)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_reshape(tensor_, shape_, input_min_, input_max_; name=nothing)
            local desc
            tf.with_op_name(name, "QuantizedReshape") do 
                desc = tf.NodeDescription("QuantizedReshape")
                tensor_ = convert(Tensor{Any}, tensor_)
                shape_ = convert(Tensor{Int32}, shape_)
                input_min_ = convert(Tensor{Float32}, input_min_)
                input_max_ = convert(Tensor{Float32}, input_max_)
                (tensor_,) = tf.tf_promote(tensor_)
                (shape_,) = tf.tf_promote(shape_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, input_min_)
                tf.add_input(desc, input_max_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_reshape(tensor_::tf.TensorHandle, shape_::tf.TensorHandle, input_min_::tf.TensorHandle, input_max_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("QuantizedReshape")
        tf.add_input(desc, tensor_)
        tf.add_input(desc, shape_)
        tf.add_input(desc, input_min_)
        tf.add_input(desc, input_max_)
        desc["T"] = tf.data_type(tensor_)
        desc["Tshape"] = tf.data_type(shape_)
        tf.execute(desc)
    end
end


"""
     floor_div(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function floor_div(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "FloorDiv") do 
                desc = tf.NodeDescription("FloorDiv")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function floor_div(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("FloorDiv")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_v2(size; element_shape=?, dynamic_size=false, clear_after_read=true, tensor_array_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_v2(size_; name=nothing, dtype=nothing, element_shape=nothing, dynamic_size=nothing, clear_after_read=nothing, tensor_array_name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayV2") do 
                desc = tf.NodeDescription("TensorArrayV2")
                size_ = convert(Tensor{Int32}, size_)
                tf.add_input(desc, size_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if element_shape !== nothing
                    desc["element_shape"] = Base.identity(element_shape)
                end
                if dynamic_size !== nothing
                    desc["dynamic_size"] = Base.Bool(dynamic_size)
                end
                if clear_after_read !== nothing
                    desc["clear_after_read"] = Base.Bool(clear_after_read)
                end
                if tensor_array_name !== nothing
                    desc["tensor_array_name"] = Base.String(tensor_array_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_v2(size_::tf.TensorHandle; name=nothing, dtype=nothing, element_shape=nothing, dynamic_size=nothing, clear_after_read=nothing, tensor_array_name=nothing)
        desc = tf.EagerOp("TensorArrayV2")
        tf.add_input(desc, size_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if element_shape !== nothing
            desc["element_shape"] = Base.identity(element_shape)
        end
        if dynamic_size !== nothing
            desc["dynamic_size"] = Base.Bool(dynamic_size)
        end
        if clear_after_read !== nothing
            desc["clear_after_read"] = Base.Bool(clear_after_read)
        end
        if tensor_array_name !== nothing
            desc["tensor_array_name"] = Base.String(tensor_array_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     barrier_close(handle; cancel_pending_enqueues=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function barrier_close(handle_; name=nothing, cancel_pending_enqueues=nothing)
            local desc
            tf.with_op_name(name, "BarrierClose") do 
                desc = tf.NodeDescription("BarrierClose")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
                if cancel_pending_enqueues !== nothing
                    desc["cancel_pending_enqueues"] = Base.Bool(cancel_pending_enqueues)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function barrier_close(handle_::tf.TensorHandle; name=nothing, cancel_pending_enqueues=nothing)
        desc = tf.EagerOp("BarrierClose")
        tf.add_input(desc, handle_)
        if cancel_pending_enqueues !== nothing
            desc["cancel_pending_enqueues"] = Base.Bool(cancel_pending_enqueues)
        end
        (tf.execute(desc))[1]
    end
end


"""
     read_variable_op(resource)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function read_variable_op(resource_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "ReadVariableOp") do 
                desc = tf.NodeDescription("ReadVariableOp")
                resource_ = convert(Tensor{Any}, resource_)
                tf.add_input(desc, resource_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function read_variable_op(resource_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("ReadVariableOp")
        tf.add_input(desc, resource_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     quantized_mul(x, y, min_x, max_x, min_y, max_y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_mul(x_, y_, min_x_, max_x_, min_y_, max_y_; name=nothing)
            local desc
            tf.with_op_name(name, "QuantizedMul") do 
                desc = tf.NodeDescription("QuantizedMul")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                min_x_ = convert(Tensor{Float32}, min_x_)
                max_x_ = convert(Tensor{Float32}, max_x_)
                min_y_ = convert(Tensor{Float32}, min_y_)
                max_y_ = convert(Tensor{Float32}, max_y_)
                (x_,) = tf.tf_promote(x_)
                (y_,) = tf.tf_promote(y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
                tf.add_input(desc, min_x_)
                tf.add_input(desc, max_x_)
                tf.add_input(desc, min_y_)
                tf.add_input(desc, max_y_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_mul(x_::tf.TensorHandle, y_::tf.TensorHandle, min_x_::tf.TensorHandle, max_x_::tf.TensorHandle, min_y_::tf.TensorHandle, max_y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("QuantizedMul")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        tf.add_input(desc, min_x_)
        tf.add_input(desc, max_x_)
        tf.add_input(desc, min_y_)
        tf.add_input(desc, max_y_)
        desc["T1"] = tf.data_type(x_)
        desc["T2"] = tf.data_type(y_)
        tf.execute(desc)
    end
end


"""
     selu(features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function selu(features_; name=nothing)
            local desc
            tf.with_op_name(name, "Selu") do 
                desc = tf.NodeDescription("Selu")
                features_ = convert(Tensor{Any}, features_)
                (features_,) = tf.tf_promote(features_)
                tf.add_input(desc, features_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function selu(features_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Selu")
        tf.add_input(desc, features_)
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     cudnn_rnn_backprop_v3(input, input_h, input_c, params, sequence_lengths, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space, host_reserved; rnn_mode=lstm, input_mode=linear_input, direction=unidirectional, dropout=?, seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cudnn_rnn_backprop_v3(input_, input_h_, input_c_, params_, sequence_lengths_, output_, output_h_, output_c_, output_backprop_, output_h_backprop_, output_c_backprop_, reserve_space_, host_reserved_; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "CudnnRNNBackpropV3") do 
                desc = tf.NodeDescription("CudnnRNNBackpropV3")
                input_ = convert(Tensor{Any}, input_)
                input_h_ = convert(Tensor{Any}, input_h_)
                input_c_ = convert(Tensor{Any}, input_c_)
                params_ = convert(Tensor{Any}, params_)
                sequence_lengths_ = convert(Tensor{Int32}, sequence_lengths_)
                output_ = convert(Tensor{Any}, output_)
                output_h_ = convert(Tensor{Any}, output_h_)
                output_c_ = convert(Tensor{Any}, output_c_)
                output_backprop_ = convert(Tensor{Any}, output_backprop_)
                output_h_backprop_ = convert(Tensor{Any}, output_h_backprop_)
                output_c_backprop_ = convert(Tensor{Any}, output_c_backprop_)
                reserve_space_ = convert(Tensor{Any}, reserve_space_)
                host_reserved_ = convert(Tensor{Any}, host_reserved_)
                (input_, input_h_, input_c_, params_, output_, output_h_, output_c_, output_backprop_, output_h_backprop_, output_c_backprop_, reserve_space_) = tf.tf_promote(input_, input_h_, input_c_, params_, output_, output_h_, output_c_, output_backprop_, output_h_backprop_, output_c_backprop_, reserve_space_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_h_)
                tf.add_input(desc, input_c_)
                tf.add_input(desc, params_)
                tf.add_input(desc, sequence_lengths_)
                tf.add_input(desc, output_)
                tf.add_input(desc, output_h_)
                tf.add_input(desc, output_c_)
                tf.add_input(desc, output_backprop_)
                tf.add_input(desc, output_h_backprop_)
                tf.add_input(desc, output_c_backprop_)
                tf.add_input(desc, reserve_space_)
                tf.add_input(desc, host_reserved_)
                if rnn_mode !== nothing
                    desc["rnn_mode"] = Base.String(rnn_mode)
                end
                if input_mode !== nothing
                    desc["input_mode"] = Base.String(input_mode)
                end
                if direction !== nothing
                    desc["direction"] = Base.String(direction)
                end
                if dropout !== nothing
                    desc["dropout"] = Base.identity(dropout)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function cudnn_rnn_backprop_v3(input_::tf.TensorHandle, input_h_::tf.TensorHandle, input_c_::tf.TensorHandle, params_::tf.TensorHandle, sequence_lengths_::tf.TensorHandle, output_::tf.TensorHandle, output_h_::tf.TensorHandle, output_c_::tf.TensorHandle, output_backprop_::tf.TensorHandle, output_h_backprop_::tf.TensorHandle, output_c_backprop_::tf.TensorHandle, reserve_space_::tf.TensorHandle, host_reserved_::tf.TensorHandle; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("CudnnRNNBackpropV3")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_h_)
        tf.add_input(desc, input_c_)
        tf.add_input(desc, params_)
        tf.add_input(desc, sequence_lengths_)
        tf.add_input(desc, output_)
        tf.add_input(desc, output_h_)
        tf.add_input(desc, output_c_)
        tf.add_input(desc, output_backprop_)
        tf.add_input(desc, output_h_backprop_)
        tf.add_input(desc, output_c_backprop_)
        tf.add_input(desc, reserve_space_)
        tf.add_input(desc, host_reserved_)
        if rnn_mode !== nothing
            desc["rnn_mode"] = Base.String(rnn_mode)
        end
        if input_mode !== nothing
            desc["input_mode"] = Base.String(input_mode)
        end
        if direction !== nothing
            desc["direction"] = Base.String(direction)
        end
        if dropout !== nothing
            desc["dropout"] = Base.identity(dropout)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(input_h_)
        desc["T"] = tf.data_type(input_c_)
        desc["T"] = tf.data_type(params_)
        desc["T"] = tf.data_type(output_)
        desc["T"] = tf.data_type(output_h_)
        desc["T"] = tf.data_type(output_c_)
        desc["T"] = tf.data_type(output_backprop_)
        desc["T"] = tf.data_type(output_h_backprop_)
        desc["T"] = tf.data_type(output_c_backprop_)
        desc["T"] = tf.data_type(reserve_space_)
        tf.execute(desc)
    end
end


"""
     lookup_table_insert(table_handle, keys, values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lookup_table_insert(table_handle_, keys_, values_; name=nothing)
            local desc
            tf.with_op_name(name, "LookupTableInsert") do 
                desc = tf.NodeDescription("LookupTableInsert")
                table_handle_ = convert(Tensor{String}, table_handle_)
                keys_ = convert(Tensor{Any}, keys_)
                values_ = convert(Tensor{Any}, values_)
                (keys_,) = tf.tf_promote(keys_)
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, table_handle_)
                tf.add_input(desc, keys_)
                tf.add_input(desc, values_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lookup_table_insert(table_handle_::tf.TensorHandle, keys_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LookupTableInsert")
        tf.add_input(desc, table_handle_)
        tf.add_input(desc, keys_)
        tf.add_input(desc, values_)
        desc["Tin"] = tf.data_type(keys_)
        desc["Tout"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     complex_abs(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function complex_abs(x_; name=nothing)
            local desc
            tf.with_op_name(name, "ComplexAbs") do 
                desc = tf.NodeDescription("ComplexAbs")
                x_ = convert(Tensor{Complex{Float32}}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function complex_abs(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ComplexAbs")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     tridiagonal_solve(diagonals, rhs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tridiagonal_solve(diagonals_, rhs_; name=nothing)
            local desc
            tf.with_op_name(name, "TridiagonalSolve") do 
                desc = tf.NodeDescription("TridiagonalSolve")
                diagonals_ = convert(Tensor{Any}, diagonals_)
                rhs_ = convert(Tensor{Any}, rhs_)
                (diagonals_, rhs_) = tf.tf_promote(diagonals_, rhs_)
                tf.add_input(desc, diagonals_)
                tf.add_input(desc, rhs_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tridiagonal_solve(diagonals_::tf.TensorHandle, rhs_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TridiagonalSolve")
        tf.add_input(desc, diagonals_)
        tf.add_input(desc, rhs_)
        desc["T"] = tf.data_type(diagonals_)
        desc["T"] = tf.data_type(rhs_)
        (tf.execute(desc))[1]
    end
end


"""
     lookup_table_import(table_handle, keys, values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lookup_table_import(table_handle_, keys_, values_; name=nothing)
            local desc
            tf.with_op_name(name, "LookupTableImport") do 
                desc = tf.NodeDescription("LookupTableImport")
                table_handle_ = convert(Tensor{String}, table_handle_)
                keys_ = convert(Tensor{Any}, keys_)
                values_ = convert(Tensor{Any}, values_)
                (keys_,) = tf.tf_promote(keys_)
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, table_handle_)
                tf.add_input(desc, keys_)
                tf.add_input(desc, values_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lookup_table_import(table_handle_::tf.TensorHandle, keys_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LookupTableImport")
        tf.add_input(desc, table_handle_)
        tf.add_input(desc, keys_)
        tf.add_input(desc, values_)
        desc["Tin"] = tf.data_type(keys_)
        desc["Tout"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     abs(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function abs(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Abs") do 
                desc = tf.NodeDescription("Abs")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function abs(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Abs")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_adam(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad; use_locking=false, use_nesterov=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_adam(var_, m_, v_, beta1_power_, beta2_power_, lr_, beta1_, beta2_, epsilon_, grad_; name=nothing, use_locking=nothing, use_nesterov=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyAdam") do 
                desc = tf.NodeDescription("ResourceApplyAdam")
                var_ = convert(Tensor{Any}, var_)
                m_ = convert(Tensor{Any}, m_)
                v_ = convert(Tensor{Any}, v_)
                beta1_power_ = convert(Tensor{Any}, beta1_power_)
                beta2_power_ = convert(Tensor{Any}, beta2_power_)
                lr_ = convert(Tensor{Any}, lr_)
                beta1_ = convert(Tensor{Any}, beta1_)
                beta2_ = convert(Tensor{Any}, beta2_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                (beta1_power_, beta2_power_, lr_, beta1_, beta2_, epsilon_, grad_) = tf.tf_promote(beta1_power_, beta2_power_, lr_, beta1_, beta2_, epsilon_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, m_)
                tf.add_input(desc, v_)
                tf.add_input(desc, beta1_power_)
                tf.add_input(desc, beta2_power_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, beta1_)
                tf.add_input(desc, beta2_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if use_nesterov !== nothing
                    desc["use_nesterov"] = Base.Bool(use_nesterov)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_adam(var_::tf.TensorHandle, m_::tf.TensorHandle, v_::tf.TensorHandle, beta1_power_::tf.TensorHandle, beta2_power_::tf.TensorHandle, lr_::tf.TensorHandle, beta1_::tf.TensorHandle, beta2_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing, use_nesterov=nothing)
        desc = tf.EagerOp("ResourceApplyAdam")
        tf.add_input(desc, var_)
        tf.add_input(desc, m_)
        tf.add_input(desc, v_)
        tf.add_input(desc, beta1_power_)
        tf.add_input(desc, beta2_power_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, beta1_)
        tf.add_input(desc, beta2_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if use_nesterov !== nothing
            desc["use_nesterov"] = Base.Bool(use_nesterov)
        end
        desc["T"] = tf.data_type(beta1_power_)
        desc["T"] = tf.data_type(beta2_power_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(beta1_)
        desc["T"] = tf.data_type(beta2_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     write_histogram_summary(writer, step, tag, values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function write_histogram_summary(writer_, step_, tag_, values_; name=nothing)
            local desc
            tf.with_op_name(name, "WriteHistogramSummary") do 
                desc = tf.NodeDescription("WriteHistogramSummary")
                writer_ = convert(Tensor{Any}, writer_)
                step_ = convert(Tensor{Int64}, step_)
                tag_ = convert(Tensor{String}, tag_)
                values_ = convert(Tensor{Float32}, values_)
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, writer_)
                tf.add_input(desc, step_)
                tf.add_input(desc, tag_)
                tf.add_input(desc, values_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function write_histogram_summary(writer_::tf.TensorHandle, step_::tf.TensorHandle, tag_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("WriteHistogramSummary")
        tf.add_input(desc, writer_)
        tf.add_input(desc, step_)
        tf.add_input(desc, tag_)
        tf.add_input(desc, values_)
        desc["T"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_indexed_dataset_materialize(dataset, materialized)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_indexed_dataset_materialize(dataset_, materialized_; name=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalIndexedDatasetMaterialize") do 
                desc = tf.NodeDescription("ExperimentalIndexedDatasetMaterialize")
                dataset_ = convert(Tensor{Any}, dataset_)
                materialized_ = convert(Tensor{Any}, materialized_)
                tf.add_input(desc, dataset_)
                tf.add_input(desc, materialized_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_indexed_dataset_materialize(dataset_::tf.TensorHandle, materialized_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ExperimentalIndexedDatasetMaterialize")
        tf.add_input(desc, dataset_)
        tf.add_input(desc, materialized_)
        (tf.execute(desc))[1]
    end
end


"""
     _host_send(tensor; client_terminated=false)

Sends the named tensor from send_device to recv_device.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _host_send(tensor_; name=nothing, tensor_name=nothing, send_device=nothing, send_device_incarnation=nothing, recv_device=nothing, client_terminated=nothing)
            local desc
            tf.with_op_name(name, "_HostSend") do 
                desc = tf.NodeDescription("_HostSend")
                tensor_ = convert(Tensor{Any}, tensor_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, tensor_)
                if tensor_name !== nothing
                    desc["tensor_name"] = Base.String(tensor_name)
                end
                if send_device !== nothing
                    desc["send_device"] = Base.String(send_device)
                end
                if send_device_incarnation !== nothing
                    desc["send_device_incarnation"] = Base.Int(send_device_incarnation)
                end
                if recv_device !== nothing
                    desc["recv_device"] = Base.String(recv_device)
                end
                if client_terminated !== nothing
                    desc["client_terminated"] = Base.Bool(client_terminated)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _host_send(tensor_::tf.TensorHandle; name=nothing, tensor_name=nothing, send_device=nothing, send_device_incarnation=nothing, recv_device=nothing, client_terminated=nothing)
        desc = tf.EagerOp("_HostSend")
        tf.add_input(desc, tensor_)
        if tensor_name !== nothing
            desc["tensor_name"] = Base.String(tensor_name)
        end
        if send_device !== nothing
            desc["send_device"] = Base.String(send_device)
        end
        if send_device_incarnation !== nothing
            desc["send_device_incarnation"] = Base.Int(send_device_incarnation)
        end
        if recv_device !== nothing
            desc["recv_device"] = Base.String(recv_device)
        end
        if client_terminated !== nothing
            desc["client_terminated"] = Base.Bool(client_terminated)
        end
        desc["T"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     greater(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function greater(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Greater") do 
                desc = tf.NodeDescription("Greater")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function greater(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Greater")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     nccl_broadcast(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function nccl_broadcast(input_; name=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "NcclBroadcast") do 
                desc = tf.NodeDescription("NcclBroadcast")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function nccl_broadcast(input_::tf.TensorHandle; name=nothing, shape=nothing)
        desc = tf.EagerOp("NcclBroadcast")
        tf.add_input(desc, input_)
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_push_back_batch(input_handles, tensor)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_push_back_batch(input_handles_, tensor_; name=nothing, element_dtype=nothing)
            local desc
            tf.with_op_name(name, "TensorListPushBackBatch") do 
                desc = tf.NodeDescription("TensorListPushBackBatch")
                input_handles_ = convert(Tensor{Any}, input_handles_)
                tensor_ = convert(Tensor{Any}, tensor_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, input_handles_)
                tf.add_input(desc, tensor_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_push_back_batch(input_handles_::tf.TensorHandle, tensor_::tf.TensorHandle; name=nothing, element_dtype=nothing)
        desc = tf.EagerOp("TensorListPushBackBatch")
        tf.add_input(desc, input_handles_)
        tf.add_input(desc, tensor_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        desc["element_dtype"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_scatter_min(resource, indices, updates)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_scatter_min(resource_, indices_, updates_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "ResourceScatterMin") do 
                desc = tf.NodeDescription("ResourceScatterMin")
                resource_ = convert(Tensor{Any}, resource_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (updates_,) = tf.tf_promote(updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_scatter_min(resource_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("ResourceScatterMin")
        tf.add_input(desc, resource_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["Tindices"] = tf.data_type(indices_)
        desc["dtype"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     slice(input, begin, size)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function slice(input_, begin_, size_; name=nothing, Index=nothing)
            local desc
            tf.with_op_name(name, "Slice") do 
                desc = tf.NodeDescription("Slice")
                input_ = convert(Tensor{Any}, input_)
                begin_ = convert(Tensor{Any}, begin_)
                begin_ = begin_ - convert(tf.Tensor{eltype(begin_)}, 1)
                size_ = convert(Tensor{Any}, size_)
                (input_,) = tf.tf_promote(input_)
                (begin_, size_) = tf.tf_promote(begin_, size_)
                tf.add_input(desc, input_)
                tf.add_input(desc, begin_)
                tf.add_input(desc, size_)
                if Index !== nothing
                    desc["Index"] = Base.identity(Index)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function slice(input_::tf.TensorHandle, begin_::tf.TensorHandle, size_::tf.TensorHandle; name=nothing, Index=nothing)
        desc = tf.EagerOp("Slice")
        tf.add_input(desc, input_)
        tf.add_input(desc, begin_)
        tf.add_input(desc, size_)
        if Index !== nothing
            desc["Index"] = Base.identity(Index)
        end
        desc["T"] = tf.data_type(input_)
        desc["Index"] = tf.data_type(begin_)
        desc["Index"] = tf.data_type(size_)
        (tf.execute(desc))[1]
    end
end


"""
     unicode_decode(input; errors=replace, replacement_char=65533, replace_control_characters=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unicode_decode(input_; name=nothing, input_encoding=nothing, errors=nothing, replacement_char=nothing, replace_control_characters=nothing)
            local desc
            tf.with_op_name(name, "UnicodeDecode") do 
                desc = tf.NodeDescription("UnicodeDecode")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
                if input_encoding !== nothing
                    desc["input_encoding"] = Base.String(input_encoding)
                end
                if errors !== nothing
                    desc["errors"] = Base.String(errors)
                end
                if replacement_char !== nothing
                    desc["replacement_char"] = Base.Int(replacement_char)
                end
                if replace_control_characters !== nothing
                    desc["replace_control_characters"] = Base.Bool(replace_control_characters)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function unicode_decode(input_::tf.TensorHandle; name=nothing, input_encoding=nothing, errors=nothing, replacement_char=nothing, replace_control_characters=nothing)
        desc = tf.EagerOp("UnicodeDecode")
        tf.add_input(desc, input_)
        if input_encoding !== nothing
            desc["input_encoding"] = Base.String(input_encoding)
        end
        if errors !== nothing
            desc["errors"] = Base.String(errors)
        end
        if replacement_char !== nothing
            desc["replacement_char"] = Base.Int(replacement_char)
        end
        if replace_control_characters !== nothing
            desc["replace_control_characters"] = Base.Bool(replace_control_characters)
        end
        tf.execute(desc)
    end
end


"""
     take_dataset(input_dataset, count)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function take_dataset(input_dataset_, count_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "TakeDataset") do 
                desc = tf.NodeDescription("TakeDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                count_ = convert(Tensor{Int64}, count_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, count_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function take_dataset(input_dataset_::tf.TensorHandle, count_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("TakeDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, count_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_make_stats_summary(node_ids, gradients, hessians, bucketized_features_list)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_make_stats_summary(node_ids_, gradients_, hessians_, bucketized_features_list_; name=nothing, max_splits=nothing, num_buckets=nothing, num_features=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesMakeStatsSummary") do 
                desc = tf.NodeDescription("BoostedTreesMakeStatsSummary")
                node_ids_ = convert(Tensor{Int32}, node_ids_)
                gradients_ = convert(Tensor{Float32}, gradients_)
                hessians_ = convert(Tensor{Float32}, hessians_)
                bucketized_features_list_ = [convert(Tensor{Int32}, x) for x = bucketized_features_list_]
                tf.add_input(desc, node_ids_)
                tf.add_input(desc, gradients_)
                tf.add_input(desc, hessians_)
                tf.add_input(desc, bucketized_features_list_)
                if max_splits !== nothing
                    desc["max_splits"] = Base.Int(max_splits)
                end
                if num_buckets !== nothing
                    desc["num_buckets"] = Base.Int(num_buckets)
                end
                if num_features !== nothing
                    desc["num_features"] = Base.Int(num_features)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_make_stats_summary(node_ids_::tf.TensorHandle, gradients_::tf.TensorHandle, hessians_::tf.TensorHandle, bucketized_features_list_::tf.TensorHandle; name=nothing, max_splits=nothing, num_buckets=nothing, num_features=nothing)
        desc = tf.EagerOp("BoostedTreesMakeStatsSummary")
        tf.add_input(desc, node_ids_)
        tf.add_input(desc, gradients_)
        tf.add_input(desc, hessians_)
        tf.add_input(desc, bucketized_features_list_)
        if max_splits !== nothing
            desc["max_splits"] = Base.Int(max_splits)
        end
        if num_buckets !== nothing
            desc["num_buckets"] = Base.Int(num_buckets)
        end
        if num_features !== nothing
            desc["num_features"] = Base.Int(num_features)
        end
        (tf.execute(desc))[1]
    end
end


"""
     all_candidate_sampler(true_classes; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function all_candidate_sampler(true_classes_; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "AllCandidateSampler") do 
                desc = tf.NodeDescription("AllCandidateSampler")
                true_classes_ = convert(Tensor{Int64}, true_classes_)
                tf.add_input(desc, true_classes_)
                if num_true !== nothing
                    desc["num_true"] = Base.Int(num_true)
                end
                if num_sampled !== nothing
                    desc["num_sampled"] = Base.Int(num_sampled)
                end
                if unique !== nothing
                    desc["unique"] = Base.Bool(unique)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function all_candidate_sampler(true_classes_::tf.TensorHandle; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("AllCandidateSampler")
        tf.add_input(desc, true_classes_)
        if num_true !== nothing
            desc["num_true"] = Base.Int(num_true)
        end
        if num_sampled !== nothing
            desc["num_sampled"] = Base.Int(num_sampled)
        end
        if unique !== nothing
            desc["unique"] = Base.Bool(unique)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        tf.execute(desc)
    end
end


"""
     conv2d_backprop_input(input_sizes, filter, out_backprop; use_cudnn_on_gpu=true, explicit_paddings=Int64[], data_format=NHWC, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function conv2d_backprop_input(input_sizes_, filter_, out_backprop_; name=nothing, strides=nothing, use_cudnn_on_gpu=nothing, padding=nothing, explicit_paddings=nothing, data_format=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "Conv2DBackpropInput") do 
                desc = tf.NodeDescription("Conv2DBackpropInput")
                input_sizes_ = convert(Tensor{Int32}, input_sizes_)
                filter_ = convert(Tensor{Any}, filter_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                (filter_, out_backprop_) = tf.tf_promote(filter_, out_backprop_)
                tf.add_input(desc, input_sizes_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, out_backprop_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if use_cudnn_on_gpu !== nothing
                    desc["use_cudnn_on_gpu"] = Base.Bool(use_cudnn_on_gpu)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if explicit_paddings !== nothing
                    desc["explicit_paddings"] = map(Base.identity, explicit_paddings)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function conv2d_backprop_input(input_sizes_::tf.TensorHandle, filter_::tf.TensorHandle, out_backprop_::tf.TensorHandle; name=nothing, strides=nothing, use_cudnn_on_gpu=nothing, padding=nothing, explicit_paddings=nothing, data_format=nothing, dilations=nothing)
        desc = tf.EagerOp("Conv2DBackpropInput")
        tf.add_input(desc, input_sizes_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, out_backprop_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if use_cudnn_on_gpu !== nothing
            desc["use_cudnn_on_gpu"] = Base.Bool(use_cudnn_on_gpu)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if explicit_paddings !== nothing
            desc["explicit_paddings"] = map(Base.identity, explicit_paddings)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["T"] = tf.data_type(filter_)
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     dataset_to_single_element(dataset)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function dataset_to_single_element(dataset_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "DatasetToSingleElement") do 
                desc = tf.NodeDescription("DatasetToSingleElement")
                dataset_ = convert(Tensor{Any}, dataset_)
                tf.add_input(desc, dataset_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function dataset_to_single_element(dataset_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("DatasetToSingleElement")
        tf.add_input(desc, dataset_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     cache_dataset(input_dataset, filename)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cache_dataset(input_dataset_, filename_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "CacheDataset") do 
                desc = tf.NodeDescription("CacheDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                filename_ = convert(Tensor{String}, filename_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, filename_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cache_dataset(input_dataset_::tf.TensorHandle, filename_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("CacheDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, filename_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     fake_quant_with_min_max_vars_gradient(gradients, inputs, min, max; num_bits=8, narrow_range=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fake_quant_with_min_max_vars_gradient(gradients_, inputs_, min_, max_; name=nothing, num_bits=nothing, narrow_range=nothing)
            local desc
            tf.with_op_name(name, "FakeQuantWithMinMaxVarsGradient") do 
                desc = tf.NodeDescription("FakeQuantWithMinMaxVarsGradient")
                gradients_ = convert(Tensor{Float32}, gradients_)
                inputs_ = convert(Tensor{Float32}, inputs_)
                min_ = convert(Tensor{Float32}, min_)
                max_ = convert(Tensor{Float32}, max_)
                tf.add_input(desc, gradients_)
                tf.add_input(desc, inputs_)
                tf.add_input(desc, min_)
                tf.add_input(desc, max_)
                if num_bits !== nothing
                    desc["num_bits"] = Base.Int(num_bits)
                end
                if narrow_range !== nothing
                    desc["narrow_range"] = Base.Bool(narrow_range)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function fake_quant_with_min_max_vars_gradient(gradients_::tf.TensorHandle, inputs_::tf.TensorHandle, min_::tf.TensorHandle, max_::tf.TensorHandle; name=nothing, num_bits=nothing, narrow_range=nothing)
        desc = tf.EagerOp("FakeQuantWithMinMaxVarsGradient")
        tf.add_input(desc, gradients_)
        tf.add_input(desc, inputs_)
        tf.add_input(desc, min_)
        tf.add_input(desc, max_)
        if num_bits !== nothing
            desc["num_bits"] = Base.Int(num_bits)
        end
        if narrow_range !== nothing
            desc["narrow_range"] = Base.Bool(narrow_range)
        end
        tf.execute(desc)
    end
end


"""
     fused_resize_and_pad_conv2d(input, size, paddings, filter; resize_align_corners=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fused_resize_and_pad_conv2d(input_, size_, paddings_, filter_; name=nothing, resize_align_corners=nothing, mode=nothing, strides=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "FusedResizeAndPadConv2D") do 
                desc = tf.NodeDescription("FusedResizeAndPadConv2D")
                input_ = convert(Tensor{Any}, input_)
                size_ = convert(Tensor{Int32}, size_)
                paddings_ = convert(Tensor{Int32}, paddings_)
                filter_ = convert(Tensor{Any}, filter_)
                (input_, filter_) = tf.tf_promote(input_, filter_)
                tf.add_input(desc, input_)
                tf.add_input(desc, size_)
                tf.add_input(desc, paddings_)
                tf.add_input(desc, filter_)
                if resize_align_corners !== nothing
                    desc["resize_align_corners"] = Base.Bool(resize_align_corners)
                end
                if mode !== nothing
                    desc["mode"] = Base.String(mode)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fused_resize_and_pad_conv2d(input_::tf.TensorHandle, size_::tf.TensorHandle, paddings_::tf.TensorHandle, filter_::tf.TensorHandle; name=nothing, resize_align_corners=nothing, mode=nothing, strides=nothing, padding=nothing)
        desc = tf.EagerOp("FusedResizeAndPadConv2D")
        tf.add_input(desc, input_)
        tf.add_input(desc, size_)
        tf.add_input(desc, paddings_)
        tf.add_input(desc, filter_)
        if resize_align_corners !== nothing
            desc["resize_align_corners"] = Base.Bool(resize_align_corners)
        end
        if mode !== nothing
            desc["mode"] = Base.String(mode)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(filter_)
        (tf.execute(desc))[1]
    end
end


"""
     batch(in_tensors; max_enqueued_batches=10, allowed_batch_sizes=Int64[], container=, shared_name=, batching_queue=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch(in_tensors_; name=nothing, num_batch_threads=nothing, max_batch_size=nothing, max_enqueued_batches=nothing, batch_timeout_micros=nothing, allowed_batch_sizes=nothing, grad_timeout_micros=nothing, container=nothing, shared_name=nothing, batching_queue=nothing, T=nothing)
            local desc
            tf.with_op_name(name, "Batch") do 
                desc = tf.NodeDescription("Batch")
                in_tensors_ = [convert(Tensor{Any}, x) for x = in_tensors_]
                tf.add_input(desc, in_tensors_)
                if num_batch_threads !== nothing
                    desc["num_batch_threads"] = Base.Int(num_batch_threads)
                end
                if max_batch_size !== nothing
                    desc["max_batch_size"] = Base.Int(max_batch_size)
                end
                if max_enqueued_batches !== nothing
                    desc["max_enqueued_batches"] = Base.Int(max_enqueued_batches)
                end
                if batch_timeout_micros !== nothing
                    desc["batch_timeout_micros"] = Base.Int(batch_timeout_micros)
                end
                if allowed_batch_sizes !== nothing
                    desc["allowed_batch_sizes"] = map(Base.identity, allowed_batch_sizes)
                end
                if grad_timeout_micros !== nothing
                    desc["grad_timeout_micros"] = Base.Int(grad_timeout_micros)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if batching_queue !== nothing
                    desc["batching_queue"] = Base.String(batching_queue)
                end
                if T !== nothing
                    desc["T"] = map(Base.identity, T)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function batch(in_tensors_::tf.TensorHandle; name=nothing, num_batch_threads=nothing, max_batch_size=nothing, max_enqueued_batches=nothing, batch_timeout_micros=nothing, allowed_batch_sizes=nothing, grad_timeout_micros=nothing, container=nothing, shared_name=nothing, batching_queue=nothing, T=nothing)
        desc = tf.EagerOp("Batch")
        tf.add_input(desc, in_tensors_)
        if num_batch_threads !== nothing
            desc["num_batch_threads"] = Base.Int(num_batch_threads)
        end
        if max_batch_size !== nothing
            desc["max_batch_size"] = Base.Int(max_batch_size)
        end
        if max_enqueued_batches !== nothing
            desc["max_enqueued_batches"] = Base.Int(max_enqueued_batches)
        end
        if batch_timeout_micros !== nothing
            desc["batch_timeout_micros"] = Base.Int(batch_timeout_micros)
        end
        if allowed_batch_sizes !== nothing
            desc["allowed_batch_sizes"] = map(Base.identity, allowed_batch_sizes)
        end
        if grad_timeout_micros !== nothing
            desc["grad_timeout_micros"] = Base.Int(grad_timeout_micros)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if batching_queue !== nothing
            desc["batching_queue"] = Base.String(batching_queue)
        end
        if T !== nothing
            desc["T"] = map(Base.identity, T)
        end
        tf.execute(desc)
    end
end


"""
     collective_bcast_recv()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function collective_bcast_recv(; name=nothing, group_size=nothing, group_key=nothing, instance_key=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "CollectiveBcastRecv") do 
                desc = tf.NodeDescription("CollectiveBcastRecv")
                if group_size !== nothing
                    desc["group_size"] = Base.Int(group_size)
                end
                if group_key !== nothing
                    desc["group_key"] = Base.Int(group_key)
                end
                if instance_key !== nothing
                    desc["instance_key"] = Base.Int(instance_key)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function collective_bcast_recv(; name=nothing, group_size=nothing, group_key=nothing, instance_key=nothing, shape=nothing)
        desc = tf.EagerOp("CollectiveBcastRecv")
        if group_size !== nothing
            desc["group_size"] = Base.Int(group_size)
        end
        if group_key !== nothing
            desc["group_key"] = Base.Int(group_key)
        end
        if instance_key !== nothing
            desc["instance_key"] = Base.Int(instance_key)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     batch_to_space_nd(input, block_shape, crops)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_to_space_nd(input_, block_shape_, crops_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchToSpaceND") do 
                desc = tf.NodeDescription("BatchToSpaceND")
                input_ = convert(Tensor{Any}, input_)
                block_shape_ = convert(Tensor{Int32}, block_shape_)
                crops_ = convert(Tensor{Int32}, crops_)
                (crops_,) = tf.tf_promote(crops_)
                (input_,) = tf.tf_promote(input_)
                (block_shape_,) = tf.tf_promote(block_shape_)
                tf.add_input(desc, input_)
                tf.add_input(desc, block_shape_)
                tf.add_input(desc, crops_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_to_space_nd(input_::tf.TensorHandle, block_shape_::tf.TensorHandle, crops_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchToSpaceND")
        tf.add_input(desc, input_)
        tf.add_input(desc, block_shape_)
        tf.add_input(desc, crops_)
        desc["T"] = tf.data_type(input_)
        desc["Tblock_shape"] = tf.data_type(block_shape_)
        desc["Tcrops"] = tf.data_type(crops_)
        (tf.execute(desc))[1]
    end
end


"""
     loop_cond(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function loop_cond(input_; name=nothing)
            local desc
            tf.with_op_name(name, "LoopCond") do 
                desc = tf.NodeDescription("LoopCond")
                input_ = convert(Tensor{Bool}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function loop_cond(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LoopCond")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     depth_to_space(input; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function depth_to_space(input_; name=nothing, block_size=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "DepthToSpace") do 
                desc = tf.NodeDescription("DepthToSpace")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if block_size !== nothing
                    desc["block_size"] = Base.Int(block_size)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function depth_to_space(input_::tf.TensorHandle; name=nothing, block_size=nothing, data_format=nothing)
        desc = tf.EagerOp("DepthToSpace")
        tf.add_input(desc, input_)
        if block_size !== nothing
            desc["block_size"] = Base.Int(block_size)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     destroy_temporary_variable(ref)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function destroy_temporary_variable(ref_; name=nothing, var_name=nothing)
            local desc
            tf.with_op_name(name, "DestroyTemporaryVariable") do 
                desc = tf.NodeDescription("DestroyTemporaryVariable")
                ref_ = convert(Tensor{Any}, ref_)
                (ref_,) = tf.tf_promote(ref_)
                tf.add_input(desc, ref_)
                if var_name !== nothing
                    desc["var_name"] = Base.String(var_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function destroy_temporary_variable(ref_::tf.TensorHandle; name=nothing, var_name=nothing)
        desc = tf.EagerOp("DestroyTemporaryVariable")
        tf.add_input(desc, ref_)
        if var_name !== nothing
            desc["var_name"] = Base.String(var_name)
        end
        desc["T"] = tf.data_type(ref_)
        (tf.execute(desc))[1]
    end
end


"""
     cudnn_rnn(input, input_h, input_c, params; rnn_mode=lstm, input_mode=linear_input, direction=unidirectional, dropout=?, seed=0, seed2=0, is_training=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cudnn_rnn(input_, input_h_, input_c_, params_; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing, is_training=nothing)
            local desc
            tf.with_op_name(name, "CudnnRNN") do 
                desc = tf.NodeDescription("CudnnRNN")
                input_ = convert(Tensor{Any}, input_)
                input_h_ = convert(Tensor{Any}, input_h_)
                input_c_ = convert(Tensor{Any}, input_c_)
                params_ = convert(Tensor{Any}, params_)
                (input_, input_h_, input_c_, params_) = tf.tf_promote(input_, input_h_, input_c_, params_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_h_)
                tf.add_input(desc, input_c_)
                tf.add_input(desc, params_)
                if rnn_mode !== nothing
                    desc["rnn_mode"] = Base.String(rnn_mode)
                end
                if input_mode !== nothing
                    desc["input_mode"] = Base.String(input_mode)
                end
                if direction !== nothing
                    desc["direction"] = Base.String(direction)
                end
                if dropout !== nothing
                    desc["dropout"] = Base.identity(dropout)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if is_training !== nothing
                    desc["is_training"] = Base.Bool(is_training)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function cudnn_rnn(input_::tf.TensorHandle, input_h_::tf.TensorHandle, input_c_::tf.TensorHandle, params_::tf.TensorHandle; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing, is_training=nothing)
        desc = tf.EagerOp("CudnnRNN")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_h_)
        tf.add_input(desc, input_c_)
        tf.add_input(desc, params_)
        if rnn_mode !== nothing
            desc["rnn_mode"] = Base.String(rnn_mode)
        end
        if input_mode !== nothing
            desc["input_mode"] = Base.String(input_mode)
        end
        if direction !== nothing
            desc["direction"] = Base.String(direction)
        end
        if dropout !== nothing
            desc["dropout"] = Base.identity(dropout)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if is_training !== nothing
            desc["is_training"] = Base.Bool(is_training)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(input_h_)
        desc["T"] = tf.data_type(input_c_)
        desc["T"] = tf.data_type(params_)
        tf.execute(desc)
    end
end


"""
     ref_identity(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ref_identity(input_; name=nothing)
            local desc
            tf.with_op_name(name, "RefIdentity") do 
                desc = tf.NodeDescription("RefIdentity")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ref_identity(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RefIdentity")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     max_pool3d_grad(orig_input, orig_output, grad; data_format=NDHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool3d_grad(orig_input_, orig_output_, grad_; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "MaxPool3DGrad") do 
                desc = tf.NodeDescription("MaxPool3DGrad")
                orig_input_ = convert(Tensor{Float32}, orig_input_)
                orig_output_ = convert(Tensor{Float32}, orig_output_)
                grad_ = convert(Tensor{Float32}, grad_)
                (grad_,) = tf.tf_promote(grad_)
                (orig_input_, orig_output_) = tf.tf_promote(orig_input_, orig_output_)
                tf.add_input(desc, orig_input_)
                tf.add_input(desc, orig_output_)
                tf.add_input(desc, grad_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max_pool3d_grad(orig_input_::tf.TensorHandle, orig_output_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("MaxPool3DGrad")
        tf.add_input(desc, orig_input_)
        tf.add_input(desc, orig_output_)
        tf.add_input(desc, grad_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["TInput"] = tf.data_type(orig_input_)
        desc["TInput"] = tf.data_type(orig_output_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_momentum_parameters_grad_accum_debug(parameters, momenta, gradient_accumulators; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_momentum_parameters_grad_accum_debug(parameters_, momenta_, gradient_accumulators_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingMomentumParametersGradAccumDebug") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingMomentumParametersGradAccumDebug")
                parameters_ = convert(Tensor{Float32}, parameters_)
                momenta_ = convert(Tensor{Float32}, momenta_)
                gradient_accumulators_ = convert(Tensor{Float32}, gradient_accumulators_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, momenta_)
                tf.add_input(desc, gradient_accumulators_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_momentum_parameters_grad_accum_debug(parameters_::tf.TensorHandle, momenta_::tf.TensorHandle, gradient_accumulators_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingMomentumParametersGradAccumDebug")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, momenta_)
        tf.add_input(desc, gradient_accumulators_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     padding_fifo_queue_v2(; shapes=Int64[], capacity=-1, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function padding_fifo_queue_v2(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "PaddingFIFOQueueV2") do 
                desc = tf.NodeDescription("PaddingFIFOQueueV2")
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function padding_fifo_queue_v2(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("PaddingFIFOQueueV2")
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     conv3d_backprop_input(input, filter, out_backprop; dilations=[1, 1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function conv3d_backprop_input(input_, filter_, out_backprop_; name=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "Conv3DBackpropInput") do 
                desc = tf.NodeDescription("Conv3DBackpropInput")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                (input_, filter_, out_backprop_) = tf.tf_promote(input_, filter_, out_backprop_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, out_backprop_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function conv3d_backprop_input(input_::tf.TensorHandle, filter_::tf.TensorHandle, out_backprop_::tf.TensorHandle; name=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("Conv3DBackpropInput")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, out_backprop_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(filter_)
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     ref_exit(data)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ref_exit(data_; name=nothing)
            local desc
            tf.with_op_name(name, "RefExit") do 
                desc = tf.NodeDescription("RefExit")
                data_ = convert(Tensor{Any}, data_)
                (data_,) = tf.tf_promote(data_)
                tf.add_input(desc, data_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ref_exit(data_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RefExit")
        tf.add_input(desc, data_)
        desc["T"] = tf.data_type(data_)
        (tf.execute(desc))[1]
    end
end


"""
     map_clear(; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function map_clear(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "MapClear") do 
                desc = tf.NodeDescription("MapClear")
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function map_clear(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("MapClear")
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     encode_wav(audio, sample_rate)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function encode_wav(audio_, sample_rate_; name=nothing)
            local desc
            tf.with_op_name(name, "EncodeWav") do 
                desc = tf.NodeDescription("EncodeWav")
                audio_ = convert(Tensor{Float32}, audio_)
                sample_rate_ = convert(Tensor{Int32}, sample_rate_)
                tf.add_input(desc, audio_)
                tf.add_input(desc, sample_rate_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function encode_wav(audio_::tf.TensorHandle, sample_rate_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("EncodeWav")
        tf.add_input(desc, audio_)
        tf.add_input(desc, sample_rate_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_summary_v2(tag, tensor, serialized_summary_metadata)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_summary_v2(tag_, tensor_, serialized_summary_metadata_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorSummaryV2") do 
                desc = tf.NodeDescription("TensorSummaryV2")
                tag_ = convert(Tensor{String}, tag_)
                tensor_ = convert(Tensor{Any}, tensor_)
                serialized_summary_metadata_ = convert(Tensor{String}, serialized_summary_metadata_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, tag_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, serialized_summary_metadata_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_summary_v2(tag_::tf.TensorHandle, tensor_::tf.TensorHandle, serialized_summary_metadata_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorSummaryV2")
        tf.add_input(desc, tag_)
        tf.add_input(desc, tensor_)
        tf.add_input(desc, serialized_summary_metadata_)
        desc["T"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     queue_dequeue_up_to(handle, n; timeout_ms=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_dequeue_up_to(handle_, n_; name=nothing, component_types=nothing, timeout_ms=nothing)
            local desc
            tf.with_op_name(name, "QueueDequeueUpTo") do 
                desc = tf.NodeDescription("QueueDequeueUpTo")
                handle_ = convert(Tensor{String}, handle_)
                n_ = convert(Tensor{Int32}, n_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, n_)
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if timeout_ms !== nothing
                    desc["timeout_ms"] = Base.Int(timeout_ms)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_dequeue_up_to(handle_::tf.TensorHandle, n_::tf.TensorHandle; name=nothing, component_types=nothing, timeout_ms=nothing)
        desc = tf.EagerOp("QueueDequeueUpTo")
        tf.add_input(desc, handle_)
        tf.add_input(desc, n_)
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if timeout_ms !== nothing
            desc["timeout_ms"] = Base.Int(timeout_ms)
        end
        (tf.execute(desc))[1]
    end
end


"""
     matrix_band_part(input, num_lower, num_upper)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_band_part(input_, num_lower_, num_upper_; name=nothing)
            local desc
            tf.with_op_name(name, "MatrixBandPart") do 
                desc = tf.NodeDescription("MatrixBandPart")
                input_ = convert(Tensor{Any}, input_)
                num_lower_ = convert(Tensor{Int64}, num_lower_)
                num_upper_ = convert(Tensor{Int64}, num_upper_)
                (input_,) = tf.tf_promote(input_)
                (num_lower_, num_upper_) = tf.tf_promote(num_lower_, num_upper_)
                tf.add_input(desc, input_)
                tf.add_input(desc, num_lower_)
                tf.add_input(desc, num_upper_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_band_part(input_::tf.TensorHandle, num_lower_::tf.TensorHandle, num_upper_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MatrixBandPart")
        tf.add_input(desc, input_)
        tf.add_input(desc, num_lower_)
        tf.add_input(desc, num_upper_)
        desc["T"] = tf.data_type(input_)
        desc["Tindex"] = tf.data_type(num_lower_)
        desc["Tindex"] = tf.data_type(num_upper_)
        (tf.execute(desc))[1]
    end
end


"""
     copy(input; tensor_name=, debug_ops_spec=Int64[])

Copy Op.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function copy(input_; name=nothing, tensor_name=nothing, debug_ops_spec=nothing)
            local desc
            tf.with_op_name(name, "Copy") do 
                desc = tf.NodeDescription("Copy")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if tensor_name !== nothing
                    desc["tensor_name"] = Base.String(tensor_name)
                end
                if debug_ops_spec !== nothing
                    desc["debug_ops_spec"] = map(Base.identity, debug_ops_spec)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function copy(input_::tf.TensorHandle; name=nothing, tensor_name=nothing, debug_ops_spec=nothing)
        desc = tf.EagerOp("Copy")
        tf.add_input(desc, input_)
        if tensor_name !== nothing
            desc["tensor_name"] = Base.String(tensor_name)
        end
        if debug_ops_spec !== nothing
            desc["debug_ops_spec"] = map(Base.identity, debug_ops_spec)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     shape_n(input; out_type=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function shape_n(input_; name=nothing, N=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "ShapeN") do 
                desc = tf.NodeDescription("ShapeN")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:N
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function shape_n(input_::tf.TensorHandle; name=nothing, N=nothing, out_type=nothing)
        desc = tf.EagerOp("ShapeN")
        tf.add_input(desc, input_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     experimental_parse_example_dataset(input_dataset, num_parallel_calls, dense_defaults; sloppy=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_parse_example_dataset(input_dataset_, num_parallel_calls_, dense_defaults_; name=nothing, sparse_keys=nothing, dense_keys=nothing, sparse_types=nothing, Tdense=nothing, dense_shapes=nothing, output_types=nothing, output_shapes=nothing, sloppy=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalParseExampleDataset") do 
                desc = tf.NodeDescription("ExperimentalParseExampleDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                num_parallel_calls_ = convert(Tensor{Int64}, num_parallel_calls_)
                dense_defaults_ = [convert(Tensor{Any}, x) for x = dense_defaults_]
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, num_parallel_calls_)
                tf.add_input(desc, dense_defaults_)
                if sparse_keys !== nothing
                    desc["sparse_keys"] = map(Base.identity, sparse_keys)
                end
                if dense_keys !== nothing
                    desc["dense_keys"] = map(Base.identity, dense_keys)
                end
                if sparse_types !== nothing
                    desc["sparse_types"] = map(Base.identity, sparse_types)
                end
                if Tdense !== nothing
                    desc["Tdense"] = map(Base.identity, Tdense)
                end
                if dense_shapes !== nothing
                    desc["dense_shapes"] = map(Base.identity, dense_shapes)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if sloppy !== nothing
                    desc["sloppy"] = Base.Bool(sloppy)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_parse_example_dataset(input_dataset_::tf.TensorHandle, num_parallel_calls_::tf.TensorHandle, dense_defaults_::tf.TensorHandle; name=nothing, sparse_keys=nothing, dense_keys=nothing, sparse_types=nothing, Tdense=nothing, dense_shapes=nothing, output_types=nothing, output_shapes=nothing, sloppy=nothing)
        desc = tf.EagerOp("ExperimentalParseExampleDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, num_parallel_calls_)
        tf.add_input(desc, dense_defaults_)
        if sparse_keys !== nothing
            desc["sparse_keys"] = map(Base.identity, sparse_keys)
        end
        if dense_keys !== nothing
            desc["dense_keys"] = map(Base.identity, dense_keys)
        end
        if sparse_types !== nothing
            desc["sparse_types"] = map(Base.identity, sparse_types)
        end
        if Tdense !== nothing
            desc["Tdense"] = map(Base.identity, Tdense)
        end
        if dense_shapes !== nothing
            desc["dense_shapes"] = map(Base.identity, dense_shapes)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if sloppy !== nothing
            desc["sloppy"] = Base.Bool(sloppy)
        end
        (tf.execute(desc))[1]
    end
end


"""
     concat(concat_dim, values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function concat(concat_dim_, values_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "Concat") do 
                desc = tf.NodeDescription("Concat")
                concat_dim_ = convert(Tensor{Int32}, concat_dim_)
                values_ = [convert(Tensor{Any}, x) for x = values_]
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, concat_dim_)
                tf.add_input(desc, values_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function concat(concat_dim_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("Concat")
        tf.add_input(desc, concat_dim_)
        tf.add_input(desc, values_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     data_format_dim_map(x; src_format=NHWC, dst_format=NCHW)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function data_format_dim_map(x_; name=nothing, src_format=nothing, dst_format=nothing)
            local desc
            tf.with_op_name(name, "DataFormatDimMap") do 
                desc = tf.NodeDescription("DataFormatDimMap")
                x_ = convert(Tensor{Int32}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
                if src_format !== nothing
                    desc["src_format"] = Base.String(src_format)
                end
                if dst_format !== nothing
                    desc["dst_format"] = Base.String(dst_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function data_format_dim_map(x_::tf.TensorHandle; name=nothing, src_format=nothing, dst_format=nothing)
        desc = tf.EagerOp("DataFormatDimMap")
        tf.add_input(desc, x_)
        if src_format !== nothing
            desc["src_format"] = Base.String(src_format)
        end
        if dst_format !== nothing
            desc["dst_format"] = Base.String(dst_format)
        end
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     identity_reader(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function identity_reader(; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "IdentityReader") do 
                desc = tf.NodeDescription("IdentityReader")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function identity_reader(; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("IdentityReader")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     softplus(features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function softplus(features_; name=nothing)
            local desc
            tf.with_op_name(name, "Softplus") do 
                desc = tf.NodeDescription("Softplus")
                features_ = convert(Tensor{Any}, features_)
                (features_,) = tf.tf_promote(features_)
                tf.add_input(desc, features_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function softplus(features_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Softplus")
        tf.add_input(desc, features_)
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_sparse_apply_proximal_adagrad(var, accum, lr, l1, l2, grad, indices; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_sparse_apply_proximal_adagrad(var_, accum_, lr_, l1_, l2_, grad_, indices_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceSparseApplyProximalAdagrad") do 
                desc = tf.NodeDescription("ResourceSparseApplyProximalAdagrad")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (lr_, l1_, l2_, grad_) = tf.tf_promote(lr_, l1_, l2_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_sparse_apply_proximal_adagrad(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceSparseApplyProximalAdagrad")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     parse_single_sequence_example(serialized, feature_list_dense_missing_assumed_empty, context_sparse_keys, context_dense_keys, feature_list_sparse_keys, feature_list_dense_keys, context_dense_defaults, debug_name; Ncontext_sparse=0, Ncontext_dense=0, Nfeature_list_sparse=0, Nfeature_list_dense=0, context_sparse_types=Int64[], Tcontext_dense=Int64[], feature_list_dense_types=Int64[], context_dense_shapes=Int64[], feature_list_sparse_types=Int64[], feature_list_dense_shapes=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function parse_single_sequence_example(serialized_, feature_list_dense_missing_assumed_empty_, context_sparse_keys_, context_dense_keys_, feature_list_sparse_keys_, feature_list_dense_keys_, context_dense_defaults_, debug_name_; name=nothing, Ncontext_sparse=nothing, Ncontext_dense=nothing, Nfeature_list_sparse=nothing, Nfeature_list_dense=nothing, context_sparse_types=nothing, Tcontext_dense=nothing, feature_list_dense_types=nothing, context_dense_shapes=nothing, feature_list_sparse_types=nothing, feature_list_dense_shapes=nothing)
            local desc
            tf.with_op_name(name, "ParseSingleSequenceExample") do 
                desc = tf.NodeDescription("ParseSingleSequenceExample")
                serialized_ = convert(Tensor{String}, serialized_)
                feature_list_dense_missing_assumed_empty_ = convert(Tensor{String}, feature_list_dense_missing_assumed_empty_)
                context_sparse_keys_ = [convert(Tensor{String}, x) for x = context_sparse_keys_]
                context_dense_keys_ = [convert(Tensor{String}, x) for x = context_dense_keys_]
                feature_list_sparse_keys_ = [convert(Tensor{String}, x) for x = feature_list_sparse_keys_]
                feature_list_dense_keys_ = [convert(Tensor{String}, x) for x = feature_list_dense_keys_]
                context_dense_defaults_ = [convert(Tensor{Any}, x) for x = context_dense_defaults_]
                debug_name_ = convert(Tensor{String}, debug_name_)
                tf.add_input(desc, serialized_)
                tf.add_input(desc, feature_list_dense_missing_assumed_empty_)
                tf.add_input(desc, context_sparse_keys_)
                tf.add_input(desc, context_dense_keys_)
                tf.add_input(desc, feature_list_sparse_keys_)
                tf.add_input(desc, feature_list_dense_keys_)
                tf.add_input(desc, context_dense_defaults_)
                tf.add_input(desc, debug_name_)
                if Ncontext_sparse !== nothing
                    desc["Ncontext_sparse"] = Base.Int(Ncontext_sparse)
                end
                if Ncontext_dense !== nothing
                    desc["Ncontext_dense"] = Base.Int(Ncontext_dense)
                end
                if Nfeature_list_sparse !== nothing
                    desc["Nfeature_list_sparse"] = Base.Int(Nfeature_list_sparse)
                end
                if Nfeature_list_dense !== nothing
                    desc["Nfeature_list_dense"] = Base.Int(Nfeature_list_dense)
                end
                if context_sparse_types !== nothing
                    desc["context_sparse_types"] = map(Base.identity, context_sparse_types)
                end
                if Tcontext_dense !== nothing
                    desc["Tcontext_dense"] = map(Base.identity, Tcontext_dense)
                end
                if feature_list_dense_types !== nothing
                    desc["feature_list_dense_types"] = map(Base.identity, feature_list_dense_types)
                end
                if context_dense_shapes !== nothing
                    desc["context_dense_shapes"] = map(Base.identity, context_dense_shapes)
                end
                if feature_list_sparse_types !== nothing
                    desc["feature_list_sparse_types"] = map(Base.identity, feature_list_sparse_types)
                end
                if feature_list_dense_shapes !== nothing
                    desc["feature_list_dense_shapes"] = map(Base.identity, feature_list_dense_shapes)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:8
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function parse_single_sequence_example(serialized_::tf.TensorHandle, feature_list_dense_missing_assumed_empty_::tf.TensorHandle, context_sparse_keys_::tf.TensorHandle, context_dense_keys_::tf.TensorHandle, feature_list_sparse_keys_::tf.TensorHandle, feature_list_dense_keys_::tf.TensorHandle, context_dense_defaults_::tf.TensorHandle, debug_name_::tf.TensorHandle; name=nothing, Ncontext_sparse=nothing, Ncontext_dense=nothing, Nfeature_list_sparse=nothing, Nfeature_list_dense=nothing, context_sparse_types=nothing, Tcontext_dense=nothing, feature_list_dense_types=nothing, context_dense_shapes=nothing, feature_list_sparse_types=nothing, feature_list_dense_shapes=nothing)
        desc = tf.EagerOp("ParseSingleSequenceExample")
        tf.add_input(desc, serialized_)
        tf.add_input(desc, feature_list_dense_missing_assumed_empty_)
        tf.add_input(desc, context_sparse_keys_)
        tf.add_input(desc, context_dense_keys_)
        tf.add_input(desc, feature_list_sparse_keys_)
        tf.add_input(desc, feature_list_dense_keys_)
        tf.add_input(desc, context_dense_defaults_)
        tf.add_input(desc, debug_name_)
        if Ncontext_sparse !== nothing
            desc["Ncontext_sparse"] = Base.Int(Ncontext_sparse)
        end
        if Ncontext_dense !== nothing
            desc["Ncontext_dense"] = Base.Int(Ncontext_dense)
        end
        if Nfeature_list_sparse !== nothing
            desc["Nfeature_list_sparse"] = Base.Int(Nfeature_list_sparse)
        end
        if Nfeature_list_dense !== nothing
            desc["Nfeature_list_dense"] = Base.Int(Nfeature_list_dense)
        end
        if context_sparse_types !== nothing
            desc["context_sparse_types"] = map(Base.identity, context_sparse_types)
        end
        if Tcontext_dense !== nothing
            desc["Tcontext_dense"] = map(Base.identity, Tcontext_dense)
        end
        if feature_list_dense_types !== nothing
            desc["feature_list_dense_types"] = map(Base.identity, feature_list_dense_types)
        end
        if context_dense_shapes !== nothing
            desc["context_dense_shapes"] = map(Base.identity, context_dense_shapes)
        end
        if feature_list_sparse_types !== nothing
            desc["feature_list_sparse_types"] = map(Base.identity, feature_list_sparse_types)
        end
        if feature_list_dense_shapes !== nothing
            desc["feature_list_dense_shapes"] = map(Base.identity, feature_list_dense_shapes)
        end
        tf.execute(desc)
    end
end


"""
     matrix_diag(diagonal)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_diag(diagonal_; name=nothing)
            local desc
            tf.with_op_name(name, "MatrixDiag") do 
                desc = tf.NodeDescription("MatrixDiag")
                diagonal_ = convert(Tensor{Any}, diagonal_)
                (diagonal_,) = tf.tf_promote(diagonal_)
                tf.add_input(desc, diagonal_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_diag(diagonal_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MatrixDiag")
        tf.add_input(desc, diagonal_)
        desc["T"] = tf.data_type(diagonal_)
        (tf.execute(desc))[1]
    end
end


"""
     fact()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fact(; name=nothing)
            local desc
            tf.with_op_name(name, "Fact") do 
                desc
                tf.NodeDescription("Fact")
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fact(; name=nothing)
        desc = tf.EagerOp("Fact")
        (tf.execute(desc))[1]
    end
end


"""
     shard_dataset(input_dataset, num_shards, index)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function shard_dataset(input_dataset_, num_shards_, index_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ShardDataset") do 
                desc = tf.NodeDescription("ShardDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                num_shards_ = convert(Tensor{Int64}, num_shards_)
                index_ = convert(Tensor{Int64}, index_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, num_shards_)
                tf.add_input(desc, index_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function shard_dataset(input_dataset_::tf.TensorHandle, num_shards_::tf.TensorHandle, index_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ShardDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, num_shards_)
        tf.add_input(desc, index_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     max_pool_grad_grad(orig_input, orig_output, grad; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool_grad_grad(orig_input_, orig_output_, grad_; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "MaxPoolGradGrad") do 
                desc = tf.NodeDescription("MaxPoolGradGrad")
                orig_input_ = convert(Tensor{Any}, orig_input_)
                orig_output_ = convert(Tensor{Any}, orig_output_)
                grad_ = convert(Tensor{Any}, grad_)
                (orig_input_, orig_output_, grad_) = tf.tf_promote(orig_input_, orig_output_, grad_)
                tf.add_input(desc, orig_input_)
                tf.add_input(desc, orig_output_)
                tf.add_input(desc, grad_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max_pool_grad_grad(orig_input_::tf.TensorHandle, orig_output_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("MaxPoolGradGrad")
        tf.add_input(desc, orig_input_)
        tf.add_input(desc, orig_output_)
        tf.add_input(desc, grad_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(orig_input_)
        desc["T"] = tf.data_type(orig_output_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     resize_bilinear_grad(grads, original_image; align_corners=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resize_bilinear_grad(grads_, original_image_; name=nothing, align_corners=nothing)
            local desc
            tf.with_op_name(name, "ResizeBilinearGrad") do 
                desc = tf.NodeDescription("ResizeBilinearGrad")
                grads_ = convert(Tensor{Float32}, grads_)
                original_image_ = convert(Tensor{Any}, original_image_)
                (original_image_,) = tf.tf_promote(original_image_)
                tf.add_input(desc, grads_)
                tf.add_input(desc, original_image_)
                if align_corners !== nothing
                    desc["align_corners"] = Base.Bool(align_corners)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resize_bilinear_grad(grads_::tf.TensorHandle, original_image_::tf.TensorHandle; name=nothing, align_corners=nothing)
        desc = tf.EagerOp("ResizeBilinearGrad")
        tf.add_input(desc, grads_)
        tf.add_input(desc, original_image_)
        if align_corners !== nothing
            desc["align_corners"] = Base.Bool(align_corners)
        end
        desc["T"] = tf.data_type(original_image_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_to_space(input, crops)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_to_space(input_, crops_; name=nothing, block_size=nothing)
            local desc
            tf.with_op_name(name, "BatchToSpace") do 
                desc = tf.NodeDescription("BatchToSpace")
                input_ = convert(Tensor{Any}, input_)
                crops_ = convert(Tensor{Int32}, crops_)
                crops_ = crops_ - convert(tf.Tensor{eltype(crops_)}, 1)
                (input_,) = tf.tf_promote(input_)
                (crops_,) = tf.tf_promote(crops_)
                tf.add_input(desc, input_)
                tf.add_input(desc, crops_)
                if block_size !== nothing
                    desc["block_size"] = Base.Int(block_size)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_to_space(input_::tf.TensorHandle, crops_::tf.TensorHandle; name=nothing, block_size=nothing)
        desc = tf.EagerOp("BatchToSpace")
        tf.add_input(desc, input_)
        tf.add_input(desc, crops_)
        if block_size !== nothing
            desc["block_size"] = Base.Int(block_size)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tidx"] = tf.data_type(crops_)
        (tf.execute(desc))[1]
    end
end


"""
     optional_from_value(components)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function optional_from_value(components_; name=nothing, Toutput_types=nothing)
            local desc
            tf.with_op_name(name, "OptionalFromValue") do 
                desc = tf.NodeDescription("OptionalFromValue")
                components_ = [convert(Tensor{Any}, x) for x = components_]
                tf.add_input(desc, components_)
                if Toutput_types !== nothing
                    desc["Toutput_types"] = map(Base.identity, Toutput_types)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function optional_from_value(components_::tf.TensorHandle; name=nothing, Toutput_types=nothing)
        desc = tf.EagerOp("OptionalFromValue")
        tf.add_input(desc, components_)
        if Toutput_types !== nothing
            desc["Toutput_types"] = map(Base.identity, Toutput_types)
        end
        (tf.execute(desc))[1]
    end
end


"""
     xlogy(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function xlogy(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Xlogy") do 
                desc = tf.NodeDescription("Xlogy")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function xlogy(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Xlogy")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     cross(a, b)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cross(a_, b_; name=nothing)
            local desc
            tf.with_op_name(name, "Cross") do 
                desc = tf.NodeDescription("Cross")
                a_ = convert(Tensor{Any}, a_)
                b_ = convert(Tensor{Any}, b_)
                (a_, b_) = tf.tf_promote(a_, b_)
                tf.add_input(desc, a_)
                tf.add_input(desc, b_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cross(a_::tf.TensorHandle, b_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Cross")
        tf.add_input(desc, a_)
        tf.add_input(desc, b_)
        desc["T"] = tf.data_type(a_)
        desc["T"] = tf.data_type(b_)
        (tf.execute(desc))[1]
    end
end


"""
     bitwise_and(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function bitwise_and(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "BitwiseAnd") do 
                desc = tf.NodeDescription("BitwiseAnd")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function bitwise_and(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BitwiseAnd")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     broadcast_to(input, shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function broadcast_to(input_, shape_; name=nothing)
            local desc
            tf.with_op_name(name, "BroadcastTo") do 
                desc = tf.NodeDescription("BroadcastTo")
                input_ = convert(Tensor{Any}, input_)
                shape_ = convert(Tensor{Int32}, shape_)
                (input_,) = tf.tf_promote(input_)
                (shape_,) = tf.tf_promote(shape_)
                tf.add_input(desc, input_)
                tf.add_input(desc, shape_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function broadcast_to(input_::tf.TensorHandle, shape_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BroadcastTo")
        tf.add_input(desc, input_)
        tf.add_input(desc, shape_)
        desc["T"] = tf.data_type(input_)
        desc["Tidx"] = tf.data_type(shape_)
        (tf.execute(desc))[1]
    end
end


"""
     elu_grad(gradients, outputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function elu_grad(gradients_, outputs_; name=nothing)
            local desc
            tf.with_op_name(name, "EluGrad") do 
                desc = tf.NodeDescription("EluGrad")
                gradients_ = convert(Tensor{Any}, gradients_)
                outputs_ = convert(Tensor{Any}, outputs_)
                (gradients_, outputs_) = tf.tf_promote(gradients_, outputs_)
                tf.add_input(desc, gradients_)
                tf.add_input(desc, outputs_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function elu_grad(gradients_::tf.TensorHandle, outputs_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("EluGrad")
        tf.add_input(desc, gradients_)
        tf.add_input(desc, outputs_)
        desc["T"] = tf.data_type(gradients_)
        desc["T"] = tf.data_type(outputs_)
        (tf.execute(desc))[1]
    end
end


"""
     cudnn_rnn_backprop(input, input_h, input_c, params, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space; rnn_mode=lstm, input_mode=linear_input, direction=unidirectional, dropout=?, seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cudnn_rnn_backprop(input_, input_h_, input_c_, params_, output_, output_h_, output_c_, output_backprop_, output_h_backprop_, output_c_backprop_, reserve_space_; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "CudnnRNNBackprop") do 
                desc = tf.NodeDescription("CudnnRNNBackprop")
                input_ = convert(Tensor{Any}, input_)
                input_h_ = convert(Tensor{Any}, input_h_)
                input_c_ = convert(Tensor{Any}, input_c_)
                params_ = convert(Tensor{Any}, params_)
                output_ = convert(Tensor{Any}, output_)
                output_h_ = convert(Tensor{Any}, output_h_)
                output_c_ = convert(Tensor{Any}, output_c_)
                output_backprop_ = convert(Tensor{Any}, output_backprop_)
                output_h_backprop_ = convert(Tensor{Any}, output_h_backprop_)
                output_c_backprop_ = convert(Tensor{Any}, output_c_backprop_)
                reserve_space_ = convert(Tensor{Any}, reserve_space_)
                (input_, input_h_, input_c_, params_, output_, output_h_, output_c_, output_backprop_, output_h_backprop_, output_c_backprop_, reserve_space_) = tf.tf_promote(input_, input_h_, input_c_, params_, output_, output_h_, output_c_, output_backprop_, output_h_backprop_, output_c_backprop_, reserve_space_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_h_)
                tf.add_input(desc, input_c_)
                tf.add_input(desc, params_)
                tf.add_input(desc, output_)
                tf.add_input(desc, output_h_)
                tf.add_input(desc, output_c_)
                tf.add_input(desc, output_backprop_)
                tf.add_input(desc, output_h_backprop_)
                tf.add_input(desc, output_c_backprop_)
                tf.add_input(desc, reserve_space_)
                if rnn_mode !== nothing
                    desc["rnn_mode"] = Base.String(rnn_mode)
                end
                if input_mode !== nothing
                    desc["input_mode"] = Base.String(input_mode)
                end
                if direction !== nothing
                    desc["direction"] = Base.String(direction)
                end
                if dropout !== nothing
                    desc["dropout"] = Base.identity(dropout)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function cudnn_rnn_backprop(input_::tf.TensorHandle, input_h_::tf.TensorHandle, input_c_::tf.TensorHandle, params_::tf.TensorHandle, output_::tf.TensorHandle, output_h_::tf.TensorHandle, output_c_::tf.TensorHandle, output_backprop_::tf.TensorHandle, output_h_backprop_::tf.TensorHandle, output_c_backprop_::tf.TensorHandle, reserve_space_::tf.TensorHandle; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("CudnnRNNBackprop")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_h_)
        tf.add_input(desc, input_c_)
        tf.add_input(desc, params_)
        tf.add_input(desc, output_)
        tf.add_input(desc, output_h_)
        tf.add_input(desc, output_c_)
        tf.add_input(desc, output_backprop_)
        tf.add_input(desc, output_h_backprop_)
        tf.add_input(desc, output_c_backprop_)
        tf.add_input(desc, reserve_space_)
        if rnn_mode !== nothing
            desc["rnn_mode"] = Base.String(rnn_mode)
        end
        if input_mode !== nothing
            desc["input_mode"] = Base.String(input_mode)
        end
        if direction !== nothing
            desc["direction"] = Base.String(direction)
        end
        if dropout !== nothing
            desc["dropout"] = Base.identity(dropout)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(input_h_)
        desc["T"] = tf.data_type(input_c_)
        desc["T"] = tf.data_type(params_)
        desc["T"] = tf.data_type(output_)
        desc["T"] = tf.data_type(output_h_)
        desc["T"] = tf.data_type(output_c_)
        desc["T"] = tf.data_type(output_backprop_)
        desc["T"] = tf.data_type(output_h_backprop_)
        desc["T"] = tf.data_type(output_c_backprop_)
        desc["T"] = tf.data_type(reserve_space_)
        tf.execute(desc)
    end
end


"""
     string_to_hash_bucket_fast(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function string_to_hash_bucket_fast(input_; name=nothing, num_buckets=nothing)
            local desc
            tf.with_op_name(name, "StringToHashBucketFast") do 
                desc = tf.NodeDescription("StringToHashBucketFast")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
                if num_buckets !== nothing
                    desc["num_buckets"] = Base.Int(num_buckets)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function string_to_hash_bucket_fast(input_::tf.TensorHandle; name=nothing, num_buckets=nothing)
        desc = tf.EagerOp("StringToHashBucketFast")
        tf.add_input(desc, input_)
        if num_buckets !== nothing
            desc["num_buckets"] = Base.Int(num_buckets)
        end
        (tf.execute(desc))[1]
    end
end


"""
     mutable_hash_table(; container=, shared_name=, use_node_name_sharing=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mutable_hash_table(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing)
            local desc
            tf.with_op_name(name, "MutableHashTable") do 
                desc = tf.NodeDescription("MutableHashTable")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if use_node_name_sharing !== nothing
                    desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
                end
                if key_dtype !== nothing
                    desc["key_dtype"] = Base.identity(key_dtype)
                end
                if value_dtype !== nothing
                    desc["value_dtype"] = Base.identity(value_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mutable_hash_table(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing)
        desc = tf.EagerOp("MutableHashTable")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if use_node_name_sharing !== nothing
            desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
        end
        if key_dtype !== nothing
            desc["key_dtype"] = Base.identity(key_dtype)
        end
        if value_dtype !== nothing
            desc["value_dtype"] = Base.identity(value_dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     relu(features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function relu(features_; name=nothing)
            local desc
            tf.with_op_name(name, "Relu") do 
                desc = tf.NodeDescription("Relu")
                features_ = convert(Tensor{Any}, features_)
                (features_,) = tf.tf_promote(features_)
                tf.add_input(desc, features_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function relu(features_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Relu")
        tf.add_input(desc, features_)
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     nth_element(input, n; reverse=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function nth_element(input_, n_; name=nothing, reverse=nothing)
            local desc
            tf.with_op_name(name, "NthElement") do 
                desc = tf.NodeDescription("NthElement")
                input_ = convert(Tensor{Any}, input_)
                n_ = convert(Tensor{Int32}, n_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, n_)
                if reverse !== nothing
                    desc["reverse"] = Base.Bool(reverse)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function nth_element(input_::tf.TensorHandle, n_::tf.TensorHandle; name=nothing, reverse=nothing)
        desc = tf.EagerOp("NthElement")
        tf.add_input(desc, input_)
        tf.add_input(desc, n_)
        if reverse !== nothing
            desc["reverse"] = Base.Bool(reverse)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     softsign(features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function softsign(features_; name=nothing)
            local desc
            tf.with_op_name(name, "Softsign") do 
                desc = tf.NodeDescription("Softsign")
                features_ = convert(Tensor{Any}, features_)
                (features_,) = tf.tf_promote(features_)
                tf.add_input(desc, features_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function softsign(features_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Softsign")
        tf.add_input(desc, features_)
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     mutable_dense_hash_table(empty_key; container=, shared_name=, use_node_name_sharing=false, value_shape=?, initial_num_buckets=131072, max_load_factor=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mutable_dense_hash_table(empty_key_; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing, value_shape=nothing, initial_num_buckets=nothing, max_load_factor=nothing)
            local desc
            tf.with_op_name(name, "MutableDenseHashTable") do 
                desc = tf.NodeDescription("MutableDenseHashTable")
                empty_key_ = convert(Tensor{Any}, empty_key_)
                (empty_key_,) = tf.tf_promote(empty_key_)
                tf.add_input(desc, empty_key_)
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if use_node_name_sharing !== nothing
                    desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
                end
                if key_dtype !== nothing
                    desc["key_dtype"] = Base.identity(key_dtype)
                end
                if value_dtype !== nothing
                    desc["value_dtype"] = Base.identity(value_dtype)
                end
                if value_shape !== nothing
                    desc["value_shape"] = Base.identity(value_shape)
                end
                if initial_num_buckets !== nothing
                    desc["initial_num_buckets"] = Base.Int(initial_num_buckets)
                end
                if max_load_factor !== nothing
                    desc["max_load_factor"] = Base.identity(max_load_factor)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mutable_dense_hash_table(empty_key_::tf.TensorHandle; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing, value_shape=nothing, initial_num_buckets=nothing, max_load_factor=nothing)
        desc = tf.EagerOp("MutableDenseHashTable")
        tf.add_input(desc, empty_key_)
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if use_node_name_sharing !== nothing
            desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
        end
        if key_dtype !== nothing
            desc["key_dtype"] = Base.identity(key_dtype)
        end
        if value_dtype !== nothing
            desc["value_dtype"] = Base.identity(value_dtype)
        end
        if value_shape !== nothing
            desc["value_shape"] = Base.identity(value_shape)
        end
        if initial_num_buckets !== nothing
            desc["initial_num_buckets"] = Base.Int(initial_num_buckets)
        end
        if max_load_factor !== nothing
            desc["max_load_factor"] = Base.identity(max_load_factor)
        end
        desc["key_dtype"] = tf.data_type(empty_key_)
        (tf.execute(desc))[1]
    end
end


"""
     _shutdown_distributed_tpu()

An op that shuts down a running distributed TPU system. The Op returns
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _shutdown_distributed_tpu(; name=nothing)
            local desc
            tf.with_op_name(name, "_ShutdownDistributedTPU") do 
                desc
                tf.NodeDescription("_ShutdownDistributedTPU")
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _shutdown_distributed_tpu(; name=nothing)
        desc = tf.EagerOp("_ShutdownDistributedTPU")
        (tf.execute(desc))[1]
    end
end


"""
     polygamma(a, x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function polygamma(a_, x_; name=nothing)
            local desc
            tf.with_op_name(name, "Polygamma") do 
                desc = tf.NodeDescription("Polygamma")
                a_ = convert(Tensor{Any}, a_)
                x_ = convert(Tensor{Any}, x_)
                (a_, x_) = tf.tf_promote(a_, x_)
                tf.add_input(desc, a_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function polygamma(a_::tf.TensorHandle, x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Polygamma")
        tf.add_input(desc, a_)
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(a_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     nccl_reduce(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function nccl_reduce(input_; name=nothing, reduction=nothing, num_devices=nothing)
            local desc
            tf.with_op_name(name, "NcclReduce") do 
                desc = tf.NodeDescription("NcclReduce")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if reduction !== nothing
                    desc["reduction"] = Base.String(reduction)
                end
                if num_devices !== nothing
                    desc["num_devices"] = Base.Int(num_devices)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function nccl_reduce(input_::tf.TensorHandle; name=nothing, reduction=nothing, num_devices=nothing)
        desc = tf.EagerOp("NcclReduce")
        tf.add_input(desc, input_)
        if reduction !== nothing
            desc["reduction"] = Base.String(reduction)
        end
        if num_devices !== nothing
            desc["num_devices"] = Base.Int(num_devices)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     arg_max(input, dimension; output_type=Int64)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function arg_max(input_, dimension_; name=nothing, output_type=nothing)
            local desc
            tf.with_op_name(name, "ArgMax") do 
                desc = tf.NodeDescription("ArgMax")
                input_ = convert(Tensor{Any}, input_)
                dimension_ = convert(Tensor{Int32}, dimension_)
                dimension_ = dimension_ - convert(tf.Tensor{eltype(dimension_)}, 1)
                (input_,) = tf.tf_promote(input_)
                (dimension_,) = tf.tf_promote(dimension_)
                tf.add_input(desc, input_)
                tf.add_input(desc, dimension_)
                if output_type !== nothing
                    desc["output_type"] = Base.identity(output_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function arg_max(input_::tf.TensorHandle, dimension_::tf.TensorHandle; name=nothing, output_type=nothing)
        desc = tf.EagerOp("ArgMax")
        tf.add_input(desc, input_)
        tf.add_input(desc, dimension_)
        if output_type !== nothing
            desc["output_type"] = Base.identity(output_type)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tidx"] = tf.data_type(dimension_)
        (tf.execute(desc))[1]
    end
end


"""
     matrix_set_diag(input, diagonal)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_set_diag(input_, diagonal_; name=nothing)
            local desc
            tf.with_op_name(name, "MatrixSetDiag") do 
                desc = tf.NodeDescription("MatrixSetDiag")
                input_ = convert(Tensor{Any}, input_)
                diagonal_ = convert(Tensor{Any}, diagonal_)
                (input_, diagonal_) = tf.tf_promote(input_, diagonal_)
                tf.add_input(desc, input_)
                tf.add_input(desc, diagonal_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_set_diag(input_::tf.TensorHandle, diagonal_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MatrixSetDiag")
        tf.add_input(desc, input_)
        tf.add_input(desc, diagonal_)
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(diagonal_)
        (tf.execute(desc))[1]
    end
end


"""
     space_to_batch_nd(input, block_shape, paddings)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function space_to_batch_nd(input_, block_shape_, paddings_; name=nothing)
            local desc
            tf.with_op_name(name, "SpaceToBatchND") do 
                desc = tf.NodeDescription("SpaceToBatchND")
                input_ = convert(Tensor{Any}, input_)
                block_shape_ = convert(Tensor{Int32}, block_shape_)
                paddings_ = convert(Tensor{Int32}, paddings_)
                (input_,) = tf.tf_promote(input_)
                (paddings_,) = tf.tf_promote(paddings_)
                (block_shape_,) = tf.tf_promote(block_shape_)
                tf.add_input(desc, input_)
                tf.add_input(desc, block_shape_)
                tf.add_input(desc, paddings_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function space_to_batch_nd(input_::tf.TensorHandle, block_shape_::tf.TensorHandle, paddings_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SpaceToBatchND")
        tf.add_input(desc, input_)
        tf.add_input(desc, block_shape_)
        tf.add_input(desc, paddings_)
        desc["T"] = tf.data_type(input_)
        desc["Tblock_shape"] = tf.data_type(block_shape_)
        desc["Tpaddings"] = tf.data_type(paddings_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_reshape(input_indices, input_shape, new_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_reshape(input_indices_, input_shape_, new_shape_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseReshape") do 
                desc = tf.NodeDescription("SparseReshape")
                input_indices_ = convert(Tensor{Int64}, input_indices_)
                input_shape_ = convert(Tensor{Int64}, input_shape_)
                new_shape_ = convert(Tensor{Int64}, new_shape_)
                tf.add_input(desc, input_indices_)
                tf.add_input(desc, input_shape_)
                tf.add_input(desc, new_shape_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_reshape(input_indices_::tf.TensorHandle, input_shape_::tf.TensorHandle, new_shape_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseReshape")
        tf.add_input(desc, input_indices_)
        tf.add_input(desc, input_shape_)
        tf.add_input(desc, new_shape_)
        tf.execute(desc)
    end
end


"""
     optimize_dataset(input_dataset, optimizations)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function optimize_dataset(input_dataset_, optimizations_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "OptimizeDataset") do 
                desc = tf.NodeDescription("OptimizeDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                optimizations_ = convert(Tensor{String}, optimizations_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, optimizations_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function optimize_dataset(input_dataset_::tf.TensorHandle, optimizations_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("OptimizeDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, optimizations_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     concat_v2(values, axis)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function concat_v2(values_, axis_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "ConcatV2") do 
                desc = tf.NodeDescription("ConcatV2")
                values_ = [convert(Tensor{Any}, x) for x = values_]
                axis_ = convert(Tensor{Int32}, axis_)
                axis_ = axis_ - convert(tf.Tensor{eltype(axis_)}, 1)
                (values_,) = tf.tf_promote(values_)
                (axis_,) = tf.tf_promote(axis_)
                tf.add_input(desc, values_)
                tf.add_input(desc, axis_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function concat_v2(values_::tf.TensorHandle, axis_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("ConcatV2")
        tf.add_input(desc, values_)
        tf.add_input(desc, axis_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(values_)
        desc["Tidx"] = tf.data_type(axis_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_sparse_apply_adadelta(var, accum, accum_update, lr, rho, epsilon, grad, indices; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_sparse_apply_adadelta(var_, accum_, accum_update_, lr_, rho_, epsilon_, grad_, indices_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceSparseApplyAdadelta") do 
                desc = tf.NodeDescription("ResourceSparseApplyAdadelta")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                accum_update_ = convert(Tensor{Any}, accum_update_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (lr_, rho_, epsilon_, grad_) = tf.tf_promote(lr_, rho_, epsilon_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, accum_update_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_sparse_apply_adadelta(var_::tf.TensorHandle, accum_::tf.TensorHandle, accum_update_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceSparseApplyAdadelta")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, accum_update_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     tile(input, multiples)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tile(input_, multiples_; name=nothing)
            local desc
            tf.with_op_name(name, "Tile") do 
                desc = tf.NodeDescription("Tile")
                input_ = convert(Tensor{Any}, input_)
                multiples_ = convert(Tensor{Int32}, multiples_)
                (input_,) = tf.tf_promote(input_)
                (multiples_,) = tf.tf_promote(multiples_)
                tf.add_input(desc, input_)
                tf.add_input(desc, multiples_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tile(input_::tf.TensorHandle, multiples_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Tile")
        tf.add_input(desc, input_)
        tf.add_input(desc, multiples_)
        desc["T"] = tf.data_type(input_)
        desc["Tmultiples"] = tf.data_type(multiples_)
        (tf.execute(desc))[1]
    end
end


"""
     mutex_v2(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mutex_v2(; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "MutexV2") do 
                desc = tf.NodeDescription("MutexV2")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mutex_v2(; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("MutexV2")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     serialize_many_sparse(sparse_indices, sparse_values, sparse_shape; out_type=String)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function serialize_many_sparse(sparse_indices_, sparse_values_, sparse_shape_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "SerializeManySparse") do 
                desc = tf.NodeDescription("SerializeManySparse")
                sparse_indices_ = convert(Tensor{Int64}, sparse_indices_)
                sparse_values_ = convert(Tensor{Any}, sparse_values_)
                sparse_shape_ = convert(Tensor{Int64}, sparse_shape_)
                (sparse_values_,) = tf.tf_promote(sparse_values_)
                tf.add_input(desc, sparse_indices_)
                tf.add_input(desc, sparse_values_)
                tf.add_input(desc, sparse_shape_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function serialize_many_sparse(sparse_indices_::tf.TensorHandle, sparse_values_::tf.TensorHandle, sparse_shape_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("SerializeManySparse")
        tf.add_input(desc, sparse_indices_)
        tf.add_input(desc, sparse_values_)
        tf.add_input(desc, sparse_shape_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["T"] = tf.data_type(sparse_values_)
        (tf.execute(desc))[1]
    end
end


"""
     tpu_embedding_activations(embedding_variable, sliced_activations)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tpu_embedding_activations(embedding_variable_, sliced_activations_; name=nothing, table_id=nothing, lookup_id=nothing)
            local desc
            tf.with_op_name(name, "TPUEmbeddingActivations") do 
                desc = tf.NodeDescription("TPUEmbeddingActivations")
                embedding_variable_ = convert(Tensor{Float32}, embedding_variable_)
                sliced_activations_ = convert(Tensor{Float32}, sliced_activations_)
                tf.add_input(desc, embedding_variable_)
                tf.add_input(desc, sliced_activations_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if lookup_id !== nothing
                    desc["lookup_id"] = Base.Int(lookup_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tpu_embedding_activations(embedding_variable_::tf.TensorHandle, sliced_activations_::tf.TensorHandle; name=nothing, table_id=nothing, lookup_id=nothing)
        desc = tf.EagerOp("TPUEmbeddingActivations")
        tf.add_input(desc, embedding_variable_)
        tf.add_input(desc, sliced_activations_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if lookup_id !== nothing
            desc["lookup_id"] = Base.Int(lookup_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     batch_matrix_solve_ls(matrix, rhs, l2_regularizer; fast=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_matrix_solve_ls(matrix_, rhs_, l2_regularizer_; name=nothing, fast=nothing)
            local desc
            tf.with_op_name(name, "BatchMatrixSolveLs") do 
                desc = tf.NodeDescription("BatchMatrixSolveLs")
                matrix_ = convert(Tensor{Any}, matrix_)
                rhs_ = convert(Tensor{Any}, rhs_)
                l2_regularizer_ = convert(Tensor{Float64}, l2_regularizer_)
                (matrix_, rhs_) = tf.tf_promote(matrix_, rhs_)
                tf.add_input(desc, matrix_)
                tf.add_input(desc, rhs_)
                tf.add_input(desc, l2_regularizer_)
                if fast !== nothing
                    desc["fast"] = Base.Bool(fast)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_matrix_solve_ls(matrix_::tf.TensorHandle, rhs_::tf.TensorHandle, l2_regularizer_::tf.TensorHandle; name=nothing, fast=nothing)
        desc = tf.EagerOp("BatchMatrixSolveLs")
        tf.add_input(desc, matrix_)
        tf.add_input(desc, rhs_)
        tf.add_input(desc, l2_regularizer_)
        if fast !== nothing
            desc["fast"] = Base.Bool(fast)
        end
        desc["T"] = tf.data_type(matrix_)
        desc["T"] = tf.data_type(rhs_)
        (tf.execute(desc))[1]
    end
end


"""
     not_equal(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function not_equal(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "NotEqual") do 
                desc = tf.NodeDescription("NotEqual")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function not_equal(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("NotEqual")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     lgamma(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lgamma(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Lgamma") do 
                desc = tf.NodeDescription("Lgamma")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lgamma(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Lgamma")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     tpu_replicate_metadata(; num_cores_per_replica=1, topology=, use_tpu=true, device_assignment=Int64[], computation_shape=Int64[], host_compute_core=Int64[], padding_map=Int64[], step_marker_location=STEP_MARK_AT_ENTRY)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tpu_replicate_metadata(; name=nothing, num_replicas=nothing, num_cores_per_replica=nothing, topology=nothing, use_tpu=nothing, device_assignment=nothing, computation_shape=nothing, host_compute_core=nothing, padding_map=nothing, step_marker_location=nothing)
            local desc
            tf.with_op_name(name, "TPUReplicateMetadata") do 
                desc = tf.NodeDescription("TPUReplicateMetadata")
                if num_replicas !== nothing
                    desc["num_replicas"] = Base.Int(num_replicas)
                end
                if num_cores_per_replica !== nothing
                    desc["num_cores_per_replica"] = Base.Int(num_cores_per_replica)
                end
                if topology !== nothing
                    desc["topology"] = Base.String(topology)
                end
                if use_tpu !== nothing
                    desc["use_tpu"] = Base.Bool(use_tpu)
                end
                if device_assignment !== nothing
                    desc["device_assignment"] = map(Base.identity, device_assignment)
                end
                if computation_shape !== nothing
                    desc["computation_shape"] = map(Base.identity, computation_shape)
                end
                if host_compute_core !== nothing
                    desc["host_compute_core"] = map(Base.identity, host_compute_core)
                end
                if padding_map !== nothing
                    desc["padding_map"] = map(Base.identity, padding_map)
                end
                if step_marker_location !== nothing
                    desc["step_marker_location"] = Base.String(step_marker_location)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tpu_replicate_metadata(; name=nothing, num_replicas=nothing, num_cores_per_replica=nothing, topology=nothing, use_tpu=nothing, device_assignment=nothing, computation_shape=nothing, host_compute_core=nothing, padding_map=nothing, step_marker_location=nothing)
        desc = tf.EagerOp("TPUReplicateMetadata")
        if num_replicas !== nothing
            desc["num_replicas"] = Base.Int(num_replicas)
        end
        if num_cores_per_replica !== nothing
            desc["num_cores_per_replica"] = Base.Int(num_cores_per_replica)
        end
        if topology !== nothing
            desc["topology"] = Base.String(topology)
        end
        if use_tpu !== nothing
            desc["use_tpu"] = Base.Bool(use_tpu)
        end
        if device_assignment !== nothing
            desc["device_assignment"] = map(Base.identity, device_assignment)
        end
        if computation_shape !== nothing
            desc["computation_shape"] = map(Base.identity, computation_shape)
        end
        if host_compute_core !== nothing
            desc["host_compute_core"] = map(Base.identity, host_compute_core)
        end
        if padding_map !== nothing
            desc["padding_map"] = map(Base.identity, padding_map)
        end
        if step_marker_location !== nothing
            desc["step_marker_location"] = Base.String(step_marker_location)
        end
        (tf.execute(desc))[1]
    end
end


"""
     experimental_thread_pool_handle(; max_intra_op_parallelism=1, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_thread_pool_handle(; name=nothing, num_threads=nothing, max_intra_op_parallelism=nothing, display_name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalThreadPoolHandle") do 
                desc = tf.NodeDescription("ExperimentalThreadPoolHandle")
                if num_threads !== nothing
                    desc["num_threads"] = Base.Int(num_threads)
                end
                if max_intra_op_parallelism !== nothing
                    desc["max_intra_op_parallelism"] = Base.Int(max_intra_op_parallelism)
                end
                if display_name !== nothing
                    desc["display_name"] = Base.String(display_name)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_thread_pool_handle(; name=nothing, num_threads=nothing, max_intra_op_parallelism=nothing, display_name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("ExperimentalThreadPoolHandle")
        if num_threads !== nothing
            desc["num_threads"] = Base.Int(num_threads)
        end
        if max_intra_op_parallelism !== nothing
            desc["max_intra_op_parallelism"] = Base.Int(max_intra_op_parallelism)
        end
        if display_name !== nothing
            desc["display_name"] = Base.String(display_name)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     self_adjoint_eig(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function self_adjoint_eig(input_; name=nothing)
            local desc
            tf.with_op_name(name, "SelfAdjointEig") do 
                desc = tf.NodeDescription("SelfAdjointEig")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function self_adjoint_eig(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SelfAdjointEig")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_quantile_stream_resource_get_bucket_boundaries(quantile_stream_resource_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_quantile_stream_resource_get_bucket_boundaries(quantile_stream_resource_handle_; name=nothing, num_features=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesQuantileStreamResourceGetBucketBoundaries") do 
                desc = tf.NodeDescription("BoostedTreesQuantileStreamResourceGetBucketBoundaries")
                quantile_stream_resource_handle_ = convert(Tensor{Any}, quantile_stream_resource_handle_)
                tf.add_input(desc, quantile_stream_resource_handle_)
                if num_features !== nothing
                    desc["num_features"] = Base.Int(num_features)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:num_features
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function boosted_trees_quantile_stream_resource_get_bucket_boundaries(quantile_stream_resource_handle_::tf.TensorHandle; name=nothing, num_features=nothing)
        desc = tf.EagerOp("BoostedTreesQuantileStreamResourceGetBucketBoundaries")
        tf.add_input(desc, quantile_stream_resource_handle_)
        if num_features !== nothing
            desc["num_features"] = Base.Int(num_features)
        end
        tf.execute(desc)
    end
end


"""
     sparse_dense_cwise_div(sp_indices, sp_values, sp_shape, dense)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_dense_cwise_div(sp_indices_, sp_values_, sp_shape_, dense_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseDenseCwiseDiv") do 
                desc = tf.NodeDescription("SparseDenseCwiseDiv")
                sp_indices_ = convert(Tensor{Int64}, sp_indices_)
                sp_values_ = convert(Tensor{Any}, sp_values_)
                sp_shape_ = convert(Tensor{Int64}, sp_shape_)
                dense_ = convert(Tensor{Any}, dense_)
                (sp_values_, dense_) = tf.tf_promote(sp_values_, dense_)
                tf.add_input(desc, sp_indices_)
                tf.add_input(desc, sp_values_)
                tf.add_input(desc, sp_shape_)
                tf.add_input(desc, dense_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_dense_cwise_div(sp_indices_::tf.TensorHandle, sp_values_::tf.TensorHandle, sp_shape_::tf.TensorHandle, dense_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseDenseCwiseDiv")
        tf.add_input(desc, sp_indices_)
        tf.add_input(desc, sp_values_)
        tf.add_input(desc, sp_shape_)
        tf.add_input(desc, dense_)
        desc["T"] = tf.data_type(sp_values_)
        desc["T"] = tf.data_type(dense_)
        (tf.execute(desc))[1]
    end
end


"""
     acos(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function acos(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Acos") do 
                desc = tf.NodeDescription("Acos")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function acos(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Acos")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     all(input, reduction_indices; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function all(input_, reduction_indices_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "All") do 
                desc = tf.NodeDescription("All")
                input_ = convert(Tensor{Bool}, input_)
                reduction_indices_ = convert(Tensor{Int32}, reduction_indices_)
                reduction_indices_ = reduction_indices_ - convert(tf.Tensor{eltype(reduction_indices_)}, 1)
                (reduction_indices_,) = tf.tf_promote(reduction_indices_)
                tf.add_input(desc, input_)
                tf.add_input(desc, reduction_indices_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function all(input_::tf.TensorHandle, reduction_indices_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("All")
        tf.add_input(desc, input_)
        tf.add_input(desc, reduction_indices_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["Tidx"] = tf.data_type(reduction_indices_)
        (tf.execute(desc))[1]
    end
end


"""
     compare_and_bitpack(input, threshold)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function compare_and_bitpack(input_, threshold_; name=nothing)
            local desc
            tf.with_op_name(name, "CompareAndBitpack") do 
                desc = tf.NodeDescription("CompareAndBitpack")
                input_ = convert(Tensor{Any}, input_)
                threshold_ = convert(Tensor{Any}, threshold_)
                (input_, threshold_) = tf.tf_promote(input_, threshold_)
                tf.add_input(desc, input_)
                tf.add_input(desc, threshold_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function compare_and_bitpack(input_::tf.TensorHandle, threshold_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("CompareAndBitpack")
        tf.add_input(desc, input_)
        tf.add_input(desc, threshold_)
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(threshold_)
        (tf.execute(desc))[1]
    end
end


"""
     var_handle_op(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function var_handle_op(; name=nothing, container=nothing, shared_name=nothing, dtype=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "VarHandleOp") do 
                desc = tf.NodeDescription("VarHandleOp")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function var_handle_op(; name=nothing, container=nothing, shared_name=nothing, dtype=nothing, shape=nothing)
        desc = tf.EagerOp("VarHandleOp")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     experimental_unique_dataset(input_dataset)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_unique_dataset(input_dataset_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalUniqueDataset") do 
                desc = tf.NodeDescription("ExperimentalUniqueDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                tf.add_input(desc, input_dataset_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_unique_dataset(input_dataset_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalUniqueDataset")
        tf.add_input(desc, input_dataset_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     quantized_conv2d_with_bias_sum_and_relu(input, filter, bias, min_input, max_input, min_filter, max_filter, summand; out_type=Float32, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_conv2d_with_bias_sum_and_relu(input_, filter_, bias_, min_input_, max_input_, min_filter_, max_filter_, summand_; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConv2DWithBiasSumAndRelu") do 
                desc = tf.NodeDescription("QuantizedConv2DWithBiasSumAndRelu")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                bias_ = convert(Tensor{Float32}, bias_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_filter_ = convert(Tensor{Float32}, min_filter_)
                max_filter_ = convert(Tensor{Float32}, max_filter_)
                summand_ = convert(Tensor{Float32}, summand_)
                (filter_,) = tf.tf_promote(filter_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, bias_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_filter_)
                tf.add_input(desc, max_filter_)
                tf.add_input(desc, summand_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_conv2d_with_bias_sum_and_relu(input_::tf.TensorHandle, filter_::tf.TensorHandle, bias_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_filter_::tf.TensorHandle, max_filter_::tf.TensorHandle, summand_::tf.TensorHandle; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("QuantizedConv2DWithBiasSumAndRelu")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, bias_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_filter_)
        tf.add_input(desc, max_filter_)
        tf.add_input(desc, summand_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tinput"] = tf.data_type(input_)
        desc["Tfilter"] = tf.data_type(filter_)
        tf.execute(desc)
    end
end


"""
     list_diff(x, y; out_idx=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function list_diff(x_, y_; name=nothing, out_idx=nothing)
            local desc
            tf.with_op_name(name, "ListDiff") do 
                desc = tf.NodeDescription("ListDiff")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
                if out_idx !== nothing
                    desc["out_idx"] = Base.identity(out_idx)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function list_diff(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing, out_idx=nothing)
        desc = tf.EagerOp("ListDiff")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        if out_idx !== nothing
            desc["out_idx"] = Base.identity(out_idx)
        end
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        tf.execute(desc)
    end
end


"""
     create_summary_file_writer(writer, logdir, max_queue, flush_millis, filename_suffix)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function create_summary_file_writer(writer_, logdir_, max_queue_, flush_millis_, filename_suffix_; name=nothing)
            local desc
            tf.with_op_name(name, "CreateSummaryFileWriter") do 
                desc = tf.NodeDescription("CreateSummaryFileWriter")
                writer_ = convert(Tensor{Any}, writer_)
                logdir_ = convert(Tensor{String}, logdir_)
                max_queue_ = convert(Tensor{Int32}, max_queue_)
                flush_millis_ = convert(Tensor{Int32}, flush_millis_)
                filename_suffix_ = convert(Tensor{String}, filename_suffix_)
                tf.add_input(desc, writer_)
                tf.add_input(desc, logdir_)
                tf.add_input(desc, max_queue_)
                tf.add_input(desc, flush_millis_)
                tf.add_input(desc, filename_suffix_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function create_summary_file_writer(writer_::tf.TensorHandle, logdir_::tf.TensorHandle, max_queue_::tf.TensorHandle, flush_millis_::tf.TensorHandle, filename_suffix_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("CreateSummaryFileWriter")
        tf.add_input(desc, writer_)
        tf.add_input(desc, logdir_)
        tf.add_input(desc, max_queue_)
        tf.add_input(desc, flush_millis_)
        tf.add_input(desc, filename_suffix_)
        (tf.execute(desc))[1]
    end
end


"""
     generate_vocab_remapping(new_vocab_file, old_vocab_file; old_vocab_size=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function generate_vocab_remapping(new_vocab_file_, old_vocab_file_; name=nothing, new_vocab_offset=nothing, num_new_vocab=nothing, old_vocab_size=nothing)
            local desc
            tf.with_op_name(name, "GenerateVocabRemapping") do 
                desc = tf.NodeDescription("GenerateVocabRemapping")
                new_vocab_file_ = convert(Tensor{String}, new_vocab_file_)
                old_vocab_file_ = convert(Tensor{String}, old_vocab_file_)
                tf.add_input(desc, new_vocab_file_)
                tf.add_input(desc, old_vocab_file_)
                if new_vocab_offset !== nothing
                    desc["new_vocab_offset"] = Base.Int(new_vocab_offset)
                end
                if num_new_vocab !== nothing
                    desc["num_new_vocab"] = Base.Int(num_new_vocab)
                end
                if old_vocab_size !== nothing
                    desc["old_vocab_size"] = Base.Int(old_vocab_size)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function generate_vocab_remapping(new_vocab_file_::tf.TensorHandle, old_vocab_file_::tf.TensorHandle; name=nothing, new_vocab_offset=nothing, num_new_vocab=nothing, old_vocab_size=nothing)
        desc = tf.EagerOp("GenerateVocabRemapping")
        tf.add_input(desc, new_vocab_file_)
        tf.add_input(desc, old_vocab_file_)
        if new_vocab_offset !== nothing
            desc["new_vocab_offset"] = Base.Int(new_vocab_offset)
        end
        if num_new_vocab !== nothing
            desc["num_new_vocab"] = Base.Int(num_new_vocab)
        end
        if old_vocab_size !== nothing
            desc["old_vocab_size"] = Base.Int(old_vocab_size)
        end
        tf.execute(desc)
    end
end


"""
     batch_matrix_inverse(input; adjoint=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_matrix_inverse(input_; name=nothing, adjoint=nothing)
            local desc
            tf.with_op_name(name, "BatchMatrixInverse") do 
                desc = tf.NodeDescription("BatchMatrixInverse")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if adjoint !== nothing
                    desc["adjoint"] = Base.Bool(adjoint)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_matrix_inverse(input_::tf.TensorHandle; name=nothing, adjoint=nothing)
        desc = tf.EagerOp("BatchMatrixInverse")
        tf.add_input(desc, input_)
        if adjoint !== nothing
            desc["adjoint"] = Base.Bool(adjoint)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     control_trigger()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function control_trigger(; name=nothing)
            local desc
            tf.with_op_name(name, "ControlTrigger") do 
                desc
                tf.NodeDescription("ControlTrigger")
            end
            tf.Tensor(tf.Operation(desc))
        end
    function control_trigger(; name=nothing)
        desc = tf.EagerOp("ControlTrigger")
        (tf.execute(desc))[1]
    end
end


"""
     tpu_ordinal_selector()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tpu_ordinal_selector(; name=nothing)
            local desc
            tf.with_op_name(name, "TPUOrdinalSelector") do 
                desc
                tf.NodeDescription("TPUOrdinalSelector")
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tpu_ordinal_selector(; name=nothing)
        desc = tf.EagerOp("TPUOrdinalSelector")
        (tf.execute(desc))[1]
    end
end


"""
     stop_gradient(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stop_gradient(input_; name=nothing)
            local desc
            tf.with_op_name(name, "StopGradient") do 
                desc = tf.NodeDescription("StopGradient")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stop_gradient(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("StopGradient")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     split(split_dim, value)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function split(split_dim_, value_; name=nothing, num_split=nothing)
            local desc
            tf.with_op_name(name, "Split") do 
                desc = tf.NodeDescription("Split")
                split_dim_ = convert(Tensor{Int32}, split_dim_)
                split_dim_ = split_dim_ - convert(tf.Tensor{eltype(split_dim_)}, 1)
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, split_dim_)
                tf.add_input(desc, value_)
                if num_split !== nothing
                    desc["num_split"] = Base.Int(num_split)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:num_split
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function split(split_dim_::tf.TensorHandle, value_::tf.TensorHandle; name=nothing, num_split=nothing)
        desc = tf.EagerOp("Split")
        tf.add_input(desc, split_dim_)
        tf.add_input(desc, value_)
        if num_split !== nothing
            desc["num_split"] = Base.Int(num_split)
        end
        desc["T"] = tf.data_type(value_)
        tf.execute(desc)
    end
end


"""
     unpack(value; axis=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unpack(value_; name=nothing, num=nothing, axis=nothing)
            local desc
            tf.with_op_name(name, "Unpack") do 
                desc = tf.NodeDescription("Unpack")
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, value_)
                if num !== nothing
                    desc["num"] = Base.Int(num)
                end
                if axis !== nothing
                    axis = Base.Int(axis) - 1
                end
                if axis !== nothing
                    desc["axis"] = Base.Int(axis)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:num
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function unpack(value_::tf.TensorHandle; name=nothing, num=nothing, axis=nothing)
        desc = tf.EagerOp("Unpack")
        tf.add_input(desc, value_)
        if num !== nothing
            desc["num"] = Base.Int(num)
        end
        if axis !== nothing
            axis = Base.Int(axis) - 1
        end
        if axis !== nothing
            desc["axis"] = Base.Int(axis)
        end
        desc["T"] = tf.data_type(value_)
        tf.execute(desc)
    end
end


"""
     resource_scatter_max(resource, indices, updates)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_scatter_max(resource_, indices_, updates_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "ResourceScatterMax") do 
                desc = tf.NodeDescription("ResourceScatterMax")
                resource_ = convert(Tensor{Any}, resource_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (updates_,) = tf.tf_promote(updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_scatter_max(resource_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("ResourceScatterMax")
        tf.add_input(desc, resource_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["Tindices"] = tf.data_type(indices_)
        desc["dtype"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_write(handle, index, value, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_write(handle_, index_, value_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayWrite") do 
                desc = tf.NodeDescription("TensorArrayWrite")
                handle_ = convert(Tensor{String}, handle_)
                index_ = convert(Tensor{Int32}, index_)
                value_ = convert(Tensor{Any}, value_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, index_)
                tf.add_input(desc, value_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_write(handle_::tf.TensorHandle, index_::tf.TensorHandle, value_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArrayWrite")
        tf.add_input(desc, handle_)
        tf.add_input(desc, index_)
        tf.add_input(desc, value_)
        tf.add_input(desc, flow_in_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     fill(dims, value; index_type=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fill(dims_, value_; name=nothing, index_type=nothing)
            local desc
            tf.with_op_name(name, "Fill") do 
                desc = tf.NodeDescription("Fill")
                dims_ = convert(Tensor{Int32}, dims_)
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                (dims_,) = tf.tf_promote(dims_)
                tf.add_input(desc, dims_)
                tf.add_input(desc, value_)
                if index_type !== nothing
                    desc["index_type"] = Base.identity(index_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fill(dims_::tf.TensorHandle, value_::tf.TensorHandle; name=nothing, index_type=nothing)
        desc = tf.EagerOp("Fill")
        tf.add_input(desc, dims_)
        tf.add_input(desc, value_)
        if index_type !== nothing
            desc["index_type"] = Base.identity(index_type)
        end
        desc["index_type"] = tf.data_type(dims_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_conv2d_with_bias_and_requantize(input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output; out_type=Float32, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_conv2d_with_bias_and_requantize(input_, filter_, bias_, min_input_, max_input_, min_filter_, max_filter_, min_freezed_output_, max_freezed_output_; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConv2DWithBiasAndRequantize") do 
                desc = tf.NodeDescription("QuantizedConv2DWithBiasAndRequantize")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                bias_ = convert(Tensor{Any}, bias_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_filter_ = convert(Tensor{Float32}, min_filter_)
                max_filter_ = convert(Tensor{Float32}, max_filter_)
                min_freezed_output_ = convert(Tensor{Float32}, min_freezed_output_)
                max_freezed_output_ = convert(Tensor{Float32}, max_freezed_output_)
                (filter_,) = tf.tf_promote(filter_)
                (input_,) = tf.tf_promote(input_)
                (bias_,) = tf.tf_promote(bias_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, bias_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_filter_)
                tf.add_input(desc, max_filter_)
                tf.add_input(desc, min_freezed_output_)
                tf.add_input(desc, max_freezed_output_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_conv2d_with_bias_and_requantize(input_::tf.TensorHandle, filter_::tf.TensorHandle, bias_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_filter_::tf.TensorHandle, max_filter_::tf.TensorHandle, min_freezed_output_::tf.TensorHandle, max_freezed_output_::tf.TensorHandle; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("QuantizedConv2DWithBiasAndRequantize")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, bias_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_filter_)
        tf.add_input(desc, max_filter_)
        tf.add_input(desc, min_freezed_output_)
        tf.add_input(desc, max_freezed_output_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tinput"] = tf.data_type(input_)
        desc["Tfilter"] = tf.data_type(filter_)
        desc["Tbias"] = tf.data_type(bias_)
        tf.execute(desc)
    end
end


"""
     softmax(logits)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function softmax(logits_; name=nothing)
            local desc
            tf.with_op_name(name, "Softmax") do 
                desc = tf.NodeDescription("Softmax")
                logits_ = convert(Tensor{Any}, logits_)
                (logits_,) = tf.tf_promote(logits_)
                tf.add_input(desc, logits_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function softmax(logits_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Softmax")
        tf.add_input(desc, logits_)
        desc["T"] = tf.data_type(logits_)
        (tf.execute(desc))[1]
    end
end


"""
     resize_bicubic(images, size; align_corners=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resize_bicubic(images_, size_; name=nothing, align_corners=nothing)
            local desc
            tf.with_op_name(name, "ResizeBicubic") do 
                desc = tf.NodeDescription("ResizeBicubic")
                images_ = convert(Tensor{Any}, images_)
                size_ = convert(Tensor{Int32}, size_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                tf.add_input(desc, size_)
                if align_corners !== nothing
                    desc["align_corners"] = Base.Bool(align_corners)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resize_bicubic(images_::tf.TensorHandle, size_::tf.TensorHandle; name=nothing, align_corners=nothing)
        desc = tf.EagerOp("ResizeBicubic")
        tf.add_input(desc, images_)
        tf.add_input(desc, size_)
        if align_corners !== nothing
            desc["align_corners"] = Base.Bool(align_corners)
        end
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     infeed_dequeue_tuple()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function infeed_dequeue_tuple(; name=nothing, dtypes=nothing, shapes=nothing)
            local desc
            tf.with_op_name(name, "InfeedDequeueTuple") do 
                desc = tf.NodeDescription("InfeedDequeueTuple")
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function infeed_dequeue_tuple(; name=nothing, dtypes=nothing, shapes=nothing)
        desc = tf.EagerOp("InfeedDequeueTuple")
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     multi_device_iterator()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function multi_device_iterator(; name=nothing, devices=nothing, shared_name=nothing, container=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "MultiDeviceIterator") do 
                desc = tf.NodeDescription("MultiDeviceIterator")
                if devices !== nothing
                    desc["devices"] = map(Base.identity, devices)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function multi_device_iterator(; name=nothing, devices=nothing, shared_name=nothing, container=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("MultiDeviceIterator")
        if devices !== nothing
            desc["devices"] = map(Base.identity, devices)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     decode_csv(records, record_defaults; field_delim=,, use_quote_delim=true, na_value=, select_cols=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_csv(records_, record_defaults_; name=nothing, OUT_TYPE=nothing, field_delim=nothing, use_quote_delim=nothing, na_value=nothing, select_cols=nothing)
            local desc
            tf.with_op_name(name, "DecodeCSV") do 
                desc = tf.NodeDescription("DecodeCSV")
                records_ = convert(Tensor{String}, records_)
                record_defaults_ = [convert(Tensor{Any}, x) for x = record_defaults_]
                tf.add_input(desc, records_)
                tf.add_input(desc, record_defaults_)
                if OUT_TYPE !== nothing
                    desc["OUT_TYPE"] = map(Base.identity, OUT_TYPE)
                end
                if field_delim !== nothing
                    desc["field_delim"] = Base.String(field_delim)
                end
                if use_quote_delim !== nothing
                    desc["use_quote_delim"] = Base.Bool(use_quote_delim)
                end
                if na_value !== nothing
                    desc["na_value"] = Base.String(na_value)
                end
                if select_cols !== nothing
                    desc["select_cols"] = map(Base.identity, select_cols)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function decode_csv(records_::tf.TensorHandle, record_defaults_::tf.TensorHandle; name=nothing, OUT_TYPE=nothing, field_delim=nothing, use_quote_delim=nothing, na_value=nothing, select_cols=nothing)
        desc = tf.EagerOp("DecodeCSV")
        tf.add_input(desc, records_)
        tf.add_input(desc, record_defaults_)
        if OUT_TYPE !== nothing
            desc["OUT_TYPE"] = map(Base.identity, OUT_TYPE)
        end
        if field_delim !== nothing
            desc["field_delim"] = Base.String(field_delim)
        end
        if use_quote_delim !== nothing
            desc["use_quote_delim"] = Base.Bool(use_quote_delim)
        end
        if na_value !== nothing
            desc["na_value"] = Base.String(na_value)
        end
        if select_cols !== nothing
            desc["select_cols"] = map(Base.identity, select_cols)
        end
        (tf.execute(desc))[1]
    end
end


"""
     lookup_table_find(table_handle, keys, default_value)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lookup_table_find(table_handle_, keys_, default_value_; name=nothing)
            local desc
            tf.with_op_name(name, "LookupTableFind") do 
                desc = tf.NodeDescription("LookupTableFind")
                table_handle_ = convert(Tensor{String}, table_handle_)
                keys_ = convert(Tensor{Any}, keys_)
                default_value_ = convert(Tensor{Any}, default_value_)
                (keys_,) = tf.tf_promote(keys_)
                (default_value_,) = tf.tf_promote(default_value_)
                tf.add_input(desc, table_handle_)
                tf.add_input(desc, keys_)
                tf.add_input(desc, default_value_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lookup_table_find(table_handle_::tf.TensorHandle, keys_::tf.TensorHandle, default_value_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LookupTableFind")
        tf.add_input(desc, table_handle_)
        tf.add_input(desc, keys_)
        tf.add_input(desc, default_value_)
        desc["Tin"] = tf.data_type(keys_)
        desc["Tout"] = tf.data_type(default_value_)
        (tf.execute(desc))[1]
    end
end


"""
     shuffle_and_repeat_dataset(input_dataset, buffer_size, seed, seed2, count)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function shuffle_and_repeat_dataset(input_dataset_, buffer_size_, seed_, seed2_, count_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ShuffleAndRepeatDataset") do 
                desc = tf.NodeDescription("ShuffleAndRepeatDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                buffer_size_ = convert(Tensor{Int64}, buffer_size_)
                seed_ = convert(Tensor{Int64}, seed_)
                seed2_ = convert(Tensor{Int64}, seed2_)
                count_ = convert(Tensor{Int64}, count_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, buffer_size_)
                tf.add_input(desc, seed_)
                tf.add_input(desc, seed2_)
                tf.add_input(desc, count_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function shuffle_and_repeat_dataset(input_dataset_::tf.TensorHandle, buffer_size_::tf.TensorHandle, seed_::tf.TensorHandle, seed2_::tf.TensorHandle, count_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ShuffleAndRepeatDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, buffer_size_)
        tf.add_input(desc, seed_)
        tf.add_input(desc, seed2_)
        tf.add_input(desc, count_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     requantization_range_per_channel(input, input_min, input_max)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function requantization_range_per_channel(input_, input_min_, input_max_; name=nothing, clip_value_max=nothing)
            local desc
            tf.with_op_name(name, "RequantizationRangePerChannel") do 
                desc = tf.NodeDescription("RequantizationRangePerChannel")
                input_ = convert(Tensor{Float32}, input_)
                input_min_ = convert(Tensor{Float32}, input_min_)
                input_max_ = convert(Tensor{Float32}, input_max_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_min_)
                tf.add_input(desc, input_max_)
                if clip_value_max !== nothing
                    desc["clip_value_max"] = Base.identity(clip_value_max)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function requantization_range_per_channel(input_::tf.TensorHandle, input_min_::tf.TensorHandle, input_max_::tf.TensorHandle; name=nothing, clip_value_max=nothing)
        desc = tf.EagerOp("RequantizationRangePerChannel")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_min_)
        tf.add_input(desc, input_max_)
        if clip_value_max !== nothing
            desc["clip_value_max"] = Base.identity(clip_value_max)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     experimental_unbatch_dataset(input_dataset)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_unbatch_dataset(input_dataset_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalUnbatchDataset") do 
                desc = tf.NodeDescription("ExperimentalUnbatchDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                tf.add_input(desc, input_dataset_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_unbatch_dataset(input_dataset_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalUnbatchDataset")
        tf.add_input(desc, input_dataset_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     avg_pool3d_grad(orig_input_shape, grad; data_format=NDHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function avg_pool3d_grad(orig_input_shape_, grad_; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "AvgPool3DGrad") do 
                desc = tf.NodeDescription("AvgPool3DGrad")
                orig_input_shape_ = convert(Tensor{Int32}, orig_input_shape_)
                grad_ = convert(Tensor{Any}, grad_)
                (grad_,) = tf.tf_promote(grad_)
                tf.add_input(desc, orig_input_shape_)
                tf.add_input(desc, grad_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function avg_pool3d_grad(orig_input_shape_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("AvgPool3DGrad")
        tf.add_input(desc, orig_input_shape_)
        tf.add_input(desc, grad_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     placeholder_with_default(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function placeholder_with_default(input_; name=nothing, dtype=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "PlaceholderWithDefault") do 
                desc = tf.NodeDescription("PlaceholderWithDefault")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function placeholder_with_default(input_::tf.TensorHandle; name=nothing, dtype=nothing, shape=nothing)
        desc = tf.EagerOp("PlaceholderWithDefault")
        tf.add_input(desc, input_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        desc["dtype"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     initialize_table_v2(table_handle, keys, values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function initialize_table_v2(table_handle_, keys_, values_; name=nothing)
            local desc
            tf.with_op_name(name, "InitializeTableV2") do 
                desc = tf.NodeDescription("InitializeTableV2")
                table_handle_ = convert(Tensor{Any}, table_handle_)
                keys_ = convert(Tensor{Any}, keys_)
                values_ = convert(Tensor{Any}, values_)
                (values_,) = tf.tf_promote(values_)
                (keys_,) = tf.tf_promote(keys_)
                tf.add_input(desc, table_handle_)
                tf.add_input(desc, keys_)
                tf.add_input(desc, values_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function initialize_table_v2(table_handle_::tf.TensorHandle, keys_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("InitializeTableV2")
        tf.add_input(desc, table_handle_)
        tf.add_input(desc, keys_)
        tf.add_input(desc, values_)
        desc["Tkey"] = tf.data_type(keys_)
        desc["Tval"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     set_size(set_indices, set_values, set_shape; validate_indices=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function set_size(set_indices_, set_values_, set_shape_; name=nothing, validate_indices=nothing)
            local desc
            tf.with_op_name(name, "SetSize") do 
                desc = tf.NodeDescription("SetSize")
                set_indices_ = convert(Tensor{Int64}, set_indices_)
                set_values_ = convert(Tensor{Any}, set_values_)
                set_shape_ = convert(Tensor{Int64}, set_shape_)
                (set_values_,) = tf.tf_promote(set_values_)
                tf.add_input(desc, set_indices_)
                tf.add_input(desc, set_values_)
                tf.add_input(desc, set_shape_)
                if validate_indices !== nothing
                    desc["validate_indices"] = Base.Bool(validate_indices)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function set_size(set_indices_::tf.TensorHandle, set_values_::tf.TensorHandle, set_shape_::tf.TensorHandle; name=nothing, validate_indices=nothing)
        desc = tf.EagerOp("SetSize")
        tf.add_input(desc, set_indices_)
        tf.add_input(desc, set_values_)
        tf.add_input(desc, set_shape_)
        if validate_indices !== nothing
            desc["validate_indices"] = Base.Bool(validate_indices)
        end
        desc["T"] = tf.data_type(set_values_)
        (tf.execute(desc))[1]
    end
end


"""
     assert(condition, data; summarize=3)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function assert(condition_, data_; name=nothing, T=nothing, summarize=nothing)
            local desc
            tf.with_op_name(name, "Assert") do 
                desc = tf.NodeDescription("Assert")
                condition_ = convert(Tensor{Bool}, condition_)
                data_ = [convert(Tensor{Any}, x) for x = data_]
                tf.add_input(desc, condition_)
                tf.add_input(desc, data_)
                if T !== nothing
                    desc["T"] = map(Base.identity, T)
                end
                if summarize !== nothing
                    desc["summarize"] = Base.Int(summarize)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function assert(condition_::tf.TensorHandle, data_::tf.TensorHandle; name=nothing, T=nothing, summarize=nothing)
        desc = tf.EagerOp("Assert")
        tf.add_input(desc, condition_)
        tf.add_input(desc, data_)
        if T !== nothing
            desc["T"] = map(Base.identity, T)
        end
        if summarize !== nothing
            desc["summarize"] = Base.Int(summarize)
        end
        (tf.execute(desc))[1]
    end
end


"""
     non_max_suppression_v4(boxes, scores, max_output_size, iou_threshold, score_threshold; pad_to_max_output_size=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function non_max_suppression_v4(boxes_, scores_, max_output_size_, iou_threshold_, score_threshold_; name=nothing, pad_to_max_output_size=nothing)
            local desc
            tf.with_op_name(name, "NonMaxSuppressionV4") do 
                desc = tf.NodeDescription("NonMaxSuppressionV4")
                boxes_ = convert(Tensor{Float32}, boxes_)
                scores_ = convert(Tensor{Float32}, scores_)
                max_output_size_ = convert(Tensor{Int32}, max_output_size_)
                iou_threshold_ = convert(Tensor{Float32}, iou_threshold_)
                score_threshold_ = convert(Tensor{Float32}, score_threshold_)
                (boxes_, scores_) = tf.tf_promote(boxes_, scores_)
                tf.add_input(desc, boxes_)
                tf.add_input(desc, scores_)
                tf.add_input(desc, max_output_size_)
                tf.add_input(desc, iou_threshold_)
                tf.add_input(desc, score_threshold_)
                if pad_to_max_output_size !== nothing
                    desc["pad_to_max_output_size"] = Base.Bool(pad_to_max_output_size)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function non_max_suppression_v4(boxes_::tf.TensorHandle, scores_::tf.TensorHandle, max_output_size_::tf.TensorHandle, iou_threshold_::tf.TensorHandle, score_threshold_::tf.TensorHandle; name=nothing, pad_to_max_output_size=nothing)
        desc = tf.EagerOp("NonMaxSuppressionV4")
        tf.add_input(desc, boxes_)
        tf.add_input(desc, scores_)
        tf.add_input(desc, max_output_size_)
        tf.add_input(desc, iou_threshold_)
        tf.add_input(desc, score_threshold_)
        if pad_to_max_output_size !== nothing
            desc["pad_to_max_output_size"] = Base.Bool(pad_to_max_output_size)
        end
        desc["T"] = tf.data_type(boxes_)
        desc["T"] = tf.data_type(scores_)
        tf.execute(desc)
    end
end


"""
     sample_distorted_bounding_box_v2(image_size, bounding_boxes, min_object_covered; seed=0, seed2=0, aspect_ratio_range=Int64[], area_range=Int64[], max_attempts=100, use_image_if_no_bounding_boxes=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sample_distorted_bounding_box_v2(image_size_, bounding_boxes_, min_object_covered_; name=nothing, seed=nothing, seed2=nothing, aspect_ratio_range=nothing, area_range=nothing, max_attempts=nothing, use_image_if_no_bounding_boxes=nothing)
            local desc
            tf.with_op_name(name, "SampleDistortedBoundingBoxV2") do 
                desc = tf.NodeDescription("SampleDistortedBoundingBoxV2")
                image_size_ = convert(Tensor{Any}, image_size_)
                bounding_boxes_ = convert(Tensor{Float32}, bounding_boxes_)
                min_object_covered_ = convert(Tensor{Float32}, min_object_covered_)
                (image_size_,) = tf.tf_promote(image_size_)
                tf.add_input(desc, image_size_)
                tf.add_input(desc, bounding_boxes_)
                tf.add_input(desc, min_object_covered_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if aspect_ratio_range !== nothing
                    desc["aspect_ratio_range"] = map(Base.identity, aspect_ratio_range)
                end
                if area_range !== nothing
                    desc["area_range"] = map(Base.identity, area_range)
                end
                if max_attempts !== nothing
                    desc["max_attempts"] = Base.Int(max_attempts)
                end
                if use_image_if_no_bounding_boxes !== nothing
                    desc["use_image_if_no_bounding_boxes"] = Base.Bool(use_image_if_no_bounding_boxes)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sample_distorted_bounding_box_v2(image_size_::tf.TensorHandle, bounding_boxes_::tf.TensorHandle, min_object_covered_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing, aspect_ratio_range=nothing, area_range=nothing, max_attempts=nothing, use_image_if_no_bounding_boxes=nothing)
        desc = tf.EagerOp("SampleDistortedBoundingBoxV2")
        tf.add_input(desc, image_size_)
        tf.add_input(desc, bounding_boxes_)
        tf.add_input(desc, min_object_covered_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if aspect_ratio_range !== nothing
            desc["aspect_ratio_range"] = map(Base.identity, aspect_ratio_range)
        end
        if area_range !== nothing
            desc["area_range"] = map(Base.identity, area_range)
        end
        if max_attempts !== nothing
            desc["max_attempts"] = Base.Int(max_attempts)
        end
        if use_image_if_no_bounding_boxes !== nothing
            desc["use_image_if_no_bounding_boxes"] = Base.Bool(use_image_if_no_bounding_boxes)
        end
        desc["T"] = tf.data_type(image_size_)
        tf.execute(desc)
    end
end


"""
     initialize_table_from_text_file(table_handle, filename; vocab_size=-1, delimiter=	)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function initialize_table_from_text_file(table_handle_, filename_; name=nothing, key_index=nothing, value_index=nothing, vocab_size=nothing, delimiter=nothing)
            local desc
            tf.with_op_name(name, "InitializeTableFromTextFile") do 
                desc = tf.NodeDescription("InitializeTableFromTextFile")
                table_handle_ = convert(Tensor{String}, table_handle_)
                filename_ = convert(Tensor{String}, filename_)
                tf.add_input(desc, table_handle_)
                tf.add_input(desc, filename_)
                if key_index !== nothing
                    desc["key_index"] = Base.Int(key_index)
                end
                if value_index !== nothing
                    desc["value_index"] = Base.Int(value_index)
                end
                if vocab_size !== nothing
                    desc["vocab_size"] = Base.Int(vocab_size)
                end
                if delimiter !== nothing
                    desc["delimiter"] = Base.String(delimiter)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function initialize_table_from_text_file(table_handle_::tf.TensorHandle, filename_::tf.TensorHandle; name=nothing, key_index=nothing, value_index=nothing, vocab_size=nothing, delimiter=nothing)
        desc = tf.EagerOp("InitializeTableFromTextFile")
        tf.add_input(desc, table_handle_)
        tf.add_input(desc, filename_)
        if key_index !== nothing
            desc["key_index"] = Base.Int(key_index)
        end
        if value_index !== nothing
            desc["value_index"] = Base.Int(value_index)
        end
        if vocab_size !== nothing
            desc["vocab_size"] = Base.Int(vocab_size)
        end
        if delimiter !== nothing
            desc["delimiter"] = Base.String(delimiter)
        end
        (tf.execute(desc))[1]
    end
end


"""
     lookup_table_size(table_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lookup_table_size(table_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "LookupTableSize") do 
                desc = tf.NodeDescription("LookupTableSize")
                table_handle_ = convert(Tensor{String}, table_handle_)
                tf.add_input(desc, table_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lookup_table_size(table_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LookupTableSize")
        tf.add_input(desc, table_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_apply_adagrad_da(var, gradient_accumulator, gradient_squared_accumulator, grad, indices, lr, l1, l2, global_step; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_apply_adagrad_da(var_, gradient_accumulator_, gradient_squared_accumulator_, grad_, indices_, lr_, l1_, l2_, global_step_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "SparseApplyAdagradDA") do 
                desc = tf.NodeDescription("SparseApplyAdagradDA")
                var_ = convert(Tensor{Any}, var_)
                gradient_accumulator_ = convert(Tensor{Any}, gradient_accumulator_)
                gradient_squared_accumulator_ = convert(Tensor{Any}, gradient_squared_accumulator_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                global_step_ = convert(Tensor{Int64}, global_step_)
                (var_, gradient_accumulator_, gradient_squared_accumulator_, grad_, lr_, l1_, l2_) = tf.tf_promote(var_, gradient_accumulator_, gradient_squared_accumulator_, grad_, lr_, l1_, l2_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, gradient_accumulator_)
                tf.add_input(desc, gradient_squared_accumulator_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, global_step_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_apply_adagrad_da(var_::tf.TensorHandle, gradient_accumulator_::tf.TensorHandle, gradient_squared_accumulator_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, global_step_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("SparseApplyAdagradDA")
        tf.add_input(desc, var_)
        tf.add_input(desc, gradient_accumulator_)
        tf.add_input(desc, gradient_squared_accumulator_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, global_step_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(gradient_accumulator_)
        desc["T"] = tf.data_type(gradient_squared_accumulator_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        (tf.execute(desc))[1]
    end
end


"""
     broadcast_gradient_args(s0, s1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function broadcast_gradient_args(s0_, s1_; name=nothing)
            local desc
            tf.with_op_name(name, "BroadcastGradientArgs") do 
                desc = tf.NodeDescription("BroadcastGradientArgs")
                s0_ = convert(Tensor{Int32}, s0_)
                s1_ = convert(Tensor{Int32}, s1_)
                (s0_, s1_) = tf.tf_promote(s0_, s1_)
                tf.add_input(desc, s0_)
                tf.add_input(desc, s1_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function broadcast_gradient_args(s0_::tf.TensorHandle, s1_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BroadcastGradientArgs")
        tf.add_input(desc, s0_)
        tf.add_input(desc, s1_)
        desc["T"] = tf.data_type(s0_)
        desc["T"] = tf.data_type(s1_)
        tf.execute(desc)
    end
end


"""
     summary_writer(; shared_name=, container=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function summary_writer(; name=nothing, shared_name=nothing, container=nothing)
            local desc
            tf.with_op_name(name, "SummaryWriter") do 
                desc = tf.NodeDescription("SummaryWriter")
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function summary_writer(; name=nothing, shared_name=nothing, container=nothing)
        desc = tf.EagerOp("SummaryWriter")
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        (tf.execute(desc))[1]
    end
end


"""
     recv_tpu_embedding_activations()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function recv_tpu_embedding_activations(; name=nothing, num_outputs=nothing, config=nothing)
            local desc
            tf.with_op_name(name, "RecvTPUEmbeddingActivations") do 
                desc = tf.NodeDescription("RecvTPUEmbeddingActivations")
                if num_outputs !== nothing
                    desc["num_outputs"] = Base.Int(num_outputs)
                end
                if config !== nothing
                    desc["config"] = Base.String(config)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:num_outputs
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function recv_tpu_embedding_activations(; name=nothing, num_outputs=nothing, config=nothing)
        desc = tf.EagerOp("RecvTPUEmbeddingActivations")
        if num_outputs !== nothing
            desc["num_outputs"] = Base.Int(num_outputs)
        end
        if config !== nothing
            desc["config"] = Base.String(config)
        end
        tf.execute(desc)
    end
end


"""
     _while(input)

output = input; While (Cond(output)) { output = Body(output) }
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _while(input_; name=nothing, T=nothing, cond=nothing, body=nothing)
            local desc
            tf.with_op_name(name, "_While") do 
                desc = tf.NodeDescription("_While")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                tf.add_input(desc, input_)
                if T !== nothing
                    desc["T"] = map(Base.identity, T)
                end
                if cond !== nothing
                    desc["cond"] = Base.identity(cond)
                end
                if body !== nothing
                    desc["body"] = Base.identity(body)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _while(input_::tf.TensorHandle; name=nothing, T=nothing, cond=nothing, body=nothing)
        desc = tf.EagerOp("_While")
        tf.add_input(desc, input_)
        if T !== nothing
            desc["T"] = map(Base.identity, T)
        end
        if cond !== nothing
            desc["cond"] = Base.identity(cond)
        end
        if body !== nothing
            desc["body"] = Base.identity(body)
        end
        (tf.execute(desc))[1]
    end
end


"""
     initialize_table(table_handle, keys, values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function initialize_table(table_handle_, keys_, values_; name=nothing)
            local desc
            tf.with_op_name(name, "InitializeTable") do 
                desc = tf.NodeDescription("InitializeTable")
                table_handle_ = convert(Tensor{String}, table_handle_)
                keys_ = convert(Tensor{Any}, keys_)
                values_ = convert(Tensor{Any}, values_)
                (values_,) = tf.tf_promote(values_)
                (keys_,) = tf.tf_promote(keys_)
                tf.add_input(desc, table_handle_)
                tf.add_input(desc, keys_)
                tf.add_input(desc, values_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function initialize_table(table_handle_::tf.TensorHandle, keys_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("InitializeTable")
        tf.add_input(desc, table_handle_)
        tf.add_input(desc, keys_)
        tf.add_input(desc, values_)
        desc["Tkey"] = tf.data_type(keys_)
        desc["Tval"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     debug_numeric_summary(input; device_name=, tensor_name=, debug_urls=Int64[], lower_bound=?, upper_bound=?, mute_if_healthy=false, gated_grpc=false)

Debug Numeric Summary Op.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function debug_numeric_summary(input_; name=nothing, device_name=nothing, tensor_name=nothing, debug_urls=nothing, lower_bound=nothing, upper_bound=nothing, mute_if_healthy=nothing, gated_grpc=nothing)
            local desc
            tf.with_op_name(name, "DebugNumericSummary") do 
                desc = tf.NodeDescription("DebugNumericSummary")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if device_name !== nothing
                    desc["device_name"] = Base.String(device_name)
                end
                if tensor_name !== nothing
                    desc["tensor_name"] = Base.String(tensor_name)
                end
                if debug_urls !== nothing
                    desc["debug_urls"] = map(Base.identity, debug_urls)
                end
                if lower_bound !== nothing
                    desc["lower_bound"] = Base.identity(lower_bound)
                end
                if upper_bound !== nothing
                    desc["upper_bound"] = Base.identity(upper_bound)
                end
                if mute_if_healthy !== nothing
                    desc["mute_if_healthy"] = Base.Bool(mute_if_healthy)
                end
                if gated_grpc !== nothing
                    desc["gated_grpc"] = Base.Bool(gated_grpc)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function debug_numeric_summary(input_::tf.TensorHandle; name=nothing, device_name=nothing, tensor_name=nothing, debug_urls=nothing, lower_bound=nothing, upper_bound=nothing, mute_if_healthy=nothing, gated_grpc=nothing)
        desc = tf.EagerOp("DebugNumericSummary")
        tf.add_input(desc, input_)
        if device_name !== nothing
            desc["device_name"] = Base.String(device_name)
        end
        if tensor_name !== nothing
            desc["tensor_name"] = Base.String(tensor_name)
        end
        if debug_urls !== nothing
            desc["debug_urls"] = map(Base.identity, debug_urls)
        end
        if lower_bound !== nothing
            desc["lower_bound"] = Base.identity(lower_bound)
        end
        if upper_bound !== nothing
            desc["upper_bound"] = Base.identity(upper_bound)
        end
        if mute_if_healthy !== nothing
            desc["mute_if_healthy"] = Base.Bool(mute_if_healthy)
        end
        if gated_grpc !== nothing
            desc["gated_grpc"] = Base.Bool(gated_grpc)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_adagrad_parameters_grad_accum_debug(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_adagrad_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingAdagradParametersGradAccumDebug") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingAdagradParametersGradAccumDebug")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_adagrad_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingAdagradParametersGradAccumDebug")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     tanh(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tanh(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Tanh") do 
                desc = tf.NodeDescription("Tanh")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tanh(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Tanh")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     symbolic_gradient(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function symbolic_gradient(input_; name=nothing, Tin=nothing, Tout=nothing, f=nothing)
            local desc
            tf.with_op_name(name, "SymbolicGradient") do 
                desc = tf.NodeDescription("SymbolicGradient")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                tf.add_input(desc, input_)
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function symbolic_gradient(input_::tf.TensorHandle; name=nothing, Tin=nothing, Tout=nothing, f=nothing)
        desc = tf.EagerOp("SymbolicGradient")
        tf.add_input(desc, input_)
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_update_ensemble(tree_ensemble_handle, feature_ids, node_ids, gains, thresholds, left_node_contribs, right_node_contribs, max_depth, learning_rate)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_update_ensemble(tree_ensemble_handle_, feature_ids_, node_ids_, gains_, thresholds_, left_node_contribs_, right_node_contribs_, max_depth_, learning_rate_; name=nothing, pruning_mode=nothing, num_features=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesUpdateEnsemble") do 
                desc = tf.NodeDescription("BoostedTreesUpdateEnsemble")
                tree_ensemble_handle_ = convert(Tensor{Any}, tree_ensemble_handle_)
                feature_ids_ = convert(Tensor{Int32}, feature_ids_)
                node_ids_ = [convert(Tensor{Int32}, x) for x = node_ids_]
                gains_ = [convert(Tensor{Float32}, x) for x = gains_]
                thresholds_ = [convert(Tensor{Int32}, x) for x = thresholds_]
                left_node_contribs_ = [convert(Tensor{Float32}, x) for x = left_node_contribs_]
                right_node_contribs_ = [convert(Tensor{Float32}, x) for x = right_node_contribs_]
                max_depth_ = convert(Tensor{Int32}, max_depth_)
                learning_rate_ = convert(Tensor{Float32}, learning_rate_)
                tf.add_input(desc, tree_ensemble_handle_)
                tf.add_input(desc, feature_ids_)
                tf.add_input(desc, node_ids_)
                tf.add_input(desc, gains_)
                tf.add_input(desc, thresholds_)
                tf.add_input(desc, left_node_contribs_)
                tf.add_input(desc, right_node_contribs_)
                tf.add_input(desc, max_depth_)
                tf.add_input(desc, learning_rate_)
                if pruning_mode !== nothing
                    desc["pruning_mode"] = Base.Int(pruning_mode)
                end
                if num_features !== nothing
                    desc["num_features"] = Base.Int(num_features)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_update_ensemble(tree_ensemble_handle_::tf.TensorHandle, feature_ids_::tf.TensorHandle, node_ids_::tf.TensorHandle, gains_::tf.TensorHandle, thresholds_::tf.TensorHandle, left_node_contribs_::tf.TensorHandle, right_node_contribs_::tf.TensorHandle, max_depth_::tf.TensorHandle, learning_rate_::tf.TensorHandle; name=nothing, pruning_mode=nothing, num_features=nothing)
        desc = tf.EagerOp("BoostedTreesUpdateEnsemble")
        tf.add_input(desc, tree_ensemble_handle_)
        tf.add_input(desc, feature_ids_)
        tf.add_input(desc, node_ids_)
        tf.add_input(desc, gains_)
        tf.add_input(desc, thresholds_)
        tf.add_input(desc, left_node_contribs_)
        tf.add_input(desc, right_node_contribs_)
        tf.add_input(desc, max_depth_)
        tf.add_input(desc, learning_rate_)
        if pruning_mode !== nothing
            desc["pruning_mode"] = Base.Int(pruning_mode)
        end
        if num_features !== nothing
            desc["num_features"] = Base.Int(num_features)
        end
        (tf.execute(desc))[1]
    end
end


"""
     apply_momentum(var, accum, lr, grad, momentum; use_locking=false, use_nesterov=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_momentum(var_, accum_, lr_, grad_, momentum_; name=nothing, use_locking=nothing, use_nesterov=nothing)
            local desc
            tf.with_op_name(name, "ApplyMomentum") do 
                desc = tf.NodeDescription("ApplyMomentum")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                grad_ = convert(Tensor{Any}, grad_)
                momentum_ = convert(Tensor{Any}, momentum_)
                (var_, accum_, lr_, grad_, momentum_) = tf.tf_promote(var_, accum_, lr_, grad_, momentum_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, momentum_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if use_nesterov !== nothing
                    desc["use_nesterov"] = Base.Bool(use_nesterov)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_momentum(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, grad_::tf.TensorHandle, momentum_::tf.TensorHandle; name=nothing, use_locking=nothing, use_nesterov=nothing)
        desc = tf.EagerOp("ApplyMomentum")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, momentum_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if use_nesterov !== nothing
            desc["use_nesterov"] = Base.Bool(use_nesterov)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(grad_)
        desc["T"] = tf.data_type(momentum_)
        (tf.execute(desc))[1]
    end
end


"""
     reader_read(reader_handle, queue_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_read(reader_handle_, queue_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderRead") do 
                desc = tf.NodeDescription("ReaderRead")
                reader_handle_ = convert(Tensor{String}, reader_handle_)
                queue_handle_ = convert(Tensor{String}, queue_handle_)
                tf.add_input(desc, reader_handle_)
                tf.add_input(desc, queue_handle_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function reader_read(reader_handle_::tf.TensorHandle, queue_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderRead")
        tf.add_input(desc, reader_handle_)
        tf.add_input(desc, queue_handle_)
        tf.execute(desc)
    end
end


"""
     _wait_for_distributed_tpu(inputs; startup_timeout_sec=20)

An op that blocks execution until a distributed TPU system has
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _wait_for_distributed_tpu(inputs_; name=nothing, startup_timeout_sec=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "_WaitForDistributedTPU") do 
                desc = tf.NodeDescription("_WaitForDistributedTPU")
                inputs_ = [convert(Tensor{Int32}, x) for x = inputs_]
                tf.add_input(desc, inputs_)
                if startup_timeout_sec !== nothing
                    desc["startup_timeout_sec"] = Base.Int(startup_timeout_sec)
                end
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _wait_for_distributed_tpu(inputs_::tf.TensorHandle; name=nothing, startup_timeout_sec=nothing, N=nothing)
        desc = tf.EagerOp("_WaitForDistributedTPU")
        tf.add_input(desc, inputs_)
        if startup_timeout_sec !== nothing
            desc["startup_timeout_sec"] = Base.Int(startup_timeout_sec)
        end
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        (tf.execute(desc))[1]
    end
end


"""
     mutex_lock(mutex)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mutex_lock(mutex_; name=nothing)
            local desc
            tf.with_op_name(name, "MutexLock") do 
                desc = tf.NodeDescription("MutexLock")
                mutex_ = convert(Tensor{Any}, mutex_)
                tf.add_input(desc, mutex_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mutex_lock(mutex_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MutexLock")
        tf.add_input(desc, mutex_)
        (tf.execute(desc))[1]
    end
end


"""
     accumulator_set_global_step(handle, new_global_step)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function accumulator_set_global_step(handle_, new_global_step_; name=nothing)
            local desc
            tf.with_op_name(name, "AccumulatorSetGlobalStep") do 
                desc = tf.NodeDescription("AccumulatorSetGlobalStep")
                handle_ = convert(Tensor{String}, handle_)
                new_global_step_ = convert(Tensor{Int64}, new_global_step_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, new_global_step_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function accumulator_set_global_step(handle_::tf.TensorHandle, new_global_step_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("AccumulatorSetGlobalStep")
        tf.add_input(desc, handle_)
        tf.add_input(desc, new_global_step_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_add(x, y, min_x, max_x, min_y, max_y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_add(x_, y_, min_x_, max_x_, min_y_, max_y_; name=nothing)
            local desc
            tf.with_op_name(name, "QuantizedAdd") do 
                desc = tf.NodeDescription("QuantizedAdd")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                min_x_ = convert(Tensor{Float32}, min_x_)
                max_x_ = convert(Tensor{Float32}, max_x_)
                min_y_ = convert(Tensor{Float32}, min_y_)
                max_y_ = convert(Tensor{Float32}, max_y_)
                (x_,) = tf.tf_promote(x_)
                (y_,) = tf.tf_promote(y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
                tf.add_input(desc, min_x_)
                tf.add_input(desc, max_x_)
                tf.add_input(desc, min_y_)
                tf.add_input(desc, max_y_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_add(x_::tf.TensorHandle, y_::tf.TensorHandle, min_x_::tf.TensorHandle, max_x_::tf.TensorHandle, min_y_::tf.TensorHandle, max_y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("QuantizedAdd")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        tf.add_input(desc, min_x_)
        tf.add_input(desc, max_x_)
        tf.add_input(desc, min_y_)
        tf.add_input(desc, max_y_)
        desc["T1"] = tf.data_type(x_)
        desc["T2"] = tf.data_type(y_)
        tf.execute(desc)
    end
end


"""
     squeeze(input; squeeze_dims=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function squeeze(input_; name=nothing, squeeze_dims=nothing)
            local desc
            tf.with_op_name(name, "Squeeze") do 
                desc = tf.NodeDescription("Squeeze")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if squeeze_dims !== nothing
                    desc["squeeze_dims"] = map(Base.identity, squeeze_dims)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function squeeze(input_::tf.TensorHandle; name=nothing, squeeze_dims=nothing)
        desc = tf.EagerOp("Squeeze")
        tf.add_input(desc, input_)
        if squeeze_dims !== nothing
            desc["squeeze_dims"] = map(Base.identity, squeeze_dims)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_matching_files_dataset(patterns)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_matching_files_dataset(patterns_; name=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalMatchingFilesDataset") do 
                desc = tf.NodeDescription("ExperimentalMatchingFilesDataset")
                patterns_ = convert(Tensor{String}, patterns_)
                tf.add_input(desc, patterns_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_matching_files_dataset(patterns_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ExperimentalMatchingFilesDataset")
        tf.add_input(desc, patterns_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_dataset_to_tf_record(input_dataset, filename, compression_type)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_dataset_to_tf_record(input_dataset_, filename_, compression_type_; name=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalDatasetToTFRecord") do 
                desc = tf.NodeDescription("ExperimentalDatasetToTFRecord")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                filename_ = convert(Tensor{String}, filename_)
                compression_type_ = convert(Tensor{String}, compression_type_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, filename_)
                tf.add_input(desc, compression_type_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_dataset_to_tf_record(input_dataset_::tf.TensorHandle, filename_::tf.TensorHandle, compression_type_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ExperimentalDatasetToTFRecord")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, filename_)
        tf.add_input(desc, compression_type_)
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_stochastic_gradient_descent_parameters(parameters; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_stochastic_gradient_descent_parameters(parameters_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingStochasticGradientDescentParameters") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingStochasticGradientDescentParameters")
                parameters_ = convert(Tensor{Float32}, parameters_)
                tf.add_input(desc, parameters_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_stochastic_gradient_descent_parameters(parameters_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingStochasticGradientDescentParameters")
        tf.add_input(desc, parameters_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     no_op()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function no_op(; name=nothing)
            local desc
            tf.with_op_name(name, "NoOp") do 
                desc
                tf.NodeDescription("NoOp")
            end
            tf.Tensor(tf.Operation(desc))
        end
    function no_op(; name=nothing)
        desc = tf.EagerOp("NoOp")
        (tf.execute(desc))[1]
    end
end


"""
     zip_dataset(input_datasets)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function zip_dataset(input_datasets_; name=nothing, output_types=nothing, output_shapes=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "ZipDataset") do 
                desc = tf.NodeDescription("ZipDataset")
                input_datasets_ = [convert(Tensor{Any}, x) for x = input_datasets_]
                tf.add_input(desc, input_datasets_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function zip_dataset(input_datasets_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing, N=nothing)
        desc = tf.EagerOp("ZipDataset")
        tf.add_input(desc, input_datasets_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        (tf.execute(desc))[1]
    end
end


"""
     identity_reader_v2(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function identity_reader_v2(; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "IdentityReaderV2") do 
                desc = tf.NodeDescription("IdentityReaderV2")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function identity_reader_v2(; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("IdentityReaderV2")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     lmdb_reader(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lmdb_reader(; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "LMDBReader") do 
                desc = tf.NodeDescription("LMDBReader")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lmdb_reader(; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("LMDBReader")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     nccl_all_reduce(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function nccl_all_reduce(input_; name=nothing, reduction=nothing, num_devices=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "NcclAllReduce") do 
                desc = tf.NodeDescription("NcclAllReduce")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if reduction !== nothing
                    desc["reduction"] = Base.String(reduction)
                end
                if num_devices !== nothing
                    desc["num_devices"] = Base.Int(num_devices)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function nccl_all_reduce(input_::tf.TensorHandle; name=nothing, reduction=nothing, num_devices=nothing, shared_name=nothing)
        desc = tf.EagerOp("NcclAllReduce")
        tf.add_input(desc, input_)
        if reduction !== nothing
            desc["reduction"] = Base.String(reduction)
        end
        if num_devices !== nothing
            desc["num_devices"] = Base.Int(num_devices)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     text_line_dataset(filenames, compression_type, buffer_size)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function text_line_dataset(filenames_, compression_type_, buffer_size_; name=nothing)
            local desc
            tf.with_op_name(name, "TextLineDataset") do 
                desc = tf.NodeDescription("TextLineDataset")
                filenames_ = convert(Tensor{String}, filenames_)
                compression_type_ = convert(Tensor{String}, compression_type_)
                buffer_size_ = convert(Tensor{Int64}, buffer_size_)
                tf.add_input(desc, filenames_)
                tf.add_input(desc, compression_type_)
                tf.add_input(desc, buffer_size_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function text_line_dataset(filenames_::tf.TensorHandle, compression_type_::tf.TensorHandle, buffer_size_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TextLineDataset")
        tf.add_input(desc, filenames_)
        tf.add_input(desc, compression_type_)
        tf.add_input(desc, buffer_size_)
        (tf.execute(desc))[1]
    end
end


"""
     sdca_shrink_l1(weights)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sdca_shrink_l1(weights_; name=nothing, num_features=nothing, l1=nothing, l2=nothing)
            local desc
            tf.with_op_name(name, "SdcaShrinkL1") do 
                desc = tf.NodeDescription("SdcaShrinkL1")
                weights_ = [convert(Tensor{Float32}, x) for x = weights_]
                tf.add_input(desc, weights_)
                if num_features !== nothing
                    desc["num_features"] = Base.Int(num_features)
                end
                if l1 !== nothing
                    desc["l1"] = Base.identity(l1)
                end
                if l2 !== nothing
                    desc["l2"] = Base.identity(l2)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sdca_shrink_l1(weights_::tf.TensorHandle; name=nothing, num_features=nothing, l1=nothing, l2=nothing)
        desc = tf.EagerOp("SdcaShrinkL1")
        tf.add_input(desc, weights_)
        if num_features !== nothing
            desc["num_features"] = Base.Int(num_features)
        end
        if l1 !== nothing
            desc["l1"] = Base.identity(l1)
        end
        if l2 !== nothing
            desc["l2"] = Base.identity(l2)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tf_record_reader_v2(; container=, shared_name=, compression_type=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tf_record_reader_v2(; name=nothing, container=nothing, shared_name=nothing, compression_type=nothing)
            local desc
            tf.with_op_name(name, "TFRecordReaderV2") do 
                desc = tf.NodeDescription("TFRecordReaderV2")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if compression_type !== nothing
                    desc["compression_type"] = Base.String(compression_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tf_record_reader_v2(; name=nothing, container=nothing, shared_name=nothing, compression_type=nothing)
        desc = tf.EagerOp("TFRecordReaderV2")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if compression_type !== nothing
            desc["compression_type"] = Base.String(compression_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     multi_device_iterator_from_string_handle(string_handle; output_types=Int64[], output_shapes=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function multi_device_iterator_from_string_handle(string_handle_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "MultiDeviceIteratorFromStringHandle") do 
                desc = tf.NodeDescription("MultiDeviceIteratorFromStringHandle")
                string_handle_ = convert(Tensor{String}, string_handle_)
                tf.add_input(desc, string_handle_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function multi_device_iterator_from_string_handle(string_handle_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("MultiDeviceIteratorFromStringHandle")
        tf.add_input(desc, string_handle_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     padded_batch_dataset_v2(input_dataset, batch_size, padded_shapes, padding_values, drop_remainder)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function padded_batch_dataset_v2(input_dataset_, batch_size_, padded_shapes_, padding_values_, drop_remainder_; name=nothing, Toutput_types=nothing, output_shapes=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "PaddedBatchDatasetV2") do 
                desc = tf.NodeDescription("PaddedBatchDatasetV2")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                batch_size_ = convert(Tensor{Int64}, batch_size_)
                padded_shapes_ = [convert(Tensor{Int64}, x) for x = padded_shapes_]
                padding_values_ = [convert(Tensor{Any}, x) for x = padding_values_]
                drop_remainder_ = convert(Tensor{Bool}, drop_remainder_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, batch_size_)
                tf.add_input(desc, padded_shapes_)
                tf.add_input(desc, padding_values_)
                tf.add_input(desc, drop_remainder_)
                if Toutput_types !== nothing
                    desc["Toutput_types"] = map(Base.identity, Toutput_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function padded_batch_dataset_v2(input_dataset_::tf.TensorHandle, batch_size_::tf.TensorHandle, padded_shapes_::tf.TensorHandle, padding_values_::tf.TensorHandle, drop_remainder_::tf.TensorHandle; name=nothing, Toutput_types=nothing, output_shapes=nothing, N=nothing)
        desc = tf.EagerOp("PaddedBatchDatasetV2")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, batch_size_)
        tf.add_input(desc, padded_shapes_)
        tf.add_input(desc, padding_values_)
        tf.add_input(desc, drop_remainder_)
        if Toutput_types !== nothing
            desc["Toutput_types"] = map(Base.identity, Toutput_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_proximal_adagrad_parameters(parameters, accumulators; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_proximal_adagrad_parameters(parameters_, accumulators_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingProximalAdagradParameters") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingProximalAdagradParameters")
                parameters_ = convert(Tensor{Float32}, parameters_)
                accumulators_ = convert(Tensor{Float32}, accumulators_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, accumulators_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_proximal_adagrad_parameters(parameters_::tf.TensorHandle, accumulators_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingProximalAdagradParameters")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, accumulators_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_size(handle, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_size(handle_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArraySize") do 
                desc = tf.NodeDescription("TensorArraySize")
                handle_ = convert(Tensor{String}, handle_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_size(handle_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArraySize")
        tf.add_input(desc, handle_)
        tf.add_input(desc, flow_in_)
        (tf.execute(desc))[1]
    end
end


"""
     ordered_map_size(; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ordered_map_size(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "OrderedMapSize") do 
                desc = tf.NodeDescription("OrderedMapSize")
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ordered_map_size(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("OrderedMapSize")
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     stateless_random_uniform(shape, seed; dtype=Float32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stateless_random_uniform(shape_, seed_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "StatelessRandomUniform") do 
                desc = tf.NodeDescription("StatelessRandomUniform")
                shape_ = convert(Tensor{Int32}, shape_)
                seed_ = convert(Tensor{Int64}, seed_)
                (shape_,) = tf.tf_promote(shape_)
                (seed_,) = tf.tf_promote(seed_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, seed_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stateless_random_uniform(shape_::tf.TensorHandle, seed_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("StatelessRandomUniform")
        tf.add_input(desc, shape_)
        tf.add_input(desc, seed_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["T"] = tf.data_type(shape_)
        desc["Tseed"] = tf.data_type(seed_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_to_sparse_set_operation(set1_indices, set1_values, set1_shape, set2_indices, set2_values, set2_shape; validate_indices=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_to_sparse_set_operation(set1_indices_, set1_values_, set1_shape_, set2_indices_, set2_values_, set2_shape_; name=nothing, set_operation=nothing, validate_indices=nothing)
            local desc
            tf.with_op_name(name, "SparseToSparseSetOperation") do 
                desc = tf.NodeDescription("SparseToSparseSetOperation")
                set1_indices_ = convert(Tensor{Int64}, set1_indices_)
                set1_values_ = convert(Tensor{Any}, set1_values_)
                set1_shape_ = convert(Tensor{Int64}, set1_shape_)
                set2_indices_ = convert(Tensor{Int64}, set2_indices_)
                set2_values_ = convert(Tensor{Any}, set2_values_)
                set2_shape_ = convert(Tensor{Int64}, set2_shape_)
                (set1_values_, set2_values_) = tf.tf_promote(set1_values_, set2_values_)
                tf.add_input(desc, set1_indices_)
                tf.add_input(desc, set1_values_)
                tf.add_input(desc, set1_shape_)
                tf.add_input(desc, set2_indices_)
                tf.add_input(desc, set2_values_)
                tf.add_input(desc, set2_shape_)
                if set_operation !== nothing
                    desc["set_operation"] = Base.String(set_operation)
                end
                if validate_indices !== nothing
                    desc["validate_indices"] = Base.Bool(validate_indices)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_to_sparse_set_operation(set1_indices_::tf.TensorHandle, set1_values_::tf.TensorHandle, set1_shape_::tf.TensorHandle, set2_indices_::tf.TensorHandle, set2_values_::tf.TensorHandle, set2_shape_::tf.TensorHandle; name=nothing, set_operation=nothing, validate_indices=nothing)
        desc = tf.EagerOp("SparseToSparseSetOperation")
        tf.add_input(desc, set1_indices_)
        tf.add_input(desc, set1_values_)
        tf.add_input(desc, set1_shape_)
        tf.add_input(desc, set2_indices_)
        tf.add_input(desc, set2_values_)
        tf.add_input(desc, set2_shape_)
        if set_operation !== nothing
            desc["set_operation"] = Base.String(set_operation)
        end
        if validate_indices !== nothing
            desc["validate_indices"] = Base.Bool(validate_indices)
        end
        desc["T"] = tf.data_type(set1_values_)
        desc["T"] = tf.data_type(set2_values_)
        tf.execute(desc)
    end
end


"""
     tensor_summary(tensor; description=, labels=Int64[], display_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_summary(tensor_; name=nothing, description=nothing, labels=nothing, display_name=nothing)
            local desc
            tf.with_op_name(name, "TensorSummary") do 
                desc = tf.NodeDescription("TensorSummary")
                tensor_ = convert(Tensor{Any}, tensor_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, tensor_)
                if description !== nothing
                    desc["description"] = Base.String(description)
                end
                if labels !== nothing
                    desc["labels"] = map(Base.identity, labels)
                end
                if display_name !== nothing
                    desc["display_name"] = Base.String(display_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_summary(tensor_::tf.TensorHandle; name=nothing, description=nothing, labels=nothing, display_name=nothing)
        desc = tf.EagerOp("TensorSummary")
        tf.add_input(desc, tensor_)
        if description !== nothing
            desc["description"] = Base.String(description)
        end
        if labels !== nothing
            desc["labels"] = map(Base.identity, labels)
        end
        if display_name !== nothing
            desc["display_name"] = Base.String(display_name)
        end
        desc["T"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     remote_fused_graph_execute(inputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function remote_fused_graph_execute(inputs_; name=nothing, Tinputs=nothing, Toutputs=nothing, serialized_remote_fused_graph_execute_info=nothing)
            local desc
            tf.with_op_name(name, "RemoteFusedGraphExecute") do 
                desc = tf.NodeDescription("RemoteFusedGraphExecute")
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                tf.add_input(desc, inputs_)
                if Tinputs !== nothing
                    desc["Tinputs"] = map(Base.identity, Tinputs)
                end
                if Toutputs !== nothing
                    desc["Toutputs"] = map(Base.identity, Toutputs)
                end
                if serialized_remote_fused_graph_execute_info !== nothing
                    desc["serialized_remote_fused_graph_execute_info"] = Base.String(serialized_remote_fused_graph_execute_info)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function remote_fused_graph_execute(inputs_::tf.TensorHandle; name=nothing, Tinputs=nothing, Toutputs=nothing, serialized_remote_fused_graph_execute_info=nothing)
        desc = tf.EagerOp("RemoteFusedGraphExecute")
        tf.add_input(desc, inputs_)
        if Tinputs !== nothing
            desc["Tinputs"] = map(Base.identity, Tinputs)
        end
        if Toutputs !== nothing
            desc["Toutputs"] = map(Base.identity, Toutputs)
        end
        if serialized_remote_fused_graph_execute_info !== nothing
            desc["serialized_remote_fused_graph_execute_info"] = Base.String(serialized_remote_fused_graph_execute_info)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_slice_grad(backprop_val_grad, input_indices, input_start, output_indices)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_slice_grad(backprop_val_grad_, input_indices_, input_start_, output_indices_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSliceGrad") do 
                desc = tf.NodeDescription("SparseSliceGrad")
                backprop_val_grad_ = convert(Tensor{Any}, backprop_val_grad_)
                input_indices_ = convert(Tensor{Int64}, input_indices_)
                input_start_ = convert(Tensor{Int64}, input_start_)
                output_indices_ = convert(Tensor{Int64}, output_indices_)
                (backprop_val_grad_,) = tf.tf_promote(backprop_val_grad_)
                tf.add_input(desc, backprop_val_grad_)
                tf.add_input(desc, input_indices_)
                tf.add_input(desc, input_start_)
                tf.add_input(desc, output_indices_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_slice_grad(backprop_val_grad_::tf.TensorHandle, input_indices_::tf.TensorHandle, input_start_::tf.TensorHandle, output_indices_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSliceGrad")
        tf.add_input(desc, backprop_val_grad_)
        tf.add_input(desc, input_indices_)
        tf.add_input(desc, input_start_)
        tf.add_input(desc, output_indices_)
        desc["T"] = tf.data_type(backprop_val_grad_)
        (tf.execute(desc))[1]
    end
end


"""
     cumsum(x, axis; exclusive=false, reverse=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cumsum(x_, axis_; name=nothing, exclusive=nothing, reverse=nothing)
            local desc
            tf.with_op_name(name, "Cumsum") do 
                desc = tf.NodeDescription("Cumsum")
                x_ = convert(Tensor{Any}, x_)
                axis_ = convert(Tensor{Int32}, axis_)
                axis_ = axis_ - convert(tf.Tensor{eltype(axis_)}, 1)
                (x_,) = tf.tf_promote(x_)
                (axis_,) = tf.tf_promote(axis_)
                tf.add_input(desc, x_)
                tf.add_input(desc, axis_)
                if exclusive !== nothing
                    desc["exclusive"] = Base.Bool(exclusive)
                end
                if reverse !== nothing
                    desc["reverse"] = Base.Bool(reverse)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cumsum(x_::tf.TensorHandle, axis_::tf.TensorHandle; name=nothing, exclusive=nothing, reverse=nothing)
        desc = tf.EagerOp("Cumsum")
        tf.add_input(desc, x_)
        tf.add_input(desc, axis_)
        if exclusive !== nothing
            desc["exclusive"] = Base.Bool(exclusive)
        end
        if reverse !== nothing
            desc["reverse"] = Base.Bool(reverse)
        end
        desc["T"] = tf.data_type(x_)
        desc["Tidx"] = tf.data_type(axis_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_norm_with_global_normalization_grad(t, m, v, gamma, backprop)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_norm_with_global_normalization_grad(t_, m_, v_, gamma_, backprop_; name=nothing, variance_epsilon=nothing, scale_after_normalization=nothing)
            local desc
            tf.with_op_name(name, "BatchNormWithGlobalNormalizationGrad") do 
                desc = tf.NodeDescription("BatchNormWithGlobalNormalizationGrad")
                t_ = convert(Tensor{Any}, t_)
                m_ = convert(Tensor{Any}, m_)
                v_ = convert(Tensor{Any}, v_)
                gamma_ = convert(Tensor{Any}, gamma_)
                backprop_ = convert(Tensor{Any}, backprop_)
                (t_, m_, v_, gamma_, backprop_) = tf.tf_promote(t_, m_, v_, gamma_, backprop_)
                tf.add_input(desc, t_)
                tf.add_input(desc, m_)
                tf.add_input(desc, v_)
                tf.add_input(desc, gamma_)
                tf.add_input(desc, backprop_)
                if variance_epsilon !== nothing
                    desc["variance_epsilon"] = Base.identity(variance_epsilon)
                end
                if scale_after_normalization !== nothing
                    desc["scale_after_normalization"] = Base.Bool(scale_after_normalization)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:5
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function batch_norm_with_global_normalization_grad(t_::tf.TensorHandle, m_::tf.TensorHandle, v_::tf.TensorHandle, gamma_::tf.TensorHandle, backprop_::tf.TensorHandle; name=nothing, variance_epsilon=nothing, scale_after_normalization=nothing)
        desc = tf.EagerOp("BatchNormWithGlobalNormalizationGrad")
        tf.add_input(desc, t_)
        tf.add_input(desc, m_)
        tf.add_input(desc, v_)
        tf.add_input(desc, gamma_)
        tf.add_input(desc, backprop_)
        if variance_epsilon !== nothing
            desc["variance_epsilon"] = Base.identity(variance_epsilon)
        end
        if scale_after_normalization !== nothing
            desc["scale_after_normalization"] = Base.Bool(scale_after_normalization)
        end
        desc["T"] = tf.data_type(t_)
        desc["T"] = tf.data_type(m_)
        desc["T"] = tf.data_type(v_)
        desc["T"] = tf.data_type(gamma_)
        desc["T"] = tf.data_type(backprop_)
        tf.execute(desc)
    end
end


"""
     avg_pool_grad(orig_input_shape, grad; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function avg_pool_grad(orig_input_shape_, grad_; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "AvgPoolGrad") do 
                desc = tf.NodeDescription("AvgPoolGrad")
                orig_input_shape_ = convert(Tensor{Int32}, orig_input_shape_)
                grad_ = convert(Tensor{Any}, grad_)
                (grad_,) = tf.tf_promote(grad_)
                tf.add_input(desc, orig_input_shape_)
                tf.add_input(desc, grad_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function avg_pool_grad(orig_input_shape_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("AvgPoolGrad")
        tf.add_input(desc, orig_input_shape_)
        tf.add_input(desc, grad_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     restore_v2(prefix, tensor_names, shape_and_slices)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function restore_v2(prefix_, tensor_names_, shape_and_slices_; name=nothing, dtypes=nothing)
            local desc
            tf.with_op_name(name, "RestoreV2") do 
                desc = tf.NodeDescription("RestoreV2")
                prefix_ = convert(Tensor{String}, prefix_)
                tensor_names_ = convert(Tensor{String}, tensor_names_)
                shape_and_slices_ = convert(Tensor{String}, shape_and_slices_)
                tf.add_input(desc, prefix_)
                tf.add_input(desc, tensor_names_)
                tf.add_input(desc, shape_and_slices_)
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function restore_v2(prefix_::tf.TensorHandle, tensor_names_::tf.TensorHandle, shape_and_slices_::tf.TensorHandle; name=nothing, dtypes=nothing)
        desc = tf.EagerOp("RestoreV2")
        tf.add_input(desc, prefix_)
        tf.add_input(desc, tensor_names_)
        tf.add_input(desc, shape_and_slices_)
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     relu6(features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function relu6(features_; name=nothing)
            local desc
            tf.with_op_name(name, "Relu6") do 
                desc = tf.NodeDescription("Relu6")
                features_ = convert(Tensor{Any}, features_)
                (features_,) = tf.tf_promote(features_)
                tf.add_input(desc, features_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function relu6(features_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Relu6")
        tf.add_input(desc, features_)
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_apply_rms_prop(var, ms, mom, lr, rho, momentum, epsilon, grad, indices; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_apply_rms_prop(var_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_, indices_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "SparseApplyRMSProp") do 
                desc = tf.NodeDescription("SparseApplyRMSProp")
                var_ = convert(Tensor{Any}, var_)
                ms_ = convert(Tensor{Any}, ms_)
                mom_ = convert(Tensor{Any}, mom_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                momentum_ = convert(Tensor{Any}, momentum_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (var_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_) = tf.tf_promote(var_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, ms_)
                tf.add_input(desc, mom_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, momentum_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_apply_rms_prop(var_::tf.TensorHandle, ms_::tf.TensorHandle, mom_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, momentum_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("SparseApplyRMSProp")
        tf.add_input(desc, var_)
        tf.add_input(desc, ms_)
        tf.add_input(desc, mom_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, momentum_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(ms_)
        desc["T"] = tf.data_type(mom_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(momentum_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     _recv(; client_terminated=false)

Receives the named tensor from send_device on recv_device.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _recv(; name=nothing, tensor_type=nothing, tensor_name=nothing, send_device=nothing, send_device_incarnation=nothing, recv_device=nothing, client_terminated=nothing)
            local desc
            tf.with_op_name(name, "_Recv") do 
                desc = tf.NodeDescription("_Recv")
                if tensor_type !== nothing
                    desc["tensor_type"] = Base.identity(tensor_type)
                end
                if tensor_name !== nothing
                    desc["tensor_name"] = Base.String(tensor_name)
                end
                if send_device !== nothing
                    desc["send_device"] = Base.String(send_device)
                end
                if send_device_incarnation !== nothing
                    desc["send_device_incarnation"] = Base.Int(send_device_incarnation)
                end
                if recv_device !== nothing
                    desc["recv_device"] = Base.String(recv_device)
                end
                if client_terminated !== nothing
                    desc["client_terminated"] = Base.Bool(client_terminated)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _recv(; name=nothing, tensor_type=nothing, tensor_name=nothing, send_device=nothing, send_device_incarnation=nothing, recv_device=nothing, client_terminated=nothing)
        desc = tf.EagerOp("_Recv")
        if tensor_type !== nothing
            desc["tensor_type"] = Base.identity(tensor_type)
        end
        if tensor_name !== nothing
            desc["tensor_name"] = Base.String(tensor_name)
        end
        if send_device !== nothing
            desc["send_device"] = Base.String(send_device)
        end
        if send_device_incarnation !== nothing
            desc["send_device_incarnation"] = Base.Int(send_device_incarnation)
        end
        if recv_device !== nothing
            desc["recv_device"] = Base.String(recv_device)
        end
        if client_terminated !== nothing
            desc["client_terminated"] = Base.Bool(client_terminated)
        end
        (tf.execute(desc))[1]
    end
end


"""
     max_pool(input; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool(input_; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "MaxPool") do 
                desc = tf.NodeDescription("MaxPool")
                input_ = convert(Tensor{Float32}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max_pool(input_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("MaxPool")
        tf.add_input(desc, input_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     invert(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function invert(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Invert") do 
                desc = tf.NodeDescription("Invert")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function invert(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Invert")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     _unary_ops_composition(x)

*NOTE*: Do not invoke this operator directly in Python. Graph rewrite pass is
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _unary_ops_composition(x_; name=nothing, op_names=nothing)
            local desc
            tf.with_op_name(name, "_UnaryOpsComposition") do 
                desc = tf.NodeDescription("_UnaryOpsComposition")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
                if op_names !== nothing
                    desc["op_names"] = map(Base.identity, op_names)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _unary_ops_composition(x_::tf.TensorHandle; name=nothing, op_names=nothing)
        desc = tf.EagerOp("_UnaryOpsComposition")
        tf.add_input(desc, x_)
        if op_names !== nothing
            desc["op_names"] = map(Base.identity, op_names)
        end
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_map_dataset(input_dataset, other_arguments; use_inter_op_parallelism=true, preserve_cardinality=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_map_dataset(input_dataset_, other_arguments_; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, use_inter_op_parallelism=nothing, preserve_cardinality=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalMapDataset") do 
                desc = tf.NodeDescription("ExperimentalMapDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, other_arguments_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if use_inter_op_parallelism !== nothing
                    desc["use_inter_op_parallelism"] = Base.Bool(use_inter_op_parallelism)
                end
                if preserve_cardinality !== nothing
                    desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_map_dataset(input_dataset_::tf.TensorHandle, other_arguments_::tf.TensorHandle; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, use_inter_op_parallelism=nothing, preserve_cardinality=nothing)
        desc = tf.EagerOp("ExperimentalMapDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, other_arguments_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if use_inter_op_parallelism !== nothing
            desc["use_inter_op_parallelism"] = Base.Bool(use_inter_op_parallelism)
        end
        if preserve_cardinality !== nothing
            desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
        end
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_adam_parameters(parameters, momenta, velocities; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_adam_parameters(parameters_, momenta_, velocities_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingADAMParameters") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingADAMParameters")
                parameters_ = convert(Tensor{Float32}, parameters_)
                momenta_ = convert(Tensor{Float32}, momenta_)
                velocities_ = convert(Tensor{Float32}, velocities_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, momenta_)
                tf.add_input(desc, velocities_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_adam_parameters(parameters_::tf.TensorHandle, momenta_::tf.TensorHandle, velocities_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingADAMParameters")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, momenta_)
        tf.add_input(desc, velocities_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     parse_tensor(serialized)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function parse_tensor(serialized_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "ParseTensor") do 
                desc = tf.NodeDescription("ParseTensor")
                serialized_ = convert(Tensor{String}, serialized_)
                tf.add_input(desc, serialized_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function parse_tensor(serialized_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("ParseTensor")
        tf.add_input(desc, serialized_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     experimental_materialized_index_dataset_handle()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_materialized_index_dataset_handle(; name=nothing, container=nothing, shared_name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalMaterializedIndexDatasetHandle") do 
                desc = tf.NodeDescription("ExperimentalMaterializedIndexDatasetHandle")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_materialized_index_dataset_handle(; name=nothing, container=nothing, shared_name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalMaterializedIndexDatasetHandle")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     multi_device_iterator_get_next_from_shard(multi_device_iterator, shard_num, incarnation_id)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function multi_device_iterator_get_next_from_shard(multi_device_iterator_, shard_num_, incarnation_id_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "MultiDeviceIteratorGetNextFromShard") do 
                desc = tf.NodeDescription("MultiDeviceIteratorGetNextFromShard")
                multi_device_iterator_ = convert(Tensor{Any}, multi_device_iterator_)
                shard_num_ = convert(Tensor{Int32}, shard_num_)
                incarnation_id_ = convert(Tensor{Int64}, incarnation_id_)
                tf.add_input(desc, multi_device_iterator_)
                tf.add_input(desc, shard_num_)
                tf.add_input(desc, incarnation_id_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function multi_device_iterator_get_next_from_shard(multi_device_iterator_::tf.TensorHandle, shard_num_::tf.TensorHandle, incarnation_id_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("MultiDeviceIteratorGetNextFromShard")
        tf.add_input(desc, multi_device_iterator_)
        tf.add_input(desc, shard_num_)
        tf.add_input(desc, incarnation_id_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     random_uniform_int(shape, minval, maxval; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function random_uniform_int(shape_, minval_, maxval_; name=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "RandomUniformInt") do 
                desc = tf.NodeDescription("RandomUniformInt")
                shape_ = convert(Tensor{Any}, shape_)
                minval_ = convert(Tensor{Any}, minval_)
                maxval_ = convert(Tensor{Any}, maxval_)
                (shape_,) = tf.tf_promote(shape_)
                (minval_, maxval_) = tf.tf_promote(minval_, maxval_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, minval_)
                tf.add_input(desc, maxval_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function random_uniform_int(shape_::tf.TensorHandle, minval_::tf.TensorHandle, maxval_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("RandomUniformInt")
        tf.add_input(desc, shape_)
        tf.add_input(desc, minval_)
        tf.add_input(desc, maxval_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        desc["T"] = tf.data_type(shape_)
        desc["Tout"] = tf.data_type(minval_)
        desc["Tout"] = tf.data_type(maxval_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_softmax_cross_entropy_with_logits(features, labels)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_softmax_cross_entropy_with_logits(features_, labels_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSoftmaxCrossEntropyWithLogits") do 
                desc = tf.NodeDescription("SparseSoftmaxCrossEntropyWithLogits")
                features_ = convert(Tensor{Any}, features_)
                labels_ = convert(Tensor{Int64}, labels_)
                (features_,) = tf.tf_promote(features_)
                (labels_,) = tf.tf_promote(labels_)
                tf.add_input(desc, features_)
                tf.add_input(desc, labels_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_softmax_cross_entropy_with_logits(features_::tf.TensorHandle, labels_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSoftmaxCrossEntropyWithLogits")
        tf.add_input(desc, features_)
        tf.add_input(desc, labels_)
        desc["T"] = tf.data_type(features_)
        desc["Tlabels"] = tf.data_type(labels_)
        tf.execute(desc)
    end
end


"""
     tensor_array_read_v2(handle, index, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_read_v2(handle_, index_, flow_in_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayReadV2") do 
                desc = tf.NodeDescription("TensorArrayReadV2")
                handle_ = convert(Tensor{String}, handle_)
                index_ = convert(Tensor{Int32}, index_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, index_)
                tf.add_input(desc, flow_in_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_read_v2(handle_::tf.TensorHandle, index_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("TensorArrayReadV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, index_)
        tf.add_input(desc, flow_in_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     reader_read_up_to(reader_handle, queue_handle, num_records)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_read_up_to(reader_handle_, queue_handle_, num_records_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderReadUpTo") do 
                desc = tf.NodeDescription("ReaderReadUpTo")
                reader_handle_ = convert(Tensor{String}, reader_handle_)
                queue_handle_ = convert(Tensor{String}, queue_handle_)
                num_records_ = convert(Tensor{Int64}, num_records_)
                tf.add_input(desc, reader_handle_)
                tf.add_input(desc, queue_handle_)
                tf.add_input(desc, num_records_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function reader_read_up_to(reader_handle_::tf.TensorHandle, queue_handle_::tf.TensorHandle, num_records_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderReadUpTo")
        tf.add_input(desc, reader_handle_)
        tf.add_input(desc, queue_handle_)
        tf.add_input(desc, num_records_)
        tf.execute(desc)
    end
end


"""
     encode_proto(sizes, values; descriptor_source=local://)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function encode_proto(sizes_, values_; name=nothing, field_names=nothing, message_type=nothing, descriptor_source=nothing, Tinput_types=nothing)
            local desc
            tf.with_op_name(name, "EncodeProto") do 
                desc = tf.NodeDescription("EncodeProto")
                sizes_ = convert(Tensor{Int32}, sizes_)
                values_ = [convert(Tensor{Any}, x) for x = values_]
                tf.add_input(desc, sizes_)
                tf.add_input(desc, values_)
                if field_names !== nothing
                    desc["field_names"] = map(Base.identity, field_names)
                end
                if message_type !== nothing
                    desc["message_type"] = Base.String(message_type)
                end
                if descriptor_source !== nothing
                    desc["descriptor_source"] = Base.String(descriptor_source)
                end
                if Tinput_types !== nothing
                    desc["Tinput_types"] = map(Base.identity, Tinput_types)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function encode_proto(sizes_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing, field_names=nothing, message_type=nothing, descriptor_source=nothing, Tinput_types=nothing)
        desc = tf.EagerOp("EncodeProto")
        tf.add_input(desc, sizes_)
        tf.add_input(desc, values_)
        if field_names !== nothing
            desc["field_names"] = map(Base.identity, field_names)
        end
        if message_type !== nothing
            desc["message_type"] = Base.String(message_type)
        end
        if descriptor_source !== nothing
            desc["descriptor_source"] = Base.String(descriptor_source)
        end
        if Tinput_types !== nothing
            desc["Tinput_types"] = map(Base.identity, Tinput_types)
        end
        (tf.execute(desc))[1]
    end
end


"""
     strided_slice_grad(shape, begin, end, strides, dy; begin_mask=0, end_mask=0, ellipsis_mask=0, new_axis_mask=0, shrink_axis_mask=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function strided_slice_grad(shape_, begin_, end_, strides_, dy_; name=nothing, Index=nothing, begin_mask=nothing, end_mask=nothing, ellipsis_mask=nothing, new_axis_mask=nothing, shrink_axis_mask=nothing)
            local desc
            tf.with_op_name(name, "StridedSliceGrad") do 
                desc = tf.NodeDescription("StridedSliceGrad")
                shape_ = convert(Tensor{Any}, shape_)
                begin_ = convert(Tensor{Any}, begin_)
                begin_ = begin_ - convert(tf.Tensor{eltype(begin_)}, 1)
                end_ = convert(Tensor{Any}, end_)
                end_ = end_ - convert(tf.Tensor{eltype(end_)}, 1)
                strides_ = convert(Tensor{Any}, strides_)
                strides_ = strides_ - convert(tf.Tensor{eltype(strides_)}, 1)
                dy_ = convert(Tensor{Any}, dy_)
                (dy_,) = tf.tf_promote(dy_)
                (shape_, begin_, end_, strides_) = tf.tf_promote(shape_, begin_, end_, strides_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, begin_)
                tf.add_input(desc, end_)
                tf.add_input(desc, strides_)
                tf.add_input(desc, dy_)
                if Index !== nothing
                    desc["Index"] = Base.identity(Index)
                end
                if begin_mask !== nothing
                    begin_mask = Base.Int(begin_mask) - 1
                end
                if begin_mask !== nothing
                    desc["begin_mask"] = Base.Int(begin_mask)
                end
                if end_mask !== nothing
                    end_mask = Base.Int(end_mask) - 1
                end
                if end_mask !== nothing
                    desc["end_mask"] = Base.Int(end_mask)
                end
                if ellipsis_mask !== nothing
                    ellipsis_mask = Base.Int(ellipsis_mask) - 1
                end
                if ellipsis_mask !== nothing
                    desc["ellipsis_mask"] = Base.Int(ellipsis_mask)
                end
                if new_axis_mask !== nothing
                    new_axis_mask = Base.Int(new_axis_mask) - 1
                end
                if new_axis_mask !== nothing
                    desc["new_axis_mask"] = Base.Int(new_axis_mask)
                end
                if shrink_axis_mask !== nothing
                    shrink_axis_mask = Base.Int(shrink_axis_mask) - 1
                end
                if shrink_axis_mask !== nothing
                    desc["shrink_axis_mask"] = Base.Int(shrink_axis_mask)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function strided_slice_grad(shape_::tf.TensorHandle, begin_::tf.TensorHandle, end_::tf.TensorHandle, strides_::tf.TensorHandle, dy_::tf.TensorHandle; name=nothing, Index=nothing, begin_mask=nothing, end_mask=nothing, ellipsis_mask=nothing, new_axis_mask=nothing, shrink_axis_mask=nothing)
        desc = tf.EagerOp("StridedSliceGrad")
        tf.add_input(desc, shape_)
        tf.add_input(desc, begin_)
        tf.add_input(desc, end_)
        tf.add_input(desc, strides_)
        tf.add_input(desc, dy_)
        if Index !== nothing
            desc["Index"] = Base.identity(Index)
        end
        if begin_mask !== nothing
            begin_mask = Base.Int(begin_mask) - 1
        end
        if begin_mask !== nothing
            desc["begin_mask"] = Base.Int(begin_mask)
        end
        if end_mask !== nothing
            end_mask = Base.Int(end_mask) - 1
        end
        if end_mask !== nothing
            desc["end_mask"] = Base.Int(end_mask)
        end
        if ellipsis_mask !== nothing
            ellipsis_mask = Base.Int(ellipsis_mask) - 1
        end
        if ellipsis_mask !== nothing
            desc["ellipsis_mask"] = Base.Int(ellipsis_mask)
        end
        if new_axis_mask !== nothing
            new_axis_mask = Base.Int(new_axis_mask) - 1
        end
        if new_axis_mask !== nothing
            desc["new_axis_mask"] = Base.Int(new_axis_mask)
        end
        if shrink_axis_mask !== nothing
            shrink_axis_mask = Base.Int(shrink_axis_mask) - 1
        end
        if shrink_axis_mask !== nothing
            desc["shrink_axis_mask"] = Base.Int(shrink_axis_mask)
        end
        desc["Index"] = tf.data_type(shape_)
        desc["Index"] = tf.data_type(begin_)
        desc["Index"] = tf.data_type(end_)
        desc["Index"] = tf.data_type(strides_)
        desc["T"] = tf.data_type(dy_)
        (tf.execute(desc))[1]
    end
end


"""
     _nccl_reduce_send(input)

Replacement node for NcclReduce.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _nccl_reduce_send(input_; name=nothing, reduction=nothing, num_devices=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "_NcclReduceSend") do 
                desc = tf.NodeDescription("_NcclReduceSend")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if reduction !== nothing
                    desc["reduction"] = Base.String(reduction)
                end
                if num_devices !== nothing
                    desc["num_devices"] = Base.Int(num_devices)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _nccl_reduce_send(input_::tf.TensorHandle; name=nothing, reduction=nothing, num_devices=nothing, shared_name=nothing)
        desc = tf.EagerOp("_NcclReduceSend")
        tf.add_input(desc, input_)
        if reduction !== nothing
            desc["reduction"] = Base.String(reduction)
        end
        if num_devices !== nothing
            desc["num_devices"] = Base.Int(num_devices)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     padded_batch_dataset(input_dataset, batch_size, padded_shapes, padding_values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function padded_batch_dataset(input_dataset_, batch_size_, padded_shapes_, padding_values_; name=nothing, Toutput_types=nothing, output_shapes=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "PaddedBatchDataset") do 
                desc = tf.NodeDescription("PaddedBatchDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                batch_size_ = convert(Tensor{Int64}, batch_size_)
                padded_shapes_ = [convert(Tensor{Int64}, x) for x = padded_shapes_]
                padding_values_ = [convert(Tensor{Any}, x) for x = padding_values_]
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, batch_size_)
                tf.add_input(desc, padded_shapes_)
                tf.add_input(desc, padding_values_)
                if Toutput_types !== nothing
                    desc["Toutput_types"] = map(Base.identity, Toutput_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function padded_batch_dataset(input_dataset_::tf.TensorHandle, batch_size_::tf.TensorHandle, padded_shapes_::tf.TensorHandle, padding_values_::tf.TensorHandle; name=nothing, Toutput_types=nothing, output_shapes=nothing, N=nothing)
        desc = tf.EagerOp("PaddedBatchDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, batch_size_)
        tf.add_input(desc, padded_shapes_)
        tf.add_input(desc, padding_values_)
        if Toutput_types !== nothing
            desc["Toutput_types"] = map(Base.identity, Toutput_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        (tf.execute(desc))[1]
    end
end


"""
     data_format_vec_permute(x; src_format=NHWC, dst_format=NCHW)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function data_format_vec_permute(x_; name=nothing, src_format=nothing, dst_format=nothing)
            local desc
            tf.with_op_name(name, "DataFormatVecPermute") do 
                desc = tf.NodeDescription("DataFormatVecPermute")
                x_ = convert(Tensor{Int32}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
                if src_format !== nothing
                    desc["src_format"] = Base.String(src_format)
                end
                if dst_format !== nothing
                    desc["dst_format"] = Base.String(dst_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function data_format_vec_permute(x_::tf.TensorHandle; name=nothing, src_format=nothing, dst_format=nothing)
        desc = tf.EagerOp("DataFormatVecPermute")
        tf.add_input(desc, x_)
        if src_format !== nothing
            desc["src_format"] = Base.String(src_format)
        end
        if dst_format !== nothing
            desc["dst_format"] = Base.String(dst_format)
        end
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     string_format(inputs; template=%s, placeholder=%s, summarize=3)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function string_format(inputs_; name=nothing, T=nothing, template=nothing, placeholder=nothing, summarize=nothing)
            local desc
            tf.with_op_name(name, "StringFormat") do 
                desc = tf.NodeDescription("StringFormat")
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                tf.add_input(desc, inputs_)
                if T !== nothing
                    desc["T"] = map(Base.identity, T)
                end
                if template !== nothing
                    desc["template"] = Base.String(template)
                end
                if placeholder !== nothing
                    desc["placeholder"] = Base.String(placeholder)
                end
                if summarize !== nothing
                    desc["summarize"] = Base.Int(summarize)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function string_format(inputs_::tf.TensorHandle; name=nothing, T=nothing, template=nothing, placeholder=nothing, summarize=nothing)
        desc = tf.EagerOp("StringFormat")
        tf.add_input(desc, inputs_)
        if T !== nothing
            desc["T"] = map(Base.identity, T)
        end
        if template !== nothing
            desc["template"] = Base.String(template)
        end
        if placeholder !== nothing
            desc["placeholder"] = Base.String(placeholder)
        end
        if summarize !== nothing
            desc["summarize"] = Base.Int(summarize)
        end
        (tf.execute(desc))[1]
    end
end


"""
     as_string(input; precision=-1, scientific=false, shortest=false, width=-1, fill=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function as_string(input_; name=nothing, precision=nothing, scientific=nothing, shortest=nothing, width=nothing, fill=nothing)
            local desc
            tf.with_op_name(name, "AsString") do 
                desc = tf.NodeDescription("AsString")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if precision !== nothing
                    desc["precision"] = Base.Int(precision)
                end
                if scientific !== nothing
                    desc["scientific"] = Base.Bool(scientific)
                end
                if shortest !== nothing
                    desc["shortest"] = Base.Bool(shortest)
                end
                if width !== nothing
                    desc["width"] = Base.Int(width)
                end
                if fill !== nothing
                    desc["fill"] = Base.String(fill)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function as_string(input_::tf.TensorHandle; name=nothing, precision=nothing, scientific=nothing, shortest=nothing, width=nothing, fill=nothing)
        desc = tf.EagerOp("AsString")
        tf.add_input(desc, input_)
        if precision !== nothing
            desc["precision"] = Base.Int(precision)
        end
        if scientific !== nothing
            desc["scientific"] = Base.Bool(scientific)
        end
        if shortest !== nothing
            desc["shortest"] = Base.Bool(shortest)
        end
        if width !== nothing
            desc["width"] = Base.Int(width)
        end
        if fill !== nothing
            desc["fill"] = Base.String(fill)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     queue_enqueue_many(handle, components; timeout_ms=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_enqueue_many(handle_, components_; name=nothing, Tcomponents=nothing, timeout_ms=nothing)
            local desc
            tf.with_op_name(name, "QueueEnqueueMany") do 
                desc = tf.NodeDescription("QueueEnqueueMany")
                handle_ = convert(Tensor{String}, handle_)
                components_ = [convert(Tensor{Any}, x) for x = components_]
                tf.add_input(desc, handle_)
                tf.add_input(desc, components_)
                if Tcomponents !== nothing
                    desc["Tcomponents"] = map(Base.identity, Tcomponents)
                end
                if timeout_ms !== nothing
                    desc["timeout_ms"] = Base.Int(timeout_ms)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_enqueue_many(handle_::tf.TensorHandle, components_::tf.TensorHandle; name=nothing, Tcomponents=nothing, timeout_ms=nothing)
        desc = tf.EagerOp("QueueEnqueueMany")
        tf.add_input(desc, handle_)
        tf.add_input(desc, components_)
        if Tcomponents !== nothing
            desc["Tcomponents"] = map(Base.identity, Tcomponents)
        end
        if timeout_ms !== nothing
            desc["timeout_ms"] = Base.Int(timeout_ms)
        end
        (tf.execute(desc))[1]
    end
end


"""
     fake_param()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fake_param(; name=nothing, dtype=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "FakeParam") do 
                desc = tf.NodeDescription("FakeParam")
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fake_param(; name=nothing, dtype=nothing, shape=nothing)
        desc = tf.EagerOp("FakeParam")
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     apply_adagrad(var, accum, lr, grad; use_locking=false, update_slots=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_adagrad(var_, accum_, lr_, grad_; name=nothing, use_locking=nothing, update_slots=nothing)
            local desc
            tf.with_op_name(name, "ApplyAdagrad") do 
                desc = tf.NodeDescription("ApplyAdagrad")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                grad_ = convert(Tensor{Any}, grad_)
                (var_, accum_, lr_, grad_) = tf.tf_promote(var_, accum_, lr_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if update_slots !== nothing
                    desc["update_slots"] = Base.Bool(update_slots)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_adagrad(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing, update_slots=nothing)
        desc = tf.EagerOp("ApplyAdagrad")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if update_slots !== nothing
            desc["update_slots"] = Base.Bool(update_slots)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_iterator_get_device(resource)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_iterator_get_device(resource_; name=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalIteratorGetDevice") do 
                desc = tf.NodeDescription("ExperimentalIteratorGetDevice")
                resource_ = convert(Tensor{Any}, resource_)
                tf.add_input(desc, resource_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_iterator_get_device(resource_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ExperimentalIteratorGetDevice")
        tf.add_input(desc, resource_)
        (tf.execute(desc))[1]
    end
end


"""
     adjust_contrast(images, contrast_factor, min_value, max_value)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function adjust_contrast(images_, contrast_factor_, min_value_, max_value_; name=nothing)
            local desc
            tf.with_op_name(name, "AdjustContrast") do 
                desc = tf.NodeDescription("AdjustContrast")
                images_ = convert(Tensor{Any}, images_)
                contrast_factor_ = convert(Tensor{Float32}, contrast_factor_)
                min_value_ = convert(Tensor{Float32}, min_value_)
                max_value_ = convert(Tensor{Float32}, max_value_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                tf.add_input(desc, contrast_factor_)
                tf.add_input(desc, min_value_)
                tf.add_input(desc, max_value_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function adjust_contrast(images_::tf.TensorHandle, contrast_factor_::tf.TensorHandle, min_value_::tf.TensorHandle, max_value_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("AdjustContrast")
        tf.add_input(desc, images_)
        tf.add_input(desc, contrast_factor_)
        tf.add_input(desc, min_value_)
        tf.add_input(desc, max_value_)
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     extract_image_patches(images)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function extract_image_patches(images_; name=nothing, ksizes=nothing, strides=nothing, rates=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "ExtractImagePatches") do 
                desc = tf.NodeDescription("ExtractImagePatches")
                images_ = convert(Tensor{Any}, images_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                if ksizes !== nothing
                    desc["ksizes"] = map(Base.identity, ksizes)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if rates !== nothing
                    desc["rates"] = map(Base.identity, rates)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function extract_image_patches(images_::tf.TensorHandle; name=nothing, ksizes=nothing, strides=nothing, rates=nothing, padding=nothing)
        desc = tf.EagerOp("ExtractImagePatches")
        tf.add_input(desc, images_)
        if ksizes !== nothing
            desc["ksizes"] = map(Base.identity, ksizes)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if rates !== nothing
            desc["rates"] = map(Base.identity, rates)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     scale_and_translate(images, size, scale, translation; kernel_type=lanczos3)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scale_and_translate(images_, size_, scale_, translation_; name=nothing, kernel_type=nothing)
            local desc
            tf.with_op_name(name, "ScaleAndTranslate") do 
                desc = tf.NodeDescription("ScaleAndTranslate")
                images_ = convert(Tensor{Any}, images_)
                size_ = convert(Tensor{Int32}, size_)
                scale_ = convert(Tensor{Float32}, scale_)
                translation_ = convert(Tensor{Float32}, translation_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                tf.add_input(desc, size_)
                tf.add_input(desc, scale_)
                tf.add_input(desc, translation_)
                if kernel_type !== nothing
                    desc["kernel_type"] = Base.String(kernel_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scale_and_translate(images_::tf.TensorHandle, size_::tf.TensorHandle, scale_::tf.TensorHandle, translation_::tf.TensorHandle; name=nothing, kernel_type=nothing)
        desc = tf.EagerOp("ScaleAndTranslate")
        tf.add_input(desc, images_)
        tf.add_input(desc, size_)
        tf.add_input(desc, scale_)
        tf.add_input(desc, translation_)
        if kernel_type !== nothing
            desc["kernel_type"] = Base.String(kernel_type)
        end
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     optional_none()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function optional_none(; name=nothing)
            local desc
            tf.with_op_name(name, "OptionalNone") do 
                desc
                tf.NodeDescription("OptionalNone")
            end
            tf.Tensor(tf.Operation(desc))
        end
    function optional_none(; name=nothing)
        desc = tf.EagerOp("OptionalNone")
        (tf.execute(desc))[1]
    end
end


"""
     variable_v2(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function variable_v2(; name=nothing, shape=nothing, dtype=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "VariableV2") do 
                desc = tf.NodeDescription("VariableV2")
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function variable_v2(; name=nothing, shape=nothing, dtype=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("VariableV2")
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     elu(features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function elu(features_; name=nothing)
            local desc
            tf.with_op_name(name, "Elu") do 
                desc = tf.NodeDescription("Elu")
                features_ = convert(Tensor{Any}, features_)
                (features_,) = tf.tf_promote(features_)
                tf.add_input(desc, features_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function elu(features_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Elu")
        tf.add_input(desc, features_)
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     scatter_update(ref, indices, updates; use_locking=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_update(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ScatterUpdate") do 
                desc = tf.NodeDescription("ScatterUpdate")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (ref_, updates_) = tf.tf_promote(ref_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_update(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ScatterUpdate")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     floor_mod(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function floor_mod(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "FloorMod") do 
                desc = tf.NodeDescription("FloorMod")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function floor_mod(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("FloorMod")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_ignore_errors_dataset(input_dataset)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_ignore_errors_dataset(input_dataset_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalIgnoreErrorsDataset") do 
                desc = tf.NodeDescription("ExperimentalIgnoreErrorsDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                tf.add_input(desc, input_dataset_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_ignore_errors_dataset(input_dataset_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalIgnoreErrorsDataset")
        tf.add_input(desc, input_dataset_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     experimental_set_stats_aggregator_dataset(input_dataset, stats_aggregator, tag, counter_prefix)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_set_stats_aggregator_dataset(input_dataset_, stats_aggregator_, tag_, counter_prefix_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalSetStatsAggregatorDataset") do 
                desc = tf.NodeDescription("ExperimentalSetStatsAggregatorDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                stats_aggregator_ = convert(Tensor{Any}, stats_aggregator_)
                tag_ = convert(Tensor{String}, tag_)
                counter_prefix_ = convert(Tensor{String}, counter_prefix_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, stats_aggregator_)
                tf.add_input(desc, tag_)
                tf.add_input(desc, counter_prefix_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_set_stats_aggregator_dataset(input_dataset_::tf.TensorHandle, stats_aggregator_::tf.TensorHandle, tag_::tf.TensorHandle, counter_prefix_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalSetStatsAggregatorDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, stats_aggregator_)
        tf.add_input(desc, tag_)
        tf.add_input(desc, counter_prefix_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     compute_accidental_hits(true_classes, sampled_candidates; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function compute_accidental_hits(true_classes_, sampled_candidates_; name=nothing, num_true=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "ComputeAccidentalHits") do 
                desc = tf.NodeDescription("ComputeAccidentalHits")
                true_classes_ = convert(Tensor{Int64}, true_classes_)
                sampled_candidates_ = convert(Tensor{Int64}, sampled_candidates_)
                tf.add_input(desc, true_classes_)
                tf.add_input(desc, sampled_candidates_)
                if num_true !== nothing
                    desc["num_true"] = Base.Int(num_true)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function compute_accidental_hits(true_classes_::tf.TensorHandle, sampled_candidates_::tf.TensorHandle; name=nothing, num_true=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("ComputeAccidentalHits")
        tf.add_input(desc, true_classes_)
        tf.add_input(desc, sampled_candidates_)
        if num_true !== nothing
            desc["num_true"] = Base.Int(num_true)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        tf.execute(desc)
    end
end


"""
     string_to_number(string_tensor; out_type=Float32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function string_to_number(string_tensor_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "StringToNumber") do 
                desc = tf.NodeDescription("StringToNumber")
                string_tensor_ = convert(Tensor{String}, string_tensor_)
                tf.add_input(desc, string_tensor_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function string_to_number(string_tensor_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("StringToNumber")
        tf.add_input(desc, string_tensor_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     snapshot(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function snapshot(input_; name=nothing)
            local desc
            tf.with_op_name(name, "Snapshot") do 
                desc = tf.NodeDescription("Snapshot")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function snapshot(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Snapshot")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     deserialize_iterator(resource_handle, serialized)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function deserialize_iterator(resource_handle_, serialized_; name=nothing)
            local desc
            tf.with_op_name(name, "DeserializeIterator") do 
                desc = tf.NodeDescription("DeserializeIterator")
                resource_handle_ = convert(Tensor{Any}, resource_handle_)
                serialized_ = convert(Tensor{Any}, serialized_)
                tf.add_input(desc, resource_handle_)
                tf.add_input(desc, serialized_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function deserialize_iterator(resource_handle_::tf.TensorHandle, serialized_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DeserializeIterator")
        tf.add_input(desc, resource_handle_)
        tf.add_input(desc, serialized_)
        (tf.execute(desc))[1]
    end
end


"""
     atan(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function atan(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Atan") do 
                desc = tf.NodeDescription("Atan")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function atan(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Atan")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     mat_mul(a, b; transpose_a=false, transpose_b=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mat_mul(a_, b_; name=nothing, transpose_a=nothing, transpose_b=nothing)
            local desc
            tf.with_op_name(name, "MatMul") do 
                desc = tf.NodeDescription("MatMul")
                a_ = convert(Tensor{Any}, a_)
                b_ = convert(Tensor{Any}, b_)
                (a_, b_) = tf.tf_promote(a_, b_)
                tf.add_input(desc, a_)
                tf.add_input(desc, b_)
                if transpose_a !== nothing
                    desc["transpose_a"] = Base.Bool(transpose_a)
                end
                if transpose_b !== nothing
                    desc["transpose_b"] = Base.Bool(transpose_b)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mat_mul(a_::tf.TensorHandle, b_::tf.TensorHandle; name=nothing, transpose_a=nothing, transpose_b=nothing)
        desc = tf.EagerOp("MatMul")
        tf.add_input(desc, a_)
        tf.add_input(desc, b_)
        if transpose_a !== nothing
            desc["transpose_a"] = Base.Bool(transpose_a)
        end
        if transpose_b !== nothing
            desc["transpose_b"] = Base.Bool(transpose_b)
        end
        desc["T"] = tf.data_type(a_)
        desc["T"] = tf.data_type(b_)
        (tf.execute(desc))[1]
    end
end


"""
     erfc(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function erfc(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Erfc") do 
                desc = tf.NodeDescription("Erfc")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function erfc(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Erfc")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     sigmoid_grad(y, dy)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sigmoid_grad(y_, dy_; name=nothing)
            local desc
            tf.with_op_name(name, "SigmoidGrad") do 
                desc = tf.NodeDescription("SigmoidGrad")
                y_ = convert(Tensor{Any}, y_)
                dy_ = convert(Tensor{Any}, dy_)
                (y_, dy_) = tf.tf_promote(y_, dy_)
                tf.add_input(desc, y_)
                tf.add_input(desc, dy_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sigmoid_grad(y_::tf.TensorHandle, dy_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SigmoidGrad")
        tf.add_input(desc, y_)
        tf.add_input(desc, dy_)
        desc["T"] = tf.data_type(y_)
        desc["T"] = tf.data_type(dy_)
        (tf.execute(desc))[1]
    end
end


"""
     fixed_length_record_reader_v2(; header_bytes=0, footer_bytes=0, hop_bytes=0, container=, shared_name=, encoding=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fixed_length_record_reader_v2(; name=nothing, header_bytes=nothing, record_bytes=nothing, footer_bytes=nothing, hop_bytes=nothing, container=nothing, shared_name=nothing, encoding=nothing)
            local desc
            tf.with_op_name(name, "FixedLengthRecordReaderV2") do 
                desc = tf.NodeDescription("FixedLengthRecordReaderV2")
                if header_bytes !== nothing
                    desc["header_bytes"] = Base.Int(header_bytes)
                end
                if record_bytes !== nothing
                    desc["record_bytes"] = Base.Int(record_bytes)
                end
                if footer_bytes !== nothing
                    desc["footer_bytes"] = Base.Int(footer_bytes)
                end
                if hop_bytes !== nothing
                    desc["hop_bytes"] = Base.Int(hop_bytes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if encoding !== nothing
                    desc["encoding"] = Base.String(encoding)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fixed_length_record_reader_v2(; name=nothing, header_bytes=nothing, record_bytes=nothing, footer_bytes=nothing, hop_bytes=nothing, container=nothing, shared_name=nothing, encoding=nothing)
        desc = tf.EagerOp("FixedLengthRecordReaderV2")
        if header_bytes !== nothing
            desc["header_bytes"] = Base.Int(header_bytes)
        end
        if record_bytes !== nothing
            desc["record_bytes"] = Base.Int(record_bytes)
        end
        if footer_bytes !== nothing
            desc["footer_bytes"] = Base.Int(footer_bytes)
        end
        if hop_bytes !== nothing
            desc["hop_bytes"] = Base.Int(hop_bytes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if encoding !== nothing
            desc["encoding"] = Base.String(encoding)
        end
        (tf.execute(desc))[1]
    end
end


"""
     non_max_suppression_v3(boxes, scores, max_output_size, iou_threshold, score_threshold)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function non_max_suppression_v3(boxes_, scores_, max_output_size_, iou_threshold_, score_threshold_; name=nothing)
            local desc
            tf.with_op_name(name, "NonMaxSuppressionV3") do 
                desc = tf.NodeDescription("NonMaxSuppressionV3")
                boxes_ = convert(Tensor{Float32}, boxes_)
                scores_ = convert(Tensor{Float32}, scores_)
                max_output_size_ = convert(Tensor{Int32}, max_output_size_)
                iou_threshold_ = convert(Tensor{Float32}, iou_threshold_)
                score_threshold_ = convert(Tensor{Float32}, score_threshold_)
                (boxes_, scores_) = tf.tf_promote(boxes_, scores_)
                tf.add_input(desc, boxes_)
                tf.add_input(desc, scores_)
                tf.add_input(desc, max_output_size_)
                tf.add_input(desc, iou_threshold_)
                tf.add_input(desc, score_threshold_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function non_max_suppression_v3(boxes_::tf.TensorHandle, scores_::tf.TensorHandle, max_output_size_::tf.TensorHandle, iou_threshold_::tf.TensorHandle, score_threshold_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("NonMaxSuppressionV3")
        tf.add_input(desc, boxes_)
        tf.add_input(desc, scores_)
        tf.add_input(desc, max_output_size_)
        tf.add_input(desc, iou_threshold_)
        tf.add_input(desc, score_threshold_)
        desc["T"] = tf.data_type(boxes_)
        desc["T"] = tf.data_type(scores_)
        (tf.execute(desc))[1]
    end
end


"""
     dilation2d_backprop_input(input, filter, out_backprop)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function dilation2d_backprop_input(input_, filter_, out_backprop_; name=nothing, strides=nothing, rates=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "Dilation2DBackpropInput") do 
                desc = tf.NodeDescription("Dilation2DBackpropInput")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                (input_, filter_, out_backprop_) = tf.tf_promote(input_, filter_, out_backprop_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, out_backprop_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if rates !== nothing
                    desc["rates"] = map(Base.identity, rates)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function dilation2d_backprop_input(input_::tf.TensorHandle, filter_::tf.TensorHandle, out_backprop_::tf.TensorHandle; name=nothing, strides=nothing, rates=nothing, padding=nothing)
        desc = tf.EagerOp("Dilation2DBackpropInput")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, out_backprop_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if rates !== nothing
            desc["rates"] = map(Base.identity, rates)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(filter_)
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     logical_or(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function logical_or(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "LogicalOr") do 
                desc = tf.NodeDescription("LogicalOr")
                x_ = convert(Tensor{Bool}, x_)
                y_ = convert(Tensor{Bool}, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function logical_or(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LogicalOr")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_adadelta(var, accum, accum_update, lr, rho, epsilon, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_adadelta(var_, accum_, accum_update_, lr_, rho_, epsilon_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyAdadelta") do 
                desc = tf.NodeDescription("ResourceApplyAdadelta")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                accum_update_ = convert(Tensor{Any}, accum_update_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                (lr_, rho_, epsilon_, grad_) = tf.tf_promote(lr_, rho_, epsilon_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, accum_update_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_adadelta(var_::tf.TensorHandle, accum_::tf.TensorHandle, accum_update_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyAdadelta")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, accum_update_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     dense_to_sparse_set_operation(set1, set2_indices, set2_values, set2_shape; validate_indices=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function dense_to_sparse_set_operation(set1_, set2_indices_, set2_values_, set2_shape_; name=nothing, set_operation=nothing, validate_indices=nothing)
            local desc
            tf.with_op_name(name, "DenseToSparseSetOperation") do 
                desc = tf.NodeDescription("DenseToSparseSetOperation")
                set1_ = convert(Tensor{Any}, set1_)
                set2_indices_ = convert(Tensor{Int64}, set2_indices_)
                set2_values_ = convert(Tensor{Any}, set2_values_)
                set2_shape_ = convert(Tensor{Int64}, set2_shape_)
                (set1_, set2_values_) = tf.tf_promote(set1_, set2_values_)
                tf.add_input(desc, set1_)
                tf.add_input(desc, set2_indices_)
                tf.add_input(desc, set2_values_)
                tf.add_input(desc, set2_shape_)
                if set_operation !== nothing
                    desc["set_operation"] = Base.String(set_operation)
                end
                if validate_indices !== nothing
                    desc["validate_indices"] = Base.Bool(validate_indices)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function dense_to_sparse_set_operation(set1_::tf.TensorHandle, set2_indices_::tf.TensorHandle, set2_values_::tf.TensorHandle, set2_shape_::tf.TensorHandle; name=nothing, set_operation=nothing, validate_indices=nothing)
        desc = tf.EagerOp("DenseToSparseSetOperation")
        tf.add_input(desc, set1_)
        tf.add_input(desc, set2_indices_)
        tf.add_input(desc, set2_values_)
        tf.add_input(desc, set2_shape_)
        if set_operation !== nothing
            desc["set_operation"] = Base.String(set_operation)
        end
        if validate_indices !== nothing
            desc["validate_indices"] = Base.Bool(validate_indices)
        end
        desc["T"] = tf.data_type(set1_)
        desc["T"] = tf.data_type(set2_values_)
        tf.execute(desc)
    end
end


"""
     reader_num_records_produced(reader_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_num_records_produced(reader_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderNumRecordsProduced") do 
                desc = tf.NodeDescription("ReaderNumRecordsProduced")
                reader_handle_ = convert(Tensor{String}, reader_handle_)
                tf.add_input(desc, reader_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reader_num_records_produced(reader_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderNumRecordsProduced")
        tf.add_input(desc, reader_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     adjust_hue(images, delta)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function adjust_hue(images_, delta_; name=nothing)
            local desc
            tf.with_op_name(name, "AdjustHue") do 
                desc = tf.NodeDescription("AdjustHue")
                images_ = convert(Tensor{Float32}, images_)
                delta_ = convert(Tensor{Float32}, delta_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                tf.add_input(desc, delta_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function adjust_hue(images_::tf.TensorHandle, delta_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("AdjustHue")
        tf.add_input(desc, images_)
        tf.add_input(desc, delta_)
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_quantile_stream_resource_flush(quantile_stream_resource_handle, num_buckets; generate_quantiles=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_quantile_stream_resource_flush(quantile_stream_resource_handle_, num_buckets_; name=nothing, generate_quantiles=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesQuantileStreamResourceFlush") do 
                desc = tf.NodeDescription("BoostedTreesQuantileStreamResourceFlush")
                quantile_stream_resource_handle_ = convert(Tensor{Any}, quantile_stream_resource_handle_)
                num_buckets_ = convert(Tensor{Int64}, num_buckets_)
                tf.add_input(desc, quantile_stream_resource_handle_)
                tf.add_input(desc, num_buckets_)
                if generate_quantiles !== nothing
                    desc["generate_quantiles"] = Base.Bool(generate_quantiles)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_quantile_stream_resource_flush(quantile_stream_resource_handle_::tf.TensorHandle, num_buckets_::tf.TensorHandle; name=nothing, generate_quantiles=nothing)
        desc = tf.EagerOp("BoostedTreesQuantileStreamResourceFlush")
        tf.add_input(desc, quantile_stream_resource_handle_)
        tf.add_input(desc, num_buckets_)
        if generate_quantiles !== nothing
            desc["generate_quantiles"] = Base.Bool(generate_quantiles)
        end
        (tf.execute(desc))[1]
    end
end


"""
     experimental_map_and_batch_dataset(input_dataset, other_arguments, batch_size, num_parallel_calls, drop_remainder; preserve_cardinality=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_map_and_batch_dataset(input_dataset_, other_arguments_, batch_size_, num_parallel_calls_, drop_remainder_; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, preserve_cardinality=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalMapAndBatchDataset") do 
                desc = tf.NodeDescription("ExperimentalMapAndBatchDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                batch_size_ = convert(Tensor{Int64}, batch_size_)
                num_parallel_calls_ = convert(Tensor{Int64}, num_parallel_calls_)
                drop_remainder_ = convert(Tensor{Bool}, drop_remainder_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, other_arguments_)
                tf.add_input(desc, batch_size_)
                tf.add_input(desc, num_parallel_calls_)
                tf.add_input(desc, drop_remainder_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if preserve_cardinality !== nothing
                    desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_map_and_batch_dataset(input_dataset_::tf.TensorHandle, other_arguments_::tf.TensorHandle, batch_size_::tf.TensorHandle, num_parallel_calls_::tf.TensorHandle, drop_remainder_::tf.TensorHandle; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, preserve_cardinality=nothing)
        desc = tf.EagerOp("ExperimentalMapAndBatchDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, other_arguments_)
        tf.add_input(desc, batch_size_)
        tf.add_input(desc, num_parallel_calls_)
        tf.add_input(desc, drop_remainder_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if preserve_cardinality !== nothing
            desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
        end
        (tf.execute(desc))[1]
    end
end


"""
     real_div(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function real_div(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "RealDiv") do 
                desc = tf.NodeDescription("RealDiv")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function real_div(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RealDiv")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     restore_slice(file_pattern, tensor_name, shape_and_slice; preferred_shard=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function restore_slice(file_pattern_, tensor_name_, shape_and_slice_; name=nothing, dt=nothing, preferred_shard=nothing)
            local desc
            tf.with_op_name(name, "RestoreSlice") do 
                desc = tf.NodeDescription("RestoreSlice")
                file_pattern_ = convert(Tensor{String}, file_pattern_)
                tensor_name_ = convert(Tensor{String}, tensor_name_)
                shape_and_slice_ = convert(Tensor{String}, shape_and_slice_)
                tf.add_input(desc, file_pattern_)
                tf.add_input(desc, tensor_name_)
                tf.add_input(desc, shape_and_slice_)
                if dt !== nothing
                    desc["dt"] = Base.identity(dt)
                end
                if preferred_shard !== nothing
                    desc["preferred_shard"] = Base.Int(preferred_shard)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function restore_slice(file_pattern_::tf.TensorHandle, tensor_name_::tf.TensorHandle, shape_and_slice_::tf.TensorHandle; name=nothing, dt=nothing, preferred_shard=nothing)
        desc = tf.EagerOp("RestoreSlice")
        tf.add_input(desc, file_pattern_)
        tf.add_input(desc, tensor_name_)
        tf.add_input(desc, shape_and_slice_)
        if dt !== nothing
            desc["dt"] = Base.identity(dt)
        end
        if preferred_shard !== nothing
            desc["preferred_shard"] = Base.Int(preferred_shard)
        end
        (tf.execute(desc))[1]
    end
end


"""
     stack_pop_v2(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stack_pop_v2(handle_; name=nothing, elem_type=nothing)
            local desc
            tf.with_op_name(name, "StackPopV2") do 
                desc = tf.NodeDescription("StackPopV2")
                handle_ = convert(Tensor{Any}, handle_)
                tf.add_input(desc, handle_)
                if elem_type !== nothing
                    desc["elem_type"] = Base.identity(elem_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stack_pop_v2(handle_::tf.TensorHandle; name=nothing, elem_type=nothing)
        desc = tf.EagerOp("StackPopV2")
        tf.add_input(desc, handle_)
        if elem_type !== nothing
            desc["elem_type"] = Base.identity(elem_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     reverse(tensor, dims)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reverse(tensor_, dims_; name=nothing)
            local desc
            tf.with_op_name(name, "Reverse") do 
                desc = tf.NodeDescription("Reverse")
                tensor_ = convert(Tensor{Any}, tensor_)
                dims_ = convert(Tensor{Bool}, dims_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, dims_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reverse(tensor_::tf.TensorHandle, dims_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Reverse")
        tf.add_input(desc, tensor_)
        tf.add_input(desc, dims_)
        desc["T"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     decode_png(contents; channels=0, dtype=UInt8)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_png(contents_; name=nothing, channels=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "DecodePng") do 
                desc = tf.NodeDescription("DecodePng")
                contents_ = convert(Tensor{String}, contents_)
                tf.add_input(desc, contents_)
                if channels !== nothing
                    desc["channels"] = Base.Int(channels)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function decode_png(contents_::tf.TensorHandle; name=nothing, channels=nothing, dtype=nothing)
        desc = tf.EagerOp("DecodePng")
        tf.add_input(desc, contents_)
        if channels !== nothing
            desc["channels"] = Base.Int(channels)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     non_max_suppression_v2(boxes, scores, max_output_size, iou_threshold)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function non_max_suppression_v2(boxes_, scores_, max_output_size_, iou_threshold_; name=nothing)
            local desc
            tf.with_op_name(name, "NonMaxSuppressionV2") do 
                desc = tf.NodeDescription("NonMaxSuppressionV2")
                boxes_ = convert(Tensor{Float32}, boxes_)
                scores_ = convert(Tensor{Float32}, scores_)
                max_output_size_ = convert(Tensor{Int32}, max_output_size_)
                iou_threshold_ = convert(Tensor{Float32}, iou_threshold_)
                (boxes_, scores_) = tf.tf_promote(boxes_, scores_)
                tf.add_input(desc, boxes_)
                tf.add_input(desc, scores_)
                tf.add_input(desc, max_output_size_)
                tf.add_input(desc, iou_threshold_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function non_max_suppression_v2(boxes_::tf.TensorHandle, scores_::tf.TensorHandle, max_output_size_::tf.TensorHandle, iou_threshold_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("NonMaxSuppressionV2")
        tf.add_input(desc, boxes_)
        tf.add_input(desc, scores_)
        tf.add_input(desc, max_output_size_)
        tf.add_input(desc, iou_threshold_)
        desc["T"] = tf.data_type(boxes_)
        desc["T"] = tf.data_type(scores_)
        (tf.execute(desc))[1]
    end
end


"""
     igamma(a, x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function igamma(a_, x_; name=nothing)
            local desc
            tf.with_op_name(name, "Igamma") do 
                desc = tf.NodeDescription("Igamma")
                a_ = convert(Tensor{Any}, a_)
                x_ = convert(Tensor{Any}, x_)
                (a_, x_) = tf.tf_promote(a_, x_)
                tf.add_input(desc, a_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function igamma(a_::tf.TensorHandle, x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Igamma")
        tf.add_input(desc, a_)
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(a_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     digamma(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function digamma(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Digamma") do 
                desc = tf.NodeDescription("Digamma")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function digamma(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Digamma")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_ada_max(var, m, v, beta1_power, lr, beta1, beta2, epsilon, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_ada_max(var_, m_, v_, beta1_power_, lr_, beta1_, beta2_, epsilon_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyAdaMax") do 
                desc = tf.NodeDescription("ResourceApplyAdaMax")
                var_ = convert(Tensor{Any}, var_)
                m_ = convert(Tensor{Any}, m_)
                v_ = convert(Tensor{Any}, v_)
                beta1_power_ = convert(Tensor{Any}, beta1_power_)
                lr_ = convert(Tensor{Any}, lr_)
                beta1_ = convert(Tensor{Any}, beta1_)
                beta2_ = convert(Tensor{Any}, beta2_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                (beta1_power_, lr_, beta1_, beta2_, epsilon_, grad_) = tf.tf_promote(beta1_power_, lr_, beta1_, beta2_, epsilon_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, m_)
                tf.add_input(desc, v_)
                tf.add_input(desc, beta1_power_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, beta1_)
                tf.add_input(desc, beta2_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_ada_max(var_::tf.TensorHandle, m_::tf.TensorHandle, v_::tf.TensorHandle, beta1_power_::tf.TensorHandle, lr_::tf.TensorHandle, beta1_::tf.TensorHandle, beta2_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyAdaMax")
        tf.add_input(desc, var_)
        tf.add_input(desc, m_)
        tf.add_input(desc, v_)
        tf.add_input(desc, beta1_power_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, beta1_)
        tf.add_input(desc, beta2_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(beta1_power_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(beta1_)
        desc["T"] = tf.data_type(beta2_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     space_to_depth(input; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function space_to_depth(input_; name=nothing, block_size=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "SpaceToDepth") do 
                desc = tf.NodeDescription("SpaceToDepth")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if block_size !== nothing
                    desc["block_size"] = Base.Int(block_size)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function space_to_depth(input_::tf.TensorHandle; name=nothing, block_size=nothing, data_format=nothing)
        desc = tf.EagerOp("SpaceToDepth")
        tf.add_input(desc, input_)
        if block_size !== nothing
            desc["block_size"] = Base.Int(block_size)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     sqrt_grad(y, dy)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sqrt_grad(y_, dy_; name=nothing)
            local desc
            tf.with_op_name(name, "SqrtGrad") do 
                desc = tf.NodeDescription("SqrtGrad")
                y_ = convert(Tensor{Any}, y_)
                dy_ = convert(Tensor{Any}, dy_)
                (y_, dy_) = tf.tf_promote(y_, dy_)
                tf.add_input(desc, y_)
                tf.add_input(desc, dy_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sqrt_grad(y_::tf.TensorHandle, dy_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SqrtGrad")
        tf.add_input(desc, y_)
        tf.add_input(desc, dy_)
        desc["T"] = tf.data_type(y_)
        desc["T"] = tf.data_type(dy_)
        (tf.execute(desc))[1]
    end
end


"""
     map_unstage(key, indices; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function map_unstage(key_, indices_; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "MapUnstage") do 
                desc = tf.NodeDescription("MapUnstage")
                key_ = convert(Tensor{Int64}, key_)
                indices_ = convert(Tensor{Int32}, indices_)
                tf.add_input(desc, key_)
                tf.add_input(desc, indices_)
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function map_unstage(key_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("MapUnstage")
        tf.add_input(desc, key_)
        tf.add_input(desc, indices_)
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     qr(input; full_matrices=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function qr(input_; name=nothing, full_matrices=nothing)
            local desc
            tf.with_op_name(name, "Qr") do 
                desc = tf.NodeDescription("Qr")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if full_matrices !== nothing
                    desc["full_matrices"] = Base.Bool(full_matrices)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function qr(input_::tf.TensorHandle; name=nothing, full_matrices=nothing)
        desc = tf.EagerOp("Qr")
        tf.add_input(desc, input_)
        if full_matrices !== nothing
            desc["full_matrices"] = Base.Bool(full_matrices)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     boosted_trees_calculate_best_gains_per_feature(node_id_range, stats_summary_list, l1, l2, tree_complexity, min_node_weight)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_calculate_best_gains_per_feature(node_id_range_, stats_summary_list_, l1_, l2_, tree_complexity_, min_node_weight_; name=nothing, max_splits=nothing, num_features=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesCalculateBestGainsPerFeature") do 
                desc = tf.NodeDescription("BoostedTreesCalculateBestGainsPerFeature")
                node_id_range_ = convert(Tensor{Int32}, node_id_range_)
                stats_summary_list_ = [convert(Tensor{Float32}, x) for x = stats_summary_list_]
                l1_ = convert(Tensor{Float32}, l1_)
                l2_ = convert(Tensor{Float32}, l2_)
                tree_complexity_ = convert(Tensor{Float32}, tree_complexity_)
                min_node_weight_ = convert(Tensor{Float32}, min_node_weight_)
                tf.add_input(desc, node_id_range_)
                tf.add_input(desc, stats_summary_list_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, tree_complexity_)
                tf.add_input(desc, min_node_weight_)
                if max_splits !== nothing
                    desc["max_splits"] = Base.Int(max_splits)
                end
                if num_features !== nothing
                    desc["num_features"] = Base.Int(num_features)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:5
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function boosted_trees_calculate_best_gains_per_feature(node_id_range_::tf.TensorHandle, stats_summary_list_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, tree_complexity_::tf.TensorHandle, min_node_weight_::tf.TensorHandle; name=nothing, max_splits=nothing, num_features=nothing)
        desc = tf.EagerOp("BoostedTreesCalculateBestGainsPerFeature")
        tf.add_input(desc, node_id_range_)
        tf.add_input(desc, stats_summary_list_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, tree_complexity_)
        tf.add_input(desc, min_node_weight_)
        if max_splits !== nothing
            desc["max_splits"] = Base.Int(max_splits)
        end
        if num_features !== nothing
            desc["num_features"] = Base.Int(num_features)
        end
        tf.execute(desc)
    end
end


"""
     unbatch_grad(original_input, batch_index, grad, id; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unbatch_grad(original_input_, batch_index_, grad_, id_; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "UnbatchGrad") do 
                desc = tf.NodeDescription("UnbatchGrad")
                original_input_ = convert(Tensor{Any}, original_input_)
                batch_index_ = convert(Tensor{Int64}, batch_index_)
                grad_ = convert(Tensor{Any}, grad_)
                id_ = convert(Tensor{Int64}, id_)
                (original_input_, grad_) = tf.tf_promote(original_input_, grad_)
                tf.add_input(desc, original_input_)
                tf.add_input(desc, batch_index_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, id_)
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unbatch_grad(original_input_::tf.TensorHandle, batch_index_::tf.TensorHandle, grad_::tf.TensorHandle, id_::tf.TensorHandle; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("UnbatchGrad")
        tf.add_input(desc, original_input_)
        tf.add_input(desc, batch_index_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, id_)
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        desc["T"] = tf.data_type(original_input_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     log_softmax(logits)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function log_softmax(logits_; name=nothing)
            local desc
            tf.with_op_name(name, "LogSoftmax") do 
                desc = tf.NodeDescription("LogSoftmax")
                logits_ = convert(Tensor{Any}, logits_)
                (logits_,) = tf.tf_promote(logits_)
                tf.add_input(desc, logits_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function log_softmax(logits_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LogSoftmax")
        tf.add_input(desc, logits_)
        desc["T"] = tf.data_type(logits_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_count_up_to(resource)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_count_up_to(resource_; name=nothing, limit=nothing)
            local desc
            tf.with_op_name(name, "ResourceCountUpTo") do 
                desc = tf.NodeDescription("ResourceCountUpTo")
                resource_ = convert(Tensor{Any}, resource_)
                tf.add_input(desc, resource_)
                if limit !== nothing
                    desc["limit"] = Base.Int(limit)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_count_up_to(resource_::tf.TensorHandle; name=nothing, limit=nothing)
        desc = tf.EagerOp("ResourceCountUpTo")
        tf.add_input(desc, resource_)
        if limit !== nothing
            desc["limit"] = Base.Int(limit)
        end
        (tf.execute(desc))[1]
    end
end


"""
     accumulate_nv2(inputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function accumulate_nv2(inputs_; name=nothing, N=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "AccumulateNV2") do 
                desc = tf.NodeDescription("AccumulateNV2")
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                (inputs_,) = tf.tf_promote(inputs_)
                tf.add_input(desc, inputs_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function accumulate_nv2(inputs_::tf.TensorHandle; name=nothing, N=nothing, shape=nothing)
        desc = tf.EagerOp("AccumulateNV2")
        tf.add_input(desc, inputs_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        desc["T"] = tf.data_type(inputs_)
        (tf.execute(desc))[1]
    end
end


"""
     parallel_map_dataset(input_dataset, other_arguments, num_parallel_calls; use_inter_op_parallelism=true, sloppy=false, preserve_cardinality=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function parallel_map_dataset(input_dataset_, other_arguments_, num_parallel_calls_; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, use_inter_op_parallelism=nothing, sloppy=nothing, preserve_cardinality=nothing)
            local desc
            tf.with_op_name(name, "ParallelMapDataset") do 
                desc = tf.NodeDescription("ParallelMapDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                num_parallel_calls_ = convert(Tensor{Int32}, num_parallel_calls_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, other_arguments_)
                tf.add_input(desc, num_parallel_calls_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if use_inter_op_parallelism !== nothing
                    desc["use_inter_op_parallelism"] = Base.Bool(use_inter_op_parallelism)
                end
                if sloppy !== nothing
                    desc["sloppy"] = Base.Bool(sloppy)
                end
                if preserve_cardinality !== nothing
                    desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function parallel_map_dataset(input_dataset_::tf.TensorHandle, other_arguments_::tf.TensorHandle, num_parallel_calls_::tf.TensorHandle; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, use_inter_op_parallelism=nothing, sloppy=nothing, preserve_cardinality=nothing)
        desc = tf.EagerOp("ParallelMapDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, other_arguments_)
        tf.add_input(desc, num_parallel_calls_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if use_inter_op_parallelism !== nothing
            desc["use_inter_op_parallelism"] = Base.Bool(use_inter_op_parallelism)
        end
        if sloppy !== nothing
            desc["sloppy"] = Base.Bool(sloppy)
        end
        if preserve_cardinality !== nothing
            desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
        end
        (tf.execute(desc))[1]
    end
end


"""
     random_uniform(shape; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function random_uniform(shape_; name=nothing, seed=nothing, seed2=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "RandomUniform") do 
                desc = tf.NodeDescription("RandomUniform")
                shape_ = convert(Tensor{Any}, shape_)
                (shape_,) = tf.tf_promote(shape_)
                tf.add_input(desc, shape_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function random_uniform(shape_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing, dtype=nothing)
        desc = tf.EagerOp("RandomUniform")
        tf.add_input(desc, shape_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["T"] = tf.data_type(shape_)
        (tf.execute(desc))[1]
    end
end


"""
     unicode_transcode(input; errors=replace, replacement_char=65533, replace_control_characters=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unicode_transcode(input_; name=nothing, input_encoding=nothing, output_encoding=nothing, errors=nothing, replacement_char=nothing, replace_control_characters=nothing)
            local desc
            tf.with_op_name(name, "UnicodeTranscode") do 
                desc = tf.NodeDescription("UnicodeTranscode")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
                if input_encoding !== nothing
                    desc["input_encoding"] = Base.String(input_encoding)
                end
                if output_encoding !== nothing
                    desc["output_encoding"] = Base.String(output_encoding)
                end
                if errors !== nothing
                    desc["errors"] = Base.String(errors)
                end
                if replacement_char !== nothing
                    desc["replacement_char"] = Base.Int(replacement_char)
                end
                if replace_control_characters !== nothing
                    desc["replace_control_characters"] = Base.Bool(replace_control_characters)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unicode_transcode(input_::tf.TensorHandle; name=nothing, input_encoding=nothing, output_encoding=nothing, errors=nothing, replacement_char=nothing, replace_control_characters=nothing)
        desc = tf.EagerOp("UnicodeTranscode")
        tf.add_input(desc, input_)
        if input_encoding !== nothing
            desc["input_encoding"] = Base.String(input_encoding)
        end
        if output_encoding !== nothing
            desc["output_encoding"] = Base.String(output_encoding)
        end
        if errors !== nothing
            desc["errors"] = Base.String(errors)
        end
        if replacement_char !== nothing
            desc["replacement_char"] = Base.Int(replacement_char)
        end
        if replace_control_characters !== nothing
            desc["replace_control_characters"] = Base.Bool(replace_control_characters)
        end
        (tf.execute(desc))[1]
    end
end


"""
     reader_reset(reader_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_reset(reader_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderReset") do 
                desc = tf.NodeDescription("ReaderReset")
                reader_handle_ = convert(Tensor{String}, reader_handle_)
                tf.add_input(desc, reader_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reader_reset(reader_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderReset")
        tf.add_input(desc, reader_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     _nccl_broadcast_send(input)

Replacement node for NcclBroadcast.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _nccl_broadcast_send(input_; name=nothing, num_devices=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "_NcclBroadcastSend") do 
                desc = tf.NodeDescription("_NcclBroadcastSend")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if num_devices !== nothing
                    desc["num_devices"] = Base.Int(num_devices)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _nccl_broadcast_send(input_::tf.TensorHandle; name=nothing, num_devices=nothing, shared_name=nothing)
        desc = tf.EagerOp("_NcclBroadcastSend")
        tf.add_input(desc, input_)
        if num_devices !== nothing
            desc["num_devices"] = Base.Int(num_devices)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_matrix_determinant(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_matrix_determinant(input_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchMatrixDeterminant") do 
                desc = tf.NodeDescription("BatchMatrixDeterminant")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_matrix_determinant(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchMatrixDeterminant")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     less_equal(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function less_equal(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "LessEqual") do 
                desc = tf.NodeDescription("LessEqual")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function less_equal(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LessEqual")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     apply_gradient_descent(var, alpha, delta; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_gradient_descent(var_, alpha_, delta_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyGradientDescent") do 
                desc = tf.NodeDescription("ApplyGradientDescent")
                var_ = convert(Tensor{Any}, var_)
                alpha_ = convert(Tensor{Any}, alpha_)
                delta_ = convert(Tensor{Any}, delta_)
                (var_, alpha_, delta_) = tf.tf_promote(var_, alpha_, delta_)
                tf.add_input(desc, var_)
                tf.add_input(desc, alpha_)
                tf.add_input(desc, delta_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_gradient_descent(var_::tf.TensorHandle, alpha_::tf.TensorHandle, delta_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyGradientDescent")
        tf.add_input(desc, var_)
        tf.add_input(desc, alpha_)
        tf.add_input(desc, delta_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(alpha_)
        desc["T"] = tf.data_type(delta_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_segment_sqrt_n(data, indices, segment_ids)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_segment_sqrt_n(data_, indices_, segment_ids_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSegmentSqrtN") do 
                desc = tf.NodeDescription("SparseSegmentSqrtN")
                data_ = convert(Tensor{Any}, data_)
                indices_ = convert(Tensor{Int32}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                segment_ids_ = convert(Tensor{Int32}, segment_ids_)
                (data_,) = tf.tf_promote(data_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, data_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, segment_ids_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_segment_sqrt_n(data_::tf.TensorHandle, indices_::tf.TensorHandle, segment_ids_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSegmentSqrtN")
        tf.add_input(desc, data_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, segment_ids_)
        desc["T"] = tf.data_type(data_)
        desc["Tidx"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     matrix_logarithm(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_logarithm(input_; name=nothing)
            local desc
            tf.with_op_name(name, "MatrixLogarithm") do 
                desc = tf.NodeDescription("MatrixLogarithm")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_logarithm(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MatrixLogarithm")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     scatter_mul(ref, indices, updates; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_mul(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ScatterMul") do 
                desc = tf.NodeDescription("ScatterMul")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (ref_, updates_) = tf.tf_promote(ref_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_mul(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ScatterMul")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     decode_jpeg(contents; channels=0, ratio=1, fancy_upscaling=true, try_recover_truncated=false, acceptable_fraction=?, dct_method=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_jpeg(contents_; name=nothing, channels=nothing, ratio=nothing, fancy_upscaling=nothing, try_recover_truncated=nothing, acceptable_fraction=nothing, dct_method=nothing)
            local desc
            tf.with_op_name(name, "DecodeJpeg") do 
                desc = tf.NodeDescription("DecodeJpeg")
                contents_ = convert(Tensor{String}, contents_)
                tf.add_input(desc, contents_)
                if channels !== nothing
                    desc["channels"] = Base.Int(channels)
                end
                if ratio !== nothing
                    desc["ratio"] = Base.Int(ratio)
                end
                if fancy_upscaling !== nothing
                    desc["fancy_upscaling"] = Base.Bool(fancy_upscaling)
                end
                if try_recover_truncated !== nothing
                    desc["try_recover_truncated"] = Base.Bool(try_recover_truncated)
                end
                if acceptable_fraction !== nothing
                    desc["acceptable_fraction"] = Base.identity(acceptable_fraction)
                end
                if dct_method !== nothing
                    desc["dct_method"] = Base.String(dct_method)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function decode_jpeg(contents_::tf.TensorHandle; name=nothing, channels=nothing, ratio=nothing, fancy_upscaling=nothing, try_recover_truncated=nothing, acceptable_fraction=nothing, dct_method=nothing)
        desc = tf.EagerOp("DecodeJpeg")
        tf.add_input(desc, contents_)
        if channels !== nothing
            desc["channels"] = Base.Int(channels)
        end
        if ratio !== nothing
            desc["ratio"] = Base.Int(ratio)
        end
        if fancy_upscaling !== nothing
            desc["fancy_upscaling"] = Base.Bool(fancy_upscaling)
        end
        if try_recover_truncated !== nothing
            desc["try_recover_truncated"] = Base.Bool(try_recover_truncated)
        end
        if acceptable_fraction !== nothing
            desc["acceptable_fraction"] = Base.identity(acceptable_fraction)
        end
        if dct_method !== nothing
            desc["dct_method"] = Base.String(dct_method)
        end
        (tf.execute(desc))[1]
    end
end


"""
     random_shuffle_queue_v2(; shapes=Int64[], capacity=-1, min_after_dequeue=0, seed=0, seed2=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function random_shuffle_queue_v2(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, min_after_dequeue=nothing, seed=nothing, seed2=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "RandomShuffleQueueV2") do 
                desc = tf.NodeDescription("RandomShuffleQueueV2")
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if min_after_dequeue !== nothing
                    desc["min_after_dequeue"] = Base.Int(min_after_dequeue)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function random_shuffle_queue_v2(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, min_after_dequeue=nothing, seed=nothing, seed2=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("RandomShuffleQueueV2")
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if min_after_dequeue !== nothing
            desc["min_after_dequeue"] = Base.Int(min_after_dequeue)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     queue_enqueue_many_v2(handle, components; timeout_ms=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_enqueue_many_v2(handle_, components_; name=nothing, Tcomponents=nothing, timeout_ms=nothing)
            local desc
            tf.with_op_name(name, "QueueEnqueueManyV2") do 
                desc = tf.NodeDescription("QueueEnqueueManyV2")
                handle_ = convert(Tensor{Any}, handle_)
                components_ = [convert(Tensor{Any}, x) for x = components_]
                tf.add_input(desc, handle_)
                tf.add_input(desc, components_)
                if Tcomponents !== nothing
                    desc["Tcomponents"] = map(Base.identity, Tcomponents)
                end
                if timeout_ms !== nothing
                    desc["timeout_ms"] = Base.Int(timeout_ms)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_enqueue_many_v2(handle_::tf.TensorHandle, components_::tf.TensorHandle; name=nothing, Tcomponents=nothing, timeout_ms=nothing)
        desc = tf.EagerOp("QueueEnqueueManyV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, components_)
        if Tcomponents !== nothing
            desc["Tcomponents"] = map(Base.identity, Tcomponents)
        end
        if timeout_ms !== nothing
            desc["timeout_ms"] = Base.Int(timeout_ms)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_sparse_apply_centered_rms_prop(var, mg, ms, mom, lr, rho, momentum, epsilon, grad, indices; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_sparse_apply_centered_rms_prop(var_, mg_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_, indices_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceSparseApplyCenteredRMSProp") do 
                desc = tf.NodeDescription("ResourceSparseApplyCenteredRMSProp")
                var_ = convert(Tensor{Any}, var_)
                mg_ = convert(Tensor{Any}, mg_)
                ms_ = convert(Tensor{Any}, ms_)
                mom_ = convert(Tensor{Any}, mom_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                momentum_ = convert(Tensor{Any}, momentum_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (lr_, rho_, momentum_, epsilon_, grad_) = tf.tf_promote(lr_, rho_, momentum_, epsilon_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, mg_)
                tf.add_input(desc, ms_)
                tf.add_input(desc, mom_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, momentum_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_sparse_apply_centered_rms_prop(var_::tf.TensorHandle, mg_::tf.TensorHandle, ms_::tf.TensorHandle, mom_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, momentum_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceSparseApplyCenteredRMSProp")
        tf.add_input(desc, var_)
        tf.add_input(desc, mg_)
        tf.add_input(desc, ms_)
        tf.add_input(desc, mom_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, momentum_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(momentum_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     interleave_dataset(input_dataset, other_arguments, cycle_length, block_length)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function interleave_dataset(input_dataset_, other_arguments_, cycle_length_, block_length_; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "InterleaveDataset") do 
                desc = tf.NodeDescription("InterleaveDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                cycle_length_ = convert(Tensor{Int64}, cycle_length_)
                block_length_ = convert(Tensor{Int64}, block_length_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, other_arguments_)
                tf.add_input(desc, cycle_length_)
                tf.add_input(desc, block_length_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function interleave_dataset(input_dataset_::tf.TensorHandle, other_arguments_::tf.TensorHandle, cycle_length_::tf.TensorHandle, block_length_::tf.TensorHandle; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("InterleaveDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, other_arguments_)
        tf.add_input(desc, cycle_length_)
        tf.add_input(desc, block_length_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     stack_pop(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stack_pop(handle_; name=nothing, elem_type=nothing)
            local desc
            tf.with_op_name(name, "StackPop") do 
                desc = tf.NodeDescription("StackPop")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
                if elem_type !== nothing
                    desc["elem_type"] = Base.identity(elem_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stack_pop(handle_::tf.TensorHandle; name=nothing, elem_type=nothing)
        desc = tf.EagerOp("StackPop")
        tf.add_input(desc, handle_)
        if elem_type !== nothing
            desc["elem_type"] = Base.identity(elem_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     max_pool_v2(input, ksize, strides; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool_v2(input_, ksize_, strides_; name=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "MaxPoolV2") do 
                desc = tf.NodeDescription("MaxPoolV2")
                input_ = convert(Tensor{Float32}, input_)
                ksize_ = convert(Tensor{Int32}, ksize_)
                strides_ = convert(Tensor{Int32}, strides_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, ksize_)
                tf.add_input(desc, strides_)
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max_pool_v2(input_::tf.TensorHandle, ksize_::tf.TensorHandle, strides_::tf.TensorHandle; name=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("MaxPoolV2")
        tf.add_input(desc, input_)
        tf.add_input(desc, ksize_)
        tf.add_input(desc, strides_)
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_deserialize_ensemble(tree_ensemble_handle, stamp_token, tree_ensemble_serialized)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_deserialize_ensemble(tree_ensemble_handle_, stamp_token_, tree_ensemble_serialized_; name=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesDeserializeEnsemble") do 
                desc = tf.NodeDescription("BoostedTreesDeserializeEnsemble")
                tree_ensemble_handle_ = convert(Tensor{Any}, tree_ensemble_handle_)
                stamp_token_ = convert(Tensor{Int64}, stamp_token_)
                tree_ensemble_serialized_ = convert(Tensor{String}, tree_ensemble_serialized_)
                tf.add_input(desc, tree_ensemble_handle_)
                tf.add_input(desc, stamp_token_)
                tf.add_input(desc, tree_ensemble_serialized_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_deserialize_ensemble(tree_ensemble_handle_::tf.TensorHandle, stamp_token_::tf.TensorHandle, tree_ensemble_serialized_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BoostedTreesDeserializeEnsemble")
        tf.add_input(desc, tree_ensemble_handle_)
        tf.add_input(desc, stamp_token_)
        tf.add_input(desc, tree_ensemble_serialized_)
        (tf.execute(desc))[1]
    end
end


"""
     load_and_remap_matrix(ckpt_path, old_tensor_name, row_remapping, col_remapping, initializing_values; max_rows_in_memory=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_and_remap_matrix(ckpt_path_, old_tensor_name_, row_remapping_, col_remapping_, initializing_values_; name=nothing, num_rows=nothing, num_cols=nothing, max_rows_in_memory=nothing)
            local desc
            tf.with_op_name(name, "LoadAndRemapMatrix") do 
                desc = tf.NodeDescription("LoadAndRemapMatrix")
                ckpt_path_ = convert(Tensor{String}, ckpt_path_)
                old_tensor_name_ = convert(Tensor{String}, old_tensor_name_)
                row_remapping_ = convert(Tensor{Int64}, row_remapping_)
                col_remapping_ = convert(Tensor{Int64}, col_remapping_)
                initializing_values_ = convert(Tensor{Float32}, initializing_values_)
                tf.add_input(desc, ckpt_path_)
                tf.add_input(desc, old_tensor_name_)
                tf.add_input(desc, row_remapping_)
                tf.add_input(desc, col_remapping_)
                tf.add_input(desc, initializing_values_)
                if num_rows !== nothing
                    desc["num_rows"] = Base.Int(num_rows)
                end
                if num_cols !== nothing
                    desc["num_cols"] = Base.Int(num_cols)
                end
                if max_rows_in_memory !== nothing
                    desc["max_rows_in_memory"] = Base.Int(max_rows_in_memory)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_and_remap_matrix(ckpt_path_::tf.TensorHandle, old_tensor_name_::tf.TensorHandle, row_remapping_::tf.TensorHandle, col_remapping_::tf.TensorHandle, initializing_values_::tf.TensorHandle; name=nothing, num_rows=nothing, num_cols=nothing, max_rows_in_memory=nothing)
        desc = tf.EagerOp("LoadAndRemapMatrix")
        tf.add_input(desc, ckpt_path_)
        tf.add_input(desc, old_tensor_name_)
        tf.add_input(desc, row_remapping_)
        tf.add_input(desc, col_remapping_)
        tf.add_input(desc, initializing_values_)
        if num_rows !== nothing
            desc["num_rows"] = Base.Int(num_rows)
        end
        if num_cols !== nothing
            desc["num_cols"] = Base.Int(num_cols)
        end
        if max_rows_in_memory !== nothing
            desc["max_rows_in_memory"] = Base.Int(max_rows_in_memory)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_apply_proximal_gradient_descent(var, alpha, l1, l2, grad, indices; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_apply_proximal_gradient_descent(var_, alpha_, l1_, l2_, grad_, indices_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "SparseApplyProximalGradientDescent") do 
                desc = tf.NodeDescription("SparseApplyProximalGradientDescent")
                var_ = convert(Tensor{Any}, var_)
                alpha_ = convert(Tensor{Any}, alpha_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (var_, alpha_, l1_, l2_, grad_) = tf.tf_promote(var_, alpha_, l1_, l2_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, alpha_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_apply_proximal_gradient_descent(var_::tf.TensorHandle, alpha_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("SparseApplyProximalGradientDescent")
        tf.add_input(desc, var_)
        tf.add_input(desc, alpha_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(alpha_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     py_func_stateless(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function py_func_stateless(input_; name=nothing, token=nothing, Tin=nothing, Tout=nothing)
            local desc
            tf.with_op_name(name, "PyFuncStateless") do 
                desc = tf.NodeDescription("PyFuncStateless")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                tf.add_input(desc, input_)
                if token !== nothing
                    desc["token"] = Base.String(token)
                end
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function py_func_stateless(input_::tf.TensorHandle; name=nothing, token=nothing, Tin=nothing, Tout=nothing)
        desc = tf.EagerOp("PyFuncStateless")
        tf.add_input(desc, input_)
        if token !== nothing
            desc["token"] = Base.String(token)
        end
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        (tf.execute(desc))[1]
    end
end


"""
     where(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function where(input_; name=nothing)
            local desc
            tf.with_op_name(name, "Where") do 
                desc = tf.NodeDescription("Where")
                input_ = convert(Tensor{Bool}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function where(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Where")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     mfcc(spectrogram, sample_rate; upper_frequency_limit=?, lower_frequency_limit=?, filterbank_channel_count=40, dct_coefficient_count=13)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mfcc(spectrogram_, sample_rate_; name=nothing, upper_frequency_limit=nothing, lower_frequency_limit=nothing, filterbank_channel_count=nothing, dct_coefficient_count=nothing)
            local desc
            tf.with_op_name(name, "Mfcc") do 
                desc = tf.NodeDescription("Mfcc")
                spectrogram_ = convert(Tensor{Float32}, spectrogram_)
                sample_rate_ = convert(Tensor{Int32}, sample_rate_)
                tf.add_input(desc, spectrogram_)
                tf.add_input(desc, sample_rate_)
                if upper_frequency_limit !== nothing
                    desc["upper_frequency_limit"] = Base.identity(upper_frequency_limit)
                end
                if lower_frequency_limit !== nothing
                    desc["lower_frequency_limit"] = Base.identity(lower_frequency_limit)
                end
                if filterbank_channel_count !== nothing
                    desc["filterbank_channel_count"] = Base.Int(filterbank_channel_count)
                end
                if dct_coefficient_count !== nothing
                    desc["dct_coefficient_count"] = Base.Int(dct_coefficient_count)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mfcc(spectrogram_::tf.TensorHandle, sample_rate_::tf.TensorHandle; name=nothing, upper_frequency_limit=nothing, lower_frequency_limit=nothing, filterbank_channel_count=nothing, dct_coefficient_count=nothing)
        desc = tf.EagerOp("Mfcc")
        tf.add_input(desc, spectrogram_)
        tf.add_input(desc, sample_rate_)
        if upper_frequency_limit !== nothing
            desc["upper_frequency_limit"] = Base.identity(upper_frequency_limit)
        end
        if lower_frequency_limit !== nothing
            desc["lower_frequency_limit"] = Base.identity(lower_frequency_limit)
        end
        if filterbank_channel_count !== nothing
            desc["filterbank_channel_count"] = Base.Int(filterbank_channel_count)
        end
        if dct_coefficient_count !== nothing
            desc["dct_coefficient_count"] = Base.Int(dct_coefficient_count)
        end
        (tf.execute(desc))[1]
    end
end


"""
     check_numerics(tensor)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function check_numerics(tensor_; name=nothing, message=nothing)
            local desc
            tf.with_op_name(name, "CheckNumerics") do 
                desc = tf.NodeDescription("CheckNumerics")
                tensor_ = convert(Tensor{Any}, tensor_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, tensor_)
                if message !== nothing
                    desc["message"] = Base.String(message)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function check_numerics(tensor_::tf.TensorHandle; name=nothing, message=nothing)
        desc = tf.EagerOp("CheckNumerics")
        tf.add_input(desc, tensor_)
        if message !== nothing
            desc["message"] = Base.String(message)
        end
        desc["T"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     tpu_compilation_result()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tpu_compilation_result(; name=nothing)
            local desc
            tf.with_op_name(name, "TPUCompilationResult") do 
                desc
                tf.NodeDescription("TPUCompilationResult")
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tpu_compilation_result(; name=nothing)
        desc = tf.EagerOp("TPUCompilationResult")
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_stochastic_gradient_descent_parameters(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_stochastic_gradient_descent_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingStochasticGradientDescentParameters") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingStochasticGradientDescentParameters")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function retrieve_tpu_embedding_stochastic_gradient_descent_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingStochasticGradientDescentParameters")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_segment_mean_grad(grad, indices, segment_ids, output_dim0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_segment_mean_grad(grad_, indices_, segment_ids_, output_dim0_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSegmentMeanGrad") do 
                desc = tf.NodeDescription("SparseSegmentMeanGrad")
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Int32}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                segment_ids_ = convert(Tensor{Int32}, segment_ids_)
                output_dim0_ = convert(Tensor{Int32}, output_dim0_)
                (grad_,) = tf.tf_promote(grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, segment_ids_)
                tf.add_input(desc, output_dim0_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_segment_mean_grad(grad_::tf.TensorHandle, indices_::tf.TensorHandle, segment_ids_::tf.TensorHandle, output_dim0_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSegmentMeanGrad")
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, segment_ids_)
        tf.add_input(desc, output_dim0_)
        desc["T"] = tf.data_type(grad_)
        desc["Tidx"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     try_rpc(address, method, request; protocol=, fail_fast=true, timeout_in_ms=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function try_rpc(address_, method_, request_; name=nothing, protocol=nothing, fail_fast=nothing, timeout_in_ms=nothing)
            local desc
            tf.with_op_name(name, "TryRpc") do 
                desc = tf.NodeDescription("TryRpc")
                address_ = convert(Tensor{String}, address_)
                method_ = convert(Tensor{String}, method_)
                request_ = convert(Tensor{String}, request_)
                tf.add_input(desc, address_)
                tf.add_input(desc, method_)
                tf.add_input(desc, request_)
                if protocol !== nothing
                    desc["protocol"] = Base.String(protocol)
                end
                if fail_fast !== nothing
                    desc["fail_fast"] = Base.Bool(fail_fast)
                end
                if timeout_in_ms !== nothing
                    desc["timeout_in_ms"] = Base.Int(timeout_in_ms)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function try_rpc(address_::tf.TensorHandle, method_::tf.TensorHandle, request_::tf.TensorHandle; name=nothing, protocol=nothing, fail_fast=nothing, timeout_in_ms=nothing)
        desc = tf.EagerOp("TryRpc")
        tf.add_input(desc, address_)
        tf.add_input(desc, method_)
        tf.add_input(desc, request_)
        if protocol !== nothing
            desc["protocol"] = Base.String(protocol)
        end
        if fail_fast !== nothing
            desc["fail_fast"] = Base.Bool(fail_fast)
        end
        if timeout_in_ms !== nothing
            desc["timeout_in_ms"] = Base.Int(timeout_in_ms)
        end
        tf.execute(desc)
    end
end


"""
     batch_matrix_triangular_solve(matrix, rhs; lower=true, adjoint=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_matrix_triangular_solve(matrix_, rhs_; name=nothing, lower=nothing, adjoint=nothing)
            local desc
            tf.with_op_name(name, "BatchMatrixTriangularSolve") do 
                desc = tf.NodeDescription("BatchMatrixTriangularSolve")
                matrix_ = convert(Tensor{Any}, matrix_)
                rhs_ = convert(Tensor{Any}, rhs_)
                (matrix_, rhs_) = tf.tf_promote(matrix_, rhs_)
                tf.add_input(desc, matrix_)
                tf.add_input(desc, rhs_)
                if lower !== nothing
                    desc["lower"] = Base.Bool(lower)
                end
                if adjoint !== nothing
                    desc["adjoint"] = Base.Bool(adjoint)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_matrix_triangular_solve(matrix_::tf.TensorHandle, rhs_::tf.TensorHandle; name=nothing, lower=nothing, adjoint=nothing)
        desc = tf.EagerOp("BatchMatrixTriangularSolve")
        tf.add_input(desc, matrix_)
        tf.add_input(desc, rhs_)
        if lower !== nothing
            desc["lower"] = Base.Bool(lower)
        end
        if adjoint !== nothing
            desc["adjoint"] = Base.Bool(adjoint)
        end
        desc["T"] = tf.data_type(matrix_)
        desc["T"] = tf.data_type(rhs_)
        (tf.execute(desc))[1]
    end
end


"""
     _retval(input)

A graph node which represents a return value of a function.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _retval(input_; name=nothing, index=nothing)
            local desc
            tf.with_op_name(name, "_Retval") do 
                desc = tf.NodeDescription("_Retval")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if index !== nothing
                    desc["index"] = Base.Int(index)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _retval(input_::tf.TensorHandle; name=nothing, index=nothing)
        desc = tf.EagerOp("_Retval")
        tf.add_input(desc, input_)
        if index !== nothing
            desc["index"] = Base.Int(index)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     unique_with_counts(x; out_idx=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unique_with_counts(x_; name=nothing, out_idx=nothing)
            local desc
            tf.with_op_name(name, "UniqueWithCounts") do 
                desc = tf.NodeDescription("UniqueWithCounts")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
                if out_idx !== nothing
                    desc["out_idx"] = Base.identity(out_idx)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function unique_with_counts(x_::tf.TensorHandle; name=nothing, out_idx=nothing)
        desc = tf.EagerOp("UniqueWithCounts")
        tf.add_input(desc, x_)
        if out_idx !== nothing
            desc["out_idx"] = Base.identity(out_idx)
        end
        desc["T"] = tf.data_type(x_)
        tf.execute(desc)
    end
end


"""
     add(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function add(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Add") do 
                desc = tf.NodeDescription("Add")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function add(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Add")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_scan_dataset(input_dataset, initial_state, other_arguments; preserve_cardinality=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_scan_dataset(input_dataset_, initial_state_, other_arguments_; name=nothing, f=nothing, Tstate=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, preserve_cardinality=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalScanDataset") do 
                desc = tf.NodeDescription("ExperimentalScanDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                initial_state_ = [convert(Tensor{Any}, x) for x = initial_state_]
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, initial_state_)
                tf.add_input(desc, other_arguments_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if Tstate !== nothing
                    desc["Tstate"] = map(Base.identity, Tstate)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if preserve_cardinality !== nothing
                    desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_scan_dataset(input_dataset_::tf.TensorHandle, initial_state_::tf.TensorHandle, other_arguments_::tf.TensorHandle; name=nothing, f=nothing, Tstate=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, preserve_cardinality=nothing)
        desc = tf.EagerOp("ExperimentalScanDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, initial_state_)
        tf.add_input(desc, other_arguments_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if Tstate !== nothing
            desc["Tstate"] = map(Base.identity, Tstate)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if preserve_cardinality !== nothing
            desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
        end
        (tf.execute(desc))[1]
    end
end


"""
     assign_add_variable_op(resource, value)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function assign_add_variable_op(resource_, value_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "AssignAddVariableOp") do 
                desc = tf.NodeDescription("AssignAddVariableOp")
                resource_ = convert(Tensor{Any}, resource_)
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, value_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function assign_add_variable_op(resource_::tf.TensorHandle, value_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("AssignAddVariableOp")
        tf.add_input(desc, resource_)
        tf.add_input(desc, value_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["dtype"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     split_v(value, size_splits, split_dim)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function split_v(value_, size_splits_, split_dim_; name=nothing, num_split=nothing)
            local desc
            tf.with_op_name(name, "SplitV") do 
                desc = tf.NodeDescription("SplitV")
                value_ = convert(Tensor{Any}, value_)
                size_splits_ = convert(Tensor{Int64}, size_splits_)
                split_dim_ = convert(Tensor{Int32}, split_dim_)
                split_dim_ = split_dim_ - convert(tf.Tensor{eltype(split_dim_)}, 1)
                (value_,) = tf.tf_promote(value_)
                (size_splits_,) = tf.tf_promote(size_splits_)
                tf.add_input(desc, value_)
                tf.add_input(desc, size_splits_)
                tf.add_input(desc, split_dim_)
                if num_split !== nothing
                    desc["num_split"] = Base.Int(num_split)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:num_split
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function split_v(value_::tf.TensorHandle, size_splits_::tf.TensorHandle, split_dim_::tf.TensorHandle; name=nothing, num_split=nothing)
        desc = tf.EagerOp("SplitV")
        tf.add_input(desc, value_)
        tf.add_input(desc, size_splits_)
        tf.add_input(desc, split_dim_)
        if num_split !== nothing
            desc["num_split"] = Base.Int(num_split)
        end
        desc["T"] = tf.data_type(value_)
        desc["Tlen"] = tf.data_type(size_splits_)
        tf.execute(desc)
    end
end


"""
     assign(ref, value; validate_shape=true, use_locking=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function assign(ref_, value_; name=nothing, validate_shape=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "Assign") do 
                desc = tf.NodeDescription("Assign")
                ref_ = convert(Tensor{Any}, ref_)
                value_ = convert(Tensor{Any}, value_)
                (ref_, value_) = tf.tf_promote(ref_, value_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, value_)
                if validate_shape !== nothing
                    desc["validate_shape"] = Base.Bool(validate_shape)
                end
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function assign(ref_::tf.TensorHandle, value_::tf.TensorHandle; name=nothing, validate_shape=nothing, use_locking=nothing)
        desc = tf.EagerOp("Assign")
        tf.add_input(desc, ref_)
        tf.add_input(desc, value_)
        if validate_shape !== nothing
            desc["validate_shape"] = Base.Bool(validate_shape)
        end
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     max_pool_with_argmax(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool_with_argmax(input_; name=nothing, ksize=nothing, strides=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "MaxPoolWithArgmax") do 
                desc = tf.NodeDescription("MaxPoolWithArgmax")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function max_pool_with_argmax(input_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing)
        desc = tf.EagerOp("MaxPoolWithArgmax")
        tf.add_input(desc, input_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     quantized_relu_x(features, max_value, min_features, max_features; out_type=Float32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_relu_x(features_, max_value_, min_features_, max_features_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "QuantizedReluX") do 
                desc = tf.NodeDescription("QuantizedReluX")
                features_ = convert(Tensor{Any}, features_)
                max_value_ = convert(Tensor{Float32}, max_value_)
                min_features_ = convert(Tensor{Float32}, min_features_)
                max_features_ = convert(Tensor{Float32}, max_features_)
                (features_,) = tf.tf_promote(features_)
                tf.add_input(desc, features_)
                tf.add_input(desc, max_value_)
                tf.add_input(desc, min_features_)
                tf.add_input(desc, max_features_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_relu_x(features_::tf.TensorHandle, max_value_::tf.TensorHandle, min_features_::tf.TensorHandle, max_features_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("QuantizedReluX")
        tf.add_input(desc, features_)
        tf.add_input(desc, max_value_)
        tf.add_input(desc, min_features_)
        tf.add_input(desc, max_features_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["Tinput"] = tf.data_type(features_)
        tf.execute(desc)
    end
end


"""
     random_shuffle_queue(; shapes=Int64[], capacity=-1, min_after_dequeue=0, seed=0, seed2=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function random_shuffle_queue(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, min_after_dequeue=nothing, seed=nothing, seed2=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "RandomShuffleQueue") do 
                desc = tf.NodeDescription("RandomShuffleQueue")
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if min_after_dequeue !== nothing
                    desc["min_after_dequeue"] = Base.Int(min_after_dequeue)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function random_shuffle_queue(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, min_after_dequeue=nothing, seed=nothing, seed2=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("RandomShuffleQueue")
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if min_after_dequeue !== nothing
            desc["min_after_dequeue"] = Base.Int(min_after_dequeue)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     fft2d(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fft2d(input_; name=nothing)
            local desc
            tf.with_op_name(name, "FFT2D") do 
                desc = tf.NodeDescription("FFT2D")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fft2d(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("FFT2D")
        tf.add_input(desc, input_)
        desc["Tcomplex"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_thread_pool_dataset(input_dataset, thread_pool)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_thread_pool_dataset(input_dataset_, thread_pool_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalThreadPoolDataset") do 
                desc = tf.NodeDescription("ExperimentalThreadPoolDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                thread_pool_ = convert(Tensor{Any}, thread_pool_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, thread_pool_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_thread_pool_dataset(input_dataset_::tf.TensorHandle, thread_pool_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalThreadPoolDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, thread_pool_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     experimental_directed_interleave_dataset(selector_input_dataset, data_input_datasets)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_directed_interleave_dataset(selector_input_dataset_, data_input_datasets_; name=nothing, output_types=nothing, output_shapes=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalDirectedInterleaveDataset") do 
                desc = tf.NodeDescription("ExperimentalDirectedInterleaveDataset")
                selector_input_dataset_ = convert(Tensor{Any}, selector_input_dataset_)
                data_input_datasets_ = [convert(Tensor{Any}, x) for x = data_input_datasets_]
                tf.add_input(desc, selector_input_dataset_)
                tf.add_input(desc, data_input_datasets_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_directed_interleave_dataset(selector_input_dataset_::tf.TensorHandle, data_input_datasets_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing, N=nothing)
        desc = tf.EagerOp("ExperimentalDirectedInterleaveDataset")
        tf.add_input(desc, selector_input_dataset_)
        tf.add_input(desc, data_input_datasets_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_segment_sqrt_n_grad(grad, indices, segment_ids, output_dim0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_segment_sqrt_n_grad(grad_, indices_, segment_ids_, output_dim0_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSegmentSqrtNGrad") do 
                desc = tf.NodeDescription("SparseSegmentSqrtNGrad")
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Int32}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                segment_ids_ = convert(Tensor{Int32}, segment_ids_)
                output_dim0_ = convert(Tensor{Int32}, output_dim0_)
                (grad_,) = tf.tf_promote(grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, segment_ids_)
                tf.add_input(desc, output_dim0_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_segment_sqrt_n_grad(grad_::tf.TensorHandle, indices_::tf.TensorHandle, segment_ids_::tf.TensorHandle, output_dim0_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSegmentSqrtNGrad")
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, segment_ids_)
        tf.add_input(desc, output_dim0_)
        desc["T"] = tf.data_type(grad_)
        desc["Tidx"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     real(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function real(input_; name=nothing)
            local desc
            tf.with_op_name(name, "Real") do 
                desc = tf.NodeDescription("Real")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function real(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Real")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     ordered_map_unstage(key, indices; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ordered_map_unstage(key_, indices_; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "OrderedMapUnstage") do 
                desc = tf.NodeDescription("OrderedMapUnstage")
                key_ = convert(Tensor{Int64}, key_)
                indices_ = convert(Tensor{Int32}, indices_)
                tf.add_input(desc, key_)
                tf.add_input(desc, indices_)
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ordered_map_unstage(key_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("OrderedMapUnstage")
        tf.add_input(desc, key_)
        tf.add_input(desc, indices_)
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     rfft2d(input, fft_length)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function rfft2d(input_, fft_length_; name=nothing)
            local desc
            tf.with_op_name(name, "RFFT2D") do 
                desc = tf.NodeDescription("RFFT2D")
                input_ = convert(Tensor{Float32}, input_)
                fft_length_ = convert(Tensor{Int32}, fft_length_)
                tf.add_input(desc, input_)
                tf.add_input(desc, fft_length_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function rfft2d(input_::tf.TensorHandle, fft_length_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RFFT2D")
        tf.add_input(desc, input_)
        tf.add_input(desc, fft_length_)
        (tf.execute(desc))[1]
    end
end


"""
     var_is_initialized_op(resource)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function var_is_initialized_op(resource_; name=nothing)
            local desc
            tf.with_op_name(name, "VarIsInitializedOp") do 
                desc = tf.NodeDescription("VarIsInitializedOp")
                resource_ = convert(Tensor{Any}, resource_)
                tf.add_input(desc, resource_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function var_is_initialized_op(resource_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("VarIsInitializedOp")
        tf.add_input(desc, resource_)
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_quantile_stream_resource_handle_op(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_quantile_stream_resource_handle_op(; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesQuantileStreamResourceHandleOp") do 
                desc = tf.NodeDescription("BoostedTreesQuantileStreamResourceHandleOp")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_quantile_stream_resource_handle_op(; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("BoostedTreesQuantileStreamResourceHandleOp")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     atan2(y, x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function atan2(y_, x_; name=nothing)
            local desc
            tf.with_op_name(name, "Atan2") do 
                desc = tf.NodeDescription("Atan2")
                y_ = convert(Tensor{Any}, y_)
                x_ = convert(Tensor{Any}, x_)
                (y_, x_) = tf.tf_promote(y_, x_)
                tf.add_input(desc, y_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function atan2(y_::tf.TensorHandle, x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Atan2")
        tf.add_input(desc, y_)
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(y_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     random_poisson(shape, rate; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function random_poisson(shape_, rate_; name=nothing, seed=nothing, seed2=nothing, S=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "RandomPoisson") do 
                desc = tf.NodeDescription("RandomPoisson")
                shape_ = convert(Tensor{Any}, shape_)
                rate_ = convert(Tensor{Any}, rate_)
                (rate_,) = tf.tf_promote(rate_)
                (shape_,) = tf.tf_promote(shape_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, rate_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if S !== nothing
                    desc["S"] = Base.identity(S)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function random_poisson(shape_::tf.TensorHandle, rate_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing, S=nothing, dtype=nothing)
        desc = tf.EagerOp("RandomPoisson")
        tf.add_input(desc, shape_)
        tf.add_input(desc, rate_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if S !== nothing
            desc["S"] = Base.identity(S)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["S"] = tf.data_type(shape_)
        desc["dtype"] = tf.data_type(rate_)
        (tf.execute(desc))[1]
    end
end


"""
     reverse_sequence(input, seq_lengths; batch_dim=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reverse_sequence(input_, seq_lengths_; name=nothing, seq_dim=nothing, batch_dim=nothing)
            local desc
            tf.with_op_name(name, "ReverseSequence") do 
                desc = tf.NodeDescription("ReverseSequence")
                input_ = convert(Tensor{Any}, input_)
                seq_lengths_ = convert(Tensor{Int64}, seq_lengths_)
                (input_,) = tf.tf_promote(input_)
                (seq_lengths_,) = tf.tf_promote(seq_lengths_)
                tf.add_input(desc, input_)
                tf.add_input(desc, seq_lengths_)
                if seq_dim !== nothing
                    desc["seq_dim"] = Base.Int(seq_dim)
                end
                if batch_dim !== nothing
                    desc["batch_dim"] = Base.Int(batch_dim)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reverse_sequence(input_::tf.TensorHandle, seq_lengths_::tf.TensorHandle; name=nothing, seq_dim=nothing, batch_dim=nothing)
        desc = tf.EagerOp("ReverseSequence")
        tf.add_input(desc, input_)
        tf.add_input(desc, seq_lengths_)
        if seq_dim !== nothing
            desc["seq_dim"] = Base.Int(seq_dim)
        end
        if batch_dim !== nothing
            desc["batch_dim"] = Base.Int(batch_dim)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tlen"] = tf.data_type(seq_lengths_)
        (tf.execute(desc))[1]
    end
end


"""
     outfeed_enqueue(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function outfeed_enqueue(input_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "OutfeedEnqueue") do 
                desc = tf.NodeDescription("OutfeedEnqueue")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function outfeed_enqueue(input_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("OutfeedEnqueue")
        tf.add_input(desc, input_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["dtype"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     sub(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sub(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Sub") do 
                desc = tf.NodeDescription("Sub")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sub(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Sub")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     string_split(input, delimiter; skip_empty=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function string_split(input_, delimiter_; name=nothing, skip_empty=nothing)
            local desc
            tf.with_op_name(name, "StringSplit") do 
                desc = tf.NodeDescription("StringSplit")
                input_ = convert(Tensor{String}, input_)
                delimiter_ = convert(Tensor{String}, delimiter_)
                tf.add_input(desc, input_)
                tf.add_input(desc, delimiter_)
                if skip_empty !== nothing
                    desc["skip_empty"] = Base.Bool(skip_empty)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function string_split(input_::tf.TensorHandle, delimiter_::tf.TensorHandle; name=nothing, skip_empty=nothing)
        desc = tf.EagerOp("StringSplit")
        tf.add_input(desc, input_)
        tf.add_input(desc, delimiter_)
        if skip_empty !== nothing
            desc["skip_empty"] = Base.Bool(skip_empty)
        end
        tf.execute(desc)
    end
end


"""
     cumprod(x, axis; exclusive=false, reverse=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cumprod(x_, axis_; name=nothing, exclusive=nothing, reverse=nothing)
            local desc
            tf.with_op_name(name, "Cumprod") do 
                desc = tf.NodeDescription("Cumprod")
                x_ = convert(Tensor{Any}, x_)
                axis_ = convert(Tensor{Int32}, axis_)
                axis_ = axis_ - convert(tf.Tensor{eltype(axis_)}, 1)
                (x_,) = tf.tf_promote(x_)
                (axis_,) = tf.tf_promote(axis_)
                tf.add_input(desc, x_)
                tf.add_input(desc, axis_)
                if exclusive !== nothing
                    desc["exclusive"] = Base.Bool(exclusive)
                end
                if reverse !== nothing
                    desc["reverse"] = Base.Bool(reverse)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cumprod(x_::tf.TensorHandle, axis_::tf.TensorHandle; name=nothing, exclusive=nothing, reverse=nothing)
        desc = tf.EagerOp("Cumprod")
        tf.add_input(desc, x_)
        tf.add_input(desc, axis_)
        if exclusive !== nothing
            desc["exclusive"] = Base.Bool(exclusive)
        end
        if reverse !== nothing
            desc["reverse"] = Base.Bool(reverse)
        end
        desc["T"] = tf.data_type(x_)
        desc["Tidx"] = tf.data_type(axis_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_resize_bilinear(images, size, min, max; align_corners=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_resize_bilinear(images_, size_, min_, max_; name=nothing, align_corners=nothing)
            local desc
            tf.with_op_name(name, "QuantizedResizeBilinear") do 
                desc = tf.NodeDescription("QuantizedResizeBilinear")
                images_ = convert(Tensor{Any}, images_)
                size_ = convert(Tensor{Int32}, size_)
                min_ = convert(Tensor{Float32}, min_)
                max_ = convert(Tensor{Float32}, max_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                tf.add_input(desc, size_)
                tf.add_input(desc, min_)
                tf.add_input(desc, max_)
                if align_corners !== nothing
                    desc["align_corners"] = Base.Bool(align_corners)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_resize_bilinear(images_::tf.TensorHandle, size_::tf.TensorHandle, min_::tf.TensorHandle, max_::tf.TensorHandle; name=nothing, align_corners=nothing)
        desc = tf.EagerOp("QuantizedResizeBilinear")
        tf.add_input(desc, images_)
        tf.add_input(desc, size_)
        tf.add_input(desc, min_)
        tf.add_input(desc, max_)
        if align_corners !== nothing
            desc["align_corners"] = Base.Bool(align_corners)
        end
        desc["T"] = tf.data_type(images_)
        tf.execute(desc)
    end
end


"""
     parse_single_example(serialized, dense_defaults)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function parse_single_example(serialized_, dense_defaults_; name=nothing, num_sparse=nothing, sparse_keys=nothing, dense_keys=nothing, sparse_types=nothing, Tdense=nothing, dense_shapes=nothing)
            local desc
            tf.with_op_name(name, "ParseSingleExample") do 
                desc = tf.NodeDescription("ParseSingleExample")
                serialized_ = convert(Tensor{String}, serialized_)
                dense_defaults_ = [convert(Tensor{Any}, x) for x = dense_defaults_]
                tf.add_input(desc, serialized_)
                tf.add_input(desc, dense_defaults_)
                if num_sparse !== nothing
                    desc["num_sparse"] = Base.Int(num_sparse)
                end
                if sparse_keys !== nothing
                    desc["sparse_keys"] = map(Base.identity, sparse_keys)
                end
                if dense_keys !== nothing
                    desc["dense_keys"] = map(Base.identity, dense_keys)
                end
                if sparse_types !== nothing
                    desc["sparse_types"] = map(Base.identity, sparse_types)
                end
                if Tdense !== nothing
                    desc["Tdense"] = map(Base.identity, Tdense)
                end
                if dense_shapes !== nothing
                    desc["dense_shapes"] = map(Base.identity, dense_shapes)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function parse_single_example(serialized_::tf.TensorHandle, dense_defaults_::tf.TensorHandle; name=nothing, num_sparse=nothing, sparse_keys=nothing, dense_keys=nothing, sparse_types=nothing, Tdense=nothing, dense_shapes=nothing)
        desc = tf.EagerOp("ParseSingleExample")
        tf.add_input(desc, serialized_)
        tf.add_input(desc, dense_defaults_)
        if num_sparse !== nothing
            desc["num_sparse"] = Base.Int(num_sparse)
        end
        if sparse_keys !== nothing
            desc["sparse_keys"] = map(Base.identity, sparse_keys)
        end
        if dense_keys !== nothing
            desc["dense_keys"] = map(Base.identity, dense_keys)
        end
        if sparse_types !== nothing
            desc["sparse_types"] = map(Base.identity, sparse_types)
        end
        if Tdense !== nothing
            desc["Tdense"] = map(Base.identity, Tdense)
        end
        if dense_shapes !== nothing
            desc["dense_shapes"] = map(Base.identity, dense_shapes)
        end
        tf.execute(desc)
    end
end


"""
     is_variable_initialized(ref)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function is_variable_initialized(ref_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "IsVariableInitialized") do 
                desc = tf.NodeDescription("IsVariableInitialized")
                ref_ = convert(Tensor{Any}, ref_)
                (ref_,) = tf.tf_promote(ref_)
                tf.add_input(desc, ref_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function is_variable_initialized(ref_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("IsVariableInitialized")
        tf.add_input(desc, ref_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["dtype"] = tf.data_type(ref_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_stats_aggregator_handle(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_stats_aggregator_handle(; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalStatsAggregatorHandle") do 
                desc = tf.NodeDescription("ExperimentalStatsAggregatorHandle")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_stats_aggregator_handle(; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("ExperimentalStatsAggregatorHandle")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_concat_v2(input_handle, element_shape, leading_dims)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_concat_v2(input_handle_, element_shape_, leading_dims_; name=nothing, element_dtype=nothing, shape_type=nothing)
            local desc
            tf.with_op_name(name, "TensorListConcatV2") do 
                desc = tf.NodeDescription("TensorListConcatV2")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                element_shape_ = convert(Tensor{Any}, element_shape_)
                leading_dims_ = convert(Tensor{Int64}, leading_dims_)
                (element_shape_,) = tf.tf_promote(element_shape_)
                tf.add_input(desc, input_handle_)
                tf.add_input(desc, element_shape_)
                tf.add_input(desc, leading_dims_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
                if shape_type !== nothing
                    desc["shape_type"] = Base.identity(shape_type)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function tensor_list_concat_v2(input_handle_::tf.TensorHandle, element_shape_::tf.TensorHandle, leading_dims_::tf.TensorHandle; name=nothing, element_dtype=nothing, shape_type=nothing)
        desc = tf.EagerOp("TensorListConcatV2")
        tf.add_input(desc, input_handle_)
        tf.add_input(desc, element_shape_)
        tf.add_input(desc, leading_dims_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        if shape_type !== nothing
            desc["shape_type"] = Base.identity(shape_type)
        end
        desc["shape_type"] = tf.data_type(element_shape_)
        tf.execute(desc)
    end
end


"""
     cudnn_rnnv2(input, input_h, input_c, params; rnn_mode=lstm, input_mode=linear_input, direction=unidirectional, dropout=?, seed=0, seed2=0, is_training=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cudnn_rnnv2(input_, input_h_, input_c_, params_; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing, is_training=nothing)
            local desc
            tf.with_op_name(name, "CudnnRNNV2") do 
                desc = tf.NodeDescription("CudnnRNNV2")
                input_ = convert(Tensor{Any}, input_)
                input_h_ = convert(Tensor{Any}, input_h_)
                input_c_ = convert(Tensor{Any}, input_c_)
                params_ = convert(Tensor{Any}, params_)
                (input_, input_h_, input_c_, params_) = tf.tf_promote(input_, input_h_, input_c_, params_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_h_)
                tf.add_input(desc, input_c_)
                tf.add_input(desc, params_)
                if rnn_mode !== nothing
                    desc["rnn_mode"] = Base.String(rnn_mode)
                end
                if input_mode !== nothing
                    desc["input_mode"] = Base.String(input_mode)
                end
                if direction !== nothing
                    desc["direction"] = Base.String(direction)
                end
                if dropout !== nothing
                    desc["dropout"] = Base.identity(dropout)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if is_training !== nothing
                    desc["is_training"] = Base.Bool(is_training)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:5
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function cudnn_rnnv2(input_::tf.TensorHandle, input_h_::tf.TensorHandle, input_c_::tf.TensorHandle, params_::tf.TensorHandle; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing, is_training=nothing)
        desc = tf.EagerOp("CudnnRNNV2")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_h_)
        tf.add_input(desc, input_c_)
        tf.add_input(desc, params_)
        if rnn_mode !== nothing
            desc["rnn_mode"] = Base.String(rnn_mode)
        end
        if input_mode !== nothing
            desc["input_mode"] = Base.String(input_mode)
        end
        if direction !== nothing
            desc["direction"] = Base.String(direction)
        end
        if dropout !== nothing
            desc["dropout"] = Base.identity(dropout)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if is_training !== nothing
            desc["is_training"] = Base.Bool(is_training)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(input_h_)
        desc["T"] = tf.data_type(input_c_)
        desc["T"] = tf.data_type(params_)
        tf.execute(desc)
    end
end


"""
     resource_scatter_sub(resource, indices, updates)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_scatter_sub(resource_, indices_, updates_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "ResourceScatterSub") do 
                desc = tf.NodeDescription("ResourceScatterSub")
                resource_ = convert(Tensor{Any}, resource_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (updates_,) = tf.tf_promote(updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_scatter_sub(resource_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("ResourceScatterSub")
        tf.add_input(desc, resource_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["Tindices"] = tf.data_type(indices_)
        desc["dtype"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     assign_add(ref, value; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function assign_add(ref_, value_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "AssignAdd") do 
                desc = tf.NodeDescription("AssignAdd")
                ref_ = convert(Tensor{Any}, ref_)
                value_ = convert(Tensor{Any}, value_)
                (ref_, value_) = tf.tf_promote(ref_, value_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, value_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function assign_add(ref_::tf.TensorHandle, value_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("AssignAdd")
        tf.add_input(desc, ref_)
        tf.add_input(desc, value_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_dataset(components)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_dataset(components_; name=nothing, Toutput_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "TensorDataset") do 
                desc = tf.NodeDescription("TensorDataset")
                components_ = [convert(Tensor{Any}, x) for x = components_]
                tf.add_input(desc, components_)
                if Toutput_types !== nothing
                    desc["Toutput_types"] = map(Base.identity, Toutput_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_dataset(components_::tf.TensorHandle; name=nothing, Toutput_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("TensorDataset")
        tf.add_input(desc, components_)
        if Toutput_types !== nothing
            desc["Toutput_types"] = map(Base.identity, Toutput_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     bucketize(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function bucketize(input_; name=nothing, boundaries=nothing)
            local desc
            tf.with_op_name(name, "Bucketize") do 
                desc = tf.NodeDescription("Bucketize")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if boundaries !== nothing
                    desc["boundaries"] = map(Base.identity, boundaries)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function bucketize(input_::tf.TensorHandle; name=nothing, boundaries=nothing)
        desc = tf.EagerOp("Bucketize")
        tf.add_input(desc, input_)
        if boundaries !== nothing
            desc["boundaries"] = map(Base.identity, boundaries)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_reduce_max(input_indices, input_values, input_shape, reduction_axes; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_reduce_max(input_indices_, input_values_, input_shape_, reduction_axes_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "SparseReduceMax") do 
                desc = tf.NodeDescription("SparseReduceMax")
                input_indices_ = convert(Tensor{Int64}, input_indices_)
                input_values_ = convert(Tensor{Any}, input_values_)
                input_shape_ = convert(Tensor{Int64}, input_shape_)
                reduction_axes_ = convert(Tensor{Int32}, reduction_axes_)
                (input_values_,) = tf.tf_promote(input_values_)
                tf.add_input(desc, input_indices_)
                tf.add_input(desc, input_values_)
                tf.add_input(desc, input_shape_)
                tf.add_input(desc, reduction_axes_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_reduce_max(input_indices_::tf.TensorHandle, input_values_::tf.TensorHandle, input_shape_::tf.TensorHandle, reduction_axes_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("SparseReduceMax")
        tf.add_input(desc, input_indices_)
        tf.add_input(desc, input_values_)
        tf.add_input(desc, input_shape_)
        tf.add_input(desc, reduction_axes_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["T"] = tf.data_type(input_values_)
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_mdl_adagrad_light_parameters(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_mdl_adagrad_light_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingMDLAdagradLightParameters") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingMDLAdagradLightParameters")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_mdl_adagrad_light_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingMDLAdagradLightParameters")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     tensor_array_grad_with_shape(handle, flow_in, shape_to_prepend)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_grad_with_shape(handle_, flow_in_, shape_to_prepend_; name=nothing, source=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayGradWithShape") do 
                desc = tf.NodeDescription("TensorArrayGradWithShape")
                handle_ = convert(Tensor{Any}, handle_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                shape_to_prepend_ = convert(Tensor{Int32}, shape_to_prepend_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, flow_in_)
                tf.add_input(desc, shape_to_prepend_)
                if source !== nothing
                    desc["source"] = Base.String(source)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function tensor_array_grad_with_shape(handle_::tf.TensorHandle, flow_in_::tf.TensorHandle, shape_to_prepend_::tf.TensorHandle; name=nothing, source=nothing)
        desc = tf.EagerOp("TensorArrayGradWithShape")
        tf.add_input(desc, handle_)
        tf.add_input(desc, flow_in_)
        tf.add_input(desc, shape_to_prepend_)
        if source !== nothing
            desc["source"] = Base.String(source)
        end
        tf.execute(desc)
    end
end


"""
     tensor_array_close_v3(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_close_v3(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayCloseV3") do 
                desc = tf.NodeDescription("TensorArrayCloseV3")
                handle_ = convert(Tensor{Any}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_close_v3(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArrayCloseV3")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     non_max_suppression_with_overlaps(overlaps, scores, max_output_size, overlap_threshold, score_threshold)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function non_max_suppression_with_overlaps(overlaps_, scores_, max_output_size_, overlap_threshold_, score_threshold_; name=nothing)
            local desc
            tf.with_op_name(name, "NonMaxSuppressionWithOverlaps") do 
                desc = tf.NodeDescription("NonMaxSuppressionWithOverlaps")
                overlaps_ = convert(Tensor{Float32}, overlaps_)
                scores_ = convert(Tensor{Float32}, scores_)
                max_output_size_ = convert(Tensor{Int32}, max_output_size_)
                overlap_threshold_ = convert(Tensor{Float32}, overlap_threshold_)
                score_threshold_ = convert(Tensor{Float32}, score_threshold_)
                tf.add_input(desc, overlaps_)
                tf.add_input(desc, scores_)
                tf.add_input(desc, max_output_size_)
                tf.add_input(desc, overlap_threshold_)
                tf.add_input(desc, score_threshold_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function non_max_suppression_with_overlaps(overlaps_::tf.TensorHandle, scores_::tf.TensorHandle, max_output_size_::tf.TensorHandle, overlap_threshold_::tf.TensorHandle, score_threshold_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("NonMaxSuppressionWithOverlaps")
        tf.add_input(desc, overlaps_)
        tf.add_input(desc, scores_)
        tf.add_input(desc, max_output_size_)
        tf.add_input(desc, overlap_threshold_)
        tf.add_input(desc, score_threshold_)
        (tf.execute(desc))[1]
    end
end


"""
     pack(values; axis=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function pack(values_; name=nothing, N=nothing, axis=nothing)
            local desc
            tf.with_op_name(name, "Pack") do 
                desc = tf.NodeDescription("Pack")
                values_ = [convert(Tensor{Any}, x) for x = values_]
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, values_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if axis !== nothing
                    axis = Base.Int(axis) - 1
                end
                if axis !== nothing
                    desc["axis"] = Base.Int(axis)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function pack(values_::tf.TensorHandle; name=nothing, N=nothing, axis=nothing)
        desc = tf.EagerOp("Pack")
        tf.add_input(desc, values_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if axis !== nothing
            axis = Base.Int(axis) - 1
        end
        if axis !== nothing
            desc["axis"] = Base.Int(axis)
        end
        desc["T"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_grad_v2(handle, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_grad_v2(handle_, flow_in_; name=nothing, source=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayGradV2") do 
                desc = tf.NodeDescription("TensorArrayGradV2")
                handle_ = convert(Tensor{String}, handle_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, flow_in_)
                if source !== nothing
                    desc["source"] = Base.String(source)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_grad_v2(handle_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, source=nothing)
        desc = tf.EagerOp("TensorArrayGradV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, flow_in_)
        if source !== nothing
            desc["source"] = Base.String(source)
        end
        (tf.execute(desc))[1]
    end
end


"""
     assign_sub_variable_op(resource, value)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function assign_sub_variable_op(resource_, value_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "AssignSubVariableOp") do 
                desc = tf.NodeDescription("AssignSubVariableOp")
                resource_ = convert(Tensor{Any}, resource_)
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, value_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function assign_sub_variable_op(resource_::tf.TensorHandle, value_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("AssignSubVariableOp")
        tf.add_input(desc, resource_)
        tf.add_input(desc, value_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["dtype"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_fft2d(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_fft2d(input_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchFFT2D") do 
                desc = tf.NodeDescription("BatchFFT2D")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_fft2d(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchFFT2D")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     close_summary_writer(writer)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function close_summary_writer(writer_; name=nothing)
            local desc
            tf.with_op_name(name, "CloseSummaryWriter") do 
                desc = tf.NodeDescription("CloseSummaryWriter")
                writer_ = convert(Tensor{Any}, writer_)
                tf.add_input(desc, writer_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function close_summary_writer(writer_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("CloseSummaryWriter")
        tf.add_input(desc, writer_)
        (tf.execute(desc))[1]
    end
end


"""
     rank(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function rank(input_; name=nothing)
            local desc
            tf.with_op_name(name, "Rank") do 
                desc = tf.NodeDescription("Rank")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function rank(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Rank")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     fft3d(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fft3d(input_; name=nothing)
            local desc
            tf.with_op_name(name, "FFT3D") do 
                desc = tf.NodeDescription("FFT3D")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fft3d(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("FFT3D")
        tf.add_input(desc, input_)
        desc["Tcomplex"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     apply_ftrl(var, accum, linear, grad, lr, l1, l2, lr_power; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_ftrl(var_, accum_, linear_, grad_, lr_, l1_, l2_, lr_power_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyFtrl") do 
                desc = tf.NodeDescription("ApplyFtrl")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                linear_ = convert(Tensor{Any}, linear_)
                grad_ = convert(Tensor{Any}, grad_)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                lr_power_ = convert(Tensor{Any}, lr_power_)
                (var_, accum_, linear_, grad_, lr_, l1_, l2_, lr_power_) = tf.tf_promote(var_, accum_, linear_, grad_, lr_, l1_, l2_, lr_power_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, linear_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, lr_power_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_ftrl(var_::tf.TensorHandle, accum_::tf.TensorHandle, linear_::tf.TensorHandle, grad_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, lr_power_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyFtrl")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, linear_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, lr_power_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(linear_)
        desc["T"] = tf.data_type(grad_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(lr_power_)
        (tf.execute(desc))[1]
    end
end


"""
     abort(; error_msg=, exit_without_error=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function abort(; name=nothing, error_msg=nothing, exit_without_error=nothing)
            local desc
            tf.with_op_name(name, "Abort") do 
                desc = tf.NodeDescription("Abort")
                if error_msg !== nothing
                    desc["error_msg"] = Base.String(error_msg)
                end
                if exit_without_error !== nothing
                    desc["exit_without_error"] = Base.Bool(exit_without_error)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function abort(; name=nothing, error_msg=nothing, exit_without_error=nothing)
        desc = tf.EagerOp("Abort")
        if error_msg !== nothing
            desc["error_msg"] = Base.String(error_msg)
        end
        if exit_without_error !== nothing
            desc["exit_without_error"] = Base.Bool(exit_without_error)
        end
        (tf.execute(desc))[1]
    end
end


"""
     audio_spectrogram(input; magnitude_squared=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function audio_spectrogram(input_; name=nothing, window_size=nothing, stride=nothing, magnitude_squared=nothing)
            local desc
            tf.with_op_name(name, "AudioSpectrogram") do 
                desc = tf.NodeDescription("AudioSpectrogram")
                input_ = convert(Tensor{Float32}, input_)
                tf.add_input(desc, input_)
                if window_size !== nothing
                    desc["window_size"] = Base.Int(window_size)
                end
                if stride !== nothing
                    desc["stride"] = Base.Int(stride)
                end
                if magnitude_squared !== nothing
                    desc["magnitude_squared"] = Base.Bool(magnitude_squared)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function audio_spectrogram(input_::tf.TensorHandle; name=nothing, window_size=nothing, stride=nothing, magnitude_squared=nothing)
        desc = tf.EagerOp("AudioSpectrogram")
        tf.add_input(desc, input_)
        if window_size !== nothing
            desc["window_size"] = Base.Int(window_size)
        end
        if stride !== nothing
            desc["stride"] = Base.Int(stride)
        end
        if magnitude_squared !== nothing
            desc["magnitude_squared"] = Base.Bool(magnitude_squared)
        end
        (tf.execute(desc))[1]
    end
end


"""
     variable_shape(input; out_type=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function variable_shape(input_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "VariableShape") do 
                desc = tf.NodeDescription("VariableShape")
                input_ = convert(Tensor{Any}, input_)
                tf.add_input(desc, input_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function variable_shape(input_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("VariableShape")
        tf.add_input(desc, input_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     fifo_queue_v2(; shapes=Int64[], capacity=-1, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fifo_queue_v2(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "FIFOQueueV2") do 
                desc = tf.NodeDescription("FIFOQueueV2")
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fifo_queue_v2(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("FIFOQueueV2")
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     variable(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function variable(; name=nothing, shape=nothing, dtype=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "Variable") do 
                desc = tf.NodeDescription("Variable")
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function variable(; name=nothing, shape=nothing, dtype=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("Variable")
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_forest_create_tree_variable(tree_handle, tree_config)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_forest_create_tree_variable(tree_handle_, tree_config_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorForestCreateTreeVariable") do 
                desc = tf.NodeDescription("TensorForestCreateTreeVariable")
                tree_handle_ = convert(Tensor{Any}, tree_handle_)
                tree_config_ = convert(Tensor{String}, tree_config_)
                tf.add_input(desc, tree_handle_)
                tf.add_input(desc, tree_config_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_forest_create_tree_variable(tree_handle_::tf.TensorHandle, tree_config_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorForestCreateTreeVariable")
        tf.add_input(desc, tree_handle_)
        tf.add_input(desc, tree_config_)
        (tf.execute(desc))[1]
    end
end


"""
     max_pool_grad_with_argmax(input, grad, argmax)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool_grad_with_argmax(input_, grad_, argmax_; name=nothing, ksize=nothing, strides=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "MaxPoolGradWithArgmax") do 
                desc = tf.NodeDescription("MaxPoolGradWithArgmax")
                input_ = convert(Tensor{Any}, input_)
                grad_ = convert(Tensor{Any}, grad_)
                argmax_ = convert(Tensor{Any}, argmax_)
                (argmax_,) = tf.tf_promote(argmax_)
                (input_, grad_) = tf.tf_promote(input_, grad_)
                tf.add_input(desc, input_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, argmax_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max_pool_grad_with_argmax(input_::tf.TensorHandle, grad_::tf.TensorHandle, argmax_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing)
        desc = tf.EagerOp("MaxPoolGradWithArgmax")
        tf.add_input(desc, input_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, argmax_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(grad_)
        desc["Targmax"] = tf.data_type(argmax_)
        (tf.execute(desc))[1]
    end
end


"""
     ref_switch(data, pred)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ref_switch(data_, pred_; name=nothing)
            local desc
            tf.with_op_name(name, "RefSwitch") do 
                desc = tf.NodeDescription("RefSwitch")
                data_ = convert(Tensor{Any}, data_)
                pred_ = convert(Tensor{Bool}, pred_)
                (data_,) = tf.tf_promote(data_)
                tf.add_input(desc, data_)
                tf.add_input(desc, pred_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function ref_switch(data_::tf.TensorHandle, pred_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RefSwitch")
        tf.add_input(desc, data_)
        tf.add_input(desc, pred_)
        desc["T"] = tf.data_type(data_)
        tf.execute(desc)
    end
end


"""
     sdca_fprint(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sdca_fprint(input_; name=nothing)
            local desc
            tf.with_op_name(name, "SdcaFprint") do 
                desc = tf.NodeDescription("SdcaFprint")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sdca_fprint(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SdcaFprint")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_choose_fastest_dataset(input_datasets)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_choose_fastest_dataset(input_datasets_; name=nothing, N=nothing, num_experiments=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalChooseFastestDataset") do 
                desc = tf.NodeDescription("ExperimentalChooseFastestDataset")
                input_datasets_ = [convert(Tensor{Any}, x) for x = input_datasets_]
                tf.add_input(desc, input_datasets_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if num_experiments !== nothing
                    desc["num_experiments"] = Base.Int(num_experiments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_choose_fastest_dataset(input_datasets_::tf.TensorHandle; name=nothing, N=nothing, num_experiments=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalChooseFastestDataset")
        tf.add_input(desc, input_datasets_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if num_experiments !== nothing
            desc["num_experiments"] = Base.Int(num_experiments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     leaky_relu(features; alpha=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function leaky_relu(features_; name=nothing, alpha=nothing)
            local desc
            tf.with_op_name(name, "LeakyRelu") do 
                desc = tf.NodeDescription("LeakyRelu")
                features_ = convert(Tensor{Float32}, features_)
                (features_,) = tf.tf_promote(features_)
                tf.add_input(desc, features_)
                if alpha !== nothing
                    desc["alpha"] = Base.identity(alpha)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function leaky_relu(features_::tf.TensorHandle; name=nothing, alpha=nothing)
        desc = tf.EagerOp("LeakyRelu")
        tf.add_input(desc, features_)
        if alpha !== nothing
            desc["alpha"] = Base.identity(alpha)
        end
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     identity_n(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function identity_n(input_; name=nothing, T=nothing)
            local desc
            tf.with_op_name(name, "IdentityN") do 
                desc = tf.NodeDescription("IdentityN")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                tf.add_input(desc, input_)
                if T !== nothing
                    desc["T"] = map(Base.identity, T)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function identity_n(input_::tf.TensorHandle; name=nothing, T=nothing)
        desc = tf.EagerOp("IdentityN")
        tf.add_input(desc, input_)
        if T !== nothing
            desc["T"] = map(Base.identity, T)
        end
        (tf.execute(desc))[1]
    end
end


"""
     cudnn_rnn_backprop_v2(input, input_h, input_c, params, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space, host_reserved; rnn_mode=lstm, input_mode=linear_input, direction=unidirectional, dropout=?, seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cudnn_rnn_backprop_v2(input_, input_h_, input_c_, params_, output_, output_h_, output_c_, output_backprop_, output_h_backprop_, output_c_backprop_, reserve_space_, host_reserved_; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "CudnnRNNBackpropV2") do 
                desc = tf.NodeDescription("CudnnRNNBackpropV2")
                input_ = convert(Tensor{Any}, input_)
                input_h_ = convert(Tensor{Any}, input_h_)
                input_c_ = convert(Tensor{Any}, input_c_)
                params_ = convert(Tensor{Any}, params_)
                output_ = convert(Tensor{Any}, output_)
                output_h_ = convert(Tensor{Any}, output_h_)
                output_c_ = convert(Tensor{Any}, output_c_)
                output_backprop_ = convert(Tensor{Any}, output_backprop_)
                output_h_backprop_ = convert(Tensor{Any}, output_h_backprop_)
                output_c_backprop_ = convert(Tensor{Any}, output_c_backprop_)
                reserve_space_ = convert(Tensor{Any}, reserve_space_)
                host_reserved_ = convert(Tensor{Any}, host_reserved_)
                (input_, input_h_, input_c_, params_, output_, output_h_, output_c_, output_backprop_, output_h_backprop_, output_c_backprop_, reserve_space_) = tf.tf_promote(input_, input_h_, input_c_, params_, output_, output_h_, output_c_, output_backprop_, output_h_backprop_, output_c_backprop_, reserve_space_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_h_)
                tf.add_input(desc, input_c_)
                tf.add_input(desc, params_)
                tf.add_input(desc, output_)
                tf.add_input(desc, output_h_)
                tf.add_input(desc, output_c_)
                tf.add_input(desc, output_backprop_)
                tf.add_input(desc, output_h_backprop_)
                tf.add_input(desc, output_c_backprop_)
                tf.add_input(desc, reserve_space_)
                tf.add_input(desc, host_reserved_)
                if rnn_mode !== nothing
                    desc["rnn_mode"] = Base.String(rnn_mode)
                end
                if input_mode !== nothing
                    desc["input_mode"] = Base.String(input_mode)
                end
                if direction !== nothing
                    desc["direction"] = Base.String(direction)
                end
                if dropout !== nothing
                    desc["dropout"] = Base.identity(dropout)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function cudnn_rnn_backprop_v2(input_::tf.TensorHandle, input_h_::tf.TensorHandle, input_c_::tf.TensorHandle, params_::tf.TensorHandle, output_::tf.TensorHandle, output_h_::tf.TensorHandle, output_c_::tf.TensorHandle, output_backprop_::tf.TensorHandle, output_h_backprop_::tf.TensorHandle, output_c_backprop_::tf.TensorHandle, reserve_space_::tf.TensorHandle, host_reserved_::tf.TensorHandle; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("CudnnRNNBackpropV2")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_h_)
        tf.add_input(desc, input_c_)
        tf.add_input(desc, params_)
        tf.add_input(desc, output_)
        tf.add_input(desc, output_h_)
        tf.add_input(desc, output_c_)
        tf.add_input(desc, output_backprop_)
        tf.add_input(desc, output_h_backprop_)
        tf.add_input(desc, output_c_backprop_)
        tf.add_input(desc, reserve_space_)
        tf.add_input(desc, host_reserved_)
        if rnn_mode !== nothing
            desc["rnn_mode"] = Base.String(rnn_mode)
        end
        if input_mode !== nothing
            desc["input_mode"] = Base.String(input_mode)
        end
        if direction !== nothing
            desc["direction"] = Base.String(direction)
        end
        if dropout !== nothing
            desc["dropout"] = Base.identity(dropout)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(input_h_)
        desc["T"] = tf.data_type(input_c_)
        desc["T"] = tf.data_type(params_)
        desc["T"] = tf.data_type(output_)
        desc["T"] = tf.data_type(output_h_)
        desc["T"] = tf.data_type(output_c_)
        desc["T"] = tf.data_type(output_backprop_)
        desc["T"] = tf.data_type(output_h_backprop_)
        desc["T"] = tf.data_type(output_c_backprop_)
        desc["T"] = tf.data_type(reserve_space_)
        tf.execute(desc)
    end
end


"""
     requantization_range(input, input_min, input_max)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function requantization_range(input_, input_min_, input_max_; name=nothing)
            local desc
            tf.with_op_name(name, "RequantizationRange") do 
                desc = tf.NodeDescription("RequantizationRange")
                input_ = convert(Tensor{Any}, input_)
                input_min_ = convert(Tensor{Float32}, input_min_)
                input_max_ = convert(Tensor{Float32}, input_max_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_min_)
                tf.add_input(desc, input_max_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function requantization_range(input_::tf.TensorHandle, input_min_::tf.TensorHandle, input_max_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RequantizationRange")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_min_)
        tf.add_input(desc, input_max_)
        desc["Tinput"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     maximum(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function maximum(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Maximum") do 
                desc = tf.NodeDescription("Maximum")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function maximum(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Maximum")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     reshape(tensor, shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reshape(tensor_, shape_; name=nothing)
            local desc
            tf.with_op_name(name, "Reshape") do 
                desc = tf.NodeDescription("Reshape")
                tensor_ = convert(Tensor{Any}, tensor_)
                shape_ = convert(Tensor{Int32}, shape_)
                (tensor_,) = tf.tf_promote(tensor_)
                (shape_,) = tf.tf_promote(shape_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, shape_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reshape(tensor_::tf.TensorHandle, shape_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Reshape")
        tf.add_input(desc, tensor_)
        tf.add_input(desc, shape_)
        desc["T"] = tf.data_type(tensor_)
        desc["Tshape"] = tf.data_type(shape_)
        (tf.execute(desc))[1]
    end
end


"""
     matrix_solve_ls(matrix, rhs, l2_regularizer; fast=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_solve_ls(matrix_, rhs_, l2_regularizer_; name=nothing, fast=nothing)
            local desc
            tf.with_op_name(name, "MatrixSolveLs") do 
                desc = tf.NodeDescription("MatrixSolveLs")
                matrix_ = convert(Tensor{Any}, matrix_)
                rhs_ = convert(Tensor{Any}, rhs_)
                l2_regularizer_ = convert(Tensor{Float64}, l2_regularizer_)
                (matrix_, rhs_) = tf.tf_promote(matrix_, rhs_)
                tf.add_input(desc, matrix_)
                tf.add_input(desc, rhs_)
                tf.add_input(desc, l2_regularizer_)
                if fast !== nothing
                    desc["fast"] = Base.Bool(fast)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_solve_ls(matrix_::tf.TensorHandle, rhs_::tf.TensorHandle, l2_regularizer_::tf.TensorHandle; name=nothing, fast=nothing)
        desc = tf.EagerOp("MatrixSolveLs")
        tf.add_input(desc, matrix_)
        tf.add_input(desc, rhs_)
        tf.add_input(desc, l2_regularizer_)
        if fast !== nothing
            desc["fast"] = Base.Bool(fast)
        end
        desc["T"] = tf.data_type(matrix_)
        desc["T"] = tf.data_type(rhs_)
        (tf.execute(desc))[1]
    end
end


"""
     tf_record_dataset(filenames, compression_type, buffer_size)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tf_record_dataset(filenames_, compression_type_, buffer_size_; name=nothing)
            local desc
            tf.with_op_name(name, "TFRecordDataset") do 
                desc = tf.NodeDescription("TFRecordDataset")
                filenames_ = convert(Tensor{String}, filenames_)
                compression_type_ = convert(Tensor{String}, compression_type_)
                buffer_size_ = convert(Tensor{Int64}, buffer_size_)
                tf.add_input(desc, filenames_)
                tf.add_input(desc, compression_type_)
                tf.add_input(desc, buffer_size_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tf_record_dataset(filenames_::tf.TensorHandle, compression_type_::tf.TensorHandle, buffer_size_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TFRecordDataset")
        tf.add_input(desc, filenames_)
        tf.add_input(desc, compression_type_)
        tf.add_input(desc, buffer_size_)
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_example_debug_outputs(tree_ensemble_handle, bucketized_features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_example_debug_outputs(tree_ensemble_handle_, bucketized_features_; name=nothing, num_bucketized_features=nothing, logits_dimension=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesExampleDebugOutputs") do 
                desc = tf.NodeDescription("BoostedTreesExampleDebugOutputs")
                tree_ensemble_handle_ = convert(Tensor{Any}, tree_ensemble_handle_)
                bucketized_features_ = [convert(Tensor{Int32}, x) for x = bucketized_features_]
                tf.add_input(desc, tree_ensemble_handle_)
                tf.add_input(desc, bucketized_features_)
                if num_bucketized_features !== nothing
                    desc["num_bucketized_features"] = Base.Int(num_bucketized_features)
                end
                if logits_dimension !== nothing
                    desc["logits_dimension"] = Base.Int(logits_dimension)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_example_debug_outputs(tree_ensemble_handle_::tf.TensorHandle, bucketized_features_::tf.TensorHandle; name=nothing, num_bucketized_features=nothing, logits_dimension=nothing)
        desc = tf.EagerOp("BoostedTreesExampleDebugOutputs")
        tf.add_input(desc, tree_ensemble_handle_)
        tf.add_input(desc, bucketized_features_)
        if num_bucketized_features !== nothing
            desc["num_bucketized_features"] = Base.Int(num_bucketized_features)
        end
        if logits_dimension !== nothing
            desc["logits_dimension"] = Base.Int(logits_dimension)
        end
        (tf.execute(desc))[1]
    end
end


"""
     hsv_to_rgb(images)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function hsv_to_rgb(images_; name=nothing)
            local desc
            tf.with_op_name(name, "HSVToRGB") do 
                desc = tf.NodeDescription("HSVToRGB")
                images_ = convert(Tensor{Float32}, images_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function hsv_to_rgb(images_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("HSVToRGB")
        tf.add_input(desc, images_)
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_max_intra_op_parallelism_dataset(input_dataset, max_intra_op_parallelism)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_max_intra_op_parallelism_dataset(input_dataset_, max_intra_op_parallelism_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalMaxIntraOpParallelismDataset") do 
                desc = tf.NodeDescription("ExperimentalMaxIntraOpParallelismDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                max_intra_op_parallelism_ = convert(Tensor{Int64}, max_intra_op_parallelism_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, max_intra_op_parallelism_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_max_intra_op_parallelism_dataset(input_dataset_::tf.TensorHandle, max_intra_op_parallelism_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalMaxIntraOpParallelismDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, max_intra_op_parallelism_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     scatter_div(ref, indices, updates; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_div(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ScatterDiv") do 
                desc = tf.NodeDescription("ScatterDiv")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (ref_, updates_) = tf.tf_promote(ref_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_div(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ScatterDiv")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     decode_wav(contents; desired_channels=-1, desired_samples=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_wav(contents_; name=nothing, desired_channels=nothing, desired_samples=nothing)
            local desc
            tf.with_op_name(name, "DecodeWav") do 
                desc = tf.NodeDescription("DecodeWav")
                contents_ = convert(Tensor{String}, contents_)
                tf.add_input(desc, contents_)
                if desired_channels !== nothing
                    desc["desired_channels"] = Base.Int(desired_channels)
                end
                if desired_samples !== nothing
                    desc["desired_samples"] = Base.Int(desired_samples)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function decode_wav(contents_::tf.TensorHandle; name=nothing, desired_channels=nothing, desired_samples=nothing)
        desc = tf.EagerOp("DecodeWav")
        tf.add_input(desc, contents_)
        if desired_channels !== nothing
            desc["desired_channels"] = Base.Int(desired_channels)
        end
        if desired_samples !== nothing
            desc["desired_samples"] = Base.Int(desired_samples)
        end
        tf.execute(desc)
    end
end


"""
     log(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function log(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Log") do 
                desc = tf.NodeDescription("Log")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function log(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Log")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     save_v2(prefix, tensor_names, shape_and_slices, tensors)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function save_v2(prefix_, tensor_names_, shape_and_slices_, tensors_; name=nothing, dtypes=nothing)
            local desc
            tf.with_op_name(name, "SaveV2") do 
                desc = tf.NodeDescription("SaveV2")
                prefix_ = convert(Tensor{String}, prefix_)
                tensor_names_ = convert(Tensor{String}, tensor_names_)
                shape_and_slices_ = convert(Tensor{String}, shape_and_slices_)
                tensors_ = [convert(Tensor{Any}, x) for x = tensors_]
                tf.add_input(desc, prefix_)
                tf.add_input(desc, tensor_names_)
                tf.add_input(desc, shape_and_slices_)
                tf.add_input(desc, tensors_)
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function save_v2(prefix_::tf.TensorHandle, tensor_names_::tf.TensorHandle, shape_and_slices_::tf.TensorHandle, tensors_::tf.TensorHandle; name=nothing, dtypes=nothing)
        desc = tf.EagerOp("SaveV2")
        tf.add_input(desc, prefix_)
        tf.add_input(desc, tensor_names_)
        tf.add_input(desc, shape_and_slices_)
        tf.add_input(desc, tensors_)
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     deep_copy(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function deep_copy(x_; name=nothing)
            local desc
            tf.with_op_name(name, "DeepCopy") do 
                desc = tf.NodeDescription("DeepCopy")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function deep_copy(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DeepCopy")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     model_dataset(input_dataset)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function model_dataset(input_dataset_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ModelDataset") do 
                desc = tf.NodeDescription("ModelDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                tf.add_input(desc, input_dataset_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function model_dataset(input_dataset_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ModelDataset")
        tf.add_input(desc, input_dataset_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     parse_sequence_example(serialized, debug_name, context_dense_defaults; Ncontext_sparse=0, Ncontext_dense=0, Nfeature_list_sparse=0, Nfeature_list_dense=0, context_sparse_types=Int64[], Tcontext_dense=Int64[], feature_list_dense_types=Int64[], context_dense_shapes=Int64[], feature_list_sparse_types=Int64[], feature_list_dense_shapes=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function parse_sequence_example(serialized_, debug_name_, context_dense_defaults_; name=nothing, feature_list_dense_missing_assumed_empty=nothing, context_sparse_keys=nothing, context_dense_keys=nothing, feature_list_sparse_keys=nothing, feature_list_dense_keys=nothing, Ncontext_sparse=nothing, Ncontext_dense=nothing, Nfeature_list_sparse=nothing, Nfeature_list_dense=nothing, context_sparse_types=nothing, Tcontext_dense=nothing, feature_list_dense_types=nothing, context_dense_shapes=nothing, feature_list_sparse_types=nothing, feature_list_dense_shapes=nothing)
            local desc
            tf.with_op_name(name, "ParseSequenceExample") do 
                desc = tf.NodeDescription("ParseSequenceExample")
                serialized_ = convert(Tensor{String}, serialized_)
                debug_name_ = convert(Tensor{String}, debug_name_)
                context_dense_defaults_ = [convert(Tensor{Any}, x) for x = context_dense_defaults_]
                tf.add_input(desc, serialized_)
                tf.add_input(desc, debug_name_)
                tf.add_input(desc, context_dense_defaults_)
                if feature_list_dense_missing_assumed_empty !== nothing
                    desc["feature_list_dense_missing_assumed_empty"] = map(Base.identity, feature_list_dense_missing_assumed_empty)
                end
                if context_sparse_keys !== nothing
                    desc["context_sparse_keys"] = map(Base.identity, context_sparse_keys)
                end
                if context_dense_keys !== nothing
                    desc["context_dense_keys"] = map(Base.identity, context_dense_keys)
                end
                if feature_list_sparse_keys !== nothing
                    desc["feature_list_sparse_keys"] = map(Base.identity, feature_list_sparse_keys)
                end
                if feature_list_dense_keys !== nothing
                    desc["feature_list_dense_keys"] = map(Base.identity, feature_list_dense_keys)
                end
                if Ncontext_sparse !== nothing
                    desc["Ncontext_sparse"] = Base.Int(Ncontext_sparse)
                end
                if Ncontext_dense !== nothing
                    desc["Ncontext_dense"] = Base.Int(Ncontext_dense)
                end
                if Nfeature_list_sparse !== nothing
                    desc["Nfeature_list_sparse"] = Base.Int(Nfeature_list_sparse)
                end
                if Nfeature_list_dense !== nothing
                    desc["Nfeature_list_dense"] = Base.Int(Nfeature_list_dense)
                end
                if context_sparse_types !== nothing
                    desc["context_sparse_types"] = map(Base.identity, context_sparse_types)
                end
                if Tcontext_dense !== nothing
                    desc["Tcontext_dense"] = map(Base.identity, Tcontext_dense)
                end
                if feature_list_dense_types !== nothing
                    desc["feature_list_dense_types"] = map(Base.identity, feature_list_dense_types)
                end
                if context_dense_shapes !== nothing
                    desc["context_dense_shapes"] = map(Base.identity, context_dense_shapes)
                end
                if feature_list_sparse_types !== nothing
                    desc["feature_list_sparse_types"] = map(Base.identity, feature_list_sparse_types)
                end
                if feature_list_dense_shapes !== nothing
                    desc["feature_list_dense_shapes"] = map(Base.identity, feature_list_dense_shapes)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:9
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function parse_sequence_example(serialized_::tf.TensorHandle, debug_name_::tf.TensorHandle, context_dense_defaults_::tf.TensorHandle; name=nothing, feature_list_dense_missing_assumed_empty=nothing, context_sparse_keys=nothing, context_dense_keys=nothing, feature_list_sparse_keys=nothing, feature_list_dense_keys=nothing, Ncontext_sparse=nothing, Ncontext_dense=nothing, Nfeature_list_sparse=nothing, Nfeature_list_dense=nothing, context_sparse_types=nothing, Tcontext_dense=nothing, feature_list_dense_types=nothing, context_dense_shapes=nothing, feature_list_sparse_types=nothing, feature_list_dense_shapes=nothing)
        desc = tf.EagerOp("ParseSequenceExample")
        tf.add_input(desc, serialized_)
        tf.add_input(desc, debug_name_)
        tf.add_input(desc, context_dense_defaults_)
        if feature_list_dense_missing_assumed_empty !== nothing
            desc["feature_list_dense_missing_assumed_empty"] = map(Base.identity, feature_list_dense_missing_assumed_empty)
        end
        if context_sparse_keys !== nothing
            desc["context_sparse_keys"] = map(Base.identity, context_sparse_keys)
        end
        if context_dense_keys !== nothing
            desc["context_dense_keys"] = map(Base.identity, context_dense_keys)
        end
        if feature_list_sparse_keys !== nothing
            desc["feature_list_sparse_keys"] = map(Base.identity, feature_list_sparse_keys)
        end
        if feature_list_dense_keys !== nothing
            desc["feature_list_dense_keys"] = map(Base.identity, feature_list_dense_keys)
        end
        if Ncontext_sparse !== nothing
            desc["Ncontext_sparse"] = Base.Int(Ncontext_sparse)
        end
        if Ncontext_dense !== nothing
            desc["Ncontext_dense"] = Base.Int(Ncontext_dense)
        end
        if Nfeature_list_sparse !== nothing
            desc["Nfeature_list_sparse"] = Base.Int(Nfeature_list_sparse)
        end
        if Nfeature_list_dense !== nothing
            desc["Nfeature_list_dense"] = Base.Int(Nfeature_list_dense)
        end
        if context_sparse_types !== nothing
            desc["context_sparse_types"] = map(Base.identity, context_sparse_types)
        end
        if Tcontext_dense !== nothing
            desc["Tcontext_dense"] = map(Base.identity, Tcontext_dense)
        end
        if feature_list_dense_types !== nothing
            desc["feature_list_dense_types"] = map(Base.identity, feature_list_dense_types)
        end
        if context_dense_shapes !== nothing
            desc["context_dense_shapes"] = map(Base.identity, context_dense_shapes)
        end
        if feature_list_sparse_types !== nothing
            desc["feature_list_sparse_types"] = map(Base.identity, feature_list_sparse_types)
        end
        if feature_list_dense_shapes !== nothing
            desc["feature_list_dense_shapes"] = map(Base.identity, feature_list_dense_shapes)
        end
        tf.execute(desc)
    end
end


"""
     sinh(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sinh(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Sinh") do 
                desc = tf.NodeDescription("Sinh")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sinh(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Sinh")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     iterator_v2()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function iterator_v2(; name=nothing, shared_name=nothing, container=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "IteratorV2") do 
                desc = tf.NodeDescription("IteratorV2")
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function iterator_v2(; name=nothing, shared_name=nothing, container=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("IteratorV2")
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_write_v2(handle, index, value, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_write_v2(handle_, index_, value_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayWriteV2") do 
                desc = tf.NodeDescription("TensorArrayWriteV2")
                handle_ = convert(Tensor{String}, handle_)
                index_ = convert(Tensor{Int32}, index_)
                value_ = convert(Tensor{Any}, value_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, index_)
                tf.add_input(desc, value_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_write_v2(handle_::tf.TensorHandle, index_::tf.TensorHandle, value_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArrayWriteV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, index_)
        tf.add_input(desc, value_)
        tf.add_input(desc, flow_in_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_element_shape(input_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_element_shape(input_handle_; name=nothing, shape_type=nothing)
            local desc
            tf.with_op_name(name, "TensorListElementShape") do 
                desc = tf.NodeDescription("TensorListElementShape")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                tf.add_input(desc, input_handle_)
                if shape_type !== nothing
                    desc["shape_type"] = Base.identity(shape_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_element_shape(input_handle_::tf.TensorHandle; name=nothing, shape_type=nothing)
        desc = tf.EagerOp("TensorListElementShape")
        tf.add_input(desc, input_handle_)
        if shape_type !== nothing
            desc["shape_type"] = Base.identity(shape_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     queue_size_v2(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_size_v2(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "QueueSizeV2") do 
                desc = tf.NodeDescription("QueueSizeV2")
                handle_ = convert(Tensor{Any}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_size_v2(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("QueueSizeV2")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     expm1(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function expm1(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Expm1") do 
                desc = tf.NodeDescription("Expm1")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function expm1(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Expm1")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_matrix_band_part(input, num_lower, num_upper)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_matrix_band_part(input_, num_lower_, num_upper_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchMatrixBandPart") do 
                desc = tf.NodeDescription("BatchMatrixBandPart")
                input_ = convert(Tensor{Any}, input_)
                num_lower_ = convert(Tensor{Int64}, num_lower_)
                num_upper_ = convert(Tensor{Int64}, num_upper_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, num_lower_)
                tf.add_input(desc, num_upper_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_matrix_band_part(input_::tf.TensorHandle, num_lower_::tf.TensorHandle, num_upper_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchMatrixBandPart")
        tf.add_input(desc, input_)
        tf.add_input(desc, num_lower_)
        tf.add_input(desc, num_upper_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     concatenate_dataset(input_dataset, another_dataset)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function concatenate_dataset(input_dataset_, another_dataset_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ConcatenateDataset") do 
                desc = tf.NodeDescription("ConcatenateDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                another_dataset_ = convert(Tensor{Any}, another_dataset_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, another_dataset_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function concatenate_dataset(input_dataset_::tf.TensorHandle, another_dataset_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ConcatenateDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, another_dataset_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     decode_gif(contents)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_gif(contents_; name=nothing)
            local desc
            tf.with_op_name(name, "DecodeGif") do 
                desc = tf.NodeDescription("DecodeGif")
                contents_ = convert(Tensor{String}, contents_)
                tf.add_input(desc, contents_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function decode_gif(contents_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DecodeGif")
        tf.add_input(desc, contents_)
        (tf.execute(desc))[1]
    end
end


"""
     tpu_replicate(inputs, broadcast_inputs, variables, guaranteed_constants; num_cores_per_replica=1, topology=, use_tpu=true, device_assignment=Int64[], host_compute_core=Int64[], padding_map=Int64[], step_marker_location=STEP_MARK_AT_ENTRY)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tpu_replicate(inputs_, broadcast_inputs_, variables_, guaranteed_constants_; name=nothing, computation=nothing, num_replicas=nothing, num_cores_per_replica=nothing, topology=nothing, use_tpu=nothing, device_assignment=nothing, host_compute_core=nothing, Tinputs=nothing, Tbroadcast_inputs=nothing, NumVariables=nothing, Tguaranteed_constants=nothing, output_types=nothing, padding_map=nothing, step_marker_location=nothing)
            local desc
            tf.with_op_name(name, "TPUReplicate") do 
                desc = tf.NodeDescription("TPUReplicate")
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                broadcast_inputs_ = [convert(Tensor{Any}, x) for x = broadcast_inputs_]
                variables_ = [convert(Tensor{Any}, x) for x = variables_]
                guaranteed_constants_ = [convert(Tensor{Any}, x) for x = guaranteed_constants_]
                tf.add_input(desc, inputs_)
                tf.add_input(desc, broadcast_inputs_)
                tf.add_input(desc, variables_)
                tf.add_input(desc, guaranteed_constants_)
                if computation !== nothing
                    desc["computation"] = Base.identity(computation)
                end
                if num_replicas !== nothing
                    desc["num_replicas"] = Base.Int(num_replicas)
                end
                if num_cores_per_replica !== nothing
                    desc["num_cores_per_replica"] = Base.Int(num_cores_per_replica)
                end
                if topology !== nothing
                    desc["topology"] = Base.String(topology)
                end
                if use_tpu !== nothing
                    desc["use_tpu"] = Base.Bool(use_tpu)
                end
                if device_assignment !== nothing
                    desc["device_assignment"] = map(Base.identity, device_assignment)
                end
                if host_compute_core !== nothing
                    desc["host_compute_core"] = map(Base.identity, host_compute_core)
                end
                if Tinputs !== nothing
                    desc["Tinputs"] = map(Base.identity, Tinputs)
                end
                if Tbroadcast_inputs !== nothing
                    desc["Tbroadcast_inputs"] = map(Base.identity, Tbroadcast_inputs)
                end
                if NumVariables !== nothing
                    desc["NumVariables"] = Base.Int(NumVariables)
                end
                if Tguaranteed_constants !== nothing
                    desc["Tguaranteed_constants"] = map(Base.identity, Tguaranteed_constants)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if padding_map !== nothing
                    desc["padding_map"] = map(Base.identity, padding_map)
                end
                if step_marker_location !== nothing
                    desc["step_marker_location"] = Base.String(step_marker_location)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tpu_replicate(inputs_::tf.TensorHandle, broadcast_inputs_::tf.TensorHandle, variables_::tf.TensorHandle, guaranteed_constants_::tf.TensorHandle; name=nothing, computation=nothing, num_replicas=nothing, num_cores_per_replica=nothing, topology=nothing, use_tpu=nothing, device_assignment=nothing, host_compute_core=nothing, Tinputs=nothing, Tbroadcast_inputs=nothing, NumVariables=nothing, Tguaranteed_constants=nothing, output_types=nothing, padding_map=nothing, step_marker_location=nothing)
        desc = tf.EagerOp("TPUReplicate")
        tf.add_input(desc, inputs_)
        tf.add_input(desc, broadcast_inputs_)
        tf.add_input(desc, variables_)
        tf.add_input(desc, guaranteed_constants_)
        if computation !== nothing
            desc["computation"] = Base.identity(computation)
        end
        if num_replicas !== nothing
            desc["num_replicas"] = Base.Int(num_replicas)
        end
        if num_cores_per_replica !== nothing
            desc["num_cores_per_replica"] = Base.Int(num_cores_per_replica)
        end
        if topology !== nothing
            desc["topology"] = Base.String(topology)
        end
        if use_tpu !== nothing
            desc["use_tpu"] = Base.Bool(use_tpu)
        end
        if device_assignment !== nothing
            desc["device_assignment"] = map(Base.identity, device_assignment)
        end
        if host_compute_core !== nothing
            desc["host_compute_core"] = map(Base.identity, host_compute_core)
        end
        if Tinputs !== nothing
            desc["Tinputs"] = map(Base.identity, Tinputs)
        end
        if Tbroadcast_inputs !== nothing
            desc["Tbroadcast_inputs"] = map(Base.identity, Tbroadcast_inputs)
        end
        if NumVariables !== nothing
            desc["NumVariables"] = Base.Int(NumVariables)
        end
        if Tguaranteed_constants !== nothing
            desc["Tguaranteed_constants"] = map(Base.identity, Tguaranteed_constants)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if padding_map !== nothing
            desc["padding_map"] = map(Base.identity, padding_map)
        end
        if step_marker_location !== nothing
            desc["step_marker_location"] = Base.String(step_marker_location)
        end
        (tf.execute(desc))[1]
    end
end


"""
     batch_self_adjoint_eig_v2(input; compute_v=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_self_adjoint_eig_v2(input_; name=nothing, compute_v=nothing)
            local desc
            tf.with_op_name(name, "BatchSelfAdjointEigV2") do 
                desc = tf.NodeDescription("BatchSelfAdjointEigV2")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if compute_v !== nothing
                    desc["compute_v"] = Base.Bool(compute_v)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function batch_self_adjoint_eig_v2(input_::tf.TensorHandle; name=nothing, compute_v=nothing)
        desc = tf.EagerOp("BatchSelfAdjointEigV2")
        tf.add_input(desc, input_)
        if compute_v !== nothing
            desc["compute_v"] = Base.Bool(compute_v)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     shape(input; out_type=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function shape(input_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "Shape") do 
                desc = tf.NodeDescription("Shape")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function shape(input_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("Shape")
        tf.add_input(desc, input_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     repeat_dataset(input_dataset, count)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function repeat_dataset(input_dataset_, count_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "RepeatDataset") do 
                desc = tf.NodeDescription("RepeatDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                count_ = convert(Tensor{Int64}, count_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, count_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function repeat_dataset(input_dataset_::tf.TensorHandle, count_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("RepeatDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, count_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     crop_and_resize_grad_boxes(grads, image, boxes, box_ind; method=bilinear)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function crop_and_resize_grad_boxes(grads_, image_, boxes_, box_ind_; name=nothing, method=nothing)
            local desc
            tf.with_op_name(name, "CropAndResizeGradBoxes") do 
                desc = tf.NodeDescription("CropAndResizeGradBoxes")
                grads_ = convert(Tensor{Float32}, grads_)
                image_ = convert(Tensor{Any}, image_)
                boxes_ = convert(Tensor{Float32}, boxes_)
                box_ind_ = convert(Tensor{Int32}, box_ind_)
                (image_,) = tf.tf_promote(image_)
                tf.add_input(desc, grads_)
                tf.add_input(desc, image_)
                tf.add_input(desc, boxes_)
                tf.add_input(desc, box_ind_)
                if method !== nothing
                    desc["method"] = Base.String(method)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function crop_and_resize_grad_boxes(grads_::tf.TensorHandle, image_::tf.TensorHandle, boxes_::tf.TensorHandle, box_ind_::tf.TensorHandle; name=nothing, method=nothing)
        desc = tf.EagerOp("CropAndResizeGradBoxes")
        tf.add_input(desc, grads_)
        tf.add_input(desc, image_)
        tf.add_input(desc, boxes_)
        tf.add_input(desc, box_ind_)
        if method !== nothing
            desc["method"] = Base.String(method)
        end
        desc["T"] = tf.data_type(image_)
        (tf.execute(desc))[1]
    end
end


"""
     reciprocal_grad(y, dy)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reciprocal_grad(y_, dy_; name=nothing)
            local desc
            tf.with_op_name(name, "ReciprocalGrad") do 
                desc = tf.NodeDescription("ReciprocalGrad")
                y_ = convert(Tensor{Any}, y_)
                dy_ = convert(Tensor{Any}, dy_)
                (y_, dy_) = tf.tf_promote(y_, dy_)
                tf.add_input(desc, y_)
                tf.add_input(desc, dy_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reciprocal_grad(y_::tf.TensorHandle, dy_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReciprocalGrad")
        tf.add_input(desc, y_)
        tf.add_input(desc, dy_)
        desc["T"] = tf.data_type(y_)
        desc["T"] = tf.data_type(dy_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_matrix_solve(matrix, rhs; adjoint=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_matrix_solve(matrix_, rhs_; name=nothing, adjoint=nothing)
            local desc
            tf.with_op_name(name, "BatchMatrixSolve") do 
                desc = tf.NodeDescription("BatchMatrixSolve")
                matrix_ = convert(Tensor{Any}, matrix_)
                rhs_ = convert(Tensor{Any}, rhs_)
                (matrix_, rhs_) = tf.tf_promote(matrix_, rhs_)
                tf.add_input(desc, matrix_)
                tf.add_input(desc, rhs_)
                if adjoint !== nothing
                    desc["adjoint"] = Base.Bool(adjoint)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_matrix_solve(matrix_::tf.TensorHandle, rhs_::tf.TensorHandle; name=nothing, adjoint=nothing)
        desc = tf.EagerOp("BatchMatrixSolve")
        tf.add_input(desc, matrix_)
        tf.add_input(desc, rhs_)
        if adjoint !== nothing
            desc["adjoint"] = Base.Bool(adjoint)
        end
        desc["T"] = tf.data_type(matrix_)
        desc["T"] = tf.data_type(rhs_)
        (tf.execute(desc))[1]
    end
end


"""
     mutable_hash_table_v2(; container=, shared_name=, use_node_name_sharing=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mutable_hash_table_v2(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing)
            local desc
            tf.with_op_name(name, "MutableHashTableV2") do 
                desc = tf.NodeDescription("MutableHashTableV2")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if use_node_name_sharing !== nothing
                    desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
                end
                if key_dtype !== nothing
                    desc["key_dtype"] = Base.identity(key_dtype)
                end
                if value_dtype !== nothing
                    desc["value_dtype"] = Base.identity(value_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mutable_hash_table_v2(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing)
        desc = tf.EagerOp("MutableHashTableV2")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if use_node_name_sharing !== nothing
            desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
        end
        if key_dtype !== nothing
            desc["key_dtype"] = Base.identity(key_dtype)
        end
        if value_dtype !== nothing
            desc["value_dtype"] = Base.identity(value_dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     exit(data)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function exit(data_; name=nothing)
            local desc
            tf.with_op_name(name, "Exit") do 
                desc = tf.NodeDescription("Exit")
                data_ = convert(Tensor{Any}, data_)
                (data_,) = tf.tf_promote(data_)
                tf.add_input(desc, data_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function exit(data_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Exit")
        tf.add_input(desc, data_)
        desc["T"] = tf.data_type(data_)
        (tf.execute(desc))[1]
    end
end


"""
     lrn(input; depth_radius=5, bias=?, alpha=?, beta=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lrn(input_; name=nothing, depth_radius=nothing, bias=nothing, alpha=nothing, beta=nothing)
            local desc
            tf.with_op_name(name, "LRN") do 
                desc = tf.NodeDescription("LRN")
                input_ = convert(Tensor{Float32}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if depth_radius !== nothing
                    desc["depth_radius"] = Base.Int(depth_radius)
                end
                if bias !== nothing
                    desc["bias"] = Base.identity(bias)
                end
                if alpha !== nothing
                    desc["alpha"] = Base.identity(alpha)
                end
                if beta !== nothing
                    desc["beta"] = Base.identity(beta)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lrn(input_::tf.TensorHandle; name=nothing, depth_radius=nothing, bias=nothing, alpha=nothing, beta=nothing)
        desc = tf.EagerOp("LRN")
        tf.add_input(desc, input_)
        if depth_radius !== nothing
            desc["depth_radius"] = Base.Int(depth_radius)
        end
        if bias !== nothing
            desc["bias"] = Base.identity(bias)
        end
        if alpha !== nothing
            desc["alpha"] = Base.identity(alpha)
        end
        if beta !== nothing
            desc["beta"] = Base.identity(beta)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     stateless_if(cond, input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stateless_if(cond_, input_; name=nothing, Tin=nothing, Tout=nothing, then_branch=nothing, else_branch=nothing)
            local desc
            tf.with_op_name(name, "StatelessIf") do 
                desc = tf.NodeDescription("StatelessIf")
                cond_ = convert(Tensor{Any}, cond_)
                input_ = [convert(Tensor{Any}, x) for x = input_]
                (cond_,) = tf.tf_promote(cond_)
                tf.add_input(desc, cond_)
                tf.add_input(desc, input_)
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
                if then_branch !== nothing
                    desc["then_branch"] = Base.identity(then_branch)
                end
                if else_branch !== nothing
                    desc["else_branch"] = Base.identity(else_branch)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stateless_if(cond_::tf.TensorHandle, input_::tf.TensorHandle; name=nothing, Tin=nothing, Tout=nothing, then_branch=nothing, else_branch=nothing)
        desc = tf.EagerOp("StatelessIf")
        tf.add_input(desc, cond_)
        tf.add_input(desc, input_)
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        if then_branch !== nothing
            desc["then_branch"] = Base.identity(then_branch)
        end
        if else_branch !== nothing
            desc["else_branch"] = Base.identity(else_branch)
        end
        desc["Tcond"] = tf.data_type(cond_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_set_item(input_handle, index, item)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_set_item(input_handle_, index_, item_; name=nothing, element_dtype=nothing)
            local desc
            tf.with_op_name(name, "TensorListSetItem") do 
                desc = tf.NodeDescription("TensorListSetItem")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                index_ = convert(Tensor{Int32}, index_)
                item_ = convert(Tensor{Any}, item_)
                (item_,) = tf.tf_promote(item_)
                tf.add_input(desc, input_handle_)
                tf.add_input(desc, index_)
                tf.add_input(desc, item_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_set_item(input_handle_::tf.TensorHandle, index_::tf.TensorHandle, item_::tf.TensorHandle; name=nothing, element_dtype=nothing)
        desc = tf.EagerOp("TensorListSetItem")
        tf.add_input(desc, input_handle_)
        tf.add_input(desc, index_)
        tf.add_input(desc, item_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        desc["element_dtype"] = tf.data_type(item_)
        (tf.execute(desc))[1]
    end
end


"""
     rsqrt(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function rsqrt(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Rsqrt") do 
                desc = tf.NodeDescription("Rsqrt")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function rsqrt(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Rsqrt")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_conv2d_with_bias_sum_and_relu_and_requantize(input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output, summand, min_summand, max_summand; out_type=Float32, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_conv2d_with_bias_sum_and_relu_and_requantize(input_, filter_, bias_, min_input_, max_input_, min_filter_, max_filter_, min_freezed_output_, max_freezed_output_, summand_, min_summand_, max_summand_; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConv2DWithBiasSumAndReluAndRequantize") do 
                desc = tf.NodeDescription("QuantizedConv2DWithBiasSumAndReluAndRequantize")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                bias_ = convert(Tensor{Any}, bias_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_filter_ = convert(Tensor{Float32}, min_filter_)
                max_filter_ = convert(Tensor{Float32}, max_filter_)
                min_freezed_output_ = convert(Tensor{Float32}, min_freezed_output_)
                max_freezed_output_ = convert(Tensor{Float32}, max_freezed_output_)
                summand_ = convert(Tensor{Any}, summand_)
                min_summand_ = convert(Tensor{Float32}, min_summand_)
                max_summand_ = convert(Tensor{Float32}, max_summand_)
                (summand_,) = tf.tf_promote(summand_)
                (filter_,) = tf.tf_promote(filter_)
                (input_,) = tf.tf_promote(input_)
                (bias_,) = tf.tf_promote(bias_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, bias_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_filter_)
                tf.add_input(desc, max_filter_)
                tf.add_input(desc, min_freezed_output_)
                tf.add_input(desc, max_freezed_output_)
                tf.add_input(desc, summand_)
                tf.add_input(desc, min_summand_)
                tf.add_input(desc, max_summand_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_conv2d_with_bias_sum_and_relu_and_requantize(input_::tf.TensorHandle, filter_::tf.TensorHandle, bias_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_filter_::tf.TensorHandle, max_filter_::tf.TensorHandle, min_freezed_output_::tf.TensorHandle, max_freezed_output_::tf.TensorHandle, summand_::tf.TensorHandle, min_summand_::tf.TensorHandle, max_summand_::tf.TensorHandle; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("QuantizedConv2DWithBiasSumAndReluAndRequantize")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, bias_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_filter_)
        tf.add_input(desc, max_filter_)
        tf.add_input(desc, min_freezed_output_)
        tf.add_input(desc, max_freezed_output_)
        tf.add_input(desc, summand_)
        tf.add_input(desc, min_summand_)
        tf.add_input(desc, max_summand_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tinput"] = tf.data_type(input_)
        desc["Tfilter"] = tf.data_type(filter_)
        desc["Tbias"] = tf.data_type(bias_)
        desc["Tsummand"] = tf.data_type(summand_)
        tf.execute(desc)
    end
end


"""
     delete_session_tensor(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function delete_session_tensor(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "DeleteSessionTensor") do 
                desc = tf.NodeDescription("DeleteSessionTensor")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function delete_session_tensor(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DeleteSessionTensor")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     one_hot(indices, depth, on_value, off_value; axis=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function one_hot(indices_, depth_, on_value_, off_value_; name=nothing, axis=nothing)
            local desc
            tf.with_op_name(name, "OneHot") do 
                desc = tf.NodeDescription("OneHot")
                indices_ = convert(Tensor{Int64}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                depth_ = convert(Tensor{Int32}, depth_)
                on_value_ = convert(Tensor{Any}, on_value_)
                off_value_ = convert(Tensor{Any}, off_value_)
                (on_value_, off_value_) = tf.tf_promote(on_value_, off_value_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, depth_)
                tf.add_input(desc, on_value_)
                tf.add_input(desc, off_value_)
                if axis !== nothing
                    axis = Base.Int(axis) - 1
                end
                if axis !== nothing
                    desc["axis"] = Base.Int(axis)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function one_hot(indices_::tf.TensorHandle, depth_::tf.TensorHandle, on_value_::tf.TensorHandle, off_value_::tf.TensorHandle; name=nothing, axis=nothing)
        desc = tf.EagerOp("OneHot")
        tf.add_input(desc, indices_)
        tf.add_input(desc, depth_)
        tf.add_input(desc, on_value_)
        tf.add_input(desc, off_value_)
        if axis !== nothing
            axis = Base.Int(axis) - 1
        end
        if axis !== nothing
            desc["axis"] = Base.Int(axis)
        end
        desc["TI"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(on_value_)
        desc["T"] = tf.data_type(off_value_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_ftrl(var, accum, linear, grad, lr, l1, l2, lr_power; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_ftrl(var_, accum_, linear_, grad_, lr_, l1_, l2_, lr_power_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyFtrl") do 
                desc = tf.NodeDescription("ResourceApplyFtrl")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                linear_ = convert(Tensor{Any}, linear_)
                grad_ = convert(Tensor{Any}, grad_)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                lr_power_ = convert(Tensor{Any}, lr_power_)
                (grad_, lr_, l1_, l2_, lr_power_) = tf.tf_promote(grad_, lr_, l1_, l2_, lr_power_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, linear_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, lr_power_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_ftrl(var_::tf.TensorHandle, accum_::tf.TensorHandle, linear_::tf.TensorHandle, grad_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, lr_power_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyFtrl")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, linear_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, lr_power_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(grad_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(lr_power_)
        (tf.execute(desc))[1]
    end
end


"""
     sdca_optimizer_v2(sparse_example_indices, sparse_feature_indices, sparse_feature_values, dense_features, example_weights, example_labels, sparse_indices, sparse_weights, dense_weights, example_state_data; adaptive=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sdca_optimizer_v2(sparse_example_indices_, sparse_feature_indices_, sparse_feature_values_, dense_features_, example_weights_, example_labels_, sparse_indices_, sparse_weights_, dense_weights_, example_state_data_; name=nothing, loss_type=nothing, adaptive=nothing, num_sparse_features=nothing, num_sparse_features_with_values=nothing, num_dense_features=nothing, l1=nothing, l2=nothing, num_loss_partitions=nothing, num_inner_iterations=nothing)
            local desc
            tf.with_op_name(name, "SdcaOptimizerV2") do 
                desc = tf.NodeDescription("SdcaOptimizerV2")
                sparse_example_indices_ = [convert(Tensor{Int64}, x) for x = sparse_example_indices_]
                sparse_feature_indices_ = [convert(Tensor{Int64}, x) for x = sparse_feature_indices_]
                sparse_feature_values_ = [convert(Tensor{Float32}, x) for x = sparse_feature_values_]
                dense_features_ = [convert(Tensor{Float32}, x) for x = dense_features_]
                example_weights_ = convert(Tensor{Float32}, example_weights_)
                example_labels_ = convert(Tensor{Float32}, example_labels_)
                sparse_indices_ = [convert(Tensor{Int64}, x) for x = sparse_indices_]
                sparse_weights_ = [convert(Tensor{Float32}, x) for x = sparse_weights_]
                dense_weights_ = [convert(Tensor{Float32}, x) for x = dense_weights_]
                example_state_data_ = convert(Tensor{Float32}, example_state_data_)
                tf.add_input(desc, sparse_example_indices_)
                tf.add_input(desc, sparse_feature_indices_)
                tf.add_input(desc, sparse_feature_values_)
                tf.add_input(desc, dense_features_)
                tf.add_input(desc, example_weights_)
                tf.add_input(desc, example_labels_)
                tf.add_input(desc, sparse_indices_)
                tf.add_input(desc, sparse_weights_)
                tf.add_input(desc, dense_weights_)
                tf.add_input(desc, example_state_data_)
                if loss_type !== nothing
                    desc["loss_type"] = Base.String(loss_type)
                end
                if adaptive !== nothing
                    desc["adaptive"] = Base.Bool(adaptive)
                end
                if num_sparse_features !== nothing
                    desc["num_sparse_features"] = Base.Int(num_sparse_features)
                end
                if num_sparse_features_with_values !== nothing
                    desc["num_sparse_features_with_values"] = Base.Int(num_sparse_features_with_values)
                end
                if num_dense_features !== nothing
                    desc["num_dense_features"] = Base.Int(num_dense_features)
                end
                if l1 !== nothing
                    desc["l1"] = Base.identity(l1)
                end
                if l2 !== nothing
                    desc["l2"] = Base.identity(l2)
                end
                if num_loss_partitions !== nothing
                    desc["num_loss_partitions"] = Base.Int(num_loss_partitions)
                end
                if num_inner_iterations !== nothing
                    desc["num_inner_iterations"] = Base.Int(num_inner_iterations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sdca_optimizer_v2(sparse_example_indices_::tf.TensorHandle, sparse_feature_indices_::tf.TensorHandle, sparse_feature_values_::tf.TensorHandle, dense_features_::tf.TensorHandle, example_weights_::tf.TensorHandle, example_labels_::tf.TensorHandle, sparse_indices_::tf.TensorHandle, sparse_weights_::tf.TensorHandle, dense_weights_::tf.TensorHandle, example_state_data_::tf.TensorHandle; name=nothing, loss_type=nothing, adaptive=nothing, num_sparse_features=nothing, num_sparse_features_with_values=nothing, num_dense_features=nothing, l1=nothing, l2=nothing, num_loss_partitions=nothing, num_inner_iterations=nothing)
        desc = tf.EagerOp("SdcaOptimizerV2")
        tf.add_input(desc, sparse_example_indices_)
        tf.add_input(desc, sparse_feature_indices_)
        tf.add_input(desc, sparse_feature_values_)
        tf.add_input(desc, dense_features_)
        tf.add_input(desc, example_weights_)
        tf.add_input(desc, example_labels_)
        tf.add_input(desc, sparse_indices_)
        tf.add_input(desc, sparse_weights_)
        tf.add_input(desc, dense_weights_)
        tf.add_input(desc, example_state_data_)
        if loss_type !== nothing
            desc["loss_type"] = Base.String(loss_type)
        end
        if adaptive !== nothing
            desc["adaptive"] = Base.Bool(adaptive)
        end
        if num_sparse_features !== nothing
            desc["num_sparse_features"] = Base.Int(num_sparse_features)
        end
        if num_sparse_features_with_values !== nothing
            desc["num_sparse_features_with_values"] = Base.Int(num_sparse_features_with_values)
        end
        if num_dense_features !== nothing
            desc["num_dense_features"] = Base.Int(num_dense_features)
        end
        if l1 !== nothing
            desc["l1"] = Base.identity(l1)
        end
        if l2 !== nothing
            desc["l2"] = Base.identity(l2)
        end
        if num_loss_partitions !== nothing
            desc["num_loss_partitions"] = Base.Int(num_loss_partitions)
        end
        if num_inner_iterations !== nothing
            desc["num_inner_iterations"] = Base.Int(num_inner_iterations)
        end
        tf.execute(desc)
    end
end


"""
     queue_enqueue(handle, components; timeout_ms=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_enqueue(handle_, components_; name=nothing, Tcomponents=nothing, timeout_ms=nothing)
            local desc
            tf.with_op_name(name, "QueueEnqueue") do 
                desc = tf.NodeDescription("QueueEnqueue")
                handle_ = convert(Tensor{String}, handle_)
                components_ = [convert(Tensor{Any}, x) for x = components_]
                tf.add_input(desc, handle_)
                tf.add_input(desc, components_)
                if Tcomponents !== nothing
                    desc["Tcomponents"] = map(Base.identity, Tcomponents)
                end
                if timeout_ms !== nothing
                    desc["timeout_ms"] = Base.Int(timeout_ms)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_enqueue(handle_::tf.TensorHandle, components_::tf.TensorHandle; name=nothing, Tcomponents=nothing, timeout_ms=nothing)
        desc = tf.EagerOp("QueueEnqueue")
        tf.add_input(desc, handle_)
        tf.add_input(desc, components_)
        if Tcomponents !== nothing
            desc["Tcomponents"] = map(Base.identity, Tcomponents)
        end
        if timeout_ms !== nothing
            desc["timeout_ms"] = Base.Int(timeout_ms)
        end
        (tf.execute(desc))[1]
    end
end


"""
     conditional_accumulator(; container=, shared_name=, reduction_type=MEAN)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function conditional_accumulator(; name=nothing, dtype=nothing, shape=nothing, container=nothing, shared_name=nothing, reduction_type=nothing)
            local desc
            tf.with_op_name(name, "ConditionalAccumulator") do 
                desc = tf.NodeDescription("ConditionalAccumulator")
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if reduction_type !== nothing
                    desc["reduction_type"] = Base.String(reduction_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function conditional_accumulator(; name=nothing, dtype=nothing, shape=nothing, container=nothing, shared_name=nothing, reduction_type=nothing)
        desc = tf.EagerOp("ConditionalAccumulator")
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if reduction_type !== nothing
            desc["reduction_type"] = Base.String(reduction_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     ctc_beam_search_decoder(inputs, sequence_length; merge_repeated=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ctc_beam_search_decoder(inputs_, sequence_length_; name=nothing, beam_width=nothing, top_paths=nothing, merge_repeated=nothing)
            local desc
            tf.with_op_name(name, "CTCBeamSearchDecoder") do 
                desc = tf.NodeDescription("CTCBeamSearchDecoder")
                inputs_ = convert(Tensor{Float32}, inputs_)
                sequence_length_ = convert(Tensor{Int32}, sequence_length_)
                tf.add_input(desc, inputs_)
                tf.add_input(desc, sequence_length_)
                if beam_width !== nothing
                    desc["beam_width"] = Base.Int(beam_width)
                end
                if top_paths !== nothing
                    desc["top_paths"] = Base.Int(top_paths)
                end
                if merge_repeated !== nothing
                    desc["merge_repeated"] = Base.Bool(merge_repeated)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function ctc_beam_search_decoder(inputs_::tf.TensorHandle, sequence_length_::tf.TensorHandle; name=nothing, beam_width=nothing, top_paths=nothing, merge_repeated=nothing)
        desc = tf.EagerOp("CTCBeamSearchDecoder")
        tf.add_input(desc, inputs_)
        tf.add_input(desc, sequence_length_)
        if beam_width !== nothing
            desc["beam_width"] = Base.Int(beam_width)
        end
        if top_paths !== nothing
            desc["top_paths"] = Base.Int(top_paths)
        end
        if merge_repeated !== nothing
            desc["merge_repeated"] = Base.Bool(merge_repeated)
        end
        tf.execute(desc)
    end
end


"""
     whole_file_reader(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function whole_file_reader(; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "WholeFileReader") do 
                desc = tf.NodeDescription("WholeFileReader")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function whole_file_reader(; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("WholeFileReader")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     apply_rms_prop(var, ms, mom, lr, rho, momentum, epsilon, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_rms_prop(var_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyRMSProp") do 
                desc = tf.NodeDescription("ApplyRMSProp")
                var_ = convert(Tensor{Any}, var_)
                ms_ = convert(Tensor{Any}, ms_)
                mom_ = convert(Tensor{Any}, mom_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                momentum_ = convert(Tensor{Any}, momentum_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                (var_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_) = tf.tf_promote(var_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, ms_)
                tf.add_input(desc, mom_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, momentum_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_rms_prop(var_::tf.TensorHandle, ms_::tf.TensorHandle, mom_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, momentum_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyRMSProp")
        tf.add_input(desc, var_)
        tf.add_input(desc, ms_)
        tf.add_input(desc, mom_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, momentum_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(ms_)
        desc["T"] = tf.data_type(mom_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(momentum_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     adjust_saturation(images, scale)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function adjust_saturation(images_, scale_; name=nothing)
            local desc
            tf.with_op_name(name, "AdjustSaturation") do 
                desc = tf.NodeDescription("AdjustSaturation")
                images_ = convert(Tensor{Float32}, images_)
                scale_ = convert(Tensor{Float32}, scale_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                tf.add_input(desc, scale_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function adjust_saturation(images_::tf.TensorHandle, scale_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("AdjustSaturation")
        tf.add_input(desc, images_)
        tf.add_input(desc, scale_)
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     lookup_table_remove_v2(table_handle, keys)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lookup_table_remove_v2(table_handle_, keys_; name=nothing)
            local desc
            tf.with_op_name(name, "LookupTableRemoveV2") do 
                desc = tf.NodeDescription("LookupTableRemoveV2")
                table_handle_ = convert(Tensor{Any}, table_handle_)
                keys_ = convert(Tensor{Any}, keys_)
                (keys_,) = tf.tf_promote(keys_)
                tf.add_input(desc, table_handle_)
                tf.add_input(desc, keys_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lookup_table_remove_v2(table_handle_::tf.TensorHandle, keys_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LookupTableRemoveV2")
        tf.add_input(desc, table_handle_)
        tf.add_input(desc, keys_)
        desc["Tin"] = tf.data_type(keys_)
        (tf.execute(desc))[1]
    end
end


"""
     queue_close(handle; cancel_pending_enqueues=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_close(handle_; name=nothing, cancel_pending_enqueues=nothing)
            local desc
            tf.with_op_name(name, "QueueClose") do 
                desc = tf.NodeDescription("QueueClose")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
                if cancel_pending_enqueues !== nothing
                    desc["cancel_pending_enqueues"] = Base.Bool(cancel_pending_enqueues)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_close(handle_::tf.TensorHandle; name=nothing, cancel_pending_enqueues=nothing)
        desc = tf.EagerOp("QueueClose")
        tf.add_input(desc, handle_)
        if cancel_pending_enqueues !== nothing
            desc["cancel_pending_enqueues"] = Base.Bool(cancel_pending_enqueues)
        end
        (tf.execute(desc))[1]
    end
end


"""
     prefetch_dataset(input_dataset, buffer_size)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function prefetch_dataset(input_dataset_, buffer_size_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "PrefetchDataset") do 
                desc = tf.NodeDescription("PrefetchDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                buffer_size_ = convert(Tensor{Int64}, buffer_size_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, buffer_size_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function prefetch_dataset(input_dataset_::tf.TensorHandle, buffer_size_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("PrefetchDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, buffer_size_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     map_dataset(input_dataset, other_arguments; use_inter_op_parallelism=true, preserve_cardinality=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function map_dataset(input_dataset_, other_arguments_; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, use_inter_op_parallelism=nothing, preserve_cardinality=nothing)
            local desc
            tf.with_op_name(name, "MapDataset") do 
                desc = tf.NodeDescription("MapDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, other_arguments_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if use_inter_op_parallelism !== nothing
                    desc["use_inter_op_parallelism"] = Base.Bool(use_inter_op_parallelism)
                end
                if preserve_cardinality !== nothing
                    desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function map_dataset(input_dataset_::tf.TensorHandle, other_arguments_::tf.TensorHandle; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, use_inter_op_parallelism=nothing, preserve_cardinality=nothing)
        desc = tf.EagerOp("MapDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, other_arguments_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if use_inter_op_parallelism !== nothing
            desc["use_inter_op_parallelism"] = Base.Bool(use_inter_op_parallelism)
        end
        if preserve_cardinality !== nothing
            desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
        end
        (tf.execute(desc))[1]
    end
end


"""
     quantized_conv2d_with_bias(input, filter, bias, min_input, max_input, min_filter, max_filter; out_type=Float32, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_conv2d_with_bias(input_, filter_, bias_, min_input_, max_input_, min_filter_, max_filter_; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConv2DWithBias") do 
                desc = tf.NodeDescription("QuantizedConv2DWithBias")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                bias_ = convert(Tensor{Float32}, bias_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_filter_ = convert(Tensor{Float32}, min_filter_)
                max_filter_ = convert(Tensor{Float32}, max_filter_)
                (filter_,) = tf.tf_promote(filter_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, bias_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_filter_)
                tf.add_input(desc, max_filter_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_conv2d_with_bias(input_::tf.TensorHandle, filter_::tf.TensorHandle, bias_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_filter_::tf.TensorHandle, max_filter_::tf.TensorHandle; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("QuantizedConv2DWithBias")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, bias_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_filter_)
        tf.add_input(desc, max_filter_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tinput"] = tf.data_type(input_)
        desc["Tfilter"] = tf.data_type(filter_)
        tf.execute(desc)
    end
end


"""
     tensor_array_read_v3(handle, index, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_read_v3(handle_, index_, flow_in_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayReadV3") do 
                desc = tf.NodeDescription("TensorArrayReadV3")
                handle_ = convert(Tensor{Any}, handle_)
                index_ = convert(Tensor{Int32}, index_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, index_)
                tf.add_input(desc, flow_in_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_read_v3(handle_::tf.TensorHandle, index_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("TensorArrayReadV3")
        tf.add_input(desc, handle_)
        tf.add_input(desc, index_)
        tf.add_input(desc, flow_in_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     identity(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function identity(input_; name=nothing)
            local desc
            tf.with_op_name(name, "Identity") do 
                desc = tf.NodeDescription("Identity")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function identity(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Identity")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     print(input, data; message=, first_n=-1, summarize=3)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function print(input_, data_; name=nothing, U=nothing, message=nothing, first_n=nothing, summarize=nothing)
            local desc
            tf.with_op_name(name, "Print") do 
                desc = tf.NodeDescription("Print")
                input_ = convert(Tensor{Any}, input_)
                data_ = [convert(Tensor{Any}, x) for x = data_]
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, data_)
                if U !== nothing
                    desc["U"] = map(Base.identity, U)
                end
                if message !== nothing
                    desc["message"] = Base.String(message)
                end
                if first_n !== nothing
                    desc["first_n"] = Base.Int(first_n)
                end
                if summarize !== nothing
                    desc["summarize"] = Base.Int(summarize)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function print(input_::tf.TensorHandle, data_::tf.TensorHandle; name=nothing, U=nothing, message=nothing, first_n=nothing, summarize=nothing)
        desc = tf.EagerOp("Print")
        tf.add_input(desc, input_)
        tf.add_input(desc, data_)
        if U !== nothing
            desc["U"] = map(Base.identity, U)
        end
        if message !== nothing
            desc["message"] = Base.String(message)
        end
        if first_n !== nothing
            desc["first_n"] = Base.Int(first_n)
        end
        if summarize !== nothing
            desc["summarize"] = Base.Int(summarize)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     collective_bcast_send(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function collective_bcast_send(input_; name=nothing, group_size=nothing, group_key=nothing, instance_key=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "CollectiveBcastSend") do 
                desc = tf.NodeDescription("CollectiveBcastSend")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if group_size !== nothing
                    desc["group_size"] = Base.Int(group_size)
                end
                if group_key !== nothing
                    desc["group_key"] = Base.Int(group_key)
                end
                if instance_key !== nothing
                    desc["instance_key"] = Base.Int(instance_key)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function collective_bcast_send(input_::tf.TensorHandle; name=nothing, group_size=nothing, group_key=nothing, instance_key=nothing, shape=nothing)
        desc = tf.EagerOp("CollectiveBcastSend")
        tf.add_input(desc, input_)
        if group_size !== nothing
            desc["group_size"] = Base.Int(group_size)
        end
        if group_key !== nothing
            desc["group_key"] = Base.Int(group_key)
        end
        if instance_key !== nothing
            desc["instance_key"] = Base.Int(instance_key)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     _list_to_array(input)

Converts a list of tensors to an array of tensors.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _list_to_array(input_; name=nothing, Tin=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "_ListToArray") do 
                desc = tf.NodeDescription("_ListToArray")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                tf.add_input(desc, input_)
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:N
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function _list_to_array(input_::tf.TensorHandle; name=nothing, Tin=nothing, N=nothing)
        desc = tf.EagerOp("_ListToArray")
        tf.add_input(desc, input_)
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        tf.execute(desc)
    end
end


"""
     neg_train(w_in, w_out, examples, labels, lr)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function neg_train(w_in_, w_out_, examples_, labels_, lr_; name=nothing, vocab_count=nothing, num_negative_samples=nothing)
            local desc
            tf.with_op_name(name, "NegTrain") do 
                desc = tf.NodeDescription("NegTrain")
                w_in_ = convert(Tensor{Float32}, w_in_)
                w_out_ = convert(Tensor{Float32}, w_out_)
                examples_ = convert(Tensor{Int32}, examples_)
                labels_ = convert(Tensor{Int32}, labels_)
                lr_ = convert(Tensor{Float32}, lr_)
                tf.add_input(desc, w_in_)
                tf.add_input(desc, w_out_)
                tf.add_input(desc, examples_)
                tf.add_input(desc, labels_)
                tf.add_input(desc, lr_)
                if vocab_count !== nothing
                    desc["vocab_count"] = map(Base.identity, vocab_count)
                end
                if num_negative_samples !== nothing
                    desc["num_negative_samples"] = Base.Int(num_negative_samples)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function neg_train(w_in_::tf.TensorHandle, w_out_::tf.TensorHandle, examples_::tf.TensorHandle, labels_::tf.TensorHandle, lr_::tf.TensorHandle; name=nothing, vocab_count=nothing, num_negative_samples=nothing)
        desc = tf.EagerOp("NegTrain")
        tf.add_input(desc, w_in_)
        tf.add_input(desc, w_out_)
        tf.add_input(desc, examples_)
        tf.add_input(desc, labels_)
        tf.add_input(desc, lr_)
        if vocab_count !== nothing
            desc["vocab_count"] = map(Base.identity, vocab_count)
        end
        if num_negative_samples !== nothing
            desc["num_negative_samples"] = Base.Int(num_negative_samples)
        end
        (tf.execute(desc))[1]
    end
end


"""
     worker_heartbeat(request)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function worker_heartbeat(request_; name=nothing)
            local desc
            tf.with_op_name(name, "WorkerHeartbeat") do 
                desc = tf.NodeDescription("WorkerHeartbeat")
                request_ = convert(Tensor{String}, request_)
                tf.add_input(desc, request_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function worker_heartbeat(request_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("WorkerHeartbeat")
        tf.add_input(desc, request_)
        (tf.execute(desc))[1]
    end
end


"""
     merge_v2checkpoints(checkpoint_prefixes, destination_prefix; delete_old_dirs=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function merge_v2checkpoints(checkpoint_prefixes_, destination_prefix_; name=nothing, delete_old_dirs=nothing)
            local desc
            tf.with_op_name(name, "MergeV2Checkpoints") do 
                desc = tf.NodeDescription("MergeV2Checkpoints")
                checkpoint_prefixes_ = convert(Tensor{String}, checkpoint_prefixes_)
                destination_prefix_ = convert(Tensor{String}, destination_prefix_)
                tf.add_input(desc, checkpoint_prefixes_)
                tf.add_input(desc, destination_prefix_)
                if delete_old_dirs !== nothing
                    desc["delete_old_dirs"] = Base.Bool(delete_old_dirs)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function merge_v2checkpoints(checkpoint_prefixes_::tf.TensorHandle, destination_prefix_::tf.TensorHandle; name=nothing, delete_old_dirs=nothing)
        desc = tf.EagerOp("MergeV2Checkpoints")
        tf.add_input(desc, checkpoint_prefixes_)
        tf.add_input(desc, destination_prefix_)
        if delete_old_dirs !== nothing
            desc["delete_old_dirs"] = Base.Bool(delete_old_dirs)
        end
        (tf.execute(desc))[1]
    end
end


"""
     collective_permute(input, source_target_pairs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function collective_permute(input_, source_target_pairs_; name=nothing)
            local desc
            tf.with_op_name(name, "CollectivePermute") do 
                desc = tf.NodeDescription("CollectivePermute")
                input_ = convert(Tensor{Any}, input_)
                source_target_pairs_ = convert(Tensor{Int32}, source_target_pairs_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, source_target_pairs_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function collective_permute(input_::tf.TensorHandle, source_target_pairs_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("CollectivePermute")
        tf.add_input(desc, input_)
        tf.add_input(desc, source_target_pairs_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     quantize_and_dequantize_v3(input, input_min, input_max, num_bits; signed_input=true, range_given=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantize_and_dequantize_v3(input_, input_min_, input_max_, num_bits_; name=nothing, signed_input=nothing, range_given=nothing)
            local desc
            tf.with_op_name(name, "QuantizeAndDequantizeV3") do 
                desc = tf.NodeDescription("QuantizeAndDequantizeV3")
                input_ = convert(Tensor{Any}, input_)
                input_min_ = convert(Tensor{Any}, input_min_)
                input_max_ = convert(Tensor{Any}, input_max_)
                num_bits_ = convert(Tensor{Int32}, num_bits_)
                (input_, input_min_, input_max_) = tf.tf_promote(input_, input_min_, input_max_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_min_)
                tf.add_input(desc, input_max_)
                tf.add_input(desc, num_bits_)
                if signed_input !== nothing
                    desc["signed_input"] = Base.Bool(signed_input)
                end
                if range_given !== nothing
                    desc["range_given"] = Base.Bool(range_given)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function quantize_and_dequantize_v3(input_::tf.TensorHandle, input_min_::tf.TensorHandle, input_max_::tf.TensorHandle, num_bits_::tf.TensorHandle; name=nothing, signed_input=nothing, range_given=nothing)
        desc = tf.EagerOp("QuantizeAndDequantizeV3")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_min_)
        tf.add_input(desc, input_max_)
        tf.add_input(desc, num_bits_)
        if signed_input !== nothing
            desc["signed_input"] = Base.Bool(signed_input)
        end
        if range_given !== nothing
            desc["range_given"] = Base.Bool(range_given)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(input_min_)
        desc["T"] = tf.data_type(input_max_)
        (tf.execute(desc))[1]
    end
end


"""
     hash_table(; container=, shared_name=, use_node_name_sharing=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function hash_table(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing)
            local desc
            tf.with_op_name(name, "HashTable") do 
                desc = tf.NodeDescription("HashTable")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if use_node_name_sharing !== nothing
                    desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
                end
                if key_dtype !== nothing
                    desc["key_dtype"] = Base.identity(key_dtype)
                end
                if value_dtype !== nothing
                    desc["value_dtype"] = Base.identity(value_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function hash_table(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing)
        desc = tf.EagerOp("HashTable")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if use_node_name_sharing !== nothing
            desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
        end
        if key_dtype !== nothing
            desc["key_dtype"] = Base.identity(key_dtype)
        end
        if value_dtype !== nothing
            desc["value_dtype"] = Base.identity(value_dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     softplus_grad(gradients, features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function softplus_grad(gradients_, features_; name=nothing)
            local desc
            tf.with_op_name(name, "SoftplusGrad") do 
                desc = tf.NodeDescription("SoftplusGrad")
                gradients_ = convert(Tensor{Any}, gradients_)
                features_ = convert(Tensor{Any}, features_)
                (gradients_, features_) = tf.tf_promote(gradients_, features_)
                tf.add_input(desc, gradients_)
                tf.add_input(desc, features_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function softplus_grad(gradients_::tf.TensorHandle, features_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SoftplusGrad")
        tf.add_input(desc, gradients_)
        tf.add_input(desc, features_)
        desc["T"] = tf.data_type(gradients_)
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     fixed_length_record_reader(; header_bytes=0, footer_bytes=0, hop_bytes=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fixed_length_record_reader(; name=nothing, header_bytes=nothing, record_bytes=nothing, footer_bytes=nothing, hop_bytes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "FixedLengthRecordReader") do 
                desc = tf.NodeDescription("FixedLengthRecordReader")
                if header_bytes !== nothing
                    desc["header_bytes"] = Base.Int(header_bytes)
                end
                if record_bytes !== nothing
                    desc["record_bytes"] = Base.Int(record_bytes)
                end
                if footer_bytes !== nothing
                    desc["footer_bytes"] = Base.Int(footer_bytes)
                end
                if hop_bytes !== nothing
                    desc["hop_bytes"] = Base.Int(hop_bytes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fixed_length_record_reader(; name=nothing, header_bytes=nothing, record_bytes=nothing, footer_bytes=nothing, hop_bytes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("FixedLengthRecordReader")
        if header_bytes !== nothing
            desc["header_bytes"] = Base.Int(header_bytes)
        end
        if record_bytes !== nothing
            desc["record_bytes"] = Base.Int(record_bytes)
        end
        if footer_bytes !== nothing
            desc["footer_bytes"] = Base.Int(footer_bytes)
        end
        if hop_bytes !== nothing
            desc["hop_bytes"] = Base.Int(hop_bytes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_scatter_v2(handle, indices, value, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_scatter_v2(handle_, indices_, value_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayScatterV2") do 
                desc = tf.NodeDescription("TensorArrayScatterV2")
                handle_ = convert(Tensor{String}, handle_)
                indices_ = convert(Tensor{Int32}, indices_)
                value_ = convert(Tensor{Any}, value_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, value_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_scatter_v2(handle_::tf.TensorHandle, indices_::tf.TensorHandle, value_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArrayScatterV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, value_)
        tf.add_input(desc, flow_in_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     decode_json_example(json_examples)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_json_example(json_examples_; name=nothing)
            local desc
            tf.with_op_name(name, "DecodeJSONExample") do 
                desc = tf.NodeDescription("DecodeJSONExample")
                json_examples_ = convert(Tensor{String}, json_examples_)
                tf.add_input(desc, json_examples_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function decode_json_example(json_examples_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DecodeJSONExample")
        tf.add_input(desc, json_examples_)
        (tf.execute(desc))[1]
    end
end


"""
     fused_batch_norm_grad_v2(y_backprop, x, scale, reserve_space_1, reserve_space_2; epsilon=?, data_format=NHWC, is_training=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fused_batch_norm_grad_v2(y_backprop_, x_, scale_, reserve_space_1_, reserve_space_2_; name=nothing, U=nothing, epsilon=nothing, data_format=nothing, is_training=nothing)
            local desc
            tf.with_op_name(name, "FusedBatchNormGradV2") do 
                desc = tf.NodeDescription("FusedBatchNormGradV2")
                y_backprop_ = convert(Tensor{Any}, y_backprop_)
                x_ = convert(Tensor{Any}, x_)
                scale_ = convert(Tensor{Float32}, scale_)
                reserve_space_1_ = convert(Tensor{Any}, reserve_space_1_)
                reserve_space_2_ = convert(Tensor{Any}, reserve_space_2_)
                (reserve_space_1_, reserve_space_2_) = tf.tf_promote(reserve_space_1_, reserve_space_2_)
                (y_backprop_, x_) = tf.tf_promote(y_backprop_, x_)
                tf.add_input(desc, y_backprop_)
                tf.add_input(desc, x_)
                tf.add_input(desc, scale_)
                tf.add_input(desc, reserve_space_1_)
                tf.add_input(desc, reserve_space_2_)
                if U !== nothing
                    desc["U"] = Base.identity(U)
                end
                if epsilon !== nothing
                    desc["epsilon"] = Base.identity(epsilon)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if is_training !== nothing
                    desc["is_training"] = Base.Bool(is_training)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:5
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function fused_batch_norm_grad_v2(y_backprop_::tf.TensorHandle, x_::tf.TensorHandle, scale_::tf.TensorHandle, reserve_space_1_::tf.TensorHandle, reserve_space_2_::tf.TensorHandle; name=nothing, U=nothing, epsilon=nothing, data_format=nothing, is_training=nothing)
        desc = tf.EagerOp("FusedBatchNormGradV2")
        tf.add_input(desc, y_backprop_)
        tf.add_input(desc, x_)
        tf.add_input(desc, scale_)
        tf.add_input(desc, reserve_space_1_)
        tf.add_input(desc, reserve_space_2_)
        if U !== nothing
            desc["U"] = Base.identity(U)
        end
        if epsilon !== nothing
            desc["epsilon"] = Base.identity(epsilon)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if is_training !== nothing
            desc["is_training"] = Base.Bool(is_training)
        end
        desc["T"] = tf.data_type(y_backprop_)
        desc["T"] = tf.data_type(x_)
        desc["U"] = tf.data_type(reserve_space_1_)
        desc["U"] = tf.data_type(reserve_space_2_)
        tf.execute(desc)
    end
end


"""
     _host_cast(x; Truncate=false)

Cast x of type SrcT to y of DstT.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _host_cast(x_; name=nothing, SrcT=nothing, DstT=nothing, Truncate=nothing)
            local desc
            tf.with_op_name(name, "_HostCast") do 
                desc = tf.NodeDescription("_HostCast")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
                if SrcT !== nothing
                    desc["SrcT"] = Base.identity(SrcT)
                end
                if DstT !== nothing
                    desc["DstT"] = Base.identity(DstT)
                end
                if Truncate !== nothing
                    desc["Truncate"] = Base.Bool(Truncate)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _host_cast(x_::tf.TensorHandle; name=nothing, SrcT=nothing, DstT=nothing, Truncate=nothing)
        desc = tf.EagerOp("_HostCast")
        tf.add_input(desc, x_)
        if SrcT !== nothing
            desc["SrcT"] = Base.identity(SrcT)
        end
        if DstT !== nothing
            desc["DstT"] = Base.identity(DstT)
        end
        if Truncate !== nothing
            desc["Truncate"] = Base.Bool(Truncate)
        end
        desc["SrcT"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     tf_record_reader(; container=, shared_name=, compression_type=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tf_record_reader(; name=nothing, container=nothing, shared_name=nothing, compression_type=nothing)
            local desc
            tf.with_op_name(name, "TFRecordReader") do 
                desc = tf.NodeDescription("TFRecordReader")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if compression_type !== nothing
                    desc["compression_type"] = Base.String(compression_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tf_record_reader(; name=nothing, container=nothing, shared_name=nothing, compression_type=nothing)
        desc = tf.EagerOp("TFRecordReader")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if compression_type !== nothing
            desc["compression_type"] = Base.String(compression_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     while_(input; output_shapes=Int64[], parallel_iterations=10)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function while_(input_; name=nothing, T=nothing, cond=nothing, body=nothing, output_shapes=nothing, parallel_iterations=nothing)
            local desc
            tf.with_op_name(name, "While") do 
                desc = tf.NodeDescription("While")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                tf.add_input(desc, input_)
                if T !== nothing
                    desc["T"] = map(Base.identity, T)
                end
                if cond !== nothing
                    desc["cond"] = Base.identity(cond)
                end
                if body !== nothing
                    desc["body"] = Base.identity(body)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if parallel_iterations !== nothing
                    desc["parallel_iterations"] = Base.Int(parallel_iterations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function while_(input_::tf.TensorHandle; name=nothing, T=nothing, cond=nothing, body=nothing, output_shapes=nothing, parallel_iterations=nothing)
        desc = tf.EagerOp("While")
        tf.add_input(desc, input_)
        if T !== nothing
            desc["T"] = map(Base.identity, T)
        end
        if cond !== nothing
            desc["cond"] = Base.identity(cond)
        end
        if body !== nothing
            desc["body"] = Base.identity(body)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if parallel_iterations !== nothing
            desc["parallel_iterations"] = Base.Int(parallel_iterations)
        end
        (tf.execute(desc))[1]
    end
end


"""
     stateless_multinomial(logits, num_samples, seed; output_dtype=Int64)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stateless_multinomial(logits_, num_samples_, seed_; name=nothing, output_dtype=nothing)
            local desc
            tf.with_op_name(name, "StatelessMultinomial") do 
                desc = tf.NodeDescription("StatelessMultinomial")
                logits_ = convert(Tensor{Any}, logits_)
                num_samples_ = convert(Tensor{Int32}, num_samples_)
                seed_ = convert(Tensor{Int64}, seed_)
                (logits_,) = tf.tf_promote(logits_)
                (seed_,) = tf.tf_promote(seed_)
                tf.add_input(desc, logits_)
                tf.add_input(desc, num_samples_)
                tf.add_input(desc, seed_)
                if output_dtype !== nothing
                    desc["output_dtype"] = Base.identity(output_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stateless_multinomial(logits_::tf.TensorHandle, num_samples_::tf.TensorHandle, seed_::tf.TensorHandle; name=nothing, output_dtype=nothing)
        desc = tf.EagerOp("StatelessMultinomial")
        tf.add_input(desc, logits_)
        tf.add_input(desc, num_samples_)
        tf.add_input(desc, seed_)
        if output_dtype !== nothing
            desc["output_dtype"] = Base.identity(output_dtype)
        end
        desc["T"] = tf.data_type(logits_)
        desc["Tseed"] = tf.data_type(seed_)
        (tf.execute(desc))[1]
    end
end


"""
     scatter_add(ref, indices, updates; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_add(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ScatterAdd") do 
                desc = tf.NodeDescription("ScatterAdd")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (ref_, updates_) = tf.tf_promote(ref_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_add(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ScatterAdd")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     conj(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function conj(input_; name=nothing)
            local desc
            tf.with_op_name(name, "Conj") do 
                desc = tf.NodeDescription("Conj")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function conj(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Conj")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     parallel_dynamic_stitch(indices, data)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function parallel_dynamic_stitch(indices_, data_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "ParallelDynamicStitch") do 
                desc = tf.NodeDescription("ParallelDynamicStitch")
                indices_ = [convert(Tensor{Int32}, x) for x = indices_]
                data_ = [convert(Tensor{Any}, x) for x = data_]
                (data_,) = tf.tf_promote(data_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, data_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function parallel_dynamic_stitch(indices_::tf.TensorHandle, data_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("ParallelDynamicStitch")
        tf.add_input(desc, indices_)
        tf.add_input(desc, data_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(data_)
        (tf.execute(desc))[1]
    end
end


"""
     make_iterator(dataset, iterator)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function make_iterator(dataset_, iterator_; name=nothing)
            local desc
            tf.with_op_name(name, "MakeIterator") do 
                desc = tf.NodeDescription("MakeIterator")
                dataset_ = convert(Tensor{Any}, dataset_)
                iterator_ = convert(Tensor{Any}, iterator_)
                tf.add_input(desc, dataset_)
                tf.add_input(desc, iterator_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function make_iterator(dataset_::tf.TensorHandle, iterator_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MakeIterator")
        tf.add_input(desc, dataset_)
        tf.add_input(desc, iterator_)
        (tf.execute(desc))[1]
    end
end


"""
     rfft3d(input, fft_length)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function rfft3d(input_, fft_length_; name=nothing)
            local desc
            tf.with_op_name(name, "RFFT3D") do 
                desc = tf.NodeDescription("RFFT3D")
                input_ = convert(Tensor{Float32}, input_)
                fft_length_ = convert(Tensor{Int32}, fft_length_)
                tf.add_input(desc, input_)
                tf.add_input(desc, fft_length_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function rfft3d(input_::tf.TensorHandle, fft_length_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RFFT3D")
        tf.add_input(desc, input_)
        tf.add_input(desc, fft_length_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_reduce_sum_sparse(input_indices, input_values, input_shape, reduction_axes; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_reduce_sum_sparse(input_indices_, input_values_, input_shape_, reduction_axes_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "SparseReduceSumSparse") do 
                desc = tf.NodeDescription("SparseReduceSumSparse")
                input_indices_ = convert(Tensor{Int64}, input_indices_)
                input_values_ = convert(Tensor{Any}, input_values_)
                input_shape_ = convert(Tensor{Int64}, input_shape_)
                reduction_axes_ = convert(Tensor{Int32}, reduction_axes_)
                (input_values_,) = tf.tf_promote(input_values_)
                tf.add_input(desc, input_indices_)
                tf.add_input(desc, input_values_)
                tf.add_input(desc, input_shape_)
                tf.add_input(desc, reduction_axes_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_reduce_sum_sparse(input_indices_::tf.TensorHandle, input_values_::tf.TensorHandle, input_shape_::tf.TensorHandle, reduction_axes_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("SparseReduceSumSparse")
        tf.add_input(desc, input_indices_)
        tf.add_input(desc, input_values_)
        tf.add_input(desc, input_shape_)
        tf.add_input(desc, reduction_axes_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["T"] = tf.data_type(input_values_)
        tf.execute(desc)
    end
end


"""
     collective_gather(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function collective_gather(input_; name=nothing, group_size=nothing, group_key=nothing, instance_key=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "CollectiveGather") do 
                desc = tf.NodeDescription("CollectiveGather")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if group_size !== nothing
                    desc["group_size"] = Base.Int(group_size)
                end
                if group_key !== nothing
                    desc["group_key"] = Base.Int(group_key)
                end
                if instance_key !== nothing
                    desc["instance_key"] = Base.Int(instance_key)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function collective_gather(input_::tf.TensorHandle; name=nothing, group_size=nothing, group_key=nothing, instance_key=nothing, shape=nothing)
        desc = tf.EagerOp("CollectiveGather")
        tf.add_input(desc, input_)
        if group_size !== nothing
            desc["group_size"] = Base.Int(group_size)
        end
        if group_key !== nothing
            desc["group_key"] = Base.Int(group_key)
        end
        if instance_key !== nothing
            desc["instance_key"] = Base.Int(instance_key)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     combined_non_max_suppression(boxes, scores, max_output_size_per_class, max_total_size, iou_threshold, score_threshold; pad_per_class=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function combined_non_max_suppression(boxes_, scores_, max_output_size_per_class_, max_total_size_, iou_threshold_, score_threshold_; name=nothing, pad_per_class=nothing)
            local desc
            tf.with_op_name(name, "CombinedNonMaxSuppression") do 
                desc = tf.NodeDescription("CombinedNonMaxSuppression")
                boxes_ = convert(Tensor{Float32}, boxes_)
                scores_ = convert(Tensor{Float32}, scores_)
                max_output_size_per_class_ = convert(Tensor{Int32}, max_output_size_per_class_)
                max_total_size_ = convert(Tensor{Int32}, max_total_size_)
                iou_threshold_ = convert(Tensor{Float32}, iou_threshold_)
                score_threshold_ = convert(Tensor{Float32}, score_threshold_)
                tf.add_input(desc, boxes_)
                tf.add_input(desc, scores_)
                tf.add_input(desc, max_output_size_per_class_)
                tf.add_input(desc, max_total_size_)
                tf.add_input(desc, iou_threshold_)
                tf.add_input(desc, score_threshold_)
                if pad_per_class !== nothing
                    desc["pad_per_class"] = Base.Bool(pad_per_class)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function combined_non_max_suppression(boxes_::tf.TensorHandle, scores_::tf.TensorHandle, max_output_size_per_class_::tf.TensorHandle, max_total_size_::tf.TensorHandle, iou_threshold_::tf.TensorHandle, score_threshold_::tf.TensorHandle; name=nothing, pad_per_class=nothing)
        desc = tf.EagerOp("CombinedNonMaxSuppression")
        tf.add_input(desc, boxes_)
        tf.add_input(desc, scores_)
        tf.add_input(desc, max_output_size_per_class_)
        tf.add_input(desc, max_total_size_)
        tf.add_input(desc, iou_threshold_)
        tf.add_input(desc, score_threshold_)
        if pad_per_class !== nothing
            desc["pad_per_class"] = Base.Bool(pad_per_class)
        end
        tf.execute(desc)
    end
end


"""
     _scoped_allocator()

Allocates a mutable tensor that becomes available to appropriately annotated
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _scoped_allocator(; name=nothing, shapes=nothing, shape=nothing, sa_name=nothing, id=nothing, expected_call_count=nothing)
            local desc
            tf.with_op_name(name, "_ScopedAllocator") do 
                desc = tf.NodeDescription("_ScopedAllocator")
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
                if sa_name !== nothing
                    desc["sa_name"] = Base.String(sa_name)
                end
                if id !== nothing
                    desc["id"] = Base.Int(id)
                end
                if expected_call_count !== nothing
                    desc["expected_call_count"] = Base.Int(expected_call_count)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _scoped_allocator(; name=nothing, shapes=nothing, shape=nothing, sa_name=nothing, id=nothing, expected_call_count=nothing)
        desc = tf.EagerOp("_ScopedAllocator")
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        if sa_name !== nothing
            desc["sa_name"] = Base.String(sa_name)
        end
        if id !== nothing
            desc["id"] = Base.Int(id)
        end
        if expected_call_count !== nothing
            desc["expected_call_count"] = Base.Int(expected_call_count)
        end
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_adadelta_parameters(parameters, accumulators, updates; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_adadelta_parameters(parameters_, accumulators_, updates_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingAdadeltaParameters") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingAdadeltaParameters")
                parameters_ = convert(Tensor{Float32}, parameters_)
                accumulators_ = convert(Tensor{Float32}, accumulators_)
                updates_ = convert(Tensor{Float32}, updates_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, accumulators_)
                tf.add_input(desc, updates_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_adadelta_parameters(parameters_::tf.TensorHandle, accumulators_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingAdadeltaParameters")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, accumulators_)
        tf.add_input(desc, updates_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_add(a_indices, a_values, a_shape, b_indices, b_values, b_shape, thresh)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_add(a_indices_, a_values_, a_shape_, b_indices_, b_values_, b_shape_, thresh_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseAdd") do 
                desc = tf.NodeDescription("SparseAdd")
                a_indices_ = convert(Tensor{Int64}, a_indices_)
                a_values_ = convert(Tensor{Any}, a_values_)
                a_shape_ = convert(Tensor{Int64}, a_shape_)
                b_indices_ = convert(Tensor{Int64}, b_indices_)
                b_values_ = convert(Tensor{Any}, b_values_)
                b_shape_ = convert(Tensor{Int64}, b_shape_)
                thresh_ = convert(Tensor{Any}, thresh_)
                (thresh_,) = tf.tf_promote(thresh_)
                (a_values_, b_values_) = tf.tf_promote(a_values_, b_values_)
                tf.add_input(desc, a_indices_)
                tf.add_input(desc, a_values_)
                tf.add_input(desc, a_shape_)
                tf.add_input(desc, b_indices_)
                tf.add_input(desc, b_values_)
                tf.add_input(desc, b_shape_)
                tf.add_input(desc, thresh_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_add(a_indices_::tf.TensorHandle, a_values_::tf.TensorHandle, a_shape_::tf.TensorHandle, b_indices_::tf.TensorHandle, b_values_::tf.TensorHandle, b_shape_::tf.TensorHandle, thresh_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseAdd")
        tf.add_input(desc, a_indices_)
        tf.add_input(desc, a_values_)
        tf.add_input(desc, a_shape_)
        tf.add_input(desc, b_indices_)
        tf.add_input(desc, b_values_)
        tf.add_input(desc, b_shape_)
        tf.add_input(desc, thresh_)
        desc["T"] = tf.data_type(a_values_)
        desc["T"] = tf.data_type(b_values_)
        desc["Treal"] = tf.data_type(thresh_)
        tf.execute(desc)
    end
end


"""
     ctc_greedy_decoder(inputs, sequence_length; merge_repeated=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ctc_greedy_decoder(inputs_, sequence_length_; name=nothing, merge_repeated=nothing)
            local desc
            tf.with_op_name(name, "CTCGreedyDecoder") do 
                desc = tf.NodeDescription("CTCGreedyDecoder")
                inputs_ = convert(Tensor{Float32}, inputs_)
                sequence_length_ = convert(Tensor{Int32}, sequence_length_)
                tf.add_input(desc, inputs_)
                tf.add_input(desc, sequence_length_)
                if merge_repeated !== nothing
                    desc["merge_repeated"] = Base.Bool(merge_repeated)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function ctc_greedy_decoder(inputs_::tf.TensorHandle, sequence_length_::tf.TensorHandle; name=nothing, merge_repeated=nothing)
        desc = tf.EagerOp("CTCGreedyDecoder")
        tf.add_input(desc, inputs_)
        tf.add_input(desc, sequence_length_)
        if merge_repeated !== nothing
            desc["merge_repeated"] = Base.Bool(merge_repeated)
        end
        tf.execute(desc)
    end
end


"""
     immutable_const()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function immutable_const(; name=nothing, dtype=nothing, shape=nothing, memory_region_name=nothing)
            local desc
            tf.with_op_name(name, "ImmutableConst") do 
                desc = tf.NodeDescription("ImmutableConst")
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
                if memory_region_name !== nothing
                    desc["memory_region_name"] = Base.String(memory_region_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function immutable_const(; name=nothing, dtype=nothing, shape=nothing, memory_region_name=nothing)
        desc = tf.EagerOp("ImmutableConst")
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        if memory_region_name !== nothing
            desc["memory_region_name"] = Base.String(memory_region_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     consume_mutex_lock(mutex_lock)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function consume_mutex_lock(mutex_lock_; name=nothing)
            local desc
            tf.with_op_name(name, "ConsumeMutexLock") do 
                desc = tf.NodeDescription("ConsumeMutexLock")
                mutex_lock_ = convert(Tensor{Any}, mutex_lock_)
                tf.add_input(desc, mutex_lock_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function consume_mutex_lock(mutex_lock_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ConsumeMutexLock")
        tf.add_input(desc, mutex_lock_)
        (tf.execute(desc))[1]
    end
end


"""
     greater_equal(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function greater_equal(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "GreaterEqual") do 
                desc = tf.NodeDescription("GreaterEqual")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function greater_equal(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("GreaterEqual")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     initialize_table_from_text_file_v2(table_handle, filename; vocab_size=-1, delimiter=	)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function initialize_table_from_text_file_v2(table_handle_, filename_; name=nothing, key_index=nothing, value_index=nothing, vocab_size=nothing, delimiter=nothing)
            local desc
            tf.with_op_name(name, "InitializeTableFromTextFileV2") do 
                desc = tf.NodeDescription("InitializeTableFromTextFileV2")
                table_handle_ = convert(Tensor{Any}, table_handle_)
                filename_ = convert(Tensor{String}, filename_)
                tf.add_input(desc, table_handle_)
                tf.add_input(desc, filename_)
                if key_index !== nothing
                    desc["key_index"] = Base.Int(key_index)
                end
                if value_index !== nothing
                    desc["value_index"] = Base.Int(value_index)
                end
                if vocab_size !== nothing
                    desc["vocab_size"] = Base.Int(vocab_size)
                end
                if delimiter !== nothing
                    desc["delimiter"] = Base.String(delimiter)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function initialize_table_from_text_file_v2(table_handle_::tf.TensorHandle, filename_::tf.TensorHandle; name=nothing, key_index=nothing, value_index=nothing, vocab_size=nothing, delimiter=nothing)
        desc = tf.EagerOp("InitializeTableFromTextFileV2")
        tf.add_input(desc, table_handle_)
        tf.add_input(desc, filename_)
        if key_index !== nothing
            desc["key_index"] = Base.Int(key_index)
        end
        if value_index !== nothing
            desc["value_index"] = Base.Int(value_index)
        end
        if vocab_size !== nothing
            desc["vocab_size"] = Base.Int(vocab_size)
        end
        if delimiter !== nothing
            desc["delimiter"] = Base.String(delimiter)
        end
        (tf.execute(desc))[1]
    end
end


"""
     queue_dequeue(handle; timeout_ms=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_dequeue(handle_; name=nothing, component_types=nothing, timeout_ms=nothing)
            local desc
            tf.with_op_name(name, "QueueDequeue") do 
                desc = tf.NodeDescription("QueueDequeue")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if timeout_ms !== nothing
                    desc["timeout_ms"] = Base.Int(timeout_ms)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_dequeue(handle_::tf.TensorHandle; name=nothing, component_types=nothing, timeout_ms=nothing)
        desc = tf.EagerOp("QueueDequeue")
        tf.add_input(desc, handle_)
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if timeout_ms !== nothing
            desc["timeout_ms"] = Base.Int(timeout_ms)
        end
        (tf.execute(desc))[1]
    end
end


"""
     equal(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function equal(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Equal") do 
                desc = tf.NodeDescription("Equal")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function equal(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Equal")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     iterator_from_string_handle(string_handle; output_types=Int64[], output_shapes=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function iterator_from_string_handle(string_handle_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "IteratorFromStringHandle") do 
                desc = tf.NodeDescription("IteratorFromStringHandle")
                string_handle_ = convert(Tensor{String}, string_handle_)
                tf.add_input(desc, string_handle_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function iterator_from_string_handle(string_handle_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("IteratorFromStringHandle")
        tf.add_input(desc, string_handle_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_split(tensor, element_shape, lengths)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_split(tensor_, element_shape_, lengths_; name=nothing, element_dtype=nothing, shape_type=nothing)
            local desc
            tf.with_op_name(name, "TensorListSplit") do 
                desc = tf.NodeDescription("TensorListSplit")
                tensor_ = convert(Tensor{Any}, tensor_)
                element_shape_ = convert(Tensor{Any}, element_shape_)
                lengths_ = convert(Tensor{Int64}, lengths_)
                (tensor_,) = tf.tf_promote(tensor_)
                (element_shape_,) = tf.tf_promote(element_shape_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, element_shape_)
                tf.add_input(desc, lengths_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
                if shape_type !== nothing
                    desc["shape_type"] = Base.identity(shape_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_split(tensor_::tf.TensorHandle, element_shape_::tf.TensorHandle, lengths_::tf.TensorHandle; name=nothing, element_dtype=nothing, shape_type=nothing)
        desc = tf.EagerOp("TensorListSplit")
        tf.add_input(desc, tensor_)
        tf.add_input(desc, element_shape_)
        tf.add_input(desc, lengths_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        if shape_type !== nothing
            desc["shape_type"] = Base.identity(shape_type)
        end
        desc["element_dtype"] = tf.data_type(tensor_)
        desc["shape_type"] = tf.data_type(element_shape_)
        (tf.execute(desc))[1]
    end
end


"""
     fractional_max_pool(value; pseudo_random=false, overlapping=false, deterministic=false, seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fractional_max_pool(value_; name=nothing, pooling_ratio=nothing, pseudo_random=nothing, overlapping=nothing, deterministic=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "FractionalMaxPool") do 
                desc = tf.NodeDescription("FractionalMaxPool")
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, value_)
                if pooling_ratio !== nothing
                    desc["pooling_ratio"] = map(Base.identity, pooling_ratio)
                end
                if pseudo_random !== nothing
                    desc["pseudo_random"] = Base.Bool(pseudo_random)
                end
                if overlapping !== nothing
                    desc["overlapping"] = Base.Bool(overlapping)
                end
                if deterministic !== nothing
                    desc["deterministic"] = Base.Bool(deterministic)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function fractional_max_pool(value_::tf.TensorHandle; name=nothing, pooling_ratio=nothing, pseudo_random=nothing, overlapping=nothing, deterministic=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("FractionalMaxPool")
        tf.add_input(desc, value_)
        if pooling_ratio !== nothing
            desc["pooling_ratio"] = map(Base.identity, pooling_ratio)
        end
        if pseudo_random !== nothing
            desc["pseudo_random"] = Base.Bool(pseudo_random)
        end
        if overlapping !== nothing
            desc["overlapping"] = Base.Bool(overlapping)
        end
        if deterministic !== nothing
            desc["deterministic"] = Base.Bool(deterministic)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        desc["T"] = tf.data_type(value_)
        tf.execute(desc)
    end
end


"""
     scatter_nd(indices, updates, shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_nd(indices_, updates_, shape_; name=nothing)
            local desc
            tf.with_op_name(name, "ScatterNd") do 
                desc = tf.NodeDescription("ScatterNd")
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                shape_ = convert(Tensor{Any}, shape_)
                (updates_,) = tf.tf_promote(updates_)
                (indices_, shape_) = tf.tf_promote(indices_, shape_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                tf.add_input(desc, shape_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_nd(indices_::tf.TensorHandle, updates_::tf.TensorHandle, shape_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ScatterNd")
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        tf.add_input(desc, shape_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        desc["Tindices"] = tf.data_type(shape_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_scatter_into_existing_list(input_handle, tensor, indices)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_scatter_into_existing_list(input_handle_, tensor_, indices_; name=nothing, element_dtype=nothing)
            local desc
            tf.with_op_name(name, "TensorListScatterIntoExistingList") do 
                desc = tf.NodeDescription("TensorListScatterIntoExistingList")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                tensor_ = convert(Tensor{Any}, tensor_)
                indices_ = convert(Tensor{Int32}, indices_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, input_handle_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, indices_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_scatter_into_existing_list(input_handle_::tf.TensorHandle, tensor_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, element_dtype=nothing)
        desc = tf.EagerOp("TensorListScatterIntoExistingList")
        tf.add_input(desc, input_handle_)
        tf.add_input(desc, tensor_)
        tf.add_input(desc, indices_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        desc["element_dtype"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     select(condition, t, e)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function select(condition_, t_, e_; name=nothing)
            local desc
            tf.with_op_name(name, "Select") do 
                desc = tf.NodeDescription("Select")
                condition_ = convert(Tensor{Bool}, condition_)
                t_ = convert(Tensor{Any}, t_)
                e_ = convert(Tensor{Any}, e_)
                (t_, e_) = tf.tf_promote(t_, e_)
                tf.add_input(desc, condition_)
                tf.add_input(desc, t_)
                tf.add_input(desc, e_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function select(condition_::tf.TensorHandle, t_::tf.TensorHandle, e_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Select")
        tf.add_input(desc, condition_)
        tf.add_input(desc, t_)
        tf.add_input(desc, e_)
        desc["T"] = tf.data_type(t_)
        desc["T"] = tf.data_type(e_)
        (tf.execute(desc))[1]
    end
end


"""
     min(input, reduction_indices; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function min(input_, reduction_indices_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "Min") do 
                desc = tf.NodeDescription("Min")
                input_ = convert(Tensor{Any}, input_)
                reduction_indices_ = convert(Tensor{Int32}, reduction_indices_)
                reduction_indices_ = reduction_indices_ - convert(tf.Tensor{eltype(reduction_indices_)}, 1)
                (input_,) = tf.tf_promote(input_)
                (reduction_indices_,) = tf.tf_promote(reduction_indices_)
                tf.add_input(desc, input_)
                tf.add_input(desc, reduction_indices_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function min(input_::tf.TensorHandle, reduction_indices_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("Min")
        tf.add_input(desc, input_)
        tf.add_input(desc, reduction_indices_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tidx"] = tf.data_type(reduction_indices_)
        (tf.execute(desc))[1]
    end
end


"""
     lrn_grad(input_grads, input_image, output_image; depth_radius=5, bias=?, alpha=?, beta=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lrn_grad(input_grads_, input_image_, output_image_; name=nothing, depth_radius=nothing, bias=nothing, alpha=nothing, beta=nothing)
            local desc
            tf.with_op_name(name, "LRNGrad") do 
                desc = tf.NodeDescription("LRNGrad")
                input_grads_ = convert(Tensor{Float32}, input_grads_)
                input_image_ = convert(Tensor{Float32}, input_image_)
                output_image_ = convert(Tensor{Float32}, output_image_)
                (input_grads_, input_image_, output_image_) = tf.tf_promote(input_grads_, input_image_, output_image_)
                tf.add_input(desc, input_grads_)
                tf.add_input(desc, input_image_)
                tf.add_input(desc, output_image_)
                if depth_radius !== nothing
                    desc["depth_radius"] = Base.Int(depth_radius)
                end
                if bias !== nothing
                    desc["bias"] = Base.identity(bias)
                end
                if alpha !== nothing
                    desc["alpha"] = Base.identity(alpha)
                end
                if beta !== nothing
                    desc["beta"] = Base.identity(beta)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lrn_grad(input_grads_::tf.TensorHandle, input_image_::tf.TensorHandle, output_image_::tf.TensorHandle; name=nothing, depth_radius=nothing, bias=nothing, alpha=nothing, beta=nothing)
        desc = tf.EagerOp("LRNGrad")
        tf.add_input(desc, input_grads_)
        tf.add_input(desc, input_image_)
        tf.add_input(desc, output_image_)
        if depth_radius !== nothing
            desc["depth_radius"] = Base.Int(depth_radius)
        end
        if bias !== nothing
            desc["bias"] = Base.identity(bias)
        end
        if alpha !== nothing
            desc["alpha"] = Base.identity(alpha)
        end
        if beta !== nothing
            desc["beta"] = Base.identity(beta)
        end
        desc["T"] = tf.data_type(input_grads_)
        desc["T"] = tf.data_type(input_image_)
        desc["T"] = tf.data_type(output_image_)
        (tf.execute(desc))[1]
    end
end


"""
     random_poisson_v2(shape, rate; seed=0, seed2=0, R=Float64, dtype=Int64)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function random_poisson_v2(shape_, rate_; name=nothing, seed=nothing, seed2=nothing, S=nothing, R=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "RandomPoissonV2") do 
                desc = tf.NodeDescription("RandomPoissonV2")
                shape_ = convert(Tensor{Any}, shape_)
                rate_ = convert(Tensor{Float64}, rate_)
                (shape_,) = tf.tf_promote(shape_)
                (rate_,) = tf.tf_promote(rate_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, rate_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if S !== nothing
                    desc["S"] = Base.identity(S)
                end
                if R !== nothing
                    desc["R"] = Base.identity(R)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function random_poisson_v2(shape_::tf.TensorHandle, rate_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing, S=nothing, R=nothing, dtype=nothing)
        desc = tf.EagerOp("RandomPoissonV2")
        tf.add_input(desc, shape_)
        tf.add_input(desc, rate_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if S !== nothing
            desc["S"] = Base.identity(S)
        end
        if R !== nothing
            desc["R"] = Base.identity(R)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["S"] = tf.data_type(shape_)
        desc["R"] = tf.data_type(rate_)
        (tf.execute(desc))[1]
    end
end


"""
     fifo_queue(; shapes=Int64[], capacity=-1, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fifo_queue(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "FIFOQueue") do 
                desc = tf.NodeDescription("FIFOQueue")
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fifo_queue(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("FIFOQueue")
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_sparse_apply_proximal_gradient_descent(var, alpha, l1, l2, grad, indices; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_sparse_apply_proximal_gradient_descent(var_, alpha_, l1_, l2_, grad_, indices_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceSparseApplyProximalGradientDescent") do 
                desc = tf.NodeDescription("ResourceSparseApplyProximalGradientDescent")
                var_ = convert(Tensor{Any}, var_)
                alpha_ = convert(Tensor{Any}, alpha_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (alpha_, l1_, l2_, grad_) = tf.tf_promote(alpha_, l1_, l2_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, alpha_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_sparse_apply_proximal_gradient_descent(var_::tf.TensorHandle, alpha_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceSparseApplyProximalGradientDescent")
        tf.add_input(desc, var_)
        tf.add_input(desc, alpha_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(alpha_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_non_serializable_dataset(input_dataset)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_non_serializable_dataset(input_dataset_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalNonSerializableDataset") do 
                desc = tf.NodeDescription("ExperimentalNonSerializableDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                tf.add_input(desc, input_dataset_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_non_serializable_dataset(input_dataset_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalNonSerializableDataset")
        tf.add_input(desc, input_dataset_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     experimental_bytes_produced_stats_dataset(input_dataset, tag)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_bytes_produced_stats_dataset(input_dataset_, tag_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalBytesProducedStatsDataset") do 
                desc = tf.NodeDescription("ExperimentalBytesProducedStatsDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                tag_ = convert(Tensor{String}, tag_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, tag_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_bytes_produced_stats_dataset(input_dataset_::tf.TensorHandle, tag_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalBytesProducedStatsDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, tag_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     dilation2d_backprop_filter(input, filter, out_backprop)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function dilation2d_backprop_filter(input_, filter_, out_backprop_; name=nothing, strides=nothing, rates=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "Dilation2DBackpropFilter") do 
                desc = tf.NodeDescription("Dilation2DBackpropFilter")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                (input_, filter_, out_backprop_) = tf.tf_promote(input_, filter_, out_backprop_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, out_backprop_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if rates !== nothing
                    desc["rates"] = map(Base.identity, rates)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function dilation2d_backprop_filter(input_::tf.TensorHandle, filter_::tf.TensorHandle, out_backprop_::tf.TensorHandle; name=nothing, strides=nothing, rates=nothing, padding=nothing)
        desc = tf.EagerOp("Dilation2DBackpropFilter")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, out_backprop_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if rates !== nothing
            desc["rates"] = map(Base.identity, rates)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(filter_)
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     _if(cond, input)

output = cond ? then_branch(input) : else_branch(input)
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _if(cond_, input_; name=nothing, Tin=nothing, Tout=nothing, then_branch=nothing, else_branch=nothing)
            local desc
            tf.with_op_name(name, "_If") do 
                desc = tf.NodeDescription("_If")
                cond_ = convert(Tensor{Any}, cond_)
                input_ = [convert(Tensor{Any}, x) for x = input_]
                (cond_,) = tf.tf_promote(cond_)
                tf.add_input(desc, cond_)
                tf.add_input(desc, input_)
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
                if then_branch !== nothing
                    desc["then_branch"] = Base.identity(then_branch)
                end
                if else_branch !== nothing
                    desc["else_branch"] = Base.identity(else_branch)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _if(cond_::tf.TensorHandle, input_::tf.TensorHandle; name=nothing, Tin=nothing, Tout=nothing, then_branch=nothing, else_branch=nothing)
        desc = tf.EagerOp("_If")
        tf.add_input(desc, cond_)
        tf.add_input(desc, input_)
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        if then_branch !== nothing
            desc["then_branch"] = Base.identity(then_branch)
        end
        if else_branch !== nothing
            desc["else_branch"] = Base.identity(else_branch)
        end
        desc["Tcond"] = tf.data_type(cond_)
        (tf.execute(desc))[1]
    end
end


"""
     bias_add_grad(out_backprop; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function bias_add_grad(out_backprop_; name=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "BiasAddGrad") do 
                desc = tf.NodeDescription("BiasAddGrad")
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                (out_backprop_,) = tf.tf_promote(out_backprop_)
                tf.add_input(desc, out_backprop_)
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function bias_add_grad(out_backprop_::tf.TensorHandle; name=nothing, data_format=nothing)
        desc = tf.EagerOp("BiasAddGrad")
        tf.add_input(desc, out_backprop_)
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     reader_serialize_state_v2(reader_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_serialize_state_v2(reader_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderSerializeStateV2") do 
                desc = tf.NodeDescription("ReaderSerializeStateV2")
                reader_handle_ = convert(Tensor{Any}, reader_handle_)
                tf.add_input(desc, reader_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reader_serialize_state_v2(reader_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderSerializeStateV2")
        tf.add_input(desc, reader_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     wrap_dataset_variant(input_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function wrap_dataset_variant(input_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "WrapDatasetVariant") do 
                desc = tf.NodeDescription("WrapDatasetVariant")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                tf.add_input(desc, input_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function wrap_dataset_variant(input_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("WrapDatasetVariant")
        tf.add_input(desc, input_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     parallel_interleave_dataset_v2(input_dataset, other_arguments, cycle_length, block_length, num_parallel_calls; sloppy=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function parallel_interleave_dataset_v2(input_dataset_, other_arguments_, cycle_length_, block_length_, num_parallel_calls_; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, sloppy=nothing)
            local desc
            tf.with_op_name(name, "ParallelInterleaveDatasetV2") do 
                desc = tf.NodeDescription("ParallelInterleaveDatasetV2")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                cycle_length_ = convert(Tensor{Int64}, cycle_length_)
                block_length_ = convert(Tensor{Int64}, block_length_)
                num_parallel_calls_ = convert(Tensor{Int64}, num_parallel_calls_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, other_arguments_)
                tf.add_input(desc, cycle_length_)
                tf.add_input(desc, block_length_)
                tf.add_input(desc, num_parallel_calls_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if sloppy !== nothing
                    desc["sloppy"] = Base.Bool(sloppy)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function parallel_interleave_dataset_v2(input_dataset_::tf.TensorHandle, other_arguments_::tf.TensorHandle, cycle_length_::tf.TensorHandle, block_length_::tf.TensorHandle, num_parallel_calls_::tf.TensorHandle; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, sloppy=nothing)
        desc = tf.EagerOp("ParallelInterleaveDatasetV2")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, other_arguments_)
        tf.add_input(desc, cycle_length_)
        tf.add_input(desc, block_length_)
        tf.add_input(desc, num_parallel_calls_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if sloppy !== nothing
            desc["sloppy"] = Base.Bool(sloppy)
        end
        (tf.execute(desc))[1]
    end
end


"""
     depthwise_conv2d_native_backprop_input(input_sizes, filter, out_backprop; data_format=NHWC, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function depthwise_conv2d_native_backprop_input(input_sizes_, filter_, out_backprop_; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "DepthwiseConv2dNativeBackpropInput") do 
                desc = tf.NodeDescription("DepthwiseConv2dNativeBackpropInput")
                input_sizes_ = convert(Tensor{Int32}, input_sizes_)
                filter_ = convert(Tensor{Any}, filter_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                (filter_, out_backprop_) = tf.tf_promote(filter_, out_backprop_)
                tf.add_input(desc, input_sizes_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, out_backprop_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function depthwise_conv2d_native_backprop_input(input_sizes_::tf.TensorHandle, filter_::tf.TensorHandle, out_backprop_::tf.TensorHandle; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
        desc = tf.EagerOp("DepthwiseConv2dNativeBackpropInput")
        tf.add_input(desc, input_sizes_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, out_backprop_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["T"] = tf.data_type(filter_)
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_rms_prop(var, ms, mom, lr, rho, momentum, epsilon, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_rms_prop(var_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyRMSProp") do 
                desc = tf.NodeDescription("ResourceApplyRMSProp")
                var_ = convert(Tensor{Any}, var_)
                ms_ = convert(Tensor{Any}, ms_)
                mom_ = convert(Tensor{Any}, mom_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                momentum_ = convert(Tensor{Any}, momentum_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                (lr_, rho_, momentum_, epsilon_, grad_) = tf.tf_promote(lr_, rho_, momentum_, epsilon_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, ms_)
                tf.add_input(desc, mom_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, momentum_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_rms_prop(var_::tf.TensorHandle, ms_::tf.TensorHandle, mom_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, momentum_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyRMSProp")
        tf.add_input(desc, var_)
        tf.add_input(desc, ms_)
        tf.add_input(desc, mom_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, momentum_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(momentum_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_accumulator_take_gradient(handle, num_required)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_accumulator_take_gradient(handle_, num_required_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "SparseAccumulatorTakeGradient") do 
                desc = tf.NodeDescription("SparseAccumulatorTakeGradient")
                handle_ = convert(Tensor{String}, handle_)
                num_required_ = convert(Tensor{Int32}, num_required_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, num_required_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_accumulator_take_gradient(handle_::tf.TensorHandle, num_required_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("SparseAccumulatorTakeGradient")
        tf.add_input(desc, handle_)
        tf.add_input(desc, num_required_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        tf.execute(desc)
    end
end


"""
     experimental_lmdb_dataset(filenames)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_lmdb_dataset(filenames_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalLMDBDataset") do 
                desc = tf.NodeDescription("ExperimentalLMDBDataset")
                filenames_ = convert(Tensor{String}, filenames_)
                tf.add_input(desc, filenames_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_lmdb_dataset(filenames_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalLMDBDataset")
        tf.add_input(desc, filenames_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     stack_close_v2(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stack_close_v2(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "StackCloseV2") do 
                desc = tf.NodeDescription("StackCloseV2")
                handle_ = convert(Tensor{Any}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stack_close_v2(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("StackCloseV2")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     map_size(; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function map_size(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "MapSize") do 
                desc = tf.NodeDescription("MapSize")
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function map_size(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("MapSize")
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_adagrad_da(var, gradient_accumulator, gradient_squared_accumulator, grad, lr, l1, l2, global_step; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_adagrad_da(var_, gradient_accumulator_, gradient_squared_accumulator_, grad_, lr_, l1_, l2_, global_step_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyAdagradDA") do 
                desc = tf.NodeDescription("ResourceApplyAdagradDA")
                var_ = convert(Tensor{Any}, var_)
                gradient_accumulator_ = convert(Tensor{Any}, gradient_accumulator_)
                gradient_squared_accumulator_ = convert(Tensor{Any}, gradient_squared_accumulator_)
                grad_ = convert(Tensor{Any}, grad_)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                global_step_ = convert(Tensor{Int64}, global_step_)
                (grad_, lr_, l1_, l2_) = tf.tf_promote(grad_, lr_, l1_, l2_)
                tf.add_input(desc, var_)
                tf.add_input(desc, gradient_accumulator_)
                tf.add_input(desc, gradient_squared_accumulator_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, global_step_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_adagrad_da(var_::tf.TensorHandle, gradient_accumulator_::tf.TensorHandle, gradient_squared_accumulator_::tf.TensorHandle, grad_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, global_step_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyAdagradDA")
        tf.add_input(desc, var_)
        tf.add_input(desc, gradient_accumulator_)
        tf.add_input(desc, gradient_squared_accumulator_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, global_step_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(grad_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_forest_tree_size(tree_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_forest_tree_size(tree_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorForestTreeSize") do 
                desc = tf.NodeDescription("TensorForestTreeSize")
                tree_handle_ = convert(Tensor{Any}, tree_handle_)
                tf.add_input(desc, tree_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_forest_tree_size(tree_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorForestTreeSize")
        tf.add_input(desc, tree_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     matrix_diag_part(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_diag_part(input_; name=nothing)
            local desc
            tf.with_op_name(name, "MatrixDiagPart") do 
                desc = tf.NodeDescription("MatrixDiagPart")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_diag_part(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MatrixDiagPart")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     reader_num_work_units_completed_v2(reader_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_num_work_units_completed_v2(reader_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderNumWorkUnitsCompletedV2") do 
                desc = tf.NodeDescription("ReaderNumWorkUnitsCompletedV2")
                reader_handle_ = convert(Tensor{Any}, reader_handle_)
                tf.add_input(desc, reader_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reader_num_work_units_completed_v2(reader_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderNumWorkUnitsCompletedV2")
        tf.add_input(desc, reader_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_split_v3(handle, value, lengths, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_split_v3(handle_, value_, lengths_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArraySplitV3") do 
                desc = tf.NodeDescription("TensorArraySplitV3")
                handle_ = convert(Tensor{Any}, handle_)
                value_ = convert(Tensor{Any}, value_)
                lengths_ = convert(Tensor{Int64}, lengths_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, value_)
                tf.add_input(desc, lengths_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_split_v3(handle_::tf.TensorHandle, value_::tf.TensorHandle, lengths_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArraySplitV3")
        tf.add_input(desc, handle_)
        tf.add_input(desc, value_)
        tf.add_input(desc, lengths_)
        tf.add_input(desc, flow_in_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_to_dense(sparse_indices, output_shape, sparse_values, default_value; validate_indices=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_to_dense(sparse_indices_, output_shape_, sparse_values_, default_value_; name=nothing, validate_indices=nothing)
            local desc
            tf.with_op_name(name, "SparseToDense") do 
                desc = tf.NodeDescription("SparseToDense")
                sparse_indices_ = convert(Tensor{Any}, sparse_indices_)
                sparse_indices_ = sparse_indices_ - convert(tf.Tensor{eltype(sparse_indices_)}, 1)
                output_shape_ = convert(Tensor{Any}, output_shape_)
                output_shape_ = output_shape_ - convert(tf.Tensor{eltype(output_shape_)}, 1)
                sparse_values_ = convert(Tensor{Any}, sparse_values_)
                default_value_ = convert(Tensor{Any}, default_value_)
                (sparse_values_, default_value_) = tf.tf_promote(sparse_values_, default_value_)
                (sparse_indices_, output_shape_) = tf.tf_promote(sparse_indices_, output_shape_)
                tf.add_input(desc, sparse_indices_)
                tf.add_input(desc, output_shape_)
                tf.add_input(desc, sparse_values_)
                tf.add_input(desc, default_value_)
                if validate_indices !== nothing
                    desc["validate_indices"] = Base.Bool(validate_indices)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_to_dense(sparse_indices_::tf.TensorHandle, output_shape_::tf.TensorHandle, sparse_values_::tf.TensorHandle, default_value_::tf.TensorHandle; name=nothing, validate_indices=nothing)
        desc = tf.EagerOp("SparseToDense")
        tf.add_input(desc, sparse_indices_)
        tf.add_input(desc, output_shape_)
        tf.add_input(desc, sparse_values_)
        tf.add_input(desc, default_value_)
        if validate_indices !== nothing
            desc["validate_indices"] = Base.Bool(validate_indices)
        end
        desc["Tindices"] = tf.data_type(sparse_indices_)
        desc["Tindices"] = tf.data_type(output_shape_)
        desc["T"] = tf.data_type(sparse_values_)
        desc["T"] = tf.data_type(default_value_)
        (tf.execute(desc))[1]
    end
end


"""
     tpu_replicated_input(inputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tpu_replicated_input(inputs_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "TPUReplicatedInput") do 
                desc = tf.NodeDescription("TPUReplicatedInput")
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                (inputs_,) = tf.tf_promote(inputs_)
                tf.add_input(desc, inputs_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tpu_replicated_input(inputs_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("TPUReplicatedInput")
        tf.add_input(desc, inputs_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(inputs_)
        (tf.execute(desc))[1]
    end
end


"""
     stack_close(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stack_close(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "StackClose") do 
                desc = tf.NodeDescription("StackClose")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stack_close(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("StackClose")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     deserialize_many_sparse(serialized_sparse)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function deserialize_many_sparse(serialized_sparse_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "DeserializeManySparse") do 
                desc = tf.NodeDescription("DeserializeManySparse")
                serialized_sparse_ = convert(Tensor{String}, serialized_sparse_)
                tf.add_input(desc, serialized_sparse_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function deserialize_many_sparse(serialized_sparse_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("DeserializeManySparse")
        tf.add_input(desc, serialized_sparse_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        tf.execute(desc)
    end
end


"""
     _nccl_reduce_recv(input)

Replacement node for NcclReduce.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _nccl_reduce_recv(input_; name=nothing, reduction=nothing, num_devices=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "_NcclReduceRecv") do 
                desc = tf.NodeDescription("_NcclReduceRecv")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if reduction !== nothing
                    desc["reduction"] = Base.String(reduction)
                end
                if num_devices !== nothing
                    desc["num_devices"] = Base.Int(num_devices)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _nccl_reduce_recv(input_::tf.TensorHandle; name=nothing, reduction=nothing, num_devices=nothing, shared_name=nothing)
        desc = tf.EagerOp("_NcclReduceRecv")
        tf.add_input(desc, input_)
        if reduction !== nothing
            desc["reduction"] = Base.String(reduction)
        end
        if num_devices !== nothing
            desc["num_devices"] = Base.Int(num_devices)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     mirror_pad_grad(input, paddings)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mirror_pad_grad(input_, paddings_; name=nothing, mode=nothing)
            local desc
            tf.with_op_name(name, "MirrorPadGrad") do 
                desc = tf.NodeDescription("MirrorPadGrad")
                input_ = convert(Tensor{Any}, input_)
                paddings_ = convert(Tensor{Int32}, paddings_)
                (input_,) = tf.tf_promote(input_)
                (paddings_,) = tf.tf_promote(paddings_)
                tf.add_input(desc, input_)
                tf.add_input(desc, paddings_)
                if mode !== nothing
                    desc["mode"] = Base.String(mode)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mirror_pad_grad(input_::tf.TensorHandle, paddings_::tf.TensorHandle; name=nothing, mode=nothing)
        desc = tf.EagerOp("MirrorPadGrad")
        tf.add_input(desc, input_)
        tf.add_input(desc, paddings_)
        if mode !== nothing
            desc["mode"] = Base.String(mode)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tpaddings"] = tf.data_type(paddings_)
        (tf.execute(desc))[1]
    end
end


"""
     broadcast_args(s0, s1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function broadcast_args(s0_, s1_; name=nothing)
            local desc
            tf.with_op_name(name, "BroadcastArgs") do 
                desc = tf.NodeDescription("BroadcastArgs")
                s0_ = convert(Tensor{Int32}, s0_)
                s1_ = convert(Tensor{Int32}, s1_)
                (s0_, s1_) = tf.tf_promote(s0_, s1_)
                tf.add_input(desc, s0_)
                tf.add_input(desc, s1_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function broadcast_args(s0_::tf.TensorHandle, s1_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BroadcastArgs")
        tf.add_input(desc, s0_)
        tf.add_input(desc, s1_)
        desc["T"] = tf.data_type(s0_)
        desc["T"] = tf.data_type(s1_)
        (tf.execute(desc))[1]
    end
end


"""
     stateless_truncated_normal(shape, seed; dtype=Float32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stateless_truncated_normal(shape_, seed_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "StatelessTruncatedNormal") do 
                desc = tf.NodeDescription("StatelessTruncatedNormal")
                shape_ = convert(Tensor{Int32}, shape_)
                seed_ = convert(Tensor{Int64}, seed_)
                (shape_,) = tf.tf_promote(shape_)
                (seed_,) = tf.tf_promote(seed_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, seed_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stateless_truncated_normal(shape_::tf.TensorHandle, seed_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("StatelessTruncatedNormal")
        tf.add_input(desc, shape_)
        tf.add_input(desc, seed_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["T"] = tf.data_type(shape_)
        desc["Tseed"] = tf.data_type(seed_)
        (tf.execute(desc))[1]
    end
end


"""
     regex_full_match(input, pattern)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function regex_full_match(input_, pattern_; name=nothing)
            local desc
            tf.with_op_name(name, "RegexFullMatch") do 
                desc = tf.NodeDescription("RegexFullMatch")
                input_ = convert(Tensor{String}, input_)
                pattern_ = convert(Tensor{String}, pattern_)
                tf.add_input(desc, input_)
                tf.add_input(desc, pattern_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function regex_full_match(input_::tf.TensorHandle, pattern_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RegexFullMatch")
        tf.add_input(desc, input_)
        tf.add_input(desc, pattern_)
        (tf.execute(desc))[1]
    end
end


"""
     unwrap_dataset_variant(input_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unwrap_dataset_variant(input_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "UnwrapDatasetVariant") do 
                desc = tf.NodeDescription("UnwrapDatasetVariant")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                tf.add_input(desc, input_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unwrap_dataset_variant(input_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("UnwrapDatasetVariant")
        tf.add_input(desc, input_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     empty(shape; init=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function empty(shape_; name=nothing, dtype=nothing, init=nothing)
            local desc
            tf.with_op_name(name, "Empty") do 
                desc = tf.NodeDescription("Empty")
                shape_ = convert(Tensor{Int32}, shape_)
                tf.add_input(desc, shape_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if init !== nothing
                    desc["init"] = Base.Bool(init)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function empty(shape_::tf.TensorHandle; name=nothing, dtype=nothing, init=nothing)
        desc = tf.EagerOp("Empty")
        tf.add_input(desc, shape_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if init !== nothing
            desc["init"] = Base.Bool(init)
        end
        (tf.execute(desc))[1]
    end
end


"""
     outfeed_dequeue_tuple(; device_ordinal=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function outfeed_dequeue_tuple(; name=nothing, dtypes=nothing, shapes=nothing, device_ordinal=nothing)
            local desc
            tf.with_op_name(name, "OutfeedDequeueTuple") do 
                desc = tf.NodeDescription("OutfeedDequeueTuple")
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if device_ordinal !== nothing
                    desc["device_ordinal"] = Base.Int(device_ordinal)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function outfeed_dequeue_tuple(; name=nothing, dtypes=nothing, shapes=nothing, device_ordinal=nothing)
        desc = tf.EagerOp("OutfeedDequeueTuple")
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if device_ordinal !== nothing
            desc["device_ordinal"] = Base.Int(device_ordinal)
        end
        (tf.execute(desc))[1]
    end
end


"""
     div(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function div(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Div") do 
                desc = tf.NodeDescription("Div")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function div(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Div")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     barrier(; shapes=Int64[], capacity=-1, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function barrier(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "Barrier") do 
                desc = tf.NodeDescription("Barrier")
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function barrier(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("Barrier")
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     truncate_div(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function truncate_div(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "TruncateDiv") do 
                desc = tf.NodeDescription("TruncateDiv")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function truncate_div(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TruncateDiv")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     unicode_encode(input_values, input_splits; errors=replace, replacement_char=65533)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unicode_encode(input_values_, input_splits_; name=nothing, errors=nothing, output_encoding=nothing, replacement_char=nothing)
            local desc
            tf.with_op_name(name, "UnicodeEncode") do 
                desc = tf.NodeDescription("UnicodeEncode")
                input_values_ = convert(Tensor{Int32}, input_values_)
                input_splits_ = convert(Tensor{Int64}, input_splits_)
                tf.add_input(desc, input_values_)
                tf.add_input(desc, input_splits_)
                if errors !== nothing
                    desc["errors"] = Base.String(errors)
                end
                if output_encoding !== nothing
                    desc["output_encoding"] = Base.String(output_encoding)
                end
                if replacement_char !== nothing
                    desc["replacement_char"] = Base.Int(replacement_char)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unicode_encode(input_values_::tf.TensorHandle, input_splits_::tf.TensorHandle; name=nothing, errors=nothing, output_encoding=nothing, replacement_char=nothing)
        desc = tf.EagerOp("UnicodeEncode")
        tf.add_input(desc, input_values_)
        tf.add_input(desc, input_splits_)
        if errors !== nothing
            desc["errors"] = Base.String(errors)
        end
        if output_encoding !== nothing
            desc["output_encoding"] = Base.String(output_encoding)
        end
        if replacement_char !== nothing
            desc["replacement_char"] = Base.Int(replacement_char)
        end
        (tf.execute(desc))[1]
    end
end


"""
     merge_summary(inputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function merge_summary(inputs_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "MergeSummary") do 
                desc = tf.NodeDescription("MergeSummary")
                inputs_ = [convert(Tensor{String}, x) for x = inputs_]
                tf.add_input(desc, inputs_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function merge_summary(inputs_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("MergeSummary")
        tf.add_input(desc, inputs_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        (tf.execute(desc))[1]
    end
end


"""
     fake_queue(resource)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fake_queue(resource_; name=nothing)
            local desc
            tf.with_op_name(name, "FakeQueue") do 
                desc = tf.NodeDescription("FakeQueue")
                resource_ = convert(Tensor{Any}, resource_)
                tf.add_input(desc, resource_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fake_queue(resource_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("FakeQueue")
        tf.add_input(desc, resource_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_cholesky(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_cholesky(input_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchCholesky") do 
                desc = tf.NodeDescription("BatchCholesky")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_cholesky(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchCholesky")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     iterator()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function iterator(; name=nothing, shared_name=nothing, container=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "Iterator") do 
                desc = tf.NodeDescription("Iterator")
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function iterator(; name=nothing, shared_name=nothing, container=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("Iterator")
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     bessel_i1e(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function bessel_i1e(x_; name=nothing)
            local desc
            tf.with_op_name(name, "BesselI1e") do 
                desc = tf.NodeDescription("BesselI1e")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function bessel_i1e(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BesselI1e")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     import_event(writer, event)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function import_event(writer_, event_; name=nothing)
            local desc
            tf.with_op_name(name, "ImportEvent") do 
                desc = tf.NodeDescription("ImportEvent")
                writer_ = convert(Tensor{Any}, writer_)
                event_ = convert(Tensor{String}, event_)
                tf.add_input(desc, writer_)
                tf.add_input(desc, event_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function import_event(writer_::tf.TensorHandle, event_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ImportEvent")
        tf.add_input(desc, writer_)
        tf.add_input(desc, event_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_instance_norm(x, x_min, x_max; output_range_given=false, given_y_min=?, given_y_max=?, variance_epsilon=?, min_separation=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_instance_norm(x_, x_min_, x_max_; name=nothing, output_range_given=nothing, given_y_min=nothing, given_y_max=nothing, variance_epsilon=nothing, min_separation=nothing)
            local desc
            tf.with_op_name(name, "QuantizedInstanceNorm") do 
                desc = tf.NodeDescription("QuantizedInstanceNorm")
                x_ = convert(Tensor{Any}, x_)
                x_min_ = convert(Tensor{Float32}, x_min_)
                x_max_ = convert(Tensor{Float32}, x_max_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
                tf.add_input(desc, x_min_)
                tf.add_input(desc, x_max_)
                if output_range_given !== nothing
                    desc["output_range_given"] = Base.Bool(output_range_given)
                end
                if given_y_min !== nothing
                    desc["given_y_min"] = Base.identity(given_y_min)
                end
                if given_y_max !== nothing
                    desc["given_y_max"] = Base.identity(given_y_max)
                end
                if variance_epsilon !== nothing
                    desc["variance_epsilon"] = Base.identity(variance_epsilon)
                end
                if min_separation !== nothing
                    desc["min_separation"] = Base.identity(min_separation)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_instance_norm(x_::tf.TensorHandle, x_min_::tf.TensorHandle, x_max_::tf.TensorHandle; name=nothing, output_range_given=nothing, given_y_min=nothing, given_y_max=nothing, variance_epsilon=nothing, min_separation=nothing)
        desc = tf.EagerOp("QuantizedInstanceNorm")
        tf.add_input(desc, x_)
        tf.add_input(desc, x_min_)
        tf.add_input(desc, x_max_)
        if output_range_given !== nothing
            desc["output_range_given"] = Base.Bool(output_range_given)
        end
        if given_y_min !== nothing
            desc["given_y_min"] = Base.identity(given_y_min)
        end
        if given_y_max !== nothing
            desc["given_y_max"] = Base.identity(given_y_max)
        end
        if variance_epsilon !== nothing
            desc["variance_epsilon"] = Base.identity(variance_epsilon)
        end
        if min_separation !== nothing
            desc["min_separation"] = Base.identity(min_separation)
        end
        desc["T"] = tf.data_type(x_)
        tf.execute(desc)
    end
end


"""
     load_tpu_embedding_adagrad_parameters(parameters, accumulators; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_adagrad_parameters(parameters_, accumulators_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingAdagradParameters") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingAdagradParameters")
                parameters_ = convert(Tensor{Float32}, parameters_)
                accumulators_ = convert(Tensor{Float32}, accumulators_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, accumulators_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_adagrad_parameters(parameters_::tf.TensorHandle, accumulators_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingAdagradParameters")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, accumulators_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_write_v3(handle, index, value, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_write_v3(handle_, index_, value_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayWriteV3") do 
                desc = tf.NodeDescription("TensorArrayWriteV3")
                handle_ = convert(Tensor{Any}, handle_)
                index_ = convert(Tensor{Int32}, index_)
                value_ = convert(Tensor{Any}, value_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, index_)
                tf.add_input(desc, value_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_write_v3(handle_::tf.TensorHandle, index_::tf.TensorHandle, value_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArrayWriteV3")
        tf.add_input(desc, handle_)
        tf.add_input(desc, index_)
        tf.add_input(desc, value_)
        tf.add_input(desc, flow_in_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     dense_to_dense_set_operation(set1, set2; validate_indices=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function dense_to_dense_set_operation(set1_, set2_; name=nothing, set_operation=nothing, validate_indices=nothing)
            local desc
            tf.with_op_name(name, "DenseToDenseSetOperation") do 
                desc = tf.NodeDescription("DenseToDenseSetOperation")
                set1_ = convert(Tensor{Any}, set1_)
                set2_ = convert(Tensor{Any}, set2_)
                (set1_, set2_) = tf.tf_promote(set1_, set2_)
                tf.add_input(desc, set1_)
                tf.add_input(desc, set2_)
                if set_operation !== nothing
                    desc["set_operation"] = Base.String(set_operation)
                end
                if validate_indices !== nothing
                    desc["validate_indices"] = Base.Bool(validate_indices)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function dense_to_dense_set_operation(set1_::tf.TensorHandle, set2_::tf.TensorHandle; name=nothing, set_operation=nothing, validate_indices=nothing)
        desc = tf.EagerOp("DenseToDenseSetOperation")
        tf.add_input(desc, set1_)
        tf.add_input(desc, set2_)
        if set_operation !== nothing
            desc["set_operation"] = Base.String(set_operation)
        end
        if validate_indices !== nothing
            desc["validate_indices"] = Base.Bool(validate_indices)
        end
        desc["T"] = tf.data_type(set1_)
        desc["T"] = tf.data_type(set2_)
        tf.execute(desc)
    end
end


"""
     encode_jpeg(image; format=, quality=95, progressive=false, optimize_size=false, chroma_downsampling=true, density_unit=in, x_density=300, y_density=300, xmp_metadata=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function encode_jpeg(image_; name=nothing, format=nothing, quality=nothing, progressive=nothing, optimize_size=nothing, chroma_downsampling=nothing, density_unit=nothing, x_density=nothing, y_density=nothing, xmp_metadata=nothing)
            local desc
            tf.with_op_name(name, "EncodeJpeg") do 
                desc = tf.NodeDescription("EncodeJpeg")
                image_ = convert(Tensor{UInt8}, image_)
                tf.add_input(desc, image_)
                if format !== nothing
                    desc["format"] = Base.String(format)
                end
                if quality !== nothing
                    desc["quality"] = Base.Int(quality)
                end
                if progressive !== nothing
                    desc["progressive"] = Base.Bool(progressive)
                end
                if optimize_size !== nothing
                    desc["optimize_size"] = Base.Bool(optimize_size)
                end
                if chroma_downsampling !== nothing
                    desc["chroma_downsampling"] = Base.Bool(chroma_downsampling)
                end
                if density_unit !== nothing
                    desc["density_unit"] = Base.String(density_unit)
                end
                if x_density !== nothing
                    desc["x_density"] = Base.Int(x_density)
                end
                if y_density !== nothing
                    desc["y_density"] = Base.Int(y_density)
                end
                if xmp_metadata !== nothing
                    desc["xmp_metadata"] = Base.String(xmp_metadata)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function encode_jpeg(image_::tf.TensorHandle; name=nothing, format=nothing, quality=nothing, progressive=nothing, optimize_size=nothing, chroma_downsampling=nothing, density_unit=nothing, x_density=nothing, y_density=nothing, xmp_metadata=nothing)
        desc = tf.EagerOp("EncodeJpeg")
        tf.add_input(desc, image_)
        if format !== nothing
            desc["format"] = Base.String(format)
        end
        if quality !== nothing
            desc["quality"] = Base.Int(quality)
        end
        if progressive !== nothing
            desc["progressive"] = Base.Bool(progressive)
        end
        if optimize_size !== nothing
            desc["optimize_size"] = Base.Bool(optimize_size)
        end
        if chroma_downsampling !== nothing
            desc["chroma_downsampling"] = Base.Bool(chroma_downsampling)
        end
        if density_unit !== nothing
            desc["density_unit"] = Base.String(density_unit)
        end
        if x_density !== nothing
            desc["x_density"] = Base.Int(x_density)
        end
        if y_density !== nothing
            desc["y_density"] = Base.Int(y_density)
        end
        if xmp_metadata !== nothing
            desc["xmp_metadata"] = Base.String(xmp_metadata)
        end
        (tf.execute(desc))[1]
    end
end


"""
     inplace_update(x, i, v)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function inplace_update(x_, i_, v_; name=nothing)
            local desc
            tf.with_op_name(name, "InplaceUpdate") do 
                desc = tf.NodeDescription("InplaceUpdate")
                x_ = convert(Tensor{Any}, x_)
                i_ = convert(Tensor{Int32}, i_)
                v_ = convert(Tensor{Any}, v_)
                (x_, v_) = tf.tf_promote(x_, v_)
                tf.add_input(desc, x_)
                tf.add_input(desc, i_)
                tf.add_input(desc, v_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function inplace_update(x_::tf.TensorHandle, i_::tf.TensorHandle, v_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("InplaceUpdate")
        tf.add_input(desc, x_)
        tf.add_input(desc, i_)
        tf.add_input(desc, v_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(v_)
        (tf.execute(desc))[1]
    end
end


"""
     fused_pad_conv2d(input, paddings, filter)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fused_pad_conv2d(input_, paddings_, filter_; name=nothing, mode=nothing, strides=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "FusedPadConv2D") do 
                desc = tf.NodeDescription("FusedPadConv2D")
                input_ = convert(Tensor{Any}, input_)
                paddings_ = convert(Tensor{Int32}, paddings_)
                filter_ = convert(Tensor{Any}, filter_)
                (input_, filter_) = tf.tf_promote(input_, filter_)
                tf.add_input(desc, input_)
                tf.add_input(desc, paddings_)
                tf.add_input(desc, filter_)
                if mode !== nothing
                    desc["mode"] = Base.String(mode)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fused_pad_conv2d(input_::tf.TensorHandle, paddings_::tf.TensorHandle, filter_::tf.TensorHandle; name=nothing, mode=nothing, strides=nothing, padding=nothing)
        desc = tf.EagerOp("FusedPadConv2D")
        tf.add_input(desc, input_)
        tf.add_input(desc, paddings_)
        tf.add_input(desc, filter_)
        if mode !== nothing
            desc["mode"] = Base.String(mode)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(filter_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_relu(features, min_features, max_features; out_type=Float32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_relu(features_, min_features_, max_features_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "QuantizedRelu") do 
                desc = tf.NodeDescription("QuantizedRelu")
                features_ = convert(Tensor{Any}, features_)
                min_features_ = convert(Tensor{Float32}, min_features_)
                max_features_ = convert(Tensor{Float32}, max_features_)
                (features_,) = tf.tf_promote(features_)
                tf.add_input(desc, features_)
                tf.add_input(desc, min_features_)
                tf.add_input(desc, max_features_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_relu(features_::tf.TensorHandle, min_features_::tf.TensorHandle, max_features_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("QuantizedRelu")
        tf.add_input(desc, features_)
        tf.add_input(desc, min_features_)
        tf.add_input(desc, max_features_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["Tinput"] = tf.data_type(features_)
        tf.execute(desc)
    end
end


"""
     gather_nd(params, indices)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function gather_nd(params_, indices_; name=nothing)
            local desc
            tf.with_op_name(name, "GatherNd") do 
                desc = tf.NodeDescription("GatherNd")
                params_ = convert(Tensor{Any}, params_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (params_,) = tf.tf_promote(params_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, params_)
                tf.add_input(desc, indices_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function gather_nd(params_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("GatherNd")
        tf.add_input(desc, params_)
        tf.add_input(desc, indices_)
        desc["Tparams"] = tf.data_type(params_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     placeholder(; shape=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function placeholder(; name=nothing, dtype=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "Placeholder") do 
                desc = tf.NodeDescription("Placeholder")
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function placeholder(; name=nothing, dtype=nothing, shape=nothing)
        desc = tf.EagerOp("Placeholder")
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     filter_by_last_component_dataset(input_dataset)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function filter_by_last_component_dataset(input_dataset_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "FilterByLastComponentDataset") do 
                desc = tf.NodeDescription("FilterByLastComponentDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                tf.add_input(desc, input_dataset_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function filter_by_last_component_dataset(input_dataset_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("FilterByLastComponentDataset")
        tf.add_input(desc, input_dataset_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     clip_by_value(t, clip_value_min, clip_value_max)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function clip_by_value(t_, clip_value_min_, clip_value_max_; name=nothing)
            local desc
            tf.with_op_name(name, "ClipByValue") do 
                desc = tf.NodeDescription("ClipByValue")
                t_ = convert(Tensor{Any}, t_)
                clip_value_min_ = convert(Tensor{Any}, clip_value_min_)
                clip_value_max_ = convert(Tensor{Any}, clip_value_max_)
                (t_, clip_value_min_, clip_value_max_) = tf.tf_promote(t_, clip_value_min_, clip_value_max_)
                tf.add_input(desc, t_)
                tf.add_input(desc, clip_value_min_)
                tf.add_input(desc, clip_value_max_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function clip_by_value(t_::tf.TensorHandle, clip_value_min_::tf.TensorHandle, clip_value_max_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ClipByValue")
        tf.add_input(desc, t_)
        tf.add_input(desc, clip_value_min_)
        tf.add_input(desc, clip_value_max_)
        desc["T"] = tf.data_type(t_)
        desc["T"] = tf.data_type(clip_value_min_)
        desc["T"] = tf.data_type(clip_value_max_)
        (tf.execute(desc))[1]
    end
end


"""
     image_summary(tag, tensor; max_images=3, bad_color=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function image_summary(tag_, tensor_; name=nothing, max_images=nothing, bad_color=nothing)
            local desc
            tf.with_op_name(name, "ImageSummary") do 
                desc = tf.NodeDescription("ImageSummary")
                tag_ = convert(Tensor{String}, tag_)
                tensor_ = convert(Tensor{Float32}, tensor_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, tag_)
                tf.add_input(desc, tensor_)
                if max_images !== nothing
                    desc["max_images"] = Base.Int(max_images)
                end
                if bad_color !== nothing
                    desc["bad_color"] = TensorFlow.RawTensor(bad_color)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function image_summary(tag_::tf.TensorHandle, tensor_::tf.TensorHandle; name=nothing, max_images=nothing, bad_color=nothing)
        desc = tf.EagerOp("ImageSummary")
        tf.add_input(desc, tag_)
        tf.add_input(desc, tensor_)
        if max_images !== nothing
            desc["max_images"] = Base.Int(max_images)
        end
        if bad_color !== nothing
            desc["bad_color"] = TensorFlow.RawTensor(bad_color)
        end
        desc["T"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_adadelta_parameters(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_adadelta_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingAdadeltaParameters") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingAdadeltaParameters")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_adadelta_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingAdadeltaParameters")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     string_join(inputs; separator=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function string_join(inputs_; name=nothing, N=nothing, separator=nothing)
            local desc
            tf.with_op_name(name, "StringJoin") do 
                desc = tf.NodeDescription("StringJoin")
                inputs_ = [convert(Tensor{String}, x) for x = inputs_]
                tf.add_input(desc, inputs_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if separator !== nothing
                    desc["separator"] = Base.String(separator)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function string_join(inputs_::tf.TensorHandle; name=nothing, N=nothing, separator=nothing)
        desc = tf.EagerOp("StringJoin")
        tf.add_input(desc, inputs_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if separator !== nothing
            desc["separator"] = Base.String(separator)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_scatter_nd_add(ref, indices, updates; use_locking=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_scatter_nd_add(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceScatterNdAdd") do 
                desc = tf.NodeDescription("ResourceScatterNdAdd")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (updates_,) = tf.tf_promote(updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_scatter_nd_add(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceScatterNdAdd")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_quantile_stream_resource_deserialize(quantile_stream_resource_handle, bucket_boundaries)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_quantile_stream_resource_deserialize(quantile_stream_resource_handle_, bucket_boundaries_; name=nothing, num_streams=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesQuantileStreamResourceDeserialize") do 
                desc = tf.NodeDescription("BoostedTreesQuantileStreamResourceDeserialize")
                quantile_stream_resource_handle_ = convert(Tensor{Any}, quantile_stream_resource_handle_)
                bucket_boundaries_ = [convert(Tensor{Float32}, x) for x = bucket_boundaries_]
                tf.add_input(desc, quantile_stream_resource_handle_)
                tf.add_input(desc, bucket_boundaries_)
                if num_streams !== nothing
                    desc["num_streams"] = Base.Int(num_streams)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_quantile_stream_resource_deserialize(quantile_stream_resource_handle_::tf.TensorHandle, bucket_boundaries_::tf.TensorHandle; name=nothing, num_streams=nothing)
        desc = tf.EagerOp("BoostedTreesQuantileStreamResourceDeserialize")
        tf.add_input(desc, quantile_stream_resource_handle_)
        tf.add_input(desc, bucket_boundaries_)
        if num_streams !== nothing
            desc["num_streams"] = Base.Int(num_streams)
        end
        (tf.execute(desc))[1]
    end
end


"""
     left_shift(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function left_shift(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "LeftShift") do 
                desc = tf.NodeDescription("LeftShift")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function left_shift(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LeftShift")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     requantize_per_channel(input, input_min, input_max, requested_output_min, requested_output_max; out_type=Float32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function requantize_per_channel(input_, input_min_, input_max_, requested_output_min_, requested_output_max_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "RequantizePerChannel") do 
                desc = tf.NodeDescription("RequantizePerChannel")
                input_ = convert(Tensor{Float32}, input_)
                input_min_ = convert(Tensor{Float32}, input_min_)
                input_max_ = convert(Tensor{Float32}, input_max_)
                requested_output_min_ = convert(Tensor{Float32}, requested_output_min_)
                requested_output_max_ = convert(Tensor{Float32}, requested_output_max_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_min_)
                tf.add_input(desc, input_max_)
                tf.add_input(desc, requested_output_min_)
                tf.add_input(desc, requested_output_max_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function requantize_per_channel(input_::tf.TensorHandle, input_min_::tf.TensorHandle, input_max_::tf.TensorHandle, requested_output_min_::tf.TensorHandle, requested_output_max_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("RequantizePerChannel")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_min_)
        tf.add_input(desc, input_max_)
        tf.add_input(desc, requested_output_min_)
        tf.add_input(desc, requested_output_max_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     tensor_scatter_add(tensor, indices, updates)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_scatter_add(tensor_, indices_, updates_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorScatterAdd") do 
                desc = tf.NodeDescription("TensorScatterAdd")
                tensor_ = convert(Tensor{Any}, tensor_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (tensor_, updates_) = tf.tf_promote(tensor_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_scatter_add(tensor_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorScatterAdd")
        tf.add_input(desc, tensor_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        desc["T"] = tf.data_type(tensor_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     _var_handles_op()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _var_handles_op(; name=nothing, containers=nothing, shared_names=nothing, N=nothing, dtypes=nothing, shapes=nothing)
            local desc
            tf.with_op_name(name, "_VarHandlesOp") do 
                desc = tf.NodeDescription("_VarHandlesOp")
                if containers !== nothing
                    desc["containers"] = map(Base.identity, containers)
                end
                if shared_names !== nothing
                    desc["shared_names"] = map(Base.identity, shared_names)
                end
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:N
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function _var_handles_op(; name=nothing, containers=nothing, shared_names=nothing, N=nothing, dtypes=nothing, shapes=nothing)
        desc = tf.EagerOp("_VarHandlesOp")
        if containers !== nothing
            desc["containers"] = map(Base.identity, containers)
        end
        if shared_names !== nothing
            desc["shared_names"] = map(Base.identity, shared_names)
        end
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        tf.execute(desc)
    end
end


"""
     ifft3d(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ifft3d(input_; name=nothing)
            local desc
            tf.with_op_name(name, "IFFT3D") do 
                desc = tf.NodeDescription("IFFT3D")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ifft3d(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IFFT3D")
        tf.add_input(desc, input_)
        desc["Tcomplex"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     euclidean_norm(input, reduction_indices; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function euclidean_norm(input_, reduction_indices_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "EuclideanNorm") do 
                desc = tf.NodeDescription("EuclideanNorm")
                input_ = convert(Tensor{Any}, input_)
                reduction_indices_ = convert(Tensor{Int32}, reduction_indices_)
                reduction_indices_ = reduction_indices_ - convert(tf.Tensor{eltype(reduction_indices_)}, 1)
                (input_,) = tf.tf_promote(input_)
                (reduction_indices_,) = tf.tf_promote(reduction_indices_)
                tf.add_input(desc, input_)
                tf.add_input(desc, reduction_indices_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function euclidean_norm(input_::tf.TensorHandle, reduction_indices_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("EuclideanNorm")
        tf.add_input(desc, input_)
        tf.add_input(desc, reduction_indices_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tidx"] = tf.data_type(reduction_indices_)
        (tf.execute(desc))[1]
    end
end


"""
     ref_select(index, inputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ref_select(index_, inputs_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "RefSelect") do 
                desc = tf.NodeDescription("RefSelect")
                index_ = convert(Tensor{Int32}, index_)
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                (inputs_,) = tf.tf_promote(inputs_)
                tf.add_input(desc, index_)
                tf.add_input(desc, inputs_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ref_select(index_::tf.TensorHandle, inputs_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("RefSelect")
        tf.add_input(desc, index_)
        tf.add_input(desc, inputs_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(inputs_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_tensor_slice_dataset(indices, values, dense_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_tensor_slice_dataset(indices_, values_, dense_shape_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseTensorSliceDataset") do 
                desc = tf.NodeDescription("SparseTensorSliceDataset")
                indices_ = convert(Tensor{Int64}, indices_)
                values_ = convert(Tensor{Any}, values_)
                dense_shape_ = convert(Tensor{Int64}, dense_shape_)
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, values_)
                tf.add_input(desc, dense_shape_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_tensor_slice_dataset(indices_::tf.TensorHandle, values_::tf.TensorHandle, dense_shape_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseTensorSliceDataset")
        tf.add_input(desc, indices_)
        tf.add_input(desc, values_)
        tf.add_input(desc, dense_shape_)
        desc["Tvalues"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_ftrl_parameters_grad_accum_debug(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_ftrl_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingFTRLParametersGradAccumDebug") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingFTRLParametersGradAccumDebug")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_ftrl_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingFTRLParametersGradAccumDebug")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     batch_ifft2d(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_ifft2d(input_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchIFFT2D") do 
                desc = tf.NodeDescription("BatchIFFT2D")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_ifft2d(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchIFFT2D")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_gather(handle, indices, flow_in; element_shape=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_gather(handle_, indices_, flow_in_; name=nothing, dtype=nothing, element_shape=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayGather") do 
                desc = tf.NodeDescription("TensorArrayGather")
                handle_ = convert(Tensor{String}, handle_)
                indices_ = convert(Tensor{Int32}, indices_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, flow_in_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if element_shape !== nothing
                    desc["element_shape"] = Base.identity(element_shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_gather(handle_::tf.TensorHandle, indices_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, dtype=nothing, element_shape=nothing)
        desc = tf.EagerOp("TensorArrayGather")
        tf.add_input(desc, handle_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, flow_in_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if element_shape !== nothing
            desc["element_shape"] = Base.identity(element_shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_segment_mean_with_num_segments(data, indices, segment_ids, num_segments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_segment_mean_with_num_segments(data_, indices_, segment_ids_, num_segments_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSegmentMeanWithNumSegments") do 
                desc = tf.NodeDescription("SparseSegmentMeanWithNumSegments")
                data_ = convert(Tensor{Any}, data_)
                indices_ = convert(Tensor{Int32}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                segment_ids_ = convert(Tensor{Int32}, segment_ids_)
                num_segments_ = convert(Tensor{Int32}, num_segments_)
                (num_segments_,) = tf.tf_promote(num_segments_)
                (data_,) = tf.tf_promote(data_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, data_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, segment_ids_)
                tf.add_input(desc, num_segments_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_segment_mean_with_num_segments(data_::tf.TensorHandle, indices_::tf.TensorHandle, segment_ids_::tf.TensorHandle, num_segments_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSegmentMeanWithNumSegments")
        tf.add_input(desc, data_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, segment_ids_)
        tf.add_input(desc, num_segments_)
        desc["T"] = tf.data_type(data_)
        desc["Tidx"] = tf.data_type(indices_)
        desc["Tnumsegments"] = tf.data_type(num_segments_)
        (tf.execute(desc))[1]
    end
end


"""
     ensure_shape(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ensure_shape(input_; name=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "EnsureShape") do 
                desc = tf.NodeDescription("EnsureShape")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ensure_shape(input_::tf.TensorHandle; name=nothing, shape=nothing)
        desc = tf.EagerOp("EnsureShape")
        tf.add_input(desc, input_)
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     apply_proximal_gradient_descent(var, alpha, l1, l2, delta; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_proximal_gradient_descent(var_, alpha_, l1_, l2_, delta_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyProximalGradientDescent") do 
                desc = tf.NodeDescription("ApplyProximalGradientDescent")
                var_ = convert(Tensor{Any}, var_)
                alpha_ = convert(Tensor{Any}, alpha_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                delta_ = convert(Tensor{Any}, delta_)
                (var_, alpha_, l1_, l2_, delta_) = tf.tf_promote(var_, alpha_, l1_, l2_, delta_)
                tf.add_input(desc, var_)
                tf.add_input(desc, alpha_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, delta_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_proximal_gradient_descent(var_::tf.TensorHandle, alpha_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, delta_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyProximalGradientDescent")
        tf.add_input(desc, var_)
        tf.add_input(desc, alpha_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, delta_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(alpha_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(delta_)
        (tf.execute(desc))[1]
    end
end


"""
     collective_reduce(input; wait_for=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function collective_reduce(input_; name=nothing, group_size=nothing, group_key=nothing, instance_key=nothing, merge_op=nothing, final_op=nothing, subdiv_offsets=nothing, wait_for=nothing)
            local desc
            tf.with_op_name(name, "CollectiveReduce") do 
                desc = tf.NodeDescription("CollectiveReduce")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if group_size !== nothing
                    desc["group_size"] = Base.Int(group_size)
                end
                if group_key !== nothing
                    desc["group_key"] = Base.Int(group_key)
                end
                if instance_key !== nothing
                    desc["instance_key"] = Base.Int(instance_key)
                end
                if merge_op !== nothing
                    desc["merge_op"] = Base.String(merge_op)
                end
                if final_op !== nothing
                    desc["final_op"] = Base.String(final_op)
                end
                if subdiv_offsets !== nothing
                    desc["subdiv_offsets"] = map(Base.identity, subdiv_offsets)
                end
                if wait_for !== nothing
                    desc["wait_for"] = map(Base.identity, wait_for)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function collective_reduce(input_::tf.TensorHandle; name=nothing, group_size=nothing, group_key=nothing, instance_key=nothing, merge_op=nothing, final_op=nothing, subdiv_offsets=nothing, wait_for=nothing)
        desc = tf.EagerOp("CollectiveReduce")
        tf.add_input(desc, input_)
        if group_size !== nothing
            desc["group_size"] = Base.Int(group_size)
        end
        if group_key !== nothing
            desc["group_key"] = Base.Int(group_key)
        end
        if instance_key !== nothing
            desc["instance_key"] = Base.Int(instance_key)
        end
        if merge_op !== nothing
            desc["merge_op"] = Base.String(merge_op)
        end
        if final_op !== nothing
            desc["final_op"] = Base.String(final_op)
        end
        if subdiv_offsets !== nothing
            desc["subdiv_offsets"] = map(Base.identity, subdiv_offsets)
        end
        if wait_for !== nothing
            desc["wait_for"] = map(Base.identity, wait_for)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     is_nan(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function is_nan(x_; name=nothing)
            local desc
            tf.with_op_name(name, "IsNan") do 
                desc = tf.NodeDescription("IsNan")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function is_nan(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IsNan")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     apply_ada_max(var, m, v, beta1_power, lr, beta1, beta2, epsilon, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_ada_max(var_, m_, v_, beta1_power_, lr_, beta1_, beta2_, epsilon_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyAdaMax") do 
                desc = tf.NodeDescription("ApplyAdaMax")
                var_ = convert(Tensor{Any}, var_)
                m_ = convert(Tensor{Any}, m_)
                v_ = convert(Tensor{Any}, v_)
                beta1_power_ = convert(Tensor{Any}, beta1_power_)
                lr_ = convert(Tensor{Any}, lr_)
                beta1_ = convert(Tensor{Any}, beta1_)
                beta2_ = convert(Tensor{Any}, beta2_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                (var_, m_, v_, beta1_power_, lr_, beta1_, beta2_, epsilon_, grad_) = tf.tf_promote(var_, m_, v_, beta1_power_, lr_, beta1_, beta2_, epsilon_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, m_)
                tf.add_input(desc, v_)
                tf.add_input(desc, beta1_power_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, beta1_)
                tf.add_input(desc, beta2_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_ada_max(var_::tf.TensorHandle, m_::tf.TensorHandle, v_::tf.TensorHandle, beta1_power_::tf.TensorHandle, lr_::tf.TensorHandle, beta1_::tf.TensorHandle, beta2_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyAdaMax")
        tf.add_input(desc, var_)
        tf.add_input(desc, m_)
        tf.add_input(desc, v_)
        tf.add_input(desc, beta1_power_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, beta1_)
        tf.add_input(desc, beta2_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(m_)
        desc["T"] = tf.data_type(v_)
        desc["T"] = tf.data_type(beta1_power_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(beta1_)
        desc["T"] = tf.data_type(beta2_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     decode_and_crop_jpeg(contents, crop_window; channels=0, ratio=1, fancy_upscaling=true, try_recover_truncated=false, acceptable_fraction=?, dct_method=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_and_crop_jpeg(contents_, crop_window_; name=nothing, channels=nothing, ratio=nothing, fancy_upscaling=nothing, try_recover_truncated=nothing, acceptable_fraction=nothing, dct_method=nothing)
            local desc
            tf.with_op_name(name, "DecodeAndCropJpeg") do 
                desc = tf.NodeDescription("DecodeAndCropJpeg")
                contents_ = convert(Tensor{String}, contents_)
                crop_window_ = convert(Tensor{Int32}, crop_window_)
                tf.add_input(desc, contents_)
                tf.add_input(desc, crop_window_)
                if channels !== nothing
                    desc["channels"] = Base.Int(channels)
                end
                if ratio !== nothing
                    desc["ratio"] = Base.Int(ratio)
                end
                if fancy_upscaling !== nothing
                    desc["fancy_upscaling"] = Base.Bool(fancy_upscaling)
                end
                if try_recover_truncated !== nothing
                    desc["try_recover_truncated"] = Base.Bool(try_recover_truncated)
                end
                if acceptable_fraction !== nothing
                    desc["acceptable_fraction"] = Base.identity(acceptable_fraction)
                end
                if dct_method !== nothing
                    desc["dct_method"] = Base.String(dct_method)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function decode_and_crop_jpeg(contents_::tf.TensorHandle, crop_window_::tf.TensorHandle; name=nothing, channels=nothing, ratio=nothing, fancy_upscaling=nothing, try_recover_truncated=nothing, acceptable_fraction=nothing, dct_method=nothing)
        desc = tf.EagerOp("DecodeAndCropJpeg")
        tf.add_input(desc, contents_)
        tf.add_input(desc, crop_window_)
        if channels !== nothing
            desc["channels"] = Base.Int(channels)
        end
        if ratio !== nothing
            desc["ratio"] = Base.Int(ratio)
        end
        if fancy_upscaling !== nothing
            desc["fancy_upscaling"] = Base.Bool(fancy_upscaling)
        end
        if try_recover_truncated !== nothing
            desc["try_recover_truncated"] = Base.Bool(try_recover_truncated)
        end
        if acceptable_fraction !== nothing
            desc["acceptable_fraction"] = Base.identity(acceptable_fraction)
        end
        if dct_method !== nothing
            desc["dct_method"] = Base.String(dct_method)
        end
        (tf.execute(desc))[1]
    end
end


"""
     apply_centered_rms_prop(var, mg, ms, mom, lr, rho, momentum, epsilon, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_centered_rms_prop(var_, mg_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyCenteredRMSProp") do 
                desc = tf.NodeDescription("ApplyCenteredRMSProp")
                var_ = convert(Tensor{Any}, var_)
                mg_ = convert(Tensor{Any}, mg_)
                ms_ = convert(Tensor{Any}, ms_)
                mom_ = convert(Tensor{Any}, mom_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                momentum_ = convert(Tensor{Any}, momentum_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                (var_, mg_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_) = tf.tf_promote(var_, mg_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, mg_)
                tf.add_input(desc, ms_)
                tf.add_input(desc, mom_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, momentum_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_centered_rms_prop(var_::tf.TensorHandle, mg_::tf.TensorHandle, ms_::tf.TensorHandle, mom_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, momentum_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyCenteredRMSProp")
        tf.add_input(desc, var_)
        tf.add_input(desc, mg_)
        tf.add_input(desc, ms_)
        tf.add_input(desc, mom_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, momentum_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(mg_)
        desc["T"] = tf.data_type(ms_)
        desc["T"] = tf.data_type(mom_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(momentum_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     conv3d_backprop_filter_v2(input, filter_sizes, out_backprop; data_format=NDHWC, dilations=[1, 1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function conv3d_backprop_filter_v2(input_, filter_sizes_, out_backprop_; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "Conv3DBackpropFilterV2") do 
                desc = tf.NodeDescription("Conv3DBackpropFilterV2")
                input_ = convert(Tensor{Any}, input_)
                filter_sizes_ = convert(Tensor{Int32}, filter_sizes_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                (input_, out_backprop_) = tf.tf_promote(input_, out_backprop_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_sizes_)
                tf.add_input(desc, out_backprop_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function conv3d_backprop_filter_v2(input_::tf.TensorHandle, filter_sizes_::tf.TensorHandle, out_backprop_::tf.TensorHandle; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
        desc = tf.EagerOp("Conv3DBackpropFilterV2")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_sizes_)
        tf.add_input(desc, out_backprop_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     matrix_triangular_solve(matrix, rhs; lower=true, adjoint=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_triangular_solve(matrix_, rhs_; name=nothing, lower=nothing, adjoint=nothing)
            local desc
            tf.with_op_name(name, "MatrixTriangularSolve") do 
                desc = tf.NodeDescription("MatrixTriangularSolve")
                matrix_ = convert(Tensor{Any}, matrix_)
                rhs_ = convert(Tensor{Any}, rhs_)
                (matrix_, rhs_) = tf.tf_promote(matrix_, rhs_)
                tf.add_input(desc, matrix_)
                tf.add_input(desc, rhs_)
                if lower !== nothing
                    desc["lower"] = Base.Bool(lower)
                end
                if adjoint !== nothing
                    desc["adjoint"] = Base.Bool(adjoint)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_triangular_solve(matrix_::tf.TensorHandle, rhs_::tf.TensorHandle; name=nothing, lower=nothing, adjoint=nothing)
        desc = tf.EagerOp("MatrixTriangularSolve")
        tf.add_input(desc, matrix_)
        tf.add_input(desc, rhs_)
        if lower !== nothing
            desc["lower"] = Base.Bool(lower)
        end
        if adjoint !== nothing
            desc["adjoint"] = Base.Bool(adjoint)
        end
        desc["T"] = tf.data_type(matrix_)
        desc["T"] = tf.data_type(rhs_)
        (tf.execute(desc))[1]
    end
end


"""
     reader_num_work_units_completed(reader_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_num_work_units_completed(reader_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderNumWorkUnitsCompleted") do 
                desc = tf.NodeDescription("ReaderNumWorkUnitsCompleted")
                reader_handle_ = convert(Tensor{String}, reader_handle_)
                tf.add_input(desc, reader_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reader_num_work_units_completed(reader_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderNumWorkUnitsCompleted")
        tf.add_input(desc, reader_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     write_audio_summary(writer, step, tag, tensor, sample_rate; max_outputs=3)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function write_audio_summary(writer_, step_, tag_, tensor_, sample_rate_; name=nothing, max_outputs=nothing)
            local desc
            tf.with_op_name(name, "WriteAudioSummary") do 
                desc = tf.NodeDescription("WriteAudioSummary")
                writer_ = convert(Tensor{Any}, writer_)
                step_ = convert(Tensor{Int64}, step_)
                tag_ = convert(Tensor{String}, tag_)
                tensor_ = convert(Tensor{Float32}, tensor_)
                sample_rate_ = convert(Tensor{Float32}, sample_rate_)
                tf.add_input(desc, writer_)
                tf.add_input(desc, step_)
                tf.add_input(desc, tag_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, sample_rate_)
                if max_outputs !== nothing
                    desc["max_outputs"] = Base.Int(max_outputs)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function write_audio_summary(writer_::tf.TensorHandle, step_::tf.TensorHandle, tag_::tf.TensorHandle, tensor_::tf.TensorHandle, sample_rate_::tf.TensorHandle; name=nothing, max_outputs=nothing)
        desc = tf.EagerOp("WriteAudioSummary")
        tf.add_input(desc, writer_)
        tf.add_input(desc, step_)
        tf.add_input(desc, tag_)
        tf.add_input(desc, tensor_)
        tf.add_input(desc, sample_rate_)
        if max_outputs !== nothing
            desc["max_outputs"] = Base.Int(max_outputs)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sharded_filespec(basename, num_shards)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sharded_filespec(basename_, num_shards_; name=nothing)
            local desc
            tf.with_op_name(name, "ShardedFilespec") do 
                desc = tf.NodeDescription("ShardedFilespec")
                basename_ = convert(Tensor{String}, basename_)
                num_shards_ = convert(Tensor{Int32}, num_shards_)
                tf.add_input(desc, basename_)
                tf.add_input(desc, num_shards_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sharded_filespec(basename_::tf.TensorHandle, num_shards_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ShardedFilespec")
        tf.add_input(desc, basename_)
        tf.add_input(desc, num_shards_)
        (tf.execute(desc))[1]
    end
end


"""
     div_no_nan(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function div_no_nan(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "DivNoNan") do 
                desc = tf.NodeDescription("DivNoNan")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function div_no_nan(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DivNoNan")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_accumulator_apply_gradient(handle, local_step, gradient_indices, gradient_values, gradient_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_accumulator_apply_gradient(handle_, local_step_, gradient_indices_, gradient_values_, gradient_shape_; name=nothing, dtype=nothing, has_known_shape=nothing)
            local desc
            tf.with_op_name(name, "SparseAccumulatorApplyGradient") do 
                desc = tf.NodeDescription("SparseAccumulatorApplyGradient")
                handle_ = convert(Tensor{String}, handle_)
                local_step_ = convert(Tensor{Int64}, local_step_)
                gradient_indices_ = convert(Tensor{Int64}, gradient_indices_)
                gradient_values_ = convert(Tensor{Any}, gradient_values_)
                gradient_shape_ = convert(Tensor{Int64}, gradient_shape_)
                (gradient_values_,) = tf.tf_promote(gradient_values_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, local_step_)
                tf.add_input(desc, gradient_indices_)
                tf.add_input(desc, gradient_values_)
                tf.add_input(desc, gradient_shape_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if has_known_shape !== nothing
                    desc["has_known_shape"] = Base.Bool(has_known_shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_accumulator_apply_gradient(handle_::tf.TensorHandle, local_step_::tf.TensorHandle, gradient_indices_::tf.TensorHandle, gradient_values_::tf.TensorHandle, gradient_shape_::tf.TensorHandle; name=nothing, dtype=nothing, has_known_shape=nothing)
        desc = tf.EagerOp("SparseAccumulatorApplyGradient")
        tf.add_input(desc, handle_)
        tf.add_input(desc, local_step_)
        tf.add_input(desc, gradient_indices_)
        tf.add_input(desc, gradient_values_)
        tf.add_input(desc, gradient_shape_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if has_known_shape !== nothing
            desc["has_known_shape"] = Base.Bool(has_known_shape)
        end
        desc["dtype"] = tf.data_type(gradient_values_)
        (tf.execute(desc))[1]
    end
end


"""
     ragged_tensor_to_sparse(rt_nested_splits, rt_dense_values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ragged_tensor_to_sparse(rt_nested_splits_, rt_dense_values_; name=nothing, RAGGED_RANK=nothing)
            local desc
            tf.with_op_name(name, "RaggedTensorToSparse") do 
                desc = tf.NodeDescription("RaggedTensorToSparse")
                rt_nested_splits_ = [convert(Tensor{Int64}, x) for x = rt_nested_splits_]
                rt_dense_values_ = convert(Tensor{Any}, rt_dense_values_)
                (rt_dense_values_,) = tf.tf_promote(rt_dense_values_)
                tf.add_input(desc, rt_nested_splits_)
                tf.add_input(desc, rt_dense_values_)
                if RAGGED_RANK !== nothing
                    desc["RAGGED_RANK"] = Base.Int(RAGGED_RANK)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function ragged_tensor_to_sparse(rt_nested_splits_::tf.TensorHandle, rt_dense_values_::tf.TensorHandle; name=nothing, RAGGED_RANK=nothing)
        desc = tf.EagerOp("RaggedTensorToSparse")
        tf.add_input(desc, rt_nested_splits_)
        tf.add_input(desc, rt_dense_values_)
        if RAGGED_RANK !== nothing
            desc["RAGGED_RANK"] = Base.Int(RAGGED_RANK)
        end
        desc["T"] = tf.data_type(rt_dense_values_)
        tf.execute(desc)
    end
end


"""
     extract_volume_patches(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function extract_volume_patches(input_; name=nothing, ksizes=nothing, strides=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "ExtractVolumePatches") do 
                desc = tf.NodeDescription("ExtractVolumePatches")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if ksizes !== nothing
                    desc["ksizes"] = map(Base.identity, ksizes)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function extract_volume_patches(input_::tf.TensorHandle; name=nothing, ksizes=nothing, strides=nothing, padding=nothing)
        desc = tf.EagerOp("ExtractVolumePatches")
        tf.add_input(desc, input_)
        if ksizes !== nothing
            desc["ksizes"] = map(Base.identity, ksizes)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     barrier_insert_many(handle, keys, values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function barrier_insert_many(handle_, keys_, values_; name=nothing, component_index=nothing)
            local desc
            tf.with_op_name(name, "BarrierInsertMany") do 
                desc = tf.NodeDescription("BarrierInsertMany")
                handle_ = convert(Tensor{String}, handle_)
                keys_ = convert(Tensor{String}, keys_)
                values_ = convert(Tensor{Any}, values_)
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, keys_)
                tf.add_input(desc, values_)
                if component_index !== nothing
                    component_index = Base.Int(component_index) - 1
                end
                if component_index !== nothing
                    desc["component_index"] = Base.Int(component_index)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function barrier_insert_many(handle_::tf.TensorHandle, keys_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing, component_index=nothing)
        desc = tf.EagerOp("BarrierInsertMany")
        tf.add_input(desc, handle_)
        tf.add_input(desc, keys_)
        tf.add_input(desc, values_)
        if component_index !== nothing
            component_index = Base.Int(component_index) - 1
        end
        if component_index !== nothing
            desc["component_index"] = Base.Int(component_index)
        end
        desc["T"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     const_()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function const_(; name=nothing, value=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "Const") do 
                desc = tf.NodeDescription("Const")
                if value !== nothing
                    desc["value"] = TensorFlow.RawTensor(value)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function const_(; name=nothing, value=nothing, dtype=nothing)
        desc = tf.EagerOp("Const")
        if value !== nothing
            desc["value"] = TensorFlow.RawTensor(value)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     space_to_batch(input, paddings)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function space_to_batch(input_, paddings_; name=nothing, block_size=nothing)
            local desc
            tf.with_op_name(name, "SpaceToBatch") do 
                desc = tf.NodeDescription("SpaceToBatch")
                input_ = convert(Tensor{Any}, input_)
                paddings_ = convert(Tensor{Int32}, paddings_)
                (input_,) = tf.tf_promote(input_)
                (paddings_,) = tf.tf_promote(paddings_)
                tf.add_input(desc, input_)
                tf.add_input(desc, paddings_)
                if block_size !== nothing
                    desc["block_size"] = Base.Int(block_size)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function space_to_batch(input_::tf.TensorHandle, paddings_::tf.TensorHandle; name=nothing, block_size=nothing)
        desc = tf.EagerOp("SpaceToBatch")
        tf.add_input(desc, input_)
        tf.add_input(desc, paddings_)
        if block_size !== nothing
            desc["block_size"] = Base.Int(block_size)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tpaddings"] = tf.data_type(paddings_)
        (tf.execute(desc))[1]
    end
end


"""
     stage_size(; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stage_size(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "StageSize") do 
                desc = tf.NodeDescription("StageSize")
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stage_size(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("StageSize")
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     empty_tensor_list(element_shape, max_num_elements)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function empty_tensor_list(element_shape_, max_num_elements_; name=nothing, element_dtype=nothing, shape_type=nothing)
            local desc
            tf.with_op_name(name, "EmptyTensorList") do 
                desc = tf.NodeDescription("EmptyTensorList")
                element_shape_ = convert(Tensor{Any}, element_shape_)
                max_num_elements_ = convert(Tensor{Int32}, max_num_elements_)
                (element_shape_,) = tf.tf_promote(element_shape_)
                tf.add_input(desc, element_shape_)
                tf.add_input(desc, max_num_elements_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
                if shape_type !== nothing
                    desc["shape_type"] = Base.identity(shape_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function empty_tensor_list(element_shape_::tf.TensorHandle, max_num_elements_::tf.TensorHandle; name=nothing, element_dtype=nothing, shape_type=nothing)
        desc = tf.EagerOp("EmptyTensorList")
        tf.add_input(desc, element_shape_)
        tf.add_input(desc, max_num_elements_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        if shape_type !== nothing
            desc["shape_type"] = Base.identity(shape_type)
        end
        desc["shape_type"] = tf.data_type(element_shape_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_conv2d_and_requantize(input, filter, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output; out_type=Float32, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_conv2d_and_requantize(input_, filter_, min_input_, max_input_, min_filter_, max_filter_, min_freezed_output_, max_freezed_output_; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConv2DAndRequantize") do 
                desc = tf.NodeDescription("QuantizedConv2DAndRequantize")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_filter_ = convert(Tensor{Float32}, min_filter_)
                max_filter_ = convert(Tensor{Float32}, max_filter_)
                min_freezed_output_ = convert(Tensor{Float32}, min_freezed_output_)
                max_freezed_output_ = convert(Tensor{Float32}, max_freezed_output_)
                (filter_,) = tf.tf_promote(filter_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_filter_)
                tf.add_input(desc, max_filter_)
                tf.add_input(desc, min_freezed_output_)
                tf.add_input(desc, max_freezed_output_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_conv2d_and_requantize(input_::tf.TensorHandle, filter_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_filter_::tf.TensorHandle, max_filter_::tf.TensorHandle, min_freezed_output_::tf.TensorHandle, max_freezed_output_::tf.TensorHandle; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("QuantizedConv2DAndRequantize")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_filter_)
        tf.add_input(desc, max_filter_)
        tf.add_input(desc, min_freezed_output_)
        tf.add_input(desc, max_freezed_output_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tinput"] = tf.data_type(input_)
        desc["Tfilter"] = tf.data_type(filter_)
        tf.execute(desc)
    end
end


"""
     lu(input; output_idx_type=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lu(input_; name=nothing, output_idx_type=nothing)
            local desc
            tf.with_op_name(name, "Lu") do 
                desc = tf.NodeDescription("Lu")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if output_idx_type !== nothing
                    desc["output_idx_type"] = Base.identity(output_idx_type)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function lu(input_::tf.TensorHandle; name=nothing, output_idx_type=nothing)
        desc = tf.EagerOp("Lu")
        tf.add_input(desc, input_)
        if output_idx_type !== nothing
            desc["output_idx_type"] = Base.identity(output_idx_type)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     decode_compressed(bytes; compression_type=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_compressed(bytes_; name=nothing, compression_type=nothing)
            local desc
            tf.with_op_name(name, "DecodeCompressed") do 
                desc = tf.NodeDescription("DecodeCompressed")
                bytes_ = convert(Tensor{String}, bytes_)
                tf.add_input(desc, bytes_)
                if compression_type !== nothing
                    desc["compression_type"] = Base.String(compression_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function decode_compressed(bytes_::tf.TensorHandle; name=nothing, compression_type=nothing)
        desc = tf.EagerOp("DecodeCompressed")
        tf.add_input(desc, bytes_)
        if compression_type !== nothing
            desc["compression_type"] = Base.String(compression_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     get_session_tensor(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function get_session_tensor(handle_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "GetSessionTensor") do 
                desc = tf.NodeDescription("GetSessionTensor")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function get_session_tensor(handle_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("GetSessionTensor")
        tf.add_input(desc, handle_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_gather_v3(handle, indices, flow_in; element_shape=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_gather_v3(handle_, indices_, flow_in_; name=nothing, dtype=nothing, element_shape=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayGatherV3") do 
                desc = tf.NodeDescription("TensorArrayGatherV3")
                handle_ = convert(Tensor{Any}, handle_)
                indices_ = convert(Tensor{Int32}, indices_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, flow_in_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if element_shape !== nothing
                    desc["element_shape"] = Base.identity(element_shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_gather_v3(handle_::tf.TensorHandle, indices_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, dtype=nothing, element_shape=nothing)
        desc = tf.EagerOp("TensorArrayGatherV3")
        tf.add_input(desc, handle_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, flow_in_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if element_shape !== nothing
            desc["element_shape"] = Base.identity(element_shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_ftrl_parameters_grad_accum_debug(parameters, accumulators, linears, gradient_accumulators; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_ftrl_parameters_grad_accum_debug(parameters_, accumulators_, linears_, gradient_accumulators_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingFTRLParametersGradAccumDebug") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingFTRLParametersGradAccumDebug")
                parameters_ = convert(Tensor{Float32}, parameters_)
                accumulators_ = convert(Tensor{Float32}, accumulators_)
                linears_ = convert(Tensor{Float32}, linears_)
                gradient_accumulators_ = convert(Tensor{Float32}, gradient_accumulators_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, accumulators_)
                tf.add_input(desc, linears_)
                tf.add_input(desc, gradient_accumulators_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_ftrl_parameters_grad_accum_debug(parameters_::tf.TensorHandle, accumulators_::tf.TensorHandle, linears_::tf.TensorHandle, gradient_accumulators_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingFTRLParametersGradAccumDebug")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, accumulators_)
        tf.add_input(desc, linears_)
        tf.add_input(desc, gradient_accumulators_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     destroy_resource_op(resource; ignore_lookup_error=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function destroy_resource_op(resource_; name=nothing, ignore_lookup_error=nothing)
            local desc
            tf.with_op_name(name, "DestroyResourceOp") do 
                desc = tf.NodeDescription("DestroyResourceOp")
                resource_ = convert(Tensor{Any}, resource_)
                tf.add_input(desc, resource_)
                if ignore_lookup_error !== nothing
                    desc["ignore_lookup_error"] = Base.Bool(ignore_lookup_error)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function destroy_resource_op(resource_::tf.TensorHandle; name=nothing, ignore_lookup_error=nothing)
        desc = tf.EagerOp("DestroyResourceOp")
        tf.add_input(desc, resource_)
        if ignore_lookup_error !== nothing
            desc["ignore_lookup_error"] = Base.Bool(ignore_lookup_error)
        end
        (tf.execute(desc))[1]
    end
end


"""
     text_line_reader(; skip_header_lines=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function text_line_reader(; name=nothing, skip_header_lines=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "TextLineReader") do 
                desc = tf.NodeDescription("TextLineReader")
                if skip_header_lines !== nothing
                    desc["skip_header_lines"] = Base.Int(skip_header_lines)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function text_line_reader(; name=nothing, skip_header_lines=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("TextLineReader")
        if skip_header_lines !== nothing
            desc["skip_header_lines"] = Base.Int(skip_header_lines)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     create_summary_db_writer(writer, db_uri, experiment_name, run_name, user_name)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function create_summary_db_writer(writer_, db_uri_, experiment_name_, run_name_, user_name_; name=nothing)
            local desc
            tf.with_op_name(name, "CreateSummaryDbWriter") do 
                desc = tf.NodeDescription("CreateSummaryDbWriter")
                writer_ = convert(Tensor{Any}, writer_)
                db_uri_ = convert(Tensor{String}, db_uri_)
                experiment_name_ = convert(Tensor{String}, experiment_name_)
                run_name_ = convert(Tensor{String}, run_name_)
                user_name_ = convert(Tensor{String}, user_name_)
                tf.add_input(desc, writer_)
                tf.add_input(desc, db_uri_)
                tf.add_input(desc, experiment_name_)
                tf.add_input(desc, run_name_)
                tf.add_input(desc, user_name_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function create_summary_db_writer(writer_::tf.TensorHandle, db_uri_::tf.TensorHandle, experiment_name_::tf.TensorHandle, run_name_::tf.TensorHandle, user_name_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("CreateSummaryDbWriter")
        tf.add_input(desc, writer_)
        tf.add_input(desc, db_uri_)
        tf.add_input(desc, experiment_name_)
        tf.add_input(desc, run_name_)
        tf.add_input(desc, user_name_)
        (tf.execute(desc))[1]
    end
end


"""
     tanh_grad(y, dy)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tanh_grad(y_, dy_; name=nothing)
            local desc
            tf.with_op_name(name, "TanhGrad") do 
                desc = tf.NodeDescription("TanhGrad")
                y_ = convert(Tensor{Any}, y_)
                dy_ = convert(Tensor{Any}, dy_)
                (y_, dy_) = tf.tf_promote(y_, dy_)
                tf.add_input(desc, y_)
                tf.add_input(desc, dy_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tanh_grad(y_::tf.TensorHandle, dy_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TanhGrad")
        tf.add_input(desc, y_)
        tf.add_input(desc, dy_)
        desc["T"] = tf.data_type(y_)
        desc["T"] = tf.data_type(dy_)
        (tf.execute(desc))[1]
    end
end


"""
     decode_base64(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_base64(input_; name=nothing)
            local desc
            tf.with_op_name(name, "DecodeBase64") do 
                desc = tf.NodeDescription("DecodeBase64")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function decode_base64(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DecodeBase64")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     max_pool_grad_grad_v2(orig_input, orig_output, grad, ksize, strides; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool_grad_grad_v2(orig_input_, orig_output_, grad_, ksize_, strides_; name=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "MaxPoolGradGradV2") do 
                desc = tf.NodeDescription("MaxPoolGradGradV2")
                orig_input_ = convert(Tensor{Any}, orig_input_)
                orig_output_ = convert(Tensor{Any}, orig_output_)
                grad_ = convert(Tensor{Any}, grad_)
                ksize_ = convert(Tensor{Int32}, ksize_)
                strides_ = convert(Tensor{Int32}, strides_)
                (orig_input_, orig_output_, grad_) = tf.tf_promote(orig_input_, orig_output_, grad_)
                tf.add_input(desc, orig_input_)
                tf.add_input(desc, orig_output_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, ksize_)
                tf.add_input(desc, strides_)
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max_pool_grad_grad_v2(orig_input_::tf.TensorHandle, orig_output_::tf.TensorHandle, grad_::tf.TensorHandle, ksize_::tf.TensorHandle, strides_::tf.TensorHandle; name=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("MaxPoolGradGradV2")
        tf.add_input(desc, orig_input_)
        tf.add_input(desc, orig_output_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, ksize_)
        tf.add_input(desc, strides_)
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(orig_input_)
        desc["T"] = tf.data_type(orig_output_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     audio_summary_v2(tag, tensor, sample_rate; max_outputs=3)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function audio_summary_v2(tag_, tensor_, sample_rate_; name=nothing, max_outputs=nothing)
            local desc
            tf.with_op_name(name, "AudioSummaryV2") do 
                desc = tf.NodeDescription("AudioSummaryV2")
                tag_ = convert(Tensor{String}, tag_)
                tensor_ = convert(Tensor{Float32}, tensor_)
                sample_rate_ = convert(Tensor{Float32}, sample_rate_)
                tf.add_input(desc, tag_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, sample_rate_)
                if max_outputs !== nothing
                    desc["max_outputs"] = Base.Int(max_outputs)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function audio_summary_v2(tag_::tf.TensorHandle, tensor_::tf.TensorHandle, sample_rate_::tf.TensorHandle; name=nothing, max_outputs=nothing)
        desc = tf.EagerOp("AudioSummaryV2")
        tf.add_input(desc, tag_)
        tf.add_input(desc, tensor_)
        tf.add_input(desc, sample_rate_)
        if max_outputs !== nothing
            desc["max_outputs"] = Base.Int(max_outputs)
        end
        (tf.execute(desc))[1]
    end
end


"""
     stateful_partitioned_call(args; config=, config_proto=, executor_type=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stateful_partitioned_call(args_; name=nothing, Tin=nothing, Tout=nothing, f=nothing, config=nothing, config_proto=nothing, executor_type=nothing)
            local desc
            tf.with_op_name(name, "StatefulPartitionedCall") do 
                desc = tf.NodeDescription("StatefulPartitionedCall")
                args_ = [convert(Tensor{Any}, x) for x = args_]
                tf.add_input(desc, args_)
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if config !== nothing
                    desc["config"] = Base.String(config)
                end
                if config_proto !== nothing
                    desc["config_proto"] = Base.String(config_proto)
                end
                if executor_type !== nothing
                    desc["executor_type"] = Base.String(executor_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stateful_partitioned_call(args_::tf.TensorHandle; name=nothing, Tin=nothing, Tout=nothing, f=nothing, config=nothing, config_proto=nothing, executor_type=nothing)
        desc = tf.EagerOp("StatefulPartitionedCall")
        tf.add_input(desc, args_)
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if config !== nothing
            desc["config"] = Base.String(config)
        end
        if config_proto !== nothing
            desc["config_proto"] = Base.String(config_proto)
        end
        if executor_type !== nothing
            desc["executor_type"] = Base.String(executor_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     _scoped_allocator_concat(backing, inputs; reshape=false)

Acts like a Concat Op that merges multple tensors into one, however it must
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _scoped_allocator_concat(backing_, inputs_; name=nothing, shape=nothing, reshape=nothing, sa_name=nothing, id=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "_ScopedAllocatorConcat") do 
                desc = tf.NodeDescription("_ScopedAllocatorConcat")
                backing_ = convert(Tensor{Any}, backing_)
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                (backing_, inputs_) = tf.tf_promote(backing_, inputs_)
                tf.add_input(desc, backing_)
                tf.add_input(desc, inputs_)
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
                if reshape !== nothing
                    desc["reshape"] = Base.Bool(reshape)
                end
                if sa_name !== nothing
                    desc["sa_name"] = Base.String(sa_name)
                end
                if id !== nothing
                    desc["id"] = Base.Int(id)
                end
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _scoped_allocator_concat(backing_::tf.TensorHandle, inputs_::tf.TensorHandle; name=nothing, shape=nothing, reshape=nothing, sa_name=nothing, id=nothing, N=nothing)
        desc = tf.EagerOp("_ScopedAllocatorConcat")
        tf.add_input(desc, backing_)
        tf.add_input(desc, inputs_)
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        if reshape !== nothing
            desc["reshape"] = Base.Bool(reshape)
        end
        if sa_name !== nothing
            desc["sa_name"] = Base.String(sa_name)
        end
        if id !== nothing
            desc["id"] = Base.Int(id)
        end
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(backing_)
        desc["T"] = tf.data_type(inputs_)
        (tf.execute(desc))[1]
    end
end


"""
     fake_quant_with_min_max_args_gradient(gradients, inputs; min=?, max=?, num_bits=8, narrow_range=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fake_quant_with_min_max_args_gradient(gradients_, inputs_; name=nothing, min=nothing, max=nothing, num_bits=nothing, narrow_range=nothing)
            local desc
            tf.with_op_name(name, "FakeQuantWithMinMaxArgsGradient") do 
                desc = tf.NodeDescription("FakeQuantWithMinMaxArgsGradient")
                gradients_ = convert(Tensor{Float32}, gradients_)
                inputs_ = convert(Tensor{Float32}, inputs_)
                tf.add_input(desc, gradients_)
                tf.add_input(desc, inputs_)
                if min !== nothing
                    desc["min"] = Base.identity(min)
                end
                if max !== nothing
                    desc["max"] = Base.identity(max)
                end
                if num_bits !== nothing
                    desc["num_bits"] = Base.Int(num_bits)
                end
                if narrow_range !== nothing
                    desc["narrow_range"] = Base.Bool(narrow_range)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fake_quant_with_min_max_args_gradient(gradients_::tf.TensorHandle, inputs_::tf.TensorHandle; name=nothing, min=nothing, max=nothing, num_bits=nothing, narrow_range=nothing)
        desc = tf.EagerOp("FakeQuantWithMinMaxArgsGradient")
        tf.add_input(desc, gradients_)
        tf.add_input(desc, inputs_)
        if min !== nothing
            desc["min"] = Base.identity(min)
        end
        if max !== nothing
            desc["max"] = Base.identity(max)
        end
        if num_bits !== nothing
            desc["num_bits"] = Base.Int(num_bits)
        end
        if narrow_range !== nothing
            desc["narrow_range"] = Base.Bool(narrow_range)
        end
        (tf.execute(desc))[1]
    end
end


"""
     batch_svd(input; compute_uv=true, full_matrices=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_svd(input_; name=nothing, compute_uv=nothing, full_matrices=nothing)
            local desc
            tf.with_op_name(name, "BatchSvd") do 
                desc = tf.NodeDescription("BatchSvd")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if compute_uv !== nothing
                    desc["compute_uv"] = Base.Bool(compute_uv)
                end
                if full_matrices !== nothing
                    desc["full_matrices"] = Base.Bool(full_matrices)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function batch_svd(input_::tf.TensorHandle; name=nothing, compute_uv=nothing, full_matrices=nothing)
        desc = tf.EagerOp("BatchSvd")
        tf.add_input(desc, input_)
        if compute_uv !== nothing
            desc["compute_uv"] = Base.Bool(compute_uv)
        end
        if full_matrices !== nothing
            desc["full_matrices"] = Base.Bool(full_matrices)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     map_stage(key, indices, values; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function map_stage(key_, indices_, values_; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, fake_dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "MapStage") do 
                desc = tf.NodeDescription("MapStage")
                key_ = convert(Tensor{Int64}, key_)
                indices_ = convert(Tensor{Int32}, indices_)
                values_ = [convert(Tensor{Any}, x) for x = values_]
                tf.add_input(desc, key_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, values_)
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if fake_dtypes !== nothing
                    desc["fake_dtypes"] = map(Base.identity, fake_dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function map_stage(key_::tf.TensorHandle, indices_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, fake_dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("MapStage")
        tf.add_input(desc, key_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, values_)
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if fake_dtypes !== nothing
            desc["fake_dtypes"] = map(Base.identity, fake_dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_sparse_apply_ftrl(var, accum, linear, grad, indices, lr, l1, l2, lr_power; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_sparse_apply_ftrl(var_, accum_, linear_, grad_, indices_, lr_, l1_, l2_, lr_power_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceSparseApplyFtrl") do 
                desc = tf.NodeDescription("ResourceSparseApplyFtrl")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                linear_ = convert(Tensor{Any}, linear_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                lr_power_ = convert(Tensor{Any}, lr_power_)
                (grad_, lr_, l1_, l2_, lr_power_) = tf.tf_promote(grad_, lr_, l1_, l2_, lr_power_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, linear_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, lr_power_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_sparse_apply_ftrl(var_::tf.TensorHandle, accum_::tf.TensorHandle, linear_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, lr_power_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceSparseApplyFtrl")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, linear_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, lr_power_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(lr_power_)
        (tf.execute(desc))[1]
    end
end


"""
     resize_nearest_neighbor(images, size; align_corners=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resize_nearest_neighbor(images_, size_; name=nothing, align_corners=nothing)
            local desc
            tf.with_op_name(name, "ResizeNearestNeighbor") do 
                desc = tf.NodeDescription("ResizeNearestNeighbor")
                images_ = convert(Tensor{Any}, images_)
                size_ = convert(Tensor{Int32}, size_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                tf.add_input(desc, size_)
                if align_corners !== nothing
                    desc["align_corners"] = Base.Bool(align_corners)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resize_nearest_neighbor(images_::tf.TensorHandle, size_::tf.TensorHandle; name=nothing, align_corners=nothing)
        desc = tf.EagerOp("ResizeNearestNeighbor")
        tf.add_input(desc, images_)
        tf.add_input(desc, size_)
        if align_corners !== nothing
            desc["align_corners"] = Base.Bool(align_corners)
        end
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_csv_dataset(filenames, compression_type, buffer_size, header, field_delim, use_quote_delim, na_value, select_cols, record_defaults)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_csv_dataset(filenames_, compression_type_, buffer_size_, header_, field_delim_, use_quote_delim_, na_value_, select_cols_, record_defaults_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalCSVDataset") do 
                desc = tf.NodeDescription("ExperimentalCSVDataset")
                filenames_ = convert(Tensor{String}, filenames_)
                compression_type_ = convert(Tensor{String}, compression_type_)
                buffer_size_ = convert(Tensor{Int64}, buffer_size_)
                header_ = convert(Tensor{Bool}, header_)
                field_delim_ = convert(Tensor{String}, field_delim_)
                use_quote_delim_ = convert(Tensor{Bool}, use_quote_delim_)
                na_value_ = convert(Tensor{String}, na_value_)
                select_cols_ = convert(Tensor{Int64}, select_cols_)
                record_defaults_ = [convert(Tensor{Any}, x) for x = record_defaults_]
                tf.add_input(desc, filenames_)
                tf.add_input(desc, compression_type_)
                tf.add_input(desc, buffer_size_)
                tf.add_input(desc, header_)
                tf.add_input(desc, field_delim_)
                tf.add_input(desc, use_quote_delim_)
                tf.add_input(desc, na_value_)
                tf.add_input(desc, select_cols_)
                tf.add_input(desc, record_defaults_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_csv_dataset(filenames_::tf.TensorHandle, compression_type_::tf.TensorHandle, buffer_size_::tf.TensorHandle, header_::tf.TensorHandle, field_delim_::tf.TensorHandle, use_quote_delim_::tf.TensorHandle, na_value_::tf.TensorHandle, select_cols_::tf.TensorHandle, record_defaults_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalCSVDataset")
        tf.add_input(desc, filenames_)
        tf.add_input(desc, compression_type_)
        tf.add_input(desc, buffer_size_)
        tf.add_input(desc, header_)
        tf.add_input(desc, field_delim_)
        tf.add_input(desc, use_quote_delim_)
        tf.add_input(desc, na_value_)
        tf.add_input(desc, select_cols_)
        tf.add_input(desc, record_defaults_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     _mkl_mul(x, y, mkl_x, mkl_y)

Returns x * y element-wise.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _mkl_mul(x_, y_, mkl_x_, mkl_y_; name=nothing)
            local desc
            tf.with_op_name(name, "_MklMul") do 
                desc = tf.NodeDescription("_MklMul")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                mkl_x_ = convert(Tensor{UInt8}, mkl_x_)
                mkl_y_ = convert(Tensor{UInt8}, mkl_y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
                tf.add_input(desc, mkl_x_)
                tf.add_input(desc, mkl_y_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function _mkl_mul(x_::tf.TensorHandle, y_::tf.TensorHandle, mkl_x_::tf.TensorHandle, mkl_y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("_MklMul")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        tf.add_input(desc, mkl_x_)
        tf.add_input(desc, mkl_y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        tf.execute(desc)
    end
end


"""
     batch_matrix_diag(diagonal)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_matrix_diag(diagonal_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchMatrixDiag") do 
                desc = tf.NodeDescription("BatchMatrixDiag")
                diagonal_ = convert(Tensor{Any}, diagonal_)
                (diagonal_,) = tf.tf_promote(diagonal_)
                tf.add_input(desc, diagonal_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_matrix_diag(diagonal_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchMatrixDiag")
        tf.add_input(desc, diagonal_)
        desc["T"] = tf.data_type(diagonal_)
        (tf.execute(desc))[1]
    end
end


"""
     is_inf(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function is_inf(x_; name=nothing)
            local desc
            tf.with_op_name(name, "IsInf") do 
                desc = tf.NodeDescription("IsInf")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function is_inf(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IsInf")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     fixed_unigram_candidate_sampler(true_classes; vocab_file=, distortion=?, num_reserved_ids=0, num_shards=1, shard=0, unigrams=Int64[], seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fixed_unigram_candidate_sampler(true_classes_; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, range_max=nothing, vocab_file=nothing, distortion=nothing, num_reserved_ids=nothing, num_shards=nothing, shard=nothing, unigrams=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "FixedUnigramCandidateSampler") do 
                desc = tf.NodeDescription("FixedUnigramCandidateSampler")
                true_classes_ = convert(Tensor{Int64}, true_classes_)
                tf.add_input(desc, true_classes_)
                if num_true !== nothing
                    desc["num_true"] = Base.Int(num_true)
                end
                if num_sampled !== nothing
                    desc["num_sampled"] = Base.Int(num_sampled)
                end
                if unique !== nothing
                    desc["unique"] = Base.Bool(unique)
                end
                if range_max !== nothing
                    desc["range_max"] = Base.Int(range_max)
                end
                if vocab_file !== nothing
                    desc["vocab_file"] = Base.String(vocab_file)
                end
                if distortion !== nothing
                    desc["distortion"] = Base.identity(distortion)
                end
                if num_reserved_ids !== nothing
                    desc["num_reserved_ids"] = Base.Int(num_reserved_ids)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard !== nothing
                    desc["shard"] = Base.Int(shard)
                end
                if unigrams !== nothing
                    desc["unigrams"] = map(Base.identity, unigrams)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function fixed_unigram_candidate_sampler(true_classes_::tf.TensorHandle; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, range_max=nothing, vocab_file=nothing, distortion=nothing, num_reserved_ids=nothing, num_shards=nothing, shard=nothing, unigrams=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("FixedUnigramCandidateSampler")
        tf.add_input(desc, true_classes_)
        if num_true !== nothing
            desc["num_true"] = Base.Int(num_true)
        end
        if num_sampled !== nothing
            desc["num_sampled"] = Base.Int(num_sampled)
        end
        if unique !== nothing
            desc["unique"] = Base.Bool(unique)
        end
        if range_max !== nothing
            desc["range_max"] = Base.Int(range_max)
        end
        if vocab_file !== nothing
            desc["vocab_file"] = Base.String(vocab_file)
        end
        if distortion !== nothing
            desc["distortion"] = Base.identity(distortion)
        end
        if num_reserved_ids !== nothing
            desc["num_reserved_ids"] = Base.Int(num_reserved_ids)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard !== nothing
            desc["shard"] = Base.Int(shard)
        end
        if unigrams !== nothing
            desc["unigrams"] = map(Base.identity, unigrams)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        tf.execute(desc)
    end
end


"""
     sparse_apply_ftrl_v2(var, accum, linear, grad, indices, lr, l1, l2, l2_shrinkage, lr_power; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_apply_ftrl_v2(var_, accum_, linear_, grad_, indices_, lr_, l1_, l2_, l2_shrinkage_, lr_power_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "SparseApplyFtrlV2") do 
                desc = tf.NodeDescription("SparseApplyFtrlV2")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                linear_ = convert(Tensor{Any}, linear_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                l2_shrinkage_ = convert(Tensor{Any}, l2_shrinkage_)
                lr_power_ = convert(Tensor{Any}, lr_power_)
                (var_, accum_, linear_, grad_, lr_, l1_, l2_, l2_shrinkage_, lr_power_) = tf.tf_promote(var_, accum_, linear_, grad_, lr_, l1_, l2_, l2_shrinkage_, lr_power_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, linear_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, l2_shrinkage_)
                tf.add_input(desc, lr_power_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_apply_ftrl_v2(var_::tf.TensorHandle, accum_::tf.TensorHandle, linear_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, l2_shrinkage_::tf.TensorHandle, lr_power_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("SparseApplyFtrlV2")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, linear_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, l2_shrinkage_)
        tf.add_input(desc, lr_power_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(linear_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(l2_shrinkage_)
        desc["T"] = tf.data_type(lr_power_)
        (tf.execute(desc))[1]
    end
end


"""
     unravel_index(indices, dims)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unravel_index(indices_, dims_; name=nothing)
            local desc
            tf.with_op_name(name, "UnravelIndex") do 
                desc = tf.NodeDescription("UnravelIndex")
                indices_ = convert(Tensor{Int32}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                dims_ = convert(Tensor{Int32}, dims_)
                dims_ = dims_ - convert(tf.Tensor{eltype(dims_)}, 1)
                (indices_, dims_) = tf.tf_promote(indices_, dims_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, dims_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unravel_index(indices_::tf.TensorHandle, dims_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("UnravelIndex")
        tf.add_input(desc, indices_)
        tf.add_input(desc, dims_)
        desc["Tidx"] = tf.data_type(indices_)
        desc["Tidx"] = tf.data_type(dims_)
        (tf.execute(desc))[1]
    end
end


"""
     max(input, reduction_indices; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max(input_, reduction_indices_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "Max") do 
                desc = tf.NodeDescription("Max")
                input_ = convert(Tensor{Any}, input_)
                reduction_indices_ = convert(Tensor{Int32}, reduction_indices_)
                reduction_indices_ = reduction_indices_ - convert(tf.Tensor{eltype(reduction_indices_)}, 1)
                (input_,) = tf.tf_promote(input_)
                (reduction_indices_,) = tf.tf_promote(reduction_indices_)
                tf.add_input(desc, input_)
                tf.add_input(desc, reduction_indices_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max(input_::tf.TensorHandle, reduction_indices_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("Max")
        tf.add_input(desc, input_)
        tf.add_input(desc, reduction_indices_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tidx"] = tf.data_type(reduction_indices_)
        (tf.execute(desc))[1]
    end
end


"""
     ifft2d(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ifft2d(input_; name=nothing)
            local desc
            tf.with_op_name(name, "IFFT2D") do 
                desc = tf.NodeDescription("IFFT2D")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ifft2d(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IFFT2D")
        tf.add_input(desc, input_)
        desc["Tcomplex"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_concat(indices, values, shapes)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_concat(indices_, values_, shapes_; name=nothing, concat_dim=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "SparseConcat") do 
                desc = tf.NodeDescription("SparseConcat")
                indices_ = [convert(Tensor{Int64}, x) for x = indices_]
                values_ = [convert(Tensor{Any}, x) for x = values_]
                shapes_ = [convert(Tensor{Int64}, x) for x = shapes_]
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, values_)
                tf.add_input(desc, shapes_)
                if concat_dim !== nothing
                    concat_dim = Base.Int(concat_dim) - 1
                end
                if concat_dim !== nothing
                    desc["concat_dim"] = Base.Int(concat_dim)
                end
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_concat(indices_::tf.TensorHandle, values_::tf.TensorHandle, shapes_::tf.TensorHandle; name=nothing, concat_dim=nothing, N=nothing)
        desc = tf.EagerOp("SparseConcat")
        tf.add_input(desc, indices_)
        tf.add_input(desc, values_)
        tf.add_input(desc, shapes_)
        if concat_dim !== nothing
            concat_dim = Base.Int(concat_dim) - 1
        end
        if concat_dim !== nothing
            desc["concat_dim"] = Base.Int(concat_dim)
        end
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(values_)
        tf.execute(desc)
    end
end


"""
     histogram_summary(tag, values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function histogram_summary(tag_, values_; name=nothing)
            local desc
            tf.with_op_name(name, "HistogramSummary") do 
                desc = tf.NodeDescription("HistogramSummary")
                tag_ = convert(Tensor{String}, tag_)
                values_ = convert(Tensor{Float32}, values_)
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, tag_)
                tf.add_input(desc, values_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function histogram_summary(tag_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("HistogramSummary")
        tf.add_input(desc, tag_)
        tf.add_input(desc, values_)
        desc["T"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     segment_sum(data, segment_ids)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function segment_sum(data_, segment_ids_; name=nothing)
            local desc
            tf.with_op_name(name, "SegmentSum") do 
                desc = tf.NodeDescription("SegmentSum")
                data_ = convert(Tensor{Any}, data_)
                segment_ids_ = convert(Tensor{Any}, segment_ids_)
                segment_ids_ = segment_ids_ - convert(tf.Tensor{eltype(segment_ids_)}, 1)
                (data_,) = tf.tf_promote(data_)
                (segment_ids_,) = tf.tf_promote(segment_ids_)
                tf.add_input(desc, data_)
                tf.add_input(desc, segment_ids_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function segment_sum(data_::tf.TensorHandle, segment_ids_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SegmentSum")
        tf.add_input(desc, data_)
        tf.add_input(desc, segment_ids_)
        desc["T"] = tf.data_type(data_)
        desc["Tindices"] = tf.data_type(segment_ids_)
        (tf.execute(desc))[1]
    end
end


"""
     exp(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function exp(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Exp") do 
                desc = tf.NodeDescription("Exp")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function exp(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Exp")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     configure_distributed_tpu(; embedding_config=, tpu_embedding_config=, is_global_init=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function configure_distributed_tpu(; name=nothing, embedding_config=nothing, tpu_embedding_config=nothing, is_global_init=nothing)
            local desc
            tf.with_op_name(name, "ConfigureDistributedTPU") do 
                desc = tf.NodeDescription("ConfigureDistributedTPU")
                if embedding_config !== nothing
                    desc["embedding_config"] = Base.String(embedding_config)
                end
                if tpu_embedding_config !== nothing
                    desc["tpu_embedding_config"] = Base.String(tpu_embedding_config)
                end
                if is_global_init !== nothing
                    desc["is_global_init"] = Base.Bool(is_global_init)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function configure_distributed_tpu(; name=nothing, embedding_config=nothing, tpu_embedding_config=nothing, is_global_init=nothing)
        desc = tf.EagerOp("ConfigureDistributedTPU")
        if embedding_config !== nothing
            desc["embedding_config"] = Base.String(embedding_config)
        end
        if tpu_embedding_config !== nothing
            desc["tpu_embedding_config"] = Base.String(tpu_embedding_config)
        end
        if is_global_init !== nothing
            desc["is_global_init"] = Base.Bool(is_global_init)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_scatter_nd_sub(ref, indices, updates; use_locking=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_scatter_nd_sub(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceScatterNdSub") do 
                desc = tf.NodeDescription("ResourceScatterNdSub")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (updates_,) = tf.tf_promote(updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_scatter_nd_sub(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceScatterNdSub")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     _xla_send_from_host(inputs, dynamic_key)

A placeholder op for multiple values that will be sent from TensorFlow to a
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _xla_send_from_host(inputs_, dynamic_key_; name=nothing, Tinputs=nothing, key=nothing, device_ordinal=nothing)
            local desc
            tf.with_op_name(name, "_XlaSendFromHost") do 
                desc = tf.NodeDescription("_XlaSendFromHost")
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                dynamic_key_ = convert(Tensor{String}, dynamic_key_)
                tf.add_input(desc, inputs_)
                tf.add_input(desc, dynamic_key_)
                if Tinputs !== nothing
                    desc["Tinputs"] = map(Base.identity, Tinputs)
                end
                if key !== nothing
                    desc["key"] = Base.String(key)
                end
                if device_ordinal !== nothing
                    desc["device_ordinal"] = Base.Int(device_ordinal)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _xla_send_from_host(inputs_::tf.TensorHandle, dynamic_key_::tf.TensorHandle; name=nothing, Tinputs=nothing, key=nothing, device_ordinal=nothing)
        desc = tf.EagerOp("_XlaSendFromHost")
        tf.add_input(desc, inputs_)
        tf.add_input(desc, dynamic_key_)
        if Tinputs !== nothing
            desc["Tinputs"] = map(Base.identity, Tinputs)
        end
        if key !== nothing
            desc["key"] = Base.String(key)
        end
        if device_ordinal !== nothing
            desc["device_ordinal"] = Base.Int(device_ordinal)
        end
        (tf.execute(desc))[1]
    end
end


"""
     get_session_handle_v2(value)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function get_session_handle_v2(value_; name=nothing)
            local desc
            tf.with_op_name(name, "GetSessionHandleV2") do 
                desc = tf.NodeDescription("GetSessionHandleV2")
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, value_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function get_session_handle_v2(value_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("GetSessionHandleV2")
        tf.add_input(desc, value_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     relu_grad(gradients, features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function relu_grad(gradients_, features_; name=nothing)
            local desc
            tf.with_op_name(name, "ReluGrad") do 
                desc = tf.NodeDescription("ReluGrad")
                gradients_ = convert(Tensor{Any}, gradients_)
                features_ = convert(Tensor{Any}, features_)
                (gradients_, features_) = tf.tf_promote(gradients_, features_)
                tf.add_input(desc, gradients_)
                tf.add_input(desc, features_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function relu_grad(gradients_::tf.TensorHandle, features_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReluGrad")
        tf.add_input(desc, gradients_)
        tf.add_input(desc, features_)
        desc["T"] = tf.data_type(gradients_)
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     unsorted_segment_min(data, segment_ids, num_segments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unsorted_segment_min(data_, segment_ids_, num_segments_; name=nothing)
            local desc
            tf.with_op_name(name, "UnsortedSegmentMin") do 
                desc = tf.NodeDescription("UnsortedSegmentMin")
                data_ = convert(Tensor{Any}, data_)
                segment_ids_ = convert(Tensor{Any}, segment_ids_)
                segment_ids_ = segment_ids_ - convert(tf.Tensor{eltype(segment_ids_)}, 1)
                num_segments_ = convert(Tensor{Int32}, num_segments_)
                (num_segments_,) = tf.tf_promote(num_segments_)
                (data_,) = tf.tf_promote(data_)
                (segment_ids_,) = tf.tf_promote(segment_ids_)
                tf.add_input(desc, data_)
                tf.add_input(desc, segment_ids_)
                tf.add_input(desc, num_segments_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unsorted_segment_min(data_::tf.TensorHandle, segment_ids_::tf.TensorHandle, num_segments_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("UnsortedSegmentMin")
        tf.add_input(desc, data_)
        tf.add_input(desc, segment_ids_)
        tf.add_input(desc, num_segments_)
        desc["T"] = tf.data_type(data_)
        desc["Tindices"] = tf.data_type(segment_ids_)
        desc["Tnumsegments"] = tf.data_type(num_segments_)
        (tf.execute(desc))[1]
    end
end


"""
     parse_example(serialized, names, sparse_keys, dense_keys, dense_defaults)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function parse_example(serialized_, names_, sparse_keys_, dense_keys_, dense_defaults_; name=nothing, Nsparse=nothing, Ndense=nothing, sparse_types=nothing, Tdense=nothing, dense_shapes=nothing)
            local desc
            tf.with_op_name(name, "ParseExample") do 
                desc = tf.NodeDescription("ParseExample")
                serialized_ = convert(Tensor{String}, serialized_)
                names_ = convert(Tensor{String}, names_)
                sparse_keys_ = [convert(Tensor{String}, x) for x = sparse_keys_]
                dense_keys_ = [convert(Tensor{String}, x) for x = dense_keys_]
                dense_defaults_ = [convert(Tensor{Any}, x) for x = dense_defaults_]
                tf.add_input(desc, serialized_)
                tf.add_input(desc, names_)
                tf.add_input(desc, sparse_keys_)
                tf.add_input(desc, dense_keys_)
                tf.add_input(desc, dense_defaults_)
                if Nsparse !== nothing
                    desc["Nsparse"] = Base.Int(Nsparse)
                end
                if Ndense !== nothing
                    desc["Ndense"] = Base.Int(Ndense)
                end
                if sparse_types !== nothing
                    desc["sparse_types"] = map(Base.identity, sparse_types)
                end
                if Tdense !== nothing
                    desc["Tdense"] = map(Base.identity, Tdense)
                end
                if dense_shapes !== nothing
                    desc["dense_shapes"] = map(Base.identity, dense_shapes)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function parse_example(serialized_::tf.TensorHandle, names_::tf.TensorHandle, sparse_keys_::tf.TensorHandle, dense_keys_::tf.TensorHandle, dense_defaults_::tf.TensorHandle; name=nothing, Nsparse=nothing, Ndense=nothing, sparse_types=nothing, Tdense=nothing, dense_shapes=nothing)
        desc = tf.EagerOp("ParseExample")
        tf.add_input(desc, serialized_)
        tf.add_input(desc, names_)
        tf.add_input(desc, sparse_keys_)
        tf.add_input(desc, dense_keys_)
        tf.add_input(desc, dense_defaults_)
        if Nsparse !== nothing
            desc["Nsparse"] = Base.Int(Nsparse)
        end
        if Ndense !== nothing
            desc["Ndense"] = Base.Int(Ndense)
        end
        if sparse_types !== nothing
            desc["sparse_types"] = map(Base.identity, sparse_types)
        end
        if Tdense !== nothing
            desc["Tdense"] = map(Base.identity, Tdense)
        end
        if dense_shapes !== nothing
            desc["dense_shapes"] = map(Base.identity, dense_shapes)
        end
        tf.execute(desc)
    end
end


"""
     queue_enqueue_v2(handle, components; timeout_ms=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_enqueue_v2(handle_, components_; name=nothing, Tcomponents=nothing, timeout_ms=nothing)
            local desc
            tf.with_op_name(name, "QueueEnqueueV2") do 
                desc = tf.NodeDescription("QueueEnqueueV2")
                handle_ = convert(Tensor{Any}, handle_)
                components_ = [convert(Tensor{Any}, x) for x = components_]
                tf.add_input(desc, handle_)
                tf.add_input(desc, components_)
                if Tcomponents !== nothing
                    desc["Tcomponents"] = map(Base.identity, Tcomponents)
                end
                if timeout_ms !== nothing
                    desc["timeout_ms"] = Base.Int(timeout_ms)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_enqueue_v2(handle_::tf.TensorHandle, components_::tf.TensorHandle; name=nothing, Tcomponents=nothing, timeout_ms=nothing)
        desc = tf.EagerOp("QueueEnqueueV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, components_)
        if Tcomponents !== nothing
            desc["Tcomponents"] = map(Base.identity, Tcomponents)
        end
        if timeout_ms !== nothing
            desc["timeout_ms"] = Base.Int(timeout_ms)
        end
        (tf.execute(desc))[1]
    end
end


"""
     scatter_nd_add(ref, indices, updates; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_nd_add(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ScatterNdAdd") do 
                desc = tf.NodeDescription("ScatterNdAdd")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (ref_, updates_) = tf.tf_promote(ref_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_nd_add(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ScatterNdAdd")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     reader_num_records_produced_v2(reader_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_num_records_produced_v2(reader_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderNumRecordsProducedV2") do 
                desc = tf.NodeDescription("ReaderNumRecordsProducedV2")
                reader_handle_ = convert(Tensor{Any}, reader_handle_)
                tf.add_input(desc, reader_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reader_num_records_produced_v2(reader_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderNumRecordsProducedV2")
        tf.add_input(desc, reader_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_centered_rms_prop_parameters(parameters, ms, mom, mg; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_centered_rms_prop_parameters(parameters_, ms_, mom_, mg_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingCenteredRMSPropParameters") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingCenteredRMSPropParameters")
                parameters_ = convert(Tensor{Float32}, parameters_)
                ms_ = convert(Tensor{Float32}, ms_)
                mom_ = convert(Tensor{Float32}, mom_)
                mg_ = convert(Tensor{Float32}, mg_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, ms_)
                tf.add_input(desc, mom_)
                tf.add_input(desc, mg_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_centered_rms_prop_parameters(parameters_::tf.TensorHandle, ms_::tf.TensorHandle, mom_::tf.TensorHandle, mg_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingCenteredRMSPropParameters")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, ms_)
        tf.add_input(desc, mom_)
        tf.add_input(desc, mg_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     assign_sub(ref, value; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function assign_sub(ref_, value_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "AssignSub") do 
                desc = tf.NodeDescription("AssignSub")
                ref_ = convert(Tensor{Any}, ref_)
                value_ = convert(Tensor{Any}, value_)
                (ref_, value_) = tf.tf_promote(ref_, value_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, value_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function assign_sub(ref_::tf.TensorHandle, value_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("AssignSub")
        tf.add_input(desc, ref_)
        tf.add_input(desc, value_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     unsorted_segment_sum(data, segment_ids, num_segments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unsorted_segment_sum(data_, segment_ids_, num_segments_; name=nothing)
            local desc
            tf.with_op_name(name, "UnsortedSegmentSum") do 
                desc = tf.NodeDescription("UnsortedSegmentSum")
                data_ = convert(Tensor{Any}, data_)
                segment_ids_ = convert(Tensor{Any}, segment_ids_)
                segment_ids_ = segment_ids_ - convert(tf.Tensor{eltype(segment_ids_)}, 1)
                num_segments_ = convert(Tensor{Int32}, num_segments_)
                (num_segments_,) = tf.tf_promote(num_segments_)
                (data_,) = tf.tf_promote(data_)
                (segment_ids_,) = tf.tf_promote(segment_ids_)
                tf.add_input(desc, data_)
                tf.add_input(desc, segment_ids_)
                tf.add_input(desc, num_segments_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unsorted_segment_sum(data_::tf.TensorHandle, segment_ids_::tf.TensorHandle, num_segments_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("UnsortedSegmentSum")
        tf.add_input(desc, data_)
        tf.add_input(desc, segment_ids_)
        tf.add_input(desc, num_segments_)
        desc["T"] = tf.data_type(data_)
        desc["Tindices"] = tf.data_type(segment_ids_)
        desc["Tnumsegments"] = tf.data_type(num_segments_)
        (tf.execute(desc))[1]
    end
end


"""
     fused_batch_norm_grad(y_backprop, x, scale, reserve_space_1, reserve_space_2; epsilon=?, data_format=NHWC, is_training=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fused_batch_norm_grad(y_backprop_, x_, scale_, reserve_space_1_, reserve_space_2_; name=nothing, epsilon=nothing, data_format=nothing, is_training=nothing)
            local desc
            tf.with_op_name(name, "FusedBatchNormGrad") do 
                desc = tf.NodeDescription("FusedBatchNormGrad")
                y_backprop_ = convert(Tensor{Any}, y_backprop_)
                x_ = convert(Tensor{Any}, x_)
                scale_ = convert(Tensor{Any}, scale_)
                reserve_space_1_ = convert(Tensor{Any}, reserve_space_1_)
                reserve_space_2_ = convert(Tensor{Any}, reserve_space_2_)
                (y_backprop_, x_, scale_, reserve_space_1_, reserve_space_2_) = tf.tf_promote(y_backprop_, x_, scale_, reserve_space_1_, reserve_space_2_)
                tf.add_input(desc, y_backprop_)
                tf.add_input(desc, x_)
                tf.add_input(desc, scale_)
                tf.add_input(desc, reserve_space_1_)
                tf.add_input(desc, reserve_space_2_)
                if epsilon !== nothing
                    desc["epsilon"] = Base.identity(epsilon)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if is_training !== nothing
                    desc["is_training"] = Base.Bool(is_training)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:5
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function fused_batch_norm_grad(y_backprop_::tf.TensorHandle, x_::tf.TensorHandle, scale_::tf.TensorHandle, reserve_space_1_::tf.TensorHandle, reserve_space_2_::tf.TensorHandle; name=nothing, epsilon=nothing, data_format=nothing, is_training=nothing)
        desc = tf.EagerOp("FusedBatchNormGrad")
        tf.add_input(desc, y_backprop_)
        tf.add_input(desc, x_)
        tf.add_input(desc, scale_)
        tf.add_input(desc, reserve_space_1_)
        tf.add_input(desc, reserve_space_2_)
        if epsilon !== nothing
            desc["epsilon"] = Base.identity(epsilon)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if is_training !== nothing
            desc["is_training"] = Base.Bool(is_training)
        end
        desc["T"] = tf.data_type(y_backprop_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(scale_)
        desc["T"] = tf.data_type(reserve_space_1_)
        desc["T"] = tf.data_type(reserve_space_2_)
        tf.execute(desc)
    end
end


"""
     max_pool_grad_v2(orig_input, orig_output, grad, ksize, strides; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool_grad_v2(orig_input_, orig_output_, grad_, ksize_, strides_; name=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "MaxPoolGradV2") do 
                desc = tf.NodeDescription("MaxPoolGradV2")
                orig_input_ = convert(Tensor{Float32}, orig_input_)
                orig_output_ = convert(Tensor{Float32}, orig_output_)
                grad_ = convert(Tensor{Float32}, grad_)
                ksize_ = convert(Tensor{Int32}, ksize_)
                strides_ = convert(Tensor{Int32}, strides_)
                (orig_input_, orig_output_, grad_) = tf.tf_promote(orig_input_, orig_output_, grad_)
                tf.add_input(desc, orig_input_)
                tf.add_input(desc, orig_output_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, ksize_)
                tf.add_input(desc, strides_)
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max_pool_grad_v2(orig_input_::tf.TensorHandle, orig_output_::tf.TensorHandle, grad_::tf.TensorHandle, ksize_::tf.TensorHandle, strides_::tf.TensorHandle; name=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("MaxPoolGradV2")
        tf.add_input(desc, orig_input_)
        tf.add_input(desc, orig_output_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, ksize_)
        tf.add_input(desc, strides_)
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(orig_input_)
        desc["T"] = tf.data_type(orig_output_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_conv2d_with_bias_and_relu(input, filter, bias, min_input, max_input, min_filter, max_filter; out_type=Float32, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_conv2d_with_bias_and_relu(input_, filter_, bias_, min_input_, max_input_, min_filter_, max_filter_; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConv2DWithBiasAndRelu") do 
                desc = tf.NodeDescription("QuantizedConv2DWithBiasAndRelu")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                bias_ = convert(Tensor{Float32}, bias_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_filter_ = convert(Tensor{Float32}, min_filter_)
                max_filter_ = convert(Tensor{Float32}, max_filter_)
                (filter_,) = tf.tf_promote(filter_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, bias_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_filter_)
                tf.add_input(desc, max_filter_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_conv2d_with_bias_and_relu(input_::tf.TensorHandle, filter_::tf.TensorHandle, bias_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_filter_::tf.TensorHandle, max_filter_::tf.TensorHandle; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("QuantizedConv2DWithBiasAndRelu")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, bias_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_filter_)
        tf.add_input(desc, max_filter_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tinput"] = tf.data_type(input_)
        desc["Tfilter"] = tf.data_type(filter_)
        tf.execute(desc)
    end
end


"""
     boosted_trees_create_ensemble(tree_ensemble_handle, stamp_token, tree_ensemble_serialized)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_create_ensemble(tree_ensemble_handle_, stamp_token_, tree_ensemble_serialized_; name=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesCreateEnsemble") do 
                desc = tf.NodeDescription("BoostedTreesCreateEnsemble")
                tree_ensemble_handle_ = convert(Tensor{Any}, tree_ensemble_handle_)
                stamp_token_ = convert(Tensor{Int64}, stamp_token_)
                tree_ensemble_serialized_ = convert(Tensor{String}, tree_ensemble_serialized_)
                tf.add_input(desc, tree_ensemble_handle_)
                tf.add_input(desc, stamp_token_)
                tf.add_input(desc, tree_ensemble_serialized_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_create_ensemble(tree_ensemble_handle_::tf.TensorHandle, stamp_token_::tf.TensorHandle, tree_ensemble_serialized_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BoostedTreesCreateEnsemble")
        tf.add_input(desc, tree_ensemble_handle_)
        tf.add_input(desc, stamp_token_)
        tf.add_input(desc, tree_ensemble_serialized_)
        (tf.execute(desc))[1]
    end
end


"""
     ordered_map_incomplete_size(; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ordered_map_incomplete_size(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "OrderedMapIncompleteSize") do 
                desc = tf.NodeDescription("OrderedMapIncompleteSize")
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ordered_map_incomplete_size(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("OrderedMapIncompleteSize")
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     skipgram(; window_size=5, min_count=5, subsample=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function skipgram(; name=nothing, filename=nothing, batch_size=nothing, window_size=nothing, min_count=nothing, subsample=nothing)
            local desc
            tf.with_op_name(name, "Skipgram") do 
                desc = tf.NodeDescription("Skipgram")
                if filename !== nothing
                    desc["filename"] = Base.String(filename)
                end
                if batch_size !== nothing
                    desc["batch_size"] = Base.Int(batch_size)
                end
                if window_size !== nothing
                    desc["window_size"] = Base.Int(window_size)
                end
                if min_count !== nothing
                    desc["min_count"] = Base.Int(min_count)
                end
                if subsample !== nothing
                    desc["subsample"] = Base.identity(subsample)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:7
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function skipgram(; name=nothing, filename=nothing, batch_size=nothing, window_size=nothing, min_count=nothing, subsample=nothing)
        desc = tf.EagerOp("Skipgram")
        if filename !== nothing
            desc["filename"] = Base.String(filename)
        end
        if batch_size !== nothing
            desc["batch_size"] = Base.Int(batch_size)
        end
        if window_size !== nothing
            desc["window_size"] = Base.Int(window_size)
        end
        if min_count !== nothing
            desc["min_count"] = Base.Int(min_count)
        end
        if subsample !== nothing
            desc["subsample"] = Base.identity(subsample)
        end
        tf.execute(desc)
    end
end


"""
     arg_min(input, dimension; output_type=Int64)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function arg_min(input_, dimension_; name=nothing, output_type=nothing)
            local desc
            tf.with_op_name(name, "ArgMin") do 
                desc = tf.NodeDescription("ArgMin")
                input_ = convert(Tensor{Any}, input_)
                dimension_ = convert(Tensor{Int32}, dimension_)
                dimension_ = dimension_ - convert(tf.Tensor{eltype(dimension_)}, 1)
                (input_,) = tf.tf_promote(input_)
                (dimension_,) = tf.tf_promote(dimension_)
                tf.add_input(desc, input_)
                tf.add_input(desc, dimension_)
                if output_type !== nothing
                    desc["output_type"] = Base.identity(output_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function arg_min(input_::tf.TensorHandle, dimension_::tf.TensorHandle; name=nothing, output_type=nothing)
        desc = tf.EagerOp("ArgMin")
        tf.add_input(desc, input_)
        tf.add_input(desc, dimension_)
        if output_type !== nothing
            desc["output_type"] = Base.identity(output_type)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tidx"] = tf.data_type(dimension_)
        (tf.execute(desc))[1]
    end
end


"""
     queue_dequeue_many(handle, n; timeout_ms=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_dequeue_many(handle_, n_; name=nothing, component_types=nothing, timeout_ms=nothing)
            local desc
            tf.with_op_name(name, "QueueDequeueMany") do 
                desc = tf.NodeDescription("QueueDequeueMany")
                handle_ = convert(Tensor{String}, handle_)
                n_ = convert(Tensor{Int32}, n_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, n_)
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if timeout_ms !== nothing
                    desc["timeout_ms"] = Base.Int(timeout_ms)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_dequeue_many(handle_::tf.TensorHandle, n_::tf.TensorHandle; name=nothing, component_types=nothing, timeout_ms=nothing)
        desc = tf.EagerOp("QueueDequeueMany")
        tf.add_input(desc, handle_)
        tf.add_input(desc, n_)
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if timeout_ms !== nothing
            desc["timeout_ms"] = Base.Int(timeout_ms)
        end
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_serialize_ensemble(tree_ensemble_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_serialize_ensemble(tree_ensemble_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesSerializeEnsemble") do 
                desc = tf.NodeDescription("BoostedTreesSerializeEnsemble")
                tree_ensemble_handle_ = convert(Tensor{Any}, tree_ensemble_handle_)
                tf.add_input(desc, tree_ensemble_handle_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function boosted_trees_serialize_ensemble(tree_ensemble_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BoostedTreesSerializeEnsemble")
        tf.add_input(desc, tree_ensemble_handle_)
        tf.execute(desc)
    end
end


"""
     minimum(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function minimum(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Minimum") do 
                desc = tf.NodeDescription("Minimum")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function minimum(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Minimum")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     substr(input, pos, len; unit=BYTE)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function substr(input_, pos_, len_; name=nothing, unit=nothing)
            local desc
            tf.with_op_name(name, "Substr") do 
                desc = tf.NodeDescription("Substr")
                input_ = convert(Tensor{String}, input_)
                pos_ = convert(Tensor{Any}, pos_)
                len_ = convert(Tensor{Any}, len_)
                (pos_, len_) = tf.tf_promote(pos_, len_)
                tf.add_input(desc, input_)
                tf.add_input(desc, pos_)
                tf.add_input(desc, len_)
                if unit !== nothing
                    desc["unit"] = Base.String(unit)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function substr(input_::tf.TensorHandle, pos_::tf.TensorHandle, len_::tf.TensorHandle; name=nothing, unit=nothing)
        desc = tf.EagerOp("Substr")
        tf.add_input(desc, input_)
        tf.add_input(desc, pos_)
        tf.add_input(desc, len_)
        if unit !== nothing
            desc["unit"] = Base.String(unit)
        end
        desc["T"] = tf.data_type(pos_)
        desc["T"] = tf.data_type(len_)
        (tf.execute(desc))[1]
    end
end


"""
     queue_size(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_size(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "QueueSize") do 
                desc = tf.NodeDescription("QueueSize")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_size(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("QueueSize")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     apply_ftrl_v2(var, accum, linear, grad, lr, l1, l2, l2_shrinkage, lr_power; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_ftrl_v2(var_, accum_, linear_, grad_, lr_, l1_, l2_, l2_shrinkage_, lr_power_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyFtrlV2") do 
                desc = tf.NodeDescription("ApplyFtrlV2")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                linear_ = convert(Tensor{Any}, linear_)
                grad_ = convert(Tensor{Any}, grad_)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                l2_shrinkage_ = convert(Tensor{Any}, l2_shrinkage_)
                lr_power_ = convert(Tensor{Any}, lr_power_)
                (var_, accum_, linear_, grad_, lr_, l1_, l2_, l2_shrinkage_, lr_power_) = tf.tf_promote(var_, accum_, linear_, grad_, lr_, l1_, l2_, l2_shrinkage_, lr_power_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, linear_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, l2_shrinkage_)
                tf.add_input(desc, lr_power_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_ftrl_v2(var_::tf.TensorHandle, accum_::tf.TensorHandle, linear_::tf.TensorHandle, grad_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, l2_shrinkage_::tf.TensorHandle, lr_power_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyFtrlV2")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, linear_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, l2_shrinkage_)
        tf.add_input(desc, lr_power_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(linear_)
        desc["T"] = tf.data_type(grad_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(l2_shrinkage_)
        desc["T"] = tf.data_type(lr_power_)
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_momentum_parameters(parameters, momenta; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_momentum_parameters(parameters_, momenta_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingMomentumParameters") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingMomentumParameters")
                parameters_ = convert(Tensor{Float32}, parameters_)
                momenta_ = convert(Tensor{Float32}, momenta_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, momenta_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_momentum_parameters(parameters_::tf.TensorHandle, momenta_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingMomentumParameters")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, momenta_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_segment_mean(data, indices, segment_ids)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_segment_mean(data_, indices_, segment_ids_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSegmentMean") do 
                desc = tf.NodeDescription("SparseSegmentMean")
                data_ = convert(Tensor{Any}, data_)
                indices_ = convert(Tensor{Int32}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                segment_ids_ = convert(Tensor{Int32}, segment_ids_)
                (data_,) = tf.tf_promote(data_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, data_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, segment_ids_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_segment_mean(data_::tf.TensorHandle, indices_::tf.TensorHandle, segment_ids_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSegmentMean")
        tf.add_input(desc, data_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, segment_ids_)
        desc["T"] = tf.data_type(data_)
        desc["Tidx"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_proximal_adagrad(var, accum, lr, l1, l2, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_proximal_adagrad(var_, accum_, lr_, l1_, l2_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyProximalAdagrad") do 
                desc = tf.NodeDescription("ResourceApplyProximalAdagrad")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                grad_ = convert(Tensor{Any}, grad_)
                (lr_, l1_, l2_, grad_) = tf.tf_promote(lr_, l1_, l2_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_proximal_adagrad(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyProximalAdagrad")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_gather_v2(handle, indices, flow_in; element_shape=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_gather_v2(handle_, indices_, flow_in_; name=nothing, dtype=nothing, element_shape=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayGatherV2") do 
                desc = tf.NodeDescription("TensorArrayGatherV2")
                handle_ = convert(Tensor{String}, handle_)
                indices_ = convert(Tensor{Int32}, indices_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, flow_in_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if element_shape !== nothing
                    desc["element_shape"] = Base.identity(element_shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_gather_v2(handle_::tf.TensorHandle, indices_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, dtype=nothing, element_shape=nothing)
        desc = tf.EagerOp("TensorArrayGatherV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, flow_in_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if element_shape !== nothing
            desc["element_shape"] = Base.identity(element_shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     less(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function less(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Less") do 
                desc = tf.NodeDescription("Less")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function less(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Less")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     host_const()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function host_const(; name=nothing, value=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "HostConst") do 
                desc = tf.NodeDescription("HostConst")
                if value !== nothing
                    desc["value"] = TensorFlow.RawTensor(value)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function host_const(; name=nothing, value=nothing, dtype=nothing)
        desc = tf.EagerOp("HostConst")
        if value !== nothing
            desc["value"] = TensorFlow.RawTensor(value)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     upper_bound(sorted_inputs, values; out_type=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function upper_bound(sorted_inputs_, values_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "UpperBound") do 
                desc = tf.NodeDescription("UpperBound")
                sorted_inputs_ = convert(Tensor{Any}, sorted_inputs_)
                values_ = convert(Tensor{Any}, values_)
                (sorted_inputs_, values_) = tf.tf_promote(sorted_inputs_, values_)
                tf.add_input(desc, sorted_inputs_)
                tf.add_input(desc, values_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function upper_bound(sorted_inputs_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("UpperBound")
        tf.add_input(desc, sorted_inputs_)
        tf.add_input(desc, values_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["T"] = tf.data_type(sorted_inputs_)
        desc["T"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_get_item(input_handle, index, element_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_get_item(input_handle_, index_, element_shape_; name=nothing, element_dtype=nothing)
            local desc
            tf.with_op_name(name, "TensorListGetItem") do 
                desc = tf.NodeDescription("TensorListGetItem")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                index_ = convert(Tensor{Int32}, index_)
                element_shape_ = convert(Tensor{Int32}, element_shape_)
                tf.add_input(desc, input_handle_)
                tf.add_input(desc, index_)
                tf.add_input(desc, element_shape_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_get_item(input_handle_::tf.TensorHandle, index_::tf.TensorHandle, element_shape_::tf.TensorHandle; name=nothing, element_dtype=nothing)
        desc = tf.EagerOp("TensorListGetItem")
        tf.add_input(desc, input_handle_)
        tf.add_input(desc, index_)
        tf.add_input(desc, element_shape_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     fake_quant_with_min_max_vars(inputs, min, max; num_bits=8, narrow_range=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fake_quant_with_min_max_vars(inputs_, min_, max_; name=nothing, num_bits=nothing, narrow_range=nothing)
            local desc
            tf.with_op_name(name, "FakeQuantWithMinMaxVars") do 
                desc = tf.NodeDescription("FakeQuantWithMinMaxVars")
                inputs_ = convert(Tensor{Float32}, inputs_)
                min_ = convert(Tensor{Float32}, min_)
                max_ = convert(Tensor{Float32}, max_)
                tf.add_input(desc, inputs_)
                tf.add_input(desc, min_)
                tf.add_input(desc, max_)
                if num_bits !== nothing
                    desc["num_bits"] = Base.Int(num_bits)
                end
                if narrow_range !== nothing
                    desc["narrow_range"] = Base.Bool(narrow_range)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fake_quant_with_min_max_vars(inputs_::tf.TensorHandle, min_::tf.TensorHandle, max_::tf.TensorHandle; name=nothing, num_bits=nothing, narrow_range=nothing)
        desc = tf.EagerOp("FakeQuantWithMinMaxVars")
        tf.add_input(desc, inputs_)
        tf.add_input(desc, min_)
        tf.add_input(desc, max_)
        if num_bits !== nothing
            desc["num_bits"] = Base.Int(num_bits)
        end
        if narrow_range !== nothing
            desc["narrow_range"] = Base.Bool(narrow_range)
        end
        (tf.execute(desc))[1]
    end
end


"""
     is_boosted_trees_quantile_stream_resource_initialized(quantile_stream_resource_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function is_boosted_trees_quantile_stream_resource_initialized(quantile_stream_resource_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "IsBoostedTreesQuantileStreamResourceInitialized") do 
                desc = tf.NodeDescription("IsBoostedTreesQuantileStreamResourceInitialized")
                quantile_stream_resource_handle_ = convert(Tensor{Any}, quantile_stream_resource_handle_)
                tf.add_input(desc, quantile_stream_resource_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function is_boosted_trees_quantile_stream_resource_initialized(quantile_stream_resource_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IsBoostedTreesQuantileStreamResourceInitialized")
        tf.add_input(desc, quantile_stream_resource_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     reader_read_up_to_v2(reader_handle, queue_handle, num_records)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_read_up_to_v2(reader_handle_, queue_handle_, num_records_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderReadUpToV2") do 
                desc = tf.NodeDescription("ReaderReadUpToV2")
                reader_handle_ = convert(Tensor{Any}, reader_handle_)
                queue_handle_ = convert(Tensor{Any}, queue_handle_)
                num_records_ = convert(Tensor{Int64}, num_records_)
                tf.add_input(desc, reader_handle_)
                tf.add_input(desc, queue_handle_)
                tf.add_input(desc, num_records_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function reader_read_up_to_v2(reader_handle_::tf.TensorHandle, queue_handle_::tf.TensorHandle, num_records_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderReadUpToV2")
        tf.add_input(desc, reader_handle_)
        tf.add_input(desc, queue_handle_)
        tf.add_input(desc, num_records_)
        tf.execute(desc)
    end
end


"""
     complex(real, imag)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function complex(real_, imag_; name=nothing)
            local desc
            tf.with_op_name(name, "Complex") do 
                desc = tf.NodeDescription("Complex")
                real_ = convert(Tensor{Float32}, real_)
                imag_ = convert(Tensor{Float32}, imag_)
                (real_, imag_) = tf.tf_promote(real_, imag_)
                tf.add_input(desc, real_)
                tf.add_input(desc, imag_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function complex(real_::tf.TensorHandle, imag_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Complex")
        tf.add_input(desc, real_)
        tf.add_input(desc, imag_)
        desc["T"] = tf.data_type(real_)
        desc["T"] = tf.data_type(imag_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_reserve(element_shape, num_elements)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_reserve(element_shape_, num_elements_; name=nothing, element_dtype=nothing, shape_type=nothing)
            local desc
            tf.with_op_name(name, "TensorListReserve") do 
                desc = tf.NodeDescription("TensorListReserve")
                element_shape_ = convert(Tensor{Any}, element_shape_)
                num_elements_ = convert(Tensor{Int32}, num_elements_)
                (element_shape_,) = tf.tf_promote(element_shape_)
                tf.add_input(desc, element_shape_)
                tf.add_input(desc, num_elements_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
                if shape_type !== nothing
                    desc["shape_type"] = Base.identity(shape_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_reserve(element_shape_::tf.TensorHandle, num_elements_::tf.TensorHandle; name=nothing, element_dtype=nothing, shape_type=nothing)
        desc = tf.EagerOp("TensorListReserve")
        tf.add_input(desc, element_shape_)
        tf.add_input(desc, num_elements_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        if shape_type !== nothing
            desc["shape_type"] = Base.identity(shape_type)
        end
        desc["shape_type"] = tf.data_type(element_shape_)
        (tf.execute(desc))[1]
    end
end


"""
     bitcast(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function bitcast(input_; name=nothing, type_=nothing)
            local desc
            tf.with_op_name(name, "Bitcast") do 
                desc = tf.NodeDescription("Bitcast")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if type_ !== nothing
                    desc["type"] = Base.identity(type_)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function bitcast(input_::tf.TensorHandle; name=nothing, type_=nothing)
        desc = tf.EagerOp("Bitcast")
        tf.add_input(desc, input_)
        if type_ !== nothing
            desc["type"] = Base.identity(type_)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     priority_queue(; component_types=Int64[], capacity=-1, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function priority_queue(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "PriorityQueue") do 
                desc = tf.NodeDescription("PriorityQueue")
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function priority_queue(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("PriorityQueue")
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     quantized_batch_norm_with_global_normalization(t, t_min, t_max, m, m_min, m_max, v, v_min, v_max, beta, beta_min, beta_max, gamma, gamma_min, gamma_max)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_batch_norm_with_global_normalization(t_, t_min_, t_max_, m_, m_min_, m_max_, v_, v_min_, v_max_, beta_, beta_min_, beta_max_, gamma_, gamma_min_, gamma_max_; name=nothing, out_type=nothing, variance_epsilon=nothing, scale_after_normalization=nothing)
            local desc
            tf.with_op_name(name, "QuantizedBatchNormWithGlobalNormalization") do 
                desc = tf.NodeDescription("QuantizedBatchNormWithGlobalNormalization")
                t_ = convert(Tensor{Any}, t_)
                t_min_ = convert(Tensor{Float32}, t_min_)
                t_max_ = convert(Tensor{Float32}, t_max_)
                m_ = convert(Tensor{Any}, m_)
                m_min_ = convert(Tensor{Float32}, m_min_)
                m_max_ = convert(Tensor{Float32}, m_max_)
                v_ = convert(Tensor{Any}, v_)
                v_min_ = convert(Tensor{Float32}, v_min_)
                v_max_ = convert(Tensor{Float32}, v_max_)
                beta_ = convert(Tensor{Any}, beta_)
                beta_min_ = convert(Tensor{Float32}, beta_min_)
                beta_max_ = convert(Tensor{Float32}, beta_max_)
                gamma_ = convert(Tensor{Any}, gamma_)
                gamma_min_ = convert(Tensor{Float32}, gamma_min_)
                gamma_max_ = convert(Tensor{Float32}, gamma_max_)
                (t_, m_, v_, beta_, gamma_) = tf.tf_promote(t_, m_, v_, beta_, gamma_)
                tf.add_input(desc, t_)
                tf.add_input(desc, t_min_)
                tf.add_input(desc, t_max_)
                tf.add_input(desc, m_)
                tf.add_input(desc, m_min_)
                tf.add_input(desc, m_max_)
                tf.add_input(desc, v_)
                tf.add_input(desc, v_min_)
                tf.add_input(desc, v_max_)
                tf.add_input(desc, beta_)
                tf.add_input(desc, beta_min_)
                tf.add_input(desc, beta_max_)
                tf.add_input(desc, gamma_)
                tf.add_input(desc, gamma_min_)
                tf.add_input(desc, gamma_max_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if variance_epsilon !== nothing
                    desc["variance_epsilon"] = Base.identity(variance_epsilon)
                end
                if scale_after_normalization !== nothing
                    desc["scale_after_normalization"] = Base.Bool(scale_after_normalization)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_batch_norm_with_global_normalization(t_::tf.TensorHandle, t_min_::tf.TensorHandle, t_max_::tf.TensorHandle, m_::tf.TensorHandle, m_min_::tf.TensorHandle, m_max_::tf.TensorHandle, v_::tf.TensorHandle, v_min_::tf.TensorHandle, v_max_::tf.TensorHandle, beta_::tf.TensorHandle, beta_min_::tf.TensorHandle, beta_max_::tf.TensorHandle, gamma_::tf.TensorHandle, gamma_min_::tf.TensorHandle, gamma_max_::tf.TensorHandle; name=nothing, out_type=nothing, variance_epsilon=nothing, scale_after_normalization=nothing)
        desc = tf.EagerOp("QuantizedBatchNormWithGlobalNormalization")
        tf.add_input(desc, t_)
        tf.add_input(desc, t_min_)
        tf.add_input(desc, t_max_)
        tf.add_input(desc, m_)
        tf.add_input(desc, m_min_)
        tf.add_input(desc, m_max_)
        tf.add_input(desc, v_)
        tf.add_input(desc, v_min_)
        tf.add_input(desc, v_max_)
        tf.add_input(desc, beta_)
        tf.add_input(desc, beta_min_)
        tf.add_input(desc, beta_max_)
        tf.add_input(desc, gamma_)
        tf.add_input(desc, gamma_min_)
        tf.add_input(desc, gamma_max_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if variance_epsilon !== nothing
            desc["variance_epsilon"] = Base.identity(variance_epsilon)
        end
        if scale_after_normalization !== nothing
            desc["scale_after_normalization"] = Base.Bool(scale_after_normalization)
        end
        desc["Tinput"] = tf.data_type(t_)
        desc["Tinput"] = tf.data_type(m_)
        desc["Tinput"] = tf.data_type(v_)
        desc["Tinput"] = tf.data_type(beta_)
        desc["Tinput"] = tf.data_type(gamma_)
        tf.execute(desc)
    end
end


"""
     cos(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cos(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Cos") do 
                desc = tf.NodeDescription("Cos")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cos(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Cos")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     quantize_down_and_shrink_range(input, input_min, input_max)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantize_down_and_shrink_range(input_, input_min_, input_max_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "QuantizeDownAndShrinkRange") do 
                desc = tf.NodeDescription("QuantizeDownAndShrinkRange")
                input_ = convert(Tensor{Any}, input_)
                input_min_ = convert(Tensor{Float32}, input_min_)
                input_max_ = convert(Tensor{Float32}, input_max_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_min_)
                tf.add_input(desc, input_max_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantize_down_and_shrink_range(input_::tf.TensorHandle, input_min_::tf.TensorHandle, input_max_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("QuantizeDownAndShrinkRange")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_min_)
        tf.add_input(desc, input_max_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["Tinput"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     experimental_random_dataset(seed, seed2)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_random_dataset(seed_, seed2_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalRandomDataset") do 
                desc = tf.NodeDescription("ExperimentalRandomDataset")
                seed_ = convert(Tensor{Int64}, seed_)
                seed2_ = convert(Tensor{Int64}, seed2_)
                tf.add_input(desc, seed_)
                tf.add_input(desc, seed2_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_random_dataset(seed_::tf.TensorHandle, seed2_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalRandomDataset")
        tf.add_input(desc, seed_)
        tf.add_input(desc, seed2_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     rpc(address, method, request; protocol=, fail_fast=true, timeout_in_ms=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function rpc(address_, method_, request_; name=nothing, protocol=nothing, fail_fast=nothing, timeout_in_ms=nothing)
            local desc
            tf.with_op_name(name, "Rpc") do 
                desc = tf.NodeDescription("Rpc")
                address_ = convert(Tensor{String}, address_)
                method_ = convert(Tensor{String}, method_)
                request_ = convert(Tensor{String}, request_)
                tf.add_input(desc, address_)
                tf.add_input(desc, method_)
                tf.add_input(desc, request_)
                if protocol !== nothing
                    desc["protocol"] = Base.String(protocol)
                end
                if fail_fast !== nothing
                    desc["fail_fast"] = Base.Bool(fail_fast)
                end
                if timeout_in_ms !== nothing
                    desc["timeout_in_ms"] = Base.Int(timeout_in_ms)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function rpc(address_::tf.TensorHandle, method_::tf.TensorHandle, request_::tf.TensorHandle; name=nothing, protocol=nothing, fail_fast=nothing, timeout_in_ms=nothing)
        desc = tf.EagerOp("Rpc")
        tf.add_input(desc, address_)
        tf.add_input(desc, method_)
        tf.add_input(desc, request_)
        if protocol !== nothing
            desc["protocol"] = Base.String(protocol)
        end
        if fail_fast !== nothing
            desc["fail_fast"] = Base.Bool(fail_fast)
        end
        if timeout_in_ms !== nothing
            desc["timeout_in_ms"] = Base.Int(timeout_in_ms)
        end
        (tf.execute(desc))[1]
    end
end


"""
     quantized_conv2d_with_bias_signed_sum_and_relu_and_requantize(input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output, summand, min_summand, max_summand; out_type=Float32, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_conv2d_with_bias_signed_sum_and_relu_and_requantize(input_, filter_, bias_, min_input_, max_input_, min_filter_, max_filter_, min_freezed_output_, max_freezed_output_, summand_, min_summand_, max_summand_; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConv2DWithBiasSignedSumAndReluAndRequantize") do 
                desc = tf.NodeDescription("QuantizedConv2DWithBiasSignedSumAndReluAndRequantize")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                bias_ = convert(Tensor{Any}, bias_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_filter_ = convert(Tensor{Float32}, min_filter_)
                max_filter_ = convert(Tensor{Float32}, max_filter_)
                min_freezed_output_ = convert(Tensor{Float32}, min_freezed_output_)
                max_freezed_output_ = convert(Tensor{Float32}, max_freezed_output_)
                summand_ = convert(Tensor{Any}, summand_)
                min_summand_ = convert(Tensor{Float32}, min_summand_)
                max_summand_ = convert(Tensor{Float32}, max_summand_)
                (summand_,) = tf.tf_promote(summand_)
                (filter_,) = tf.tf_promote(filter_)
                (input_,) = tf.tf_promote(input_)
                (bias_,) = tf.tf_promote(bias_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, bias_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_filter_)
                tf.add_input(desc, max_filter_)
                tf.add_input(desc, min_freezed_output_)
                tf.add_input(desc, max_freezed_output_)
                tf.add_input(desc, summand_)
                tf.add_input(desc, min_summand_)
                tf.add_input(desc, max_summand_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_conv2d_with_bias_signed_sum_and_relu_and_requantize(input_::tf.TensorHandle, filter_::tf.TensorHandle, bias_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_filter_::tf.TensorHandle, max_filter_::tf.TensorHandle, min_freezed_output_::tf.TensorHandle, max_freezed_output_::tf.TensorHandle, summand_::tf.TensorHandle, min_summand_::tf.TensorHandle, max_summand_::tf.TensorHandle; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("QuantizedConv2DWithBiasSignedSumAndReluAndRequantize")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, bias_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_filter_)
        tf.add_input(desc, max_filter_)
        tf.add_input(desc, min_freezed_output_)
        tf.add_input(desc, max_freezed_output_)
        tf.add_input(desc, summand_)
        tf.add_input(desc, min_summand_)
        tf.add_input(desc, max_summand_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tinput"] = tf.data_type(input_)
        desc["Tfilter"] = tf.data_type(filter_)
        desc["Tbias"] = tf.data_type(bias_)
        desc["Tsummand"] = tf.data_type(summand_)
        tf.execute(desc)
    end
end


"""
     tensor_list_length(input_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_length(input_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorListLength") do 
                desc = tf.NodeDescription("TensorListLength")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                tf.add_input(desc, input_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_length(input_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorListLength")
        tf.add_input(desc, input_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     map_incomplete_size(; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function map_incomplete_size(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "MapIncompleteSize") do 
                desc = tf.NodeDescription("MapIncompleteSize")
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function map_incomplete_size(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("MapIncompleteSize")
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     stateless_while(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stateless_while(input_; name=nothing, T=nothing, cond=nothing, body=nothing)
            local desc
            tf.with_op_name(name, "StatelessWhile") do 
                desc = tf.NodeDescription("StatelessWhile")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                tf.add_input(desc, input_)
                if T !== nothing
                    desc["T"] = map(Base.identity, T)
                end
                if cond !== nothing
                    desc["cond"] = Base.identity(cond)
                end
                if body !== nothing
                    desc["body"] = Base.identity(body)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stateless_while(input_::tf.TensorHandle; name=nothing, T=nothing, cond=nothing, body=nothing)
        desc = tf.EagerOp("StatelessWhile")
        tf.add_input(desc, input_)
        if T !== nothing
            desc["T"] = map(Base.identity, T)
        end
        if cond !== nothing
            desc["cond"] = Base.identity(cond)
        end
        if body !== nothing
            desc["body"] = Base.identity(body)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_conditional_accumulator(; container=, shared_name=, reduction_type=MEAN)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_conditional_accumulator(; name=nothing, dtype=nothing, shape=nothing, container=nothing, shared_name=nothing, reduction_type=nothing)
            local desc
            tf.with_op_name(name, "SparseConditionalAccumulator") do 
                desc = tf.NodeDescription("SparseConditionalAccumulator")
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if reduction_type !== nothing
                    desc["reduction_type"] = Base.String(reduction_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_conditional_accumulator(; name=nothing, dtype=nothing, shape=nothing, container=nothing, shared_name=nothing, reduction_type=nothing)
        desc = tf.EagerOp("SparseConditionalAccumulator")
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if reduction_type !== nothing
            desc["reduction_type"] = Base.String(reduction_type)
        end
        (tf.execute(desc))[1]
    end
end


"""
     segment_min(data, segment_ids)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function segment_min(data_, segment_ids_; name=nothing)
            local desc
            tf.with_op_name(name, "SegmentMin") do 
                desc = tf.NodeDescription("SegmentMin")
                data_ = convert(Tensor{Any}, data_)
                segment_ids_ = convert(Tensor{Any}, segment_ids_)
                segment_ids_ = segment_ids_ - convert(tf.Tensor{eltype(segment_ids_)}, 1)
                (data_,) = tf.tf_promote(data_)
                (segment_ids_,) = tf.tf_promote(segment_ids_)
                tf.add_input(desc, data_)
                tf.add_input(desc, segment_ids_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function segment_min(data_::tf.TensorHandle, segment_ids_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SegmentMin")
        tf.add_input(desc, data_)
        tf.add_input(desc, segment_ids_)
        desc["T"] = tf.data_type(data_)
        desc["Tindices"] = tf.data_type(segment_ids_)
        (tf.execute(desc))[1]
    end
end


"""
     write_graph_summary(writer, step, tensor)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function write_graph_summary(writer_, step_, tensor_; name=nothing)
            local desc
            tf.with_op_name(name, "WriteGraphSummary") do 
                desc = tf.NodeDescription("WriteGraphSummary")
                writer_ = convert(Tensor{Any}, writer_)
                step_ = convert(Tensor{Int64}, step_)
                tensor_ = convert(Tensor{String}, tensor_)
                tf.add_input(desc, writer_)
                tf.add_input(desc, step_)
                tf.add_input(desc, tensor_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function write_graph_summary(writer_::tf.TensorHandle, step_::tf.TensorHandle, tensor_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("WriteGraphSummary")
        tf.add_input(desc, writer_)
        tf.add_input(desc, step_)
        tf.add_input(desc, tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     cholesky_grad(l, grad)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cholesky_grad(l_, grad_; name=nothing)
            local desc
            tf.with_op_name(name, "CholeskyGrad") do 
                desc = tf.NodeDescription("CholeskyGrad")
                l_ = convert(Tensor{Any}, l_)
                grad_ = convert(Tensor{Any}, grad_)
                (l_, grad_) = tf.tf_promote(l_, grad_)
                tf.add_input(desc, l_)
                tf.add_input(desc, grad_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cholesky_grad(l_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("CholeskyGrad")
        tf.add_input(desc, l_)
        tf.add_input(desc, grad_)
        desc["T"] = tf.data_type(l_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     log_uniform_candidate_sampler(true_classes; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function log_uniform_candidate_sampler(true_classes_; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, range_max=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "LogUniformCandidateSampler") do 
                desc = tf.NodeDescription("LogUniformCandidateSampler")
                true_classes_ = convert(Tensor{Int64}, true_classes_)
                tf.add_input(desc, true_classes_)
                if num_true !== nothing
                    desc["num_true"] = Base.Int(num_true)
                end
                if num_sampled !== nothing
                    desc["num_sampled"] = Base.Int(num_sampled)
                end
                if unique !== nothing
                    desc["unique"] = Base.Bool(unique)
                end
                if range_max !== nothing
                    desc["range_max"] = Base.Int(range_max)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function log_uniform_candidate_sampler(true_classes_::tf.TensorHandle; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, range_max=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("LogUniformCandidateSampler")
        tf.add_input(desc, true_classes_)
        if num_true !== nothing
            desc["num_true"] = Base.Int(num_true)
        end
        if num_sampled !== nothing
            desc["num_sampled"] = Base.Int(num_sampled)
        end
        if unique !== nothing
            desc["unique"] = Base.Bool(unique)
        end
        if range_max !== nothing
            desc["range_max"] = Base.Int(range_max)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        tf.execute(desc)
    end
end


"""
     serialize_sparse(sparse_indices, sparse_values, sparse_shape; out_type=String)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function serialize_sparse(sparse_indices_, sparse_values_, sparse_shape_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "SerializeSparse") do 
                desc = tf.NodeDescription("SerializeSparse")
                sparse_indices_ = convert(Tensor{Int64}, sparse_indices_)
                sparse_values_ = convert(Tensor{Any}, sparse_values_)
                sparse_shape_ = convert(Tensor{Int64}, sparse_shape_)
                (sparse_values_,) = tf.tf_promote(sparse_values_)
                tf.add_input(desc, sparse_indices_)
                tf.add_input(desc, sparse_values_)
                tf.add_input(desc, sparse_shape_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function serialize_sparse(sparse_indices_::tf.TensorHandle, sparse_values_::tf.TensorHandle, sparse_shape_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("SerializeSparse")
        tf.add_input(desc, sparse_indices_)
        tf.add_input(desc, sparse_values_)
        tf.add_input(desc, sparse_shape_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["T"] = tf.data_type(sparse_values_)
        (tf.execute(desc))[1]
    end
end


"""
     scatter_nd_non_aliasing_add(input, indices, updates)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_nd_non_aliasing_add(input_, indices_, updates_; name=nothing)
            local desc
            tf.with_op_name(name, "ScatterNdNonAliasingAdd") do 
                desc = tf.NodeDescription("ScatterNdNonAliasingAdd")
                input_ = convert(Tensor{Any}, input_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (input_, updates_) = tf.tf_promote(input_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, input_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_nd_non_aliasing_add(input_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ScatterNdNonAliasingAdd")
        tf.add_input(desc, input_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        desc["T"] = tf.data_type(input_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     ref_merge(inputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ref_merge(inputs_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "RefMerge") do 
                desc = tf.NodeDescription("RefMerge")
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                (inputs_,) = tf.tf_promote(inputs_)
                tf.add_input(desc, inputs_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function ref_merge(inputs_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("RefMerge")
        tf.add_input(desc, inputs_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(inputs_)
        tf.execute(desc)
    end
end


"""
     tensor_list_concat(input_handle; element_shape=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_concat(input_handle_; name=nothing, element_dtype=nothing, element_shape=nothing)
            local desc
            tf.with_op_name(name, "TensorListConcat") do 
                desc = tf.NodeDescription("TensorListConcat")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                tf.add_input(desc, input_handle_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
                if element_shape !== nothing
                    desc["element_shape"] = Base.identity(element_shape)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function tensor_list_concat(input_handle_::tf.TensorHandle; name=nothing, element_dtype=nothing, element_shape=nothing)
        desc = tf.EagerOp("TensorListConcat")
        tf.add_input(desc, input_handle_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        if element_shape !== nothing
            desc["element_shape"] = Base.identity(element_shape)
        end
        tf.execute(desc)
    end
end


"""
     cudnn_rnn_canonical_to_params(num_layers, num_units, input_size, weights, biases; rnn_mode=lstm, input_mode=linear_input, direction=unidirectional, dropout=?, seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cudnn_rnn_canonical_to_params(num_layers_, num_units_, input_size_, weights_, biases_; name=nothing, num_params=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "CudnnRNNCanonicalToParams") do 
                desc = tf.NodeDescription("CudnnRNNCanonicalToParams")
                num_layers_ = convert(Tensor{Int32}, num_layers_)
                num_units_ = convert(Tensor{Int32}, num_units_)
                input_size_ = convert(Tensor{Int32}, input_size_)
                weights_ = [convert(Tensor{Any}, x) for x = weights_]
                biases_ = [convert(Tensor{Any}, x) for x = biases_]
                (weights_, biases_) = tf.tf_promote(weights_, biases_)
                tf.add_input(desc, num_layers_)
                tf.add_input(desc, num_units_)
                tf.add_input(desc, input_size_)
                tf.add_input(desc, weights_)
                tf.add_input(desc, biases_)
                if num_params !== nothing
                    desc["num_params"] = Base.Int(num_params)
                end
                if rnn_mode !== nothing
                    desc["rnn_mode"] = Base.String(rnn_mode)
                end
                if input_mode !== nothing
                    desc["input_mode"] = Base.String(input_mode)
                end
                if direction !== nothing
                    desc["direction"] = Base.String(direction)
                end
                if dropout !== nothing
                    desc["dropout"] = Base.identity(dropout)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cudnn_rnn_canonical_to_params(num_layers_::tf.TensorHandle, num_units_::tf.TensorHandle, input_size_::tf.TensorHandle, weights_::tf.TensorHandle, biases_::tf.TensorHandle; name=nothing, num_params=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("CudnnRNNCanonicalToParams")
        tf.add_input(desc, num_layers_)
        tf.add_input(desc, num_units_)
        tf.add_input(desc, input_size_)
        tf.add_input(desc, weights_)
        tf.add_input(desc, biases_)
        if num_params !== nothing
            desc["num_params"] = Base.Int(num_params)
        end
        if rnn_mode !== nothing
            desc["rnn_mode"] = Base.String(rnn_mode)
        end
        if input_mode !== nothing
            desc["input_mode"] = Base.String(input_mode)
        end
        if direction !== nothing
            desc["direction"] = Base.String(direction)
        end
        if dropout !== nothing
            desc["dropout"] = Base.identity(dropout)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        desc["T"] = tf.data_type(weights_)
        desc["T"] = tf.data_type(biases_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_apply_adadelta(var, accum, accum_update, lr, rho, epsilon, grad, indices; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_apply_adadelta(var_, accum_, accum_update_, lr_, rho_, epsilon_, grad_, indices_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "SparseApplyAdadelta") do 
                desc = tf.NodeDescription("SparseApplyAdadelta")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                accum_update_ = convert(Tensor{Any}, accum_update_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (var_, accum_, accum_update_, lr_, rho_, epsilon_, grad_) = tf.tf_promote(var_, accum_, accum_update_, lr_, rho_, epsilon_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, accum_update_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_apply_adadelta(var_::tf.TensorHandle, accum_::tf.TensorHandle, accum_update_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("SparseApplyAdadelta")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, accum_update_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(accum_update_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_close(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_close(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayClose") do 
                desc = tf.NodeDescription("TensorArrayClose")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_close(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArrayClose")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     selu_grad(gradients, outputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function selu_grad(gradients_, outputs_; name=nothing)
            local desc
            tf.with_op_name(name, "SeluGrad") do 
                desc = tf.NodeDescription("SeluGrad")
                gradients_ = convert(Tensor{Any}, gradients_)
                outputs_ = convert(Tensor{Any}, outputs_)
                (gradients_, outputs_) = tf.tf_promote(gradients_, outputs_)
                tf.add_input(desc, gradients_)
                tf.add_input(desc, outputs_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function selu_grad(gradients_::tf.TensorHandle, outputs_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SeluGrad")
        tf.add_input(desc, gradients_)
        tf.add_input(desc, outputs_)
        desc["T"] = tf.data_type(gradients_)
        desc["T"] = tf.data_type(outputs_)
        (tf.execute(desc))[1]
    end
end


"""
     crop_and_resize_grad_image(grads, boxes, box_ind, image_size; method=bilinear)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function crop_and_resize_grad_image(grads_, boxes_, box_ind_, image_size_; name=nothing, method=nothing)
            local desc
            tf.with_op_name(name, "CropAndResizeGradImage") do 
                desc = tf.NodeDescription("CropAndResizeGradImage")
                grads_ = convert(Tensor{Float32}, grads_)
                boxes_ = convert(Tensor{Float32}, boxes_)
                box_ind_ = convert(Tensor{Int32}, box_ind_)
                image_size_ = convert(Tensor{Int32}, image_size_)
                tf.add_input(desc, grads_)
                tf.add_input(desc, boxes_)
                tf.add_input(desc, box_ind_)
                tf.add_input(desc, image_size_)
                if method !== nothing
                    desc["method"] = Base.String(method)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function crop_and_resize_grad_image(grads_::tf.TensorHandle, boxes_::tf.TensorHandle, box_ind_::tf.TensorHandle, image_size_::tf.TensorHandle; name=nothing, method=nothing)
        desc = tf.EagerOp("CropAndResizeGradImage")
        tf.add_input(desc, grads_)
        tf.add_input(desc, boxes_)
        tf.add_input(desc, box_ind_)
        tf.add_input(desc, image_size_)
        if method !== nothing
            desc["method"] = Base.String(method)
        end
        (tf.execute(desc))[1]
    end
end


"""
     rfft(input, fft_length)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function rfft(input_, fft_length_; name=nothing)
            local desc
            tf.with_op_name(name, "RFFT") do 
                desc = tf.NodeDescription("RFFT")
                input_ = convert(Tensor{Float32}, input_)
                fft_length_ = convert(Tensor{Int32}, fft_length_)
                tf.add_input(desc, input_)
                tf.add_input(desc, fft_length_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function rfft(input_::tf.TensorHandle, fft_length_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RFFT")
        tf.add_input(desc, input_)
        tf.add_input(desc, fft_length_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_sql_dataset(driver_name, data_source_name, query)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_sql_dataset(driver_name_, data_source_name_, query_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalSqlDataset") do 
                desc = tf.NodeDescription("ExperimentalSqlDataset")
                driver_name_ = convert(Tensor{String}, driver_name_)
                data_source_name_ = convert(Tensor{String}, data_source_name_)
                query_ = convert(Tensor{String}, query_)
                tf.add_input(desc, driver_name_)
                tf.add_input(desc, data_source_name_)
                tf.add_input(desc, query_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_sql_dataset(driver_name_::tf.TensorHandle, data_source_name_::tf.TensorHandle, query_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalSqlDataset")
        tf.add_input(desc, driver_name_)
        tf.add_input(desc, data_source_name_)
        tf.add_input(desc, query_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_power_sign(var, m, lr, logbase, sign_decay, beta, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_power_sign(var_, m_, lr_, logbase_, sign_decay_, beta_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyPowerSign") do 
                desc = tf.NodeDescription("ResourceApplyPowerSign")
                var_ = convert(Tensor{Any}, var_)
                m_ = convert(Tensor{Any}, m_)
                lr_ = convert(Tensor{Any}, lr_)
                logbase_ = convert(Tensor{Any}, logbase_)
                sign_decay_ = convert(Tensor{Any}, sign_decay_)
                beta_ = convert(Tensor{Any}, beta_)
                grad_ = convert(Tensor{Any}, grad_)
                (lr_, logbase_, sign_decay_, beta_, grad_) = tf.tf_promote(lr_, logbase_, sign_decay_, beta_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, m_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, logbase_)
                tf.add_input(desc, sign_decay_)
                tf.add_input(desc, beta_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_power_sign(var_::tf.TensorHandle, m_::tf.TensorHandle, lr_::tf.TensorHandle, logbase_::tf.TensorHandle, sign_decay_::tf.TensorHandle, beta_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyPowerSign")
        tf.add_input(desc, var_)
        tf.add_input(desc, m_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, logbase_)
        tf.add_input(desc, sign_decay_)
        tf.add_input(desc, beta_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(logbase_)
        desc["T"] = tf.data_type(sign_decay_)
        desc["T"] = tf.data_type(beta_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     matrix_determinant(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_determinant(input_; name=nothing)
            local desc
            tf.with_op_name(name, "MatrixDeterminant") do 
                desc = tf.NodeDescription("MatrixDeterminant")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_determinant(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MatrixDeterminant")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     static_regex_replace(input; replace_global=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function static_regex_replace(input_; name=nothing, pattern=nothing, rewrite=nothing, replace_global=nothing)
            local desc
            tf.with_op_name(name, "StaticRegexReplace") do 
                desc = tf.NodeDescription("StaticRegexReplace")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
                if pattern !== nothing
                    desc["pattern"] = Base.String(pattern)
                end
                if rewrite !== nothing
                    desc["rewrite"] = Base.String(rewrite)
                end
                if replace_global !== nothing
                    desc["replace_global"] = Base.Bool(replace_global)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function static_regex_replace(input_::tf.TensorHandle; name=nothing, pattern=nothing, rewrite=nothing, replace_global=nothing)
        desc = tf.EagerOp("StaticRegexReplace")
        tf.add_input(desc, input_)
        if pattern !== nothing
            desc["pattern"] = Base.String(pattern)
        end
        if rewrite !== nothing
            desc["rewrite"] = Base.String(rewrite)
        end
        if replace_global !== nothing
            desc["replace_global"] = Base.Bool(replace_global)
        end
        (tf.execute(desc))[1]
    end
end


"""
     avg_pool(value; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function avg_pool(value_; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "AvgPool") do 
                desc = tf.NodeDescription("AvgPool")
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, value_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function avg_pool(value_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("AvgPool")
        tf.add_input(desc, value_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_dense_cwise_add(sp_indices, sp_values, sp_shape, dense)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_dense_cwise_add(sp_indices_, sp_values_, sp_shape_, dense_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseDenseCwiseAdd") do 
                desc = tf.NodeDescription("SparseDenseCwiseAdd")
                sp_indices_ = convert(Tensor{Int64}, sp_indices_)
                sp_values_ = convert(Tensor{Any}, sp_values_)
                sp_shape_ = convert(Tensor{Int64}, sp_shape_)
                dense_ = convert(Tensor{Any}, dense_)
                (sp_values_, dense_) = tf.tf_promote(sp_values_, dense_)
                tf.add_input(desc, sp_indices_)
                tf.add_input(desc, sp_values_)
                tf.add_input(desc, sp_shape_)
                tf.add_input(desc, dense_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_dense_cwise_add(sp_indices_::tf.TensorHandle, sp_values_::tf.TensorHandle, sp_shape_::tf.TensorHandle, dense_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseDenseCwiseAdd")
        tf.add_input(desc, sp_indices_)
        tf.add_input(desc, sp_values_)
        tf.add_input(desc, sp_shape_)
        tf.add_input(desc, dense_)
        desc["T"] = tf.data_type(sp_values_)
        desc["T"] = tf.data_type(dense_)
        (tf.execute(desc))[1]
    end
end


"""
     bias_add_v1(value, bias)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function bias_add_v1(value_, bias_; name=nothing)
            local desc
            tf.with_op_name(name, "BiasAddV1") do 
                desc = tf.NodeDescription("BiasAddV1")
                value_ = convert(Tensor{Any}, value_)
                bias_ = convert(Tensor{Any}, bias_)
                (value_, bias_) = tf.tf_promote(value_, bias_)
                tf.add_input(desc, value_)
                tf.add_input(desc, bias_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function bias_add_v1(value_::tf.TensorHandle, bias_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BiasAddV1")
        tf.add_input(desc, value_)
        tf.add_input(desc, bias_)
        desc["T"] = tf.data_type(value_)
        desc["T"] = tf.data_type(bias_)
        (tf.execute(desc))[1]
    end
end


"""
     invert_permutation(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function invert_permutation(x_; name=nothing)
            local desc
            tf.with_op_name(name, "InvertPermutation") do 
                desc = tf.NodeDescription("InvertPermutation")
                x_ = convert(Tensor{Int32}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function invert_permutation(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("InvertPermutation")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     hash_table_v2(; container=, shared_name=, use_node_name_sharing=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function hash_table_v2(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing)
            local desc
            tf.with_op_name(name, "HashTableV2") do 
                desc = tf.NodeDescription("HashTableV2")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if use_node_name_sharing !== nothing
                    desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
                end
                if key_dtype !== nothing
                    desc["key_dtype"] = Base.identity(key_dtype)
                end
                if value_dtype !== nothing
                    desc["value_dtype"] = Base.identity(value_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function hash_table_v2(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing)
        desc = tf.EagerOp("HashTableV2")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if use_node_name_sharing !== nothing
            desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
        end
        if key_dtype !== nothing
            desc["key_dtype"] = Base.identity(key_dtype)
        end
        if value_dtype !== nothing
            desc["value_dtype"] = Base.identity(value_dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_apply_momentum(var, accum, lr, grad, indices, momentum; use_locking=false, use_nesterov=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_apply_momentum(var_, accum_, lr_, grad_, indices_, momentum_; name=nothing, use_locking=nothing, use_nesterov=nothing)
            local desc
            tf.with_op_name(name, "SparseApplyMomentum") do 
                desc = tf.NodeDescription("SparseApplyMomentum")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                momentum_ = convert(Tensor{Any}, momentum_)
                (var_, accum_, lr_, grad_, momentum_) = tf.tf_promote(var_, accum_, lr_, grad_, momentum_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, momentum_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if use_nesterov !== nothing
                    desc["use_nesterov"] = Base.Bool(use_nesterov)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_apply_momentum(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle, momentum_::tf.TensorHandle; name=nothing, use_locking=nothing, use_nesterov=nothing)
        desc = tf.EagerOp("SparseApplyMomentum")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, momentum_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if use_nesterov !== nothing
            desc["use_nesterov"] = Base.Bool(use_nesterov)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(momentum_)
        (tf.execute(desc))[1]
    end
end


"""
     infeed_enqueue(input; shape=?, layout=Int64[], device_ordinal=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function infeed_enqueue(input_; name=nothing, dtype=nothing, shape=nothing, layout=nothing, device_ordinal=nothing)
            local desc
            tf.with_op_name(name, "InfeedEnqueue") do 
                desc = tf.NodeDescription("InfeedEnqueue")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
                if layout !== nothing
                    desc["layout"] = map(Base.identity, layout)
                end
                if device_ordinal !== nothing
                    desc["device_ordinal"] = Base.Int(device_ordinal)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function infeed_enqueue(input_::tf.TensorHandle; name=nothing, dtype=nothing, shape=nothing, layout=nothing, device_ordinal=nothing)
        desc = tf.EagerOp("InfeedEnqueue")
        tf.add_input(desc, input_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        if layout !== nothing
            desc["layout"] = map(Base.identity, layout)
        end
        if device_ordinal !== nothing
            desc["device_ordinal"] = Base.Int(device_ordinal)
        end
        desc["dtype"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     stateless_random_uniform_int(shape, seed, minval, maxval)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stateless_random_uniform_int(shape_, seed_, minval_, maxval_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "StatelessRandomUniformInt") do 
                desc = tf.NodeDescription("StatelessRandomUniformInt")
                shape_ = convert(Tensor{Any}, shape_)
                seed_ = convert(Tensor{Int64}, seed_)
                minval_ = convert(Tensor{Any}, minval_)
                maxval_ = convert(Tensor{Any}, maxval_)
                (minval_, maxval_) = tf.tf_promote(minval_, maxval_)
                (shape_,) = tf.tf_promote(shape_)
                (seed_,) = tf.tf_promote(seed_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, seed_)
                tf.add_input(desc, minval_)
                tf.add_input(desc, maxval_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stateless_random_uniform_int(shape_::tf.TensorHandle, seed_::tf.TensorHandle, minval_::tf.TensorHandle, maxval_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("StatelessRandomUniformInt")
        tf.add_input(desc, shape_)
        tf.add_input(desc, seed_)
        tf.add_input(desc, minval_)
        tf.add_input(desc, maxval_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["T"] = tf.data_type(shape_)
        desc["Tseed"] = tf.data_type(seed_)
        desc["dtype"] = tf.data_type(minval_)
        desc["dtype"] = tf.data_type(maxval_)
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_adadelta_parameters_grad_accum_debug(parameters, accumulators, updates, gradient_accumulators; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_adadelta_parameters_grad_accum_debug(parameters_, accumulators_, updates_, gradient_accumulators_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingAdadeltaParametersGradAccumDebug") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingAdadeltaParametersGradAccumDebug")
                parameters_ = convert(Tensor{Float32}, parameters_)
                accumulators_ = convert(Tensor{Float32}, accumulators_)
                updates_ = convert(Tensor{Float32}, updates_)
                gradient_accumulators_ = convert(Tensor{Float32}, gradient_accumulators_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, accumulators_)
                tf.add_input(desc, updates_)
                tf.add_input(desc, gradient_accumulators_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_adadelta_parameters_grad_accum_debug(parameters_::tf.TensorHandle, accumulators_::tf.TensorHandle, updates_::tf.TensorHandle, gradient_accumulators_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingAdadeltaParametersGradAccumDebug")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, accumulators_)
        tf.add_input(desc, updates_)
        tf.add_input(desc, gradient_accumulators_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     _send(tensor; client_terminated=false)

Sends the named tensor from send_device to recv_device.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _send(tensor_; name=nothing, tensor_name=nothing, send_device=nothing, send_device_incarnation=nothing, recv_device=nothing, client_terminated=nothing)
            local desc
            tf.with_op_name(name, "_Send") do 
                desc = tf.NodeDescription("_Send")
                tensor_ = convert(Tensor{Any}, tensor_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, tensor_)
                if tensor_name !== nothing
                    desc["tensor_name"] = Base.String(tensor_name)
                end
                if send_device !== nothing
                    desc["send_device"] = Base.String(send_device)
                end
                if send_device_incarnation !== nothing
                    desc["send_device_incarnation"] = Base.Int(send_device_incarnation)
                end
                if recv_device !== nothing
                    desc["recv_device"] = Base.String(recv_device)
                end
                if client_terminated !== nothing
                    desc["client_terminated"] = Base.Bool(client_terminated)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _send(tensor_::tf.TensorHandle; name=nothing, tensor_name=nothing, send_device=nothing, send_device_incarnation=nothing, recv_device=nothing, client_terminated=nothing)
        desc = tf.EagerOp("_Send")
        tf.add_input(desc, tensor_)
        if tensor_name !== nothing
            desc["tensor_name"] = Base.String(tensor_name)
        end
        if send_device !== nothing
            desc["send_device"] = Base.String(send_device)
        end
        if send_device_incarnation !== nothing
            desc["send_device_incarnation"] = Base.Int(send_device_incarnation)
        end
        if recv_device !== nothing
            desc["recv_device"] = Base.String(recv_device)
        end
        if client_terminated !== nothing
            desc["client_terminated"] = Base.Bool(client_terminated)
        end
        desc["T"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     map_peek(key, indices; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function map_peek(key_, indices_; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "MapPeek") do 
                desc = tf.NodeDescription("MapPeek")
                key_ = convert(Tensor{Int64}, key_)
                indices_ = convert(Tensor{Int32}, indices_)
                tf.add_input(desc, key_)
                tf.add_input(desc, indices_)
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function map_peek(key_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("MapPeek")
        tf.add_input(desc, key_)
        tf.add_input(desc, indices_)
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     write_scalar_summary(writer, step, tag, value)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function write_scalar_summary(writer_, step_, tag_, value_; name=nothing)
            local desc
            tf.with_op_name(name, "WriteScalarSummary") do 
                desc = tf.NodeDescription("WriteScalarSummary")
                writer_ = convert(Tensor{Any}, writer_)
                step_ = convert(Tensor{Int64}, step_)
                tag_ = convert(Tensor{String}, tag_)
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, writer_)
                tf.add_input(desc, step_)
                tf.add_input(desc, tag_)
                tf.add_input(desc, value_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function write_scalar_summary(writer_::tf.TensorHandle, step_::tf.TensorHandle, tag_::tf.TensorHandle, value_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("WriteScalarSummary")
        tf.add_input(desc, writer_)
        tf.add_input(desc, step_)
        tf.add_input(desc, tag_)
        tf.add_input(desc, value_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     ordered_map_unstage_no_key(indices; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ordered_map_unstage_no_key(indices_; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "OrderedMapUnstageNoKey") do 
                desc = tf.NodeDescription("OrderedMapUnstageNoKey")
                indices_ = convert(Tensor{Int32}, indices_)
                tf.add_input(desc, indices_)
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function ordered_map_unstage_no_key(indices_::tf.TensorHandle; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("OrderedMapUnstageNoKey")
        tf.add_input(desc, indices_)
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        tf.execute(desc)
    end
end


"""
     sparse_apply_centered_rms_prop(var, mg, ms, mom, lr, rho, momentum, epsilon, grad, indices; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_apply_centered_rms_prop(var_, mg_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_, indices_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "SparseApplyCenteredRMSProp") do 
                desc = tf.NodeDescription("SparseApplyCenteredRMSProp")
                var_ = convert(Tensor{Any}, var_)
                mg_ = convert(Tensor{Any}, mg_)
                ms_ = convert(Tensor{Any}, ms_)
                mom_ = convert(Tensor{Any}, mom_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                momentum_ = convert(Tensor{Any}, momentum_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (var_, mg_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_) = tf.tf_promote(var_, mg_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, mg_)
                tf.add_input(desc, ms_)
                tf.add_input(desc, mom_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, momentum_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_apply_centered_rms_prop(var_::tf.TensorHandle, mg_::tf.TensorHandle, ms_::tf.TensorHandle, mom_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, momentum_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("SparseApplyCenteredRMSProp")
        tf.add_input(desc, var_)
        tf.add_input(desc, mg_)
        tf.add_input(desc, ms_)
        tf.add_input(desc, mom_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, momentum_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(mg_)
        desc["T"] = tf.data_type(ms_)
        desc["T"] = tf.data_type(mom_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(momentum_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_scatter_v2(tensor, indices, element_shape, num_elements)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_scatter_v2(tensor_, indices_, element_shape_, num_elements_; name=nothing, element_dtype=nothing, shape_type=nothing)
            local desc
            tf.with_op_name(name, "TensorListScatterV2") do 
                desc = tf.NodeDescription("TensorListScatterV2")
                tensor_ = convert(Tensor{Any}, tensor_)
                indices_ = convert(Tensor{Int32}, indices_)
                element_shape_ = convert(Tensor{Any}, element_shape_)
                num_elements_ = convert(Tensor{Int32}, num_elements_)
                (tensor_,) = tf.tf_promote(tensor_)
                (element_shape_,) = tf.tf_promote(element_shape_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, element_shape_)
                tf.add_input(desc, num_elements_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
                if shape_type !== nothing
                    desc["shape_type"] = Base.identity(shape_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_scatter_v2(tensor_::tf.TensorHandle, indices_::tf.TensorHandle, element_shape_::tf.TensorHandle, num_elements_::tf.TensorHandle; name=nothing, element_dtype=nothing, shape_type=nothing)
        desc = tf.EagerOp("TensorListScatterV2")
        tf.add_input(desc, tensor_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, element_shape_)
        tf.add_input(desc, num_elements_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        if shape_type !== nothing
            desc["shape_type"] = Base.identity(shape_type)
        end
        desc["element_dtype"] = tf.data_type(tensor_)
        desc["shape_type"] = tf.data_type(element_shape_)
        (tf.execute(desc))[1]
    end
end


"""
     conv3d_backprop_input_v2(input_sizes, filter, out_backprop; data_format=NDHWC, dilations=[1, 1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function conv3d_backprop_input_v2(input_sizes_, filter_, out_backprop_; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "Conv3DBackpropInputV2") do 
                desc = tf.NodeDescription("Conv3DBackpropInputV2")
                input_sizes_ = convert(Tensor{Int32}, input_sizes_)
                filter_ = convert(Tensor{Any}, filter_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                (filter_, out_backprop_) = tf.tf_promote(filter_, out_backprop_)
                (input_sizes_,) = tf.tf_promote(input_sizes_)
                tf.add_input(desc, input_sizes_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, out_backprop_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function conv3d_backprop_input_v2(input_sizes_::tf.TensorHandle, filter_::tf.TensorHandle, out_backprop_::tf.TensorHandle; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
        desc = tf.EagerOp("Conv3DBackpropInputV2")
        tf.add_input(desc, input_sizes_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, out_backprop_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tshape"] = tf.data_type(input_sizes_)
        desc["T"] = tf.data_type(filter_)
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_proximal_adagrad_parameters(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_proximal_adagrad_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingProximalAdagradParameters") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingProximalAdagradParameters")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_proximal_adagrad_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingProximalAdagradParameters")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     random_shuffle(value; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function random_shuffle(value_; name=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "RandomShuffle") do 
                desc = tf.NodeDescription("RandomShuffle")
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, value_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function random_shuffle(value_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("RandomShuffle")
        tf.add_input(desc, value_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     uniform_candidate_sampler(true_classes; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function uniform_candidate_sampler(true_classes_; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, range_max=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "UniformCandidateSampler") do 
                desc = tf.NodeDescription("UniformCandidateSampler")
                true_classes_ = convert(Tensor{Int64}, true_classes_)
                tf.add_input(desc, true_classes_)
                if num_true !== nothing
                    desc["num_true"] = Base.Int(num_true)
                end
                if num_sampled !== nothing
                    desc["num_sampled"] = Base.Int(num_sampled)
                end
                if unique !== nothing
                    desc["unique"] = Base.Bool(unique)
                end
                if range_max !== nothing
                    desc["range_max"] = Base.Int(range_max)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function uniform_candidate_sampler(true_classes_::tf.TensorHandle; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, range_max=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("UniformCandidateSampler")
        tf.add_input(desc, true_classes_)
        if num_true !== nothing
            desc["num_true"] = Base.Int(num_true)
        end
        if num_sampled !== nothing
            desc["num_sampled"] = Base.Int(num_sampled)
        end
        if unique !== nothing
            desc["unique"] = Base.Bool(unique)
        end
        if range_max !== nothing
            desc["range_max"] = Base.Int(range_max)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        tf.execute(desc)
    end
end


"""
     tensor_array_split_v2(handle, value, lengths, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_split_v2(handle_, value_, lengths_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArraySplitV2") do 
                desc = tf.NodeDescription("TensorArraySplitV2")
                handle_ = convert(Tensor{String}, handle_)
                value_ = convert(Tensor{Any}, value_)
                lengths_ = convert(Tensor{Int64}, lengths_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, value_)
                tf.add_input(desc, lengths_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_split_v2(handle_::tf.TensorHandle, value_::tf.TensorHandle, lengths_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArraySplitV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, value_)
        tf.add_input(desc, lengths_)
        tf.add_input(desc, flow_in_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     mutable_dense_hash_table_v2(empty_key, deleted_key; container=, shared_name=, use_node_name_sharing=false, value_shape=?, initial_num_buckets=131072, max_load_factor=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mutable_dense_hash_table_v2(empty_key_, deleted_key_; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing, value_shape=nothing, initial_num_buckets=nothing, max_load_factor=nothing)
            local desc
            tf.with_op_name(name, "MutableDenseHashTableV2") do 
                desc = tf.NodeDescription("MutableDenseHashTableV2")
                empty_key_ = convert(Tensor{Any}, empty_key_)
                deleted_key_ = convert(Tensor{Any}, deleted_key_)
                (empty_key_, deleted_key_) = tf.tf_promote(empty_key_, deleted_key_)
                tf.add_input(desc, empty_key_)
                tf.add_input(desc, deleted_key_)
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if use_node_name_sharing !== nothing
                    desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
                end
                if key_dtype !== nothing
                    desc["key_dtype"] = Base.identity(key_dtype)
                end
                if value_dtype !== nothing
                    desc["value_dtype"] = Base.identity(value_dtype)
                end
                if value_shape !== nothing
                    desc["value_shape"] = Base.identity(value_shape)
                end
                if initial_num_buckets !== nothing
                    desc["initial_num_buckets"] = Base.Int(initial_num_buckets)
                end
                if max_load_factor !== nothing
                    desc["max_load_factor"] = Base.identity(max_load_factor)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mutable_dense_hash_table_v2(empty_key_::tf.TensorHandle, deleted_key_::tf.TensorHandle; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing, value_shape=nothing, initial_num_buckets=nothing, max_load_factor=nothing)
        desc = tf.EagerOp("MutableDenseHashTableV2")
        tf.add_input(desc, empty_key_)
        tf.add_input(desc, deleted_key_)
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if use_node_name_sharing !== nothing
            desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
        end
        if key_dtype !== nothing
            desc["key_dtype"] = Base.identity(key_dtype)
        end
        if value_dtype !== nothing
            desc["value_dtype"] = Base.identity(value_dtype)
        end
        if value_shape !== nothing
            desc["value_shape"] = Base.identity(value_shape)
        end
        if initial_num_buckets !== nothing
            desc["initial_num_buckets"] = Base.Int(initial_num_buckets)
        end
        if max_load_factor !== nothing
            desc["max_load_factor"] = Base.identity(max_load_factor)
        end
        desc["key_dtype"] = tf.data_type(empty_key_)
        desc["key_dtype"] = tf.data_type(deleted_key_)
        (tf.execute(desc))[1]
    end
end


"""
     draw_bounding_boxes(images, boxes)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function draw_bounding_boxes(images_, boxes_; name=nothing)
            local desc
            tf.with_op_name(name, "DrawBoundingBoxes") do 
                desc = tf.NodeDescription("DrawBoundingBoxes")
                images_ = convert(Tensor{Float32}, images_)
                boxes_ = convert(Tensor{Float32}, boxes_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                tf.add_input(desc, boxes_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function draw_bounding_boxes(images_::tf.TensorHandle, boxes_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DrawBoundingBoxes")
        tf.add_input(desc, images_)
        tf.add_input(desc, boxes_)
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_apply_proximal_adagrad(var, accum, lr, l1, l2, grad, indices; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_apply_proximal_adagrad(var_, accum_, lr_, l1_, l2_, grad_, indices_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "SparseApplyProximalAdagrad") do 
                desc = tf.NodeDescription("SparseApplyProximalAdagrad")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (var_, accum_, lr_, l1_, l2_, grad_) = tf.tf_promote(var_, accum_, lr_, l1_, l2_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_apply_proximal_adagrad(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("SparseApplyProximalAdagrad")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     range_dataset(start, stop, step)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function range_dataset(start_, stop_, step_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "RangeDataset") do 
                desc = tf.NodeDescription("RangeDataset")
                start_ = convert(Tensor{Int64}, start_)
                stop_ = convert(Tensor{Int64}, stop_)
                step_ = convert(Tensor{Int64}, step_)
                tf.add_input(desc, start_)
                tf.add_input(desc, stop_)
                tf.add_input(desc, step_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function range_dataset(start_::tf.TensorHandle, stop_::tf.TensorHandle, step_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("RangeDataset")
        tf.add_input(desc, start_)
        tf.add_input(desc, stop_)
        tf.add_input(desc, step_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     reader_restore_state_v2(reader_handle, state)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_restore_state_v2(reader_handle_, state_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderRestoreStateV2") do 
                desc = tf.NodeDescription("ReaderRestoreStateV2")
                reader_handle_ = convert(Tensor{Any}, reader_handle_)
                state_ = convert(Tensor{String}, state_)
                tf.add_input(desc, reader_handle_)
                tf.add_input(desc, state_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reader_restore_state_v2(reader_handle_::tf.TensorHandle, state_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderRestoreStateV2")
        tf.add_input(desc, reader_handle_)
        tf.add_input(desc, state_)
        (tf.execute(desc))[1]
    end
end


"""
     top_kv2(input, k; sorted=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function top_kv2(input_, k_; name=nothing, sorted=nothing)
            local desc
            tf.with_op_name(name, "TopKV2") do 
                desc = tf.NodeDescription("TopKV2")
                input_ = convert(Tensor{Any}, input_)
                k_ = convert(Tensor{Int32}, k_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, k_)
                if sorted !== nothing
                    desc["sorted"] = Base.Bool(sorted)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function top_kv2(input_::tf.TensorHandle, k_::tf.TensorHandle; name=nothing, sorted=nothing)
        desc = tf.EagerOp("TopKV2")
        tf.add_input(desc, input_)
        tf.add_input(desc, k_)
        if sorted !== nothing
            desc["sorted"] = Base.Bool(sorted)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     atanh(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function atanh(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Atanh") do 
                desc = tf.NodeDescription("Atanh")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function atanh(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Atanh")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     debug_gradient_identity(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function debug_gradient_identity(input_; name=nothing)
            local desc
            tf.with_op_name(name, "DebugGradientIdentity") do 
                desc = tf.NodeDescription("DebugGradientIdentity")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function debug_gradient_identity(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DebugGradientIdentity")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_add_grad(backprop_val_grad, a_indices, b_indices, sum_indices)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_add_grad(backprop_val_grad_, a_indices_, b_indices_, sum_indices_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseAddGrad") do 
                desc = tf.NodeDescription("SparseAddGrad")
                backprop_val_grad_ = convert(Tensor{Any}, backprop_val_grad_)
                a_indices_ = convert(Tensor{Int64}, a_indices_)
                b_indices_ = convert(Tensor{Int64}, b_indices_)
                sum_indices_ = convert(Tensor{Int64}, sum_indices_)
                (backprop_val_grad_,) = tf.tf_promote(backprop_val_grad_)
                tf.add_input(desc, backprop_val_grad_)
                tf.add_input(desc, a_indices_)
                tf.add_input(desc, b_indices_)
                tf.add_input(desc, sum_indices_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_add_grad(backprop_val_grad_::tf.TensorHandle, a_indices_::tf.TensorHandle, b_indices_::tf.TensorHandle, sum_indices_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseAddGrad")
        tf.add_input(desc, backprop_val_grad_)
        tf.add_input(desc, a_indices_)
        tf.add_input(desc, b_indices_)
        tf.add_input(desc, sum_indices_)
        desc["T"] = tf.data_type(backprop_val_grad_)
        tf.execute(desc)
    end
end


"""
     resource_scatter_add(resource, indices, updates)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_scatter_add(resource_, indices_, updates_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "ResourceScatterAdd") do 
                desc = tf.NodeDescription("ResourceScatterAdd")
                resource_ = convert(Tensor{Any}, resource_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (updates_,) = tf.tf_promote(updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_scatter_add(resource_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("ResourceScatterAdd")
        tf.add_input(desc, resource_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["Tindices"] = tf.data_type(indices_)
        desc["dtype"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     ceil(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ceil(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Ceil") do 
                desc = tf.NodeDescription("Ceil")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ceil(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Ceil")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     save(filename, tensor_names, data)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function save(filename_, tensor_names_, data_; name=nothing, T=nothing)
            local desc
            tf.with_op_name(name, "Save") do 
                desc = tf.NodeDescription("Save")
                filename_ = convert(Tensor{String}, filename_)
                tensor_names_ = convert(Tensor{String}, tensor_names_)
                data_ = [convert(Tensor{Any}, x) for x = data_]
                tf.add_input(desc, filename_)
                tf.add_input(desc, tensor_names_)
                tf.add_input(desc, data_)
                if T !== nothing
                    desc["T"] = map(Base.identity, T)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function save(filename_::tf.TensorHandle, tensor_names_::tf.TensorHandle, data_::tf.TensorHandle; name=nothing, T=nothing)
        desc = tf.EagerOp("Save")
        tf.add_input(desc, filename_)
        tf.add_input(desc, tensor_names_)
        tf.add_input(desc, data_)
        if T !== nothing
            desc["T"] = map(Base.identity, T)
        end
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_centered_rms_prop_parameters(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_centered_rms_prop_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingCenteredRMSPropParameters") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingCenteredRMSPropParameters")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_centered_rms_prop_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingCenteredRMSPropParameters")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     quantized_concat(concat_dim, values, input_mins, input_maxes)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_concat(concat_dim_, values_, input_mins_, input_maxes_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConcat") do 
                desc = tf.NodeDescription("QuantizedConcat")
                concat_dim_ = convert(Tensor{Int32}, concat_dim_)
                values_ = [convert(Tensor{Any}, x) for x = values_]
                input_mins_ = [convert(Tensor{Float32}, x) for x = input_mins_]
                input_maxes_ = [convert(Tensor{Float32}, x) for x = input_maxes_]
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, concat_dim_)
                tf.add_input(desc, values_)
                tf.add_input(desc, input_mins_)
                tf.add_input(desc, input_maxes_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_concat(concat_dim_::tf.TensorHandle, values_::tf.TensorHandle, input_mins_::tf.TensorHandle, input_maxes_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("QuantizedConcat")
        tf.add_input(desc, concat_dim_)
        tf.add_input(desc, values_)
        tf.add_input(desc, input_mins_)
        tf.add_input(desc, input_maxes_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(values_)
        tf.execute(desc)
    end
end


"""
     zeros_like(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function zeros_like(x_; name=nothing)
            local desc
            tf.with_op_name(name, "ZerosLike") do 
                desc = tf.NodeDescription("ZerosLike")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function zeros_like(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ZerosLike")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     fractional_avg_pool(value; pseudo_random=false, overlapping=false, deterministic=false, seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fractional_avg_pool(value_; name=nothing, pooling_ratio=nothing, pseudo_random=nothing, overlapping=nothing, deterministic=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "FractionalAvgPool") do 
                desc = tf.NodeDescription("FractionalAvgPool")
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, value_)
                if pooling_ratio !== nothing
                    desc["pooling_ratio"] = map(Base.identity, pooling_ratio)
                end
                if pseudo_random !== nothing
                    desc["pseudo_random"] = Base.Bool(pseudo_random)
                end
                if overlapping !== nothing
                    desc["overlapping"] = Base.Bool(overlapping)
                end
                if deterministic !== nothing
                    desc["deterministic"] = Base.Bool(deterministic)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function fractional_avg_pool(value_::tf.TensorHandle; name=nothing, pooling_ratio=nothing, pseudo_random=nothing, overlapping=nothing, deterministic=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("FractionalAvgPool")
        tf.add_input(desc, value_)
        if pooling_ratio !== nothing
            desc["pooling_ratio"] = map(Base.identity, pooling_ratio)
        end
        if pseudo_random !== nothing
            desc["pseudo_random"] = Base.Bool(pseudo_random)
        end
        if overlapping !== nothing
            desc["overlapping"] = Base.Bool(overlapping)
        end
        if deterministic !== nothing
            desc["deterministic"] = Base.Bool(deterministic)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        desc["T"] = tf.data_type(value_)
        tf.execute(desc)
    end
end


"""
     edit_distance(hypothesis_indices, hypothesis_values, hypothesis_shape, truth_indices, truth_values, truth_shape; normalize=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function edit_distance(hypothesis_indices_, hypothesis_values_, hypothesis_shape_, truth_indices_, truth_values_, truth_shape_; name=nothing, normalize=nothing)
            local desc
            tf.with_op_name(name, "EditDistance") do 
                desc = tf.NodeDescription("EditDistance")
                hypothesis_indices_ = convert(Tensor{Int64}, hypothesis_indices_)
                hypothesis_values_ = convert(Tensor{Any}, hypothesis_values_)
                hypothesis_shape_ = convert(Tensor{Int64}, hypothesis_shape_)
                truth_indices_ = convert(Tensor{Int64}, truth_indices_)
                truth_values_ = convert(Tensor{Any}, truth_values_)
                truth_shape_ = convert(Tensor{Int64}, truth_shape_)
                (hypothesis_values_, truth_values_) = tf.tf_promote(hypothesis_values_, truth_values_)
                tf.add_input(desc, hypothesis_indices_)
                tf.add_input(desc, hypothesis_values_)
                tf.add_input(desc, hypothesis_shape_)
                tf.add_input(desc, truth_indices_)
                tf.add_input(desc, truth_values_)
                tf.add_input(desc, truth_shape_)
                if normalize !== nothing
                    desc["normalize"] = Base.Bool(normalize)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function edit_distance(hypothesis_indices_::tf.TensorHandle, hypothesis_values_::tf.TensorHandle, hypothesis_shape_::tf.TensorHandle, truth_indices_::tf.TensorHandle, truth_values_::tf.TensorHandle, truth_shape_::tf.TensorHandle; name=nothing, normalize=nothing)
        desc = tf.EagerOp("EditDistance")
        tf.add_input(desc, hypothesis_indices_)
        tf.add_input(desc, hypothesis_values_)
        tf.add_input(desc, hypothesis_shape_)
        tf.add_input(desc, truth_indices_)
        tf.add_input(desc, truth_values_)
        tf.add_input(desc, truth_shape_)
        if normalize !== nothing
            desc["normalize"] = Base.Bool(normalize)
        end
        desc["T"] = tf.data_type(hypothesis_values_)
        desc["T"] = tf.data_type(truth_values_)
        (tf.execute(desc))[1]
    end
end


"""
     unique_v2(x, axis; out_idx=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unique_v2(x_, axis_; name=nothing, out_idx=nothing)
            local desc
            tf.with_op_name(name, "UniqueV2") do 
                desc = tf.NodeDescription("UniqueV2")
                x_ = convert(Tensor{Any}, x_)
                axis_ = convert(Tensor{Int64}, axis_)
                (x_,) = tf.tf_promote(x_)
                (axis_,) = tf.tf_promote(axis_)
                tf.add_input(desc, x_)
                tf.add_input(desc, axis_)
                if out_idx !== nothing
                    desc["out_idx"] = Base.identity(out_idx)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function unique_v2(x_::tf.TensorHandle, axis_::tf.TensorHandle; name=nothing, out_idx=nothing)
        desc = tf.EagerOp("UniqueV2")
        tf.add_input(desc, x_)
        tf.add_input(desc, axis_)
        if out_idx !== nothing
            desc["out_idx"] = Base.identity(out_idx)
        end
        desc["T"] = tf.data_type(x_)
        desc["Taxis"] = tf.data_type(axis_)
        tf.execute(desc)
    end
end


"""
     quantize_and_dequantize_v2(input, input_min, input_max; signed_input=true, num_bits=8, range_given=false, round_mode=HALF_TO_EVEN)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantize_and_dequantize_v2(input_, input_min_, input_max_; name=nothing, signed_input=nothing, num_bits=nothing, range_given=nothing, round_mode=nothing)
            local desc
            tf.with_op_name(name, "QuantizeAndDequantizeV2") do 
                desc = tf.NodeDescription("QuantizeAndDequantizeV2")
                input_ = convert(Tensor{Any}, input_)
                input_min_ = convert(Tensor{Any}, input_min_)
                input_max_ = convert(Tensor{Any}, input_max_)
                (input_, input_min_, input_max_) = tf.tf_promote(input_, input_min_, input_max_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_min_)
                tf.add_input(desc, input_max_)
                if signed_input !== nothing
                    desc["signed_input"] = Base.Bool(signed_input)
                end
                if num_bits !== nothing
                    desc["num_bits"] = Base.Int(num_bits)
                end
                if range_given !== nothing
                    desc["range_given"] = Base.Bool(range_given)
                end
                if round_mode !== nothing
                    desc["round_mode"] = Base.String(round_mode)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function quantize_and_dequantize_v2(input_::tf.TensorHandle, input_min_::tf.TensorHandle, input_max_::tf.TensorHandle; name=nothing, signed_input=nothing, num_bits=nothing, range_given=nothing, round_mode=nothing)
        desc = tf.EagerOp("QuantizeAndDequantizeV2")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_min_)
        tf.add_input(desc, input_max_)
        if signed_input !== nothing
            desc["signed_input"] = Base.Bool(signed_input)
        end
        if num_bits !== nothing
            desc["num_bits"] = Base.Int(num_bits)
        end
        if range_given !== nothing
            desc["range_given"] = Base.Bool(range_given)
        end
        if round_mode !== nothing
            desc["round_mode"] = Base.String(round_mode)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(input_min_)
        desc["T"] = tf.data_type(input_max_)
        (tf.execute(desc))[1]
    end
end


"""
     quantize_and_dequantize(input; signed_input=true, num_bits=8, range_given=false, input_min=?, input_max=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantize_and_dequantize(input_; name=nothing, signed_input=nothing, num_bits=nothing, range_given=nothing, input_min=nothing, input_max=nothing)
            local desc
            tf.with_op_name(name, "QuantizeAndDequantize") do 
                desc = tf.NodeDescription("QuantizeAndDequantize")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if signed_input !== nothing
                    desc["signed_input"] = Base.Bool(signed_input)
                end
                if num_bits !== nothing
                    desc["num_bits"] = Base.Int(num_bits)
                end
                if range_given !== nothing
                    desc["range_given"] = Base.Bool(range_given)
                end
                if input_min !== nothing
                    desc["input_min"] = Base.identity(input_min)
                end
                if input_max !== nothing
                    desc["input_max"] = Base.identity(input_max)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function quantize_and_dequantize(input_::tf.TensorHandle; name=nothing, signed_input=nothing, num_bits=nothing, range_given=nothing, input_min=nothing, input_max=nothing)
        desc = tf.EagerOp("QuantizeAndDequantize")
        tf.add_input(desc, input_)
        if signed_input !== nothing
            desc["signed_input"] = Base.Bool(signed_input)
        end
        if num_bits !== nothing
            desc["num_bits"] = Base.Int(num_bits)
        end
        if range_given !== nothing
            desc["range_given"] = Base.Bool(range_given)
        end
        if input_min !== nothing
            desc["input_min"] = Base.identity(input_min)
        end
        if input_max !== nothing
            desc["input_max"] = Base.identity(input_max)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_pop_back(input_handle, element_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_pop_back(input_handle_, element_shape_; name=nothing, element_dtype=nothing)
            local desc
            tf.with_op_name(name, "TensorListPopBack") do 
                desc = tf.NodeDescription("TensorListPopBack")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                element_shape_ = convert(Tensor{Int32}, element_shape_)
                tf.add_input(desc, input_handle_)
                tf.add_input(desc, element_shape_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function tensor_list_pop_back(input_handle_::tf.TensorHandle, element_shape_::tf.TensorHandle; name=nothing, element_dtype=nothing)
        desc = tf.EagerOp("TensorListPopBack")
        tf.add_input(desc, input_handle_)
        tf.add_input(desc, element_shape_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        tf.execute(desc)
    end
end


"""
     debug_nan_count(input; device_name=, tensor_name=, debug_urls=Int64[], gated_grpc=false)

Debug NaN Value Counter Op
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function debug_nan_count(input_; name=nothing, device_name=nothing, tensor_name=nothing, debug_urls=nothing, gated_grpc=nothing)
            local desc
            tf.with_op_name(name, "DebugNanCount") do 
                desc = tf.NodeDescription("DebugNanCount")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if device_name !== nothing
                    desc["device_name"] = Base.String(device_name)
                end
                if tensor_name !== nothing
                    desc["tensor_name"] = Base.String(tensor_name)
                end
                if debug_urls !== nothing
                    desc["debug_urls"] = map(Base.identity, debug_urls)
                end
                if gated_grpc !== nothing
                    desc["gated_grpc"] = Base.Bool(gated_grpc)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function debug_nan_count(input_::tf.TensorHandle; name=nothing, device_name=nothing, tensor_name=nothing, debug_urls=nothing, gated_grpc=nothing)
        desc = tf.EagerOp("DebugNanCount")
        tf.add_input(desc, input_)
        if device_name !== nothing
            desc["device_name"] = Base.String(device_name)
        end
        if tensor_name !== nothing
            desc["tensor_name"] = Base.String(tensor_name)
        end
        if debug_urls !== nothing
            desc["debug_urls"] = map(Base.identity, debug_urls)
        end
        if gated_grpc !== nothing
            desc["gated_grpc"] = Base.Bool(gated_grpc)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     apply_adagrad_da(var, gradient_accumulator, gradient_squared_accumulator, grad, lr, l1, l2, global_step; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_adagrad_da(var_, gradient_accumulator_, gradient_squared_accumulator_, grad_, lr_, l1_, l2_, global_step_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyAdagradDA") do 
                desc = tf.NodeDescription("ApplyAdagradDA")
                var_ = convert(Tensor{Any}, var_)
                gradient_accumulator_ = convert(Tensor{Any}, gradient_accumulator_)
                gradient_squared_accumulator_ = convert(Tensor{Any}, gradient_squared_accumulator_)
                grad_ = convert(Tensor{Any}, grad_)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                global_step_ = convert(Tensor{Int64}, global_step_)
                (var_, gradient_accumulator_, gradient_squared_accumulator_, grad_, lr_, l1_, l2_) = tf.tf_promote(var_, gradient_accumulator_, gradient_squared_accumulator_, grad_, lr_, l1_, l2_)
                tf.add_input(desc, var_)
                tf.add_input(desc, gradient_accumulator_)
                tf.add_input(desc, gradient_squared_accumulator_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, global_step_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_adagrad_da(var_::tf.TensorHandle, gradient_accumulator_::tf.TensorHandle, gradient_squared_accumulator_::tf.TensorHandle, grad_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, global_step_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyAdagradDA")
        tf.add_input(desc, var_)
        tf.add_input(desc, gradient_accumulator_)
        tf.add_input(desc, gradient_squared_accumulator_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, global_step_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(gradient_accumulator_)
        desc["T"] = tf.data_type(gradient_squared_accumulator_)
        desc["T"] = tf.data_type(grad_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        (tf.execute(desc))[1]
    end
end


"""
     depthwise_conv2d_native(input, filter; data_format=NHWC, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function depthwise_conv2d_native(input_, filter_; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "DepthwiseConv2dNative") do 
                desc = tf.NodeDescription("DepthwiseConv2dNative")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                (input_, filter_) = tf.tf_promote(input_, filter_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function depthwise_conv2d_native(input_::tf.TensorHandle, filter_::tf.TensorHandle; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
        desc = tf.EagerOp("DepthwiseConv2dNative")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(filter_)
        (tf.execute(desc))[1]
    end
end


"""
     serialize_iterator(resource_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function serialize_iterator(resource_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "SerializeIterator") do 
                desc = tf.NodeDescription("SerializeIterator")
                resource_handle_ = convert(Tensor{Any}, resource_handle_)
                tf.add_input(desc, resource_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function serialize_iterator(resource_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SerializeIterator")
        tf.add_input(desc, resource_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     dataset_to_graph(input_dataset)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function dataset_to_graph(input_dataset_; name=nothing)
            local desc
            tf.with_op_name(name, "DatasetToGraph") do 
                desc = tf.NodeDescription("DatasetToGraph")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                tf.add_input(desc, input_dataset_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function dataset_to_graph(input_dataset_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DatasetToGraph")
        tf.add_input(desc, input_dataset_)
        (tf.execute(desc))[1]
    end
end


"""
     top_k(input; sorted=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function top_k(input_; name=nothing, k=nothing, sorted=nothing)
            local desc
            tf.with_op_name(name, "TopK") do 
                desc = tf.NodeDescription("TopK")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if k !== nothing
                    desc["k"] = Base.Int(k)
                end
                if sorted !== nothing
                    desc["sorted"] = Base.Bool(sorted)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function top_k(input_::tf.TensorHandle; name=nothing, k=nothing, sorted=nothing)
        desc = tf.EagerOp("TopK")
        tf.add_input(desc, input_)
        if k !== nothing
            desc["k"] = Base.Int(k)
        end
        if sorted !== nothing
            desc["sorted"] = Base.Bool(sorted)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     resource_apply_ftrl_v2(var, accum, linear, grad, lr, l1, l2, l2_shrinkage, lr_power; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_ftrl_v2(var_, accum_, linear_, grad_, lr_, l1_, l2_, l2_shrinkage_, lr_power_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyFtrlV2") do 
                desc = tf.NodeDescription("ResourceApplyFtrlV2")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                linear_ = convert(Tensor{Any}, linear_)
                grad_ = convert(Tensor{Any}, grad_)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                l2_shrinkage_ = convert(Tensor{Any}, l2_shrinkage_)
                lr_power_ = convert(Tensor{Any}, lr_power_)
                (grad_, lr_, l1_, l2_, l2_shrinkage_, lr_power_) = tf.tf_promote(grad_, lr_, l1_, l2_, l2_shrinkage_, lr_power_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, linear_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, l2_shrinkage_)
                tf.add_input(desc, lr_power_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_ftrl_v2(var_::tf.TensorHandle, accum_::tf.TensorHandle, linear_::tf.TensorHandle, grad_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, l2_shrinkage_::tf.TensorHandle, lr_power_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyFtrlV2")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, linear_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, l2_shrinkage_)
        tf.add_input(desc, lr_power_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(grad_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(l2_shrinkage_)
        desc["T"] = tf.data_type(lr_power_)
        (tf.execute(desc))[1]
    end
end


"""
     _nccl_broadcast_recv(shape)

Replacement node for NcclBroadcast.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _nccl_broadcast_recv(shape_; name=nothing, num_devices=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "_NcclBroadcastRecv") do 
                desc = tf.NodeDescription("_NcclBroadcastRecv")
                shape_ = convert(Tensor{Int32}, shape_)
                tf.add_input(desc, shape_)
                if num_devices !== nothing
                    desc["num_devices"] = Base.Int(num_devices)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _nccl_broadcast_recv(shape_::tf.TensorHandle; name=nothing, num_devices=nothing, shared_name=nothing)
        desc = tf.EagerOp("_NcclBroadcastRecv")
        tf.add_input(desc, shape_)
        if num_devices !== nothing
            desc["num_devices"] = Base.Int(num_devices)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     queue_is_closed(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_is_closed(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "QueueIsClosed") do 
                desc = tf.NodeDescription("QueueIsClosed")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_is_closed(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("QueueIsClosed")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     shuffle_dataset(input_dataset, buffer_size, seed, seed2; reshuffle_each_iteration=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function shuffle_dataset(input_dataset_, buffer_size_, seed_, seed2_; name=nothing, reshuffle_each_iteration=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ShuffleDataset") do 
                desc = tf.NodeDescription("ShuffleDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                buffer_size_ = convert(Tensor{Int64}, buffer_size_)
                seed_ = convert(Tensor{Int64}, seed_)
                seed2_ = convert(Tensor{Int64}, seed2_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, buffer_size_)
                tf.add_input(desc, seed_)
                tf.add_input(desc, seed2_)
                if reshuffle_each_iteration !== nothing
                    desc["reshuffle_each_iteration"] = Base.Bool(reshuffle_each_iteration)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function shuffle_dataset(input_dataset_::tf.TensorHandle, buffer_size_::tf.TensorHandle, seed_::tf.TensorHandle, seed2_::tf.TensorHandle; name=nothing, reshuffle_each_iteration=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ShuffleDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, buffer_size_)
        tf.add_input(desc, seed_)
        tf.add_input(desc, seed2_)
        if reshuffle_each_iteration !== nothing
            desc["reshuffle_each_iteration"] = Base.Bool(reshuffle_each_iteration)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     deserialize_sparse(serialized_sparse)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function deserialize_sparse(serialized_sparse_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "DeserializeSparse") do 
                desc = tf.NodeDescription("DeserializeSparse")
                serialized_sparse_ = convert(Tensor{String}, serialized_sparse_)
                (serialized_sparse_,) = tf.tf_promote(serialized_sparse_)
                tf.add_input(desc, serialized_sparse_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function deserialize_sparse(serialized_sparse_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("DeserializeSparse")
        tf.add_input(desc, serialized_sparse_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["Tserialized"] = tf.data_type(serialized_sparse_)
        tf.execute(desc)
    end
end


"""
     priority_queue_v2(; component_types=Int64[], capacity=-1, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function priority_queue_v2(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "PriorityQueueV2") do 
                desc = tf.NodeDescription("PriorityQueueV2")
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function priority_queue_v2(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("PriorityQueueV2")
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     _device_arg()

A graph node which represents an argument to a function.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _device_arg(; name=nothing, index=nothing)
            local desc
            tf.with_op_name(name, "_DeviceArg") do 
                desc = tf.NodeDescription("_DeviceArg")
                if index !== nothing
                    desc["index"] = Base.Int(index)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _device_arg(; name=nothing, index=nothing)
        desc = tf.EagerOp("_DeviceArg")
        if index !== nothing
            desc["index"] = Base.Int(index)
        end
        (tf.execute(desc))[1]
    end
end


"""
     truncated_normal(shape; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function truncated_normal(shape_; name=nothing, seed=nothing, seed2=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "TruncatedNormal") do 
                desc = tf.NodeDescription("TruncatedNormal")
                shape_ = convert(Tensor{Any}, shape_)
                (shape_,) = tf.tf_promote(shape_)
                tf.add_input(desc, shape_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function truncated_normal(shape_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing, dtype=nothing)
        desc = tf.EagerOp("TruncatedNormal")
        tf.add_input(desc, shape_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["T"] = tf.data_type(shape_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_forest_tree_predict(tree_handle, dense_features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_forest_tree_predict(tree_handle_, dense_features_; name=nothing, logits_dimension=nothing)
            local desc
            tf.with_op_name(name, "TensorForestTreePredict") do 
                desc = tf.NodeDescription("TensorForestTreePredict")
                tree_handle_ = convert(Tensor{Any}, tree_handle_)
                dense_features_ = convert(Tensor{Float32}, dense_features_)
                tf.add_input(desc, tree_handle_)
                tf.add_input(desc, dense_features_)
                if logits_dimension !== nothing
                    desc["logits_dimension"] = Base.Int(logits_dimension)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_forest_tree_predict(tree_handle_::tf.TensorHandle, dense_features_::tf.TensorHandle; name=nothing, logits_dimension=nothing)
        desc = tf.EagerOp("TensorForestTreePredict")
        tf.add_input(desc, tree_handle_)
        tf.add_input(desc, dense_features_)
        if logits_dimension !== nothing
            desc["logits_dimension"] = Base.Int(logits_dimension)
        end
        (tf.execute(desc))[1]
    end
end


"""
     stack_v2(max_size; stack_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stack_v2(max_size_; name=nothing, elem_type=nothing, stack_name=nothing)
            local desc
            tf.with_op_name(name, "StackV2") do 
                desc = tf.NodeDescription("StackV2")
                max_size_ = convert(Tensor{Int32}, max_size_)
                tf.add_input(desc, max_size_)
                if elem_type !== nothing
                    desc["elem_type"] = Base.identity(elem_type)
                end
                if stack_name !== nothing
                    desc["stack_name"] = Base.String(stack_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stack_v2(max_size_::tf.TensorHandle; name=nothing, elem_type=nothing, stack_name=nothing)
        desc = tf.EagerOp("StackV2")
        tf.add_input(desc, max_size_)
        if elem_type !== nothing
            desc["elem_type"] = Base.identity(elem_type)
        end
        if stack_name !== nothing
            desc["stack_name"] = Base.String(stack_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     accumulator_num_accumulated(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function accumulator_num_accumulated(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "AccumulatorNumAccumulated") do 
                desc = tf.NodeDescription("AccumulatorNumAccumulated")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function accumulator_num_accumulated(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("AccumulatorNumAccumulated")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     reader_reset_v2(reader_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_reset_v2(reader_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderResetV2") do 
                desc = tf.NodeDescription("ReaderResetV2")
                reader_handle_ = convert(Tensor{Any}, reader_handle_)
                tf.add_input(desc, reader_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reader_reset_v2(reader_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderResetV2")
        tf.add_input(desc, reader_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     apply_add_sign(var, m, lr, alpha, sign_decay, beta, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_add_sign(var_, m_, lr_, alpha_, sign_decay_, beta_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyAddSign") do 
                desc = tf.NodeDescription("ApplyAddSign")
                var_ = convert(Tensor{Any}, var_)
                m_ = convert(Tensor{Any}, m_)
                lr_ = convert(Tensor{Any}, lr_)
                alpha_ = convert(Tensor{Any}, alpha_)
                sign_decay_ = convert(Tensor{Any}, sign_decay_)
                beta_ = convert(Tensor{Any}, beta_)
                grad_ = convert(Tensor{Any}, grad_)
                (var_, m_, lr_, alpha_, sign_decay_, beta_, grad_) = tf.tf_promote(var_, m_, lr_, alpha_, sign_decay_, beta_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, m_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, alpha_)
                tf.add_input(desc, sign_decay_)
                tf.add_input(desc, beta_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_add_sign(var_::tf.TensorHandle, m_::tf.TensorHandle, lr_::tf.TensorHandle, alpha_::tf.TensorHandle, sign_decay_::tf.TensorHandle, beta_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyAddSign")
        tf.add_input(desc, var_)
        tf.add_input(desc, m_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, alpha_)
        tf.add_input(desc, sign_decay_)
        tf.add_input(desc, beta_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(m_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(alpha_)
        desc["T"] = tf.data_type(sign_decay_)
        desc["T"] = tf.data_type(beta_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_rms_prop_parameters_grad_accum_debug(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_rms_prop_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingRMSPropParametersGradAccumDebug") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingRMSPropParametersGradAccumDebug")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_rms_prop_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingRMSPropParametersGradAccumDebug")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     rint(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function rint(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Rint") do 
                desc = tf.NodeDescription("Rint")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function rint(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Rint")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_adadelta_parameters_grad_accum_debug(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_adadelta_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingAdadeltaParametersGradAccumDebug") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingAdadeltaParametersGradAccumDebug")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_adadelta_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingAdadeltaParametersGradAccumDebug")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     extract_glimpse(input, size, offsets; centered=true, normalized=true, uniform_noise=true, noise=uniform)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function extract_glimpse(input_, size_, offsets_; name=nothing, centered=nothing, normalized=nothing, uniform_noise=nothing, noise=nothing)
            local desc
            tf.with_op_name(name, "ExtractGlimpse") do 
                desc = tf.NodeDescription("ExtractGlimpse")
                input_ = convert(Tensor{Float32}, input_)
                size_ = convert(Tensor{Int32}, size_)
                offsets_ = convert(Tensor{Float32}, offsets_)
                tf.add_input(desc, input_)
                tf.add_input(desc, size_)
                tf.add_input(desc, offsets_)
                if centered !== nothing
                    desc["centered"] = Base.Bool(centered)
                end
                if normalized !== nothing
                    desc["normalized"] = Base.Bool(normalized)
                end
                if uniform_noise !== nothing
                    desc["uniform_noise"] = Base.Bool(uniform_noise)
                end
                if noise !== nothing
                    desc["noise"] = Base.String(noise)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function extract_glimpse(input_::tf.TensorHandle, size_::tf.TensorHandle, offsets_::tf.TensorHandle; name=nothing, centered=nothing, normalized=nothing, uniform_noise=nothing, noise=nothing)
        desc = tf.EagerOp("ExtractGlimpse")
        tf.add_input(desc, input_)
        tf.add_input(desc, size_)
        tf.add_input(desc, offsets_)
        if centered !== nothing
            desc["centered"] = Base.Bool(centered)
        end
        if normalized !== nothing
            desc["normalized"] = Base.Bool(normalized)
        end
        if uniform_noise !== nothing
            desc["uniform_noise"] = Base.Bool(uniform_noise)
        end
        if noise !== nothing
            desc["noise"] = Base.String(noise)
        end
        (tf.execute(desc))[1]
    end
end


"""
     string_to_hash_bucket_strong(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function string_to_hash_bucket_strong(input_; name=nothing, num_buckets=nothing, key=nothing)
            local desc
            tf.with_op_name(name, "StringToHashBucketStrong") do 
                desc = tf.NodeDescription("StringToHashBucketStrong")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
                if num_buckets !== nothing
                    desc["num_buckets"] = Base.Int(num_buckets)
                end
                if key !== nothing
                    desc["key"] = map(Base.identity, key)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function string_to_hash_bucket_strong(input_::tf.TensorHandle; name=nothing, num_buckets=nothing, key=nothing)
        desc = tf.EagerOp("StringToHashBucketStrong")
        tf.add_input(desc, input_)
        if num_buckets !== nothing
            desc["num_buckets"] = Base.Int(num_buckets)
        end
        if key !== nothing
            desc["key"] = map(Base.identity, key)
        end
        (tf.execute(desc))[1]
    end
end


"""
     one_shot_iterator(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function one_shot_iterator(; name=nothing, dataset_factory=nothing, output_types=nothing, output_shapes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "OneShotIterator") do 
                desc = tf.NodeDescription("OneShotIterator")
                if dataset_factory !== nothing
                    desc["dataset_factory"] = Base.identity(dataset_factory)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function one_shot_iterator(; name=nothing, dataset_factory=nothing, output_types=nothing, output_shapes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("OneShotIterator")
        if dataset_factory !== nothing
            desc["dataset_factory"] = Base.identity(dataset_factory)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_sparse_apply_momentum(var, accum, lr, grad, indices, momentum; use_locking=false, use_nesterov=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_sparse_apply_momentum(var_, accum_, lr_, grad_, indices_, momentum_; name=nothing, use_locking=nothing, use_nesterov=nothing)
            local desc
            tf.with_op_name(name, "ResourceSparseApplyMomentum") do 
                desc = tf.NodeDescription("ResourceSparseApplyMomentum")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                momentum_ = convert(Tensor{Any}, momentum_)
                (lr_, grad_, momentum_) = tf.tf_promote(lr_, grad_, momentum_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, momentum_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if use_nesterov !== nothing
                    desc["use_nesterov"] = Base.Bool(use_nesterov)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_sparse_apply_momentum(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle, momentum_::tf.TensorHandle; name=nothing, use_locking=nothing, use_nesterov=nothing)
        desc = tf.EagerOp("ResourceSparseApplyMomentum")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, momentum_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if use_nesterov !== nothing
            desc["use_nesterov"] = Base.Bool(use_nesterov)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(momentum_)
        (tf.execute(desc))[1]
    end
end


"""
     save_slices(filename, tensor_names, shapes_and_slices, data)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function save_slices(filename_, tensor_names_, shapes_and_slices_, data_; name=nothing, T=nothing)
            local desc
            tf.with_op_name(name, "SaveSlices") do 
                desc = tf.NodeDescription("SaveSlices")
                filename_ = convert(Tensor{String}, filename_)
                tensor_names_ = convert(Tensor{String}, tensor_names_)
                shapes_and_slices_ = convert(Tensor{String}, shapes_and_slices_)
                data_ = [convert(Tensor{Any}, x) for x = data_]
                tf.add_input(desc, filename_)
                tf.add_input(desc, tensor_names_)
                tf.add_input(desc, shapes_and_slices_)
                tf.add_input(desc, data_)
                if T !== nothing
                    desc["T"] = map(Base.identity, T)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function save_slices(filename_::tf.TensorHandle, tensor_names_::tf.TensorHandle, shapes_and_slices_::tf.TensorHandle, data_::tf.TensorHandle; name=nothing, T=nothing)
        desc = tf.EagerOp("SaveSlices")
        tf.add_input(desc, filename_)
        tf.add_input(desc, tensor_names_)
        tf.add_input(desc, shapes_and_slices_)
        tf.add_input(desc, data_)
        if T !== nothing
            desc["T"] = map(Base.identity, T)
        end
        (tf.execute(desc))[1]
    end
end


"""
     experimental_dataset_cardinality(input_dataset)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_dataset_cardinality(input_dataset_; name=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalDatasetCardinality") do 
                desc = tf.NodeDescription("ExperimentalDatasetCardinality")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                tf.add_input(desc, input_dataset_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_dataset_cardinality(input_dataset_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ExperimentalDatasetCardinality")
        tf.add_input(desc, input_dataset_)
        (tf.execute(desc))[1]
    end
end


"""
     is_finite(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function is_finite(x_; name=nothing)
            local desc
            tf.with_op_name(name, "IsFinite") do 
                desc = tf.NodeDescription("IsFinite")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function is_finite(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IsFinite")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_numa_map_and_batch_dataset(input_dataset, other_arguments, batch_size, num_parallel_calls, drop_remainder; preserve_cardinality=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_numa_map_and_batch_dataset(input_dataset_, other_arguments_, batch_size_, num_parallel_calls_, drop_remainder_; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, preserve_cardinality=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalNumaMapAndBatchDataset") do 
                desc = tf.NodeDescription("ExperimentalNumaMapAndBatchDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                batch_size_ = convert(Tensor{Int64}, batch_size_)
                num_parallel_calls_ = convert(Tensor{Int64}, num_parallel_calls_)
                drop_remainder_ = convert(Tensor{Bool}, drop_remainder_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, other_arguments_)
                tf.add_input(desc, batch_size_)
                tf.add_input(desc, num_parallel_calls_)
                tf.add_input(desc, drop_remainder_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if preserve_cardinality !== nothing
                    desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_numa_map_and_batch_dataset(input_dataset_::tf.TensorHandle, other_arguments_::tf.TensorHandle, batch_size_::tf.TensorHandle, num_parallel_calls_::tf.TensorHandle, drop_remainder_::tf.TensorHandle; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing, preserve_cardinality=nothing)
        desc = tf.EagerOp("ExperimentalNumaMapAndBatchDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, other_arguments_)
        tf.add_input(desc, batch_size_)
        tf.add_input(desc, num_parallel_calls_)
        tf.add_input(desc, drop_remainder_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if preserve_cardinality !== nothing
            desc["preserve_cardinality"] = Base.Bool(preserve_cardinality)
        end
        (tf.execute(desc))[1]
    end
end


"""
     all_to_all(input, group_assignment)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function all_to_all(input_, group_assignment_; name=nothing, concat_dimension=nothing, split_dimension=nothing, split_count=nothing)
            local desc
            tf.with_op_name(name, "AllToAll") do 
                desc = tf.NodeDescription("AllToAll")
                input_ = convert(Tensor{Any}, input_)
                group_assignment_ = convert(Tensor{Int32}, group_assignment_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, group_assignment_)
                if concat_dimension !== nothing
                    desc["concat_dimension"] = Base.Int(concat_dimension)
                end
                if split_dimension !== nothing
                    desc["split_dimension"] = Base.Int(split_dimension)
                end
                if split_count !== nothing
                    desc["split_count"] = Base.Int(split_count)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function all_to_all(input_::tf.TensorHandle, group_assignment_::tf.TensorHandle; name=nothing, concat_dimension=nothing, split_dimension=nothing, split_count=nothing)
        desc = tf.EagerOp("AllToAll")
        tf.add_input(desc, input_)
        tf.add_input(desc, group_assignment_)
        if concat_dimension !== nothing
            desc["concat_dimension"] = Base.Int(concat_dimension)
        end
        if split_dimension !== nothing
            desc["split_dimension"] = Base.Int(split_dimension)
        end
        if split_count !== nothing
            desc["split_count"] = Base.Int(split_count)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     take_many_sparse_from_tensors_map(sparse_handles; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function take_many_sparse_from_tensors_map(sparse_handles_; name=nothing, dtype=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "TakeManySparseFromTensorsMap") do 
                desc = tf.NodeDescription("TakeManySparseFromTensorsMap")
                sparse_handles_ = convert(Tensor{Int64}, sparse_handles_)
                tf.add_input(desc, sparse_handles_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function take_many_sparse_from_tensors_map(sparse_handles_::tf.TensorHandle; name=nothing, dtype=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("TakeManySparseFromTensorsMap")
        tf.add_input(desc, sparse_handles_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        tf.execute(desc)
    end
end


"""
     batch_matrix_diag_part(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_matrix_diag_part(input_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchMatrixDiagPart") do 
                desc = tf.NodeDescription("BatchMatrixDiagPart")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_matrix_diag_part(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchMatrixDiagPart")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     fixed_length_record_dataset(filenames, header_bytes, record_bytes, footer_bytes, buffer_size)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fixed_length_record_dataset(filenames_, header_bytes_, record_bytes_, footer_bytes_, buffer_size_; name=nothing)
            local desc
            tf.with_op_name(name, "FixedLengthRecordDataset") do 
                desc = tf.NodeDescription("FixedLengthRecordDataset")
                filenames_ = convert(Tensor{String}, filenames_)
                header_bytes_ = convert(Tensor{Int64}, header_bytes_)
                record_bytes_ = convert(Tensor{Int64}, record_bytes_)
                footer_bytes_ = convert(Tensor{Int64}, footer_bytes_)
                buffer_size_ = convert(Tensor{Int64}, buffer_size_)
                tf.add_input(desc, filenames_)
                tf.add_input(desc, header_bytes_)
                tf.add_input(desc, record_bytes_)
                tf.add_input(desc, footer_bytes_)
                tf.add_input(desc, buffer_size_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fixed_length_record_dataset(filenames_::tf.TensorHandle, header_bytes_::tf.TensorHandle, record_bytes_::tf.TensorHandle, footer_bytes_::tf.TensorHandle, buffer_size_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("FixedLengthRecordDataset")
        tf.add_input(desc, filenames_)
        tf.add_input(desc, header_bytes_)
        tf.add_input(desc, record_bytes_)
        tf.add_input(desc, footer_bytes_)
        tf.add_input(desc, buffer_size_)
        (tf.execute(desc))[1]
    end
end


"""
     stack_push(handle, elem; swap_memory=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stack_push(handle_, elem_; name=nothing, swap_memory=nothing)
            local desc
            tf.with_op_name(name, "StackPush") do 
                desc = tf.NodeDescription("StackPush")
                handle_ = convert(Tensor{String}, handle_)
                elem_ = convert(Tensor{Any}, elem_)
                (elem_,) = tf.tf_promote(elem_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, elem_)
                if swap_memory !== nothing
                    desc["swap_memory"] = Base.Bool(swap_memory)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stack_push(handle_::tf.TensorHandle, elem_::tf.TensorHandle; name=nothing, swap_memory=nothing)
        desc = tf.EagerOp("StackPush")
        tf.add_input(desc, handle_)
        tf.add_input(desc, elem_)
        if swap_memory !== nothing
            desc["swap_memory"] = Base.Bool(swap_memory)
        end
        desc["T"] = tf.data_type(elem_)
        (tf.execute(desc))[1]
    end
end


"""
     placeholder_v2()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function placeholder_v2(; name=nothing, dtype=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "PlaceholderV2") do 
                desc = tf.NodeDescription("PlaceholderV2")
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function placeholder_v2(; name=nothing, dtype=nothing, shape=nothing)
        desc = tf.EagerOp("PlaceholderV2")
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     multi_device_iterator_init(dataset, multi_device_iterator, max_buffer_size)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function multi_device_iterator_init(dataset_, multi_device_iterator_, max_buffer_size_; name=nothing)
            local desc
            tf.with_op_name(name, "MultiDeviceIteratorInit") do 
                desc = tf.NodeDescription("MultiDeviceIteratorInit")
                dataset_ = convert(Tensor{Any}, dataset_)
                multi_device_iterator_ = convert(Tensor{Any}, multi_device_iterator_)
                max_buffer_size_ = convert(Tensor{Int64}, max_buffer_size_)
                tf.add_input(desc, dataset_)
                tf.add_input(desc, multi_device_iterator_)
                tf.add_input(desc, max_buffer_size_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function multi_device_iterator_init(dataset_::tf.TensorHandle, multi_device_iterator_::tf.TensorHandle, max_buffer_size_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MultiDeviceIteratorInit")
        tf.add_input(desc, dataset_)
        tf.add_input(desc, multi_device_iterator_)
        tf.add_input(desc, max_buffer_size_)
        (tf.execute(desc))[1]
    end
end


"""
     gcs_configure_block_cache(max_cache_size, block_size, max_staleness)

Re-configures the GCS block cache with the new configuration values.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function gcs_configure_block_cache(max_cache_size_, block_size_, max_staleness_; name=nothing)
            local desc
            tf.with_op_name(name, "GcsConfigureBlockCache") do 
                desc = tf.NodeDescription("GcsConfigureBlockCache")
                max_cache_size_ = convert(Tensor{Any}, max_cache_size_)
                block_size_ = convert(Tensor{Any}, block_size_)
                max_staleness_ = convert(Tensor{Any}, max_staleness_)
                tf.add_input(desc, max_cache_size_)
                tf.add_input(desc, block_size_)
                tf.add_input(desc, max_staleness_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function gcs_configure_block_cache(max_cache_size_::tf.TensorHandle, block_size_::tf.TensorHandle, max_staleness_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("GcsConfigureBlockCache")
        tf.add_input(desc, max_cache_size_)
        tf.add_input(desc, block_size_)
        tf.add_input(desc, max_staleness_)
        (tf.execute(desc))[1]
    end
end


"""
     queue_dequeue_v2(handle; timeout_ms=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_dequeue_v2(handle_; name=nothing, component_types=nothing, timeout_ms=nothing)
            local desc
            tf.with_op_name(name, "QueueDequeueV2") do 
                desc = tf.NodeDescription("QueueDequeueV2")
                handle_ = convert(Tensor{Any}, handle_)
                tf.add_input(desc, handle_)
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if timeout_ms !== nothing
                    desc["timeout_ms"] = Base.Int(timeout_ms)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_dequeue_v2(handle_::tf.TensorHandle; name=nothing, component_types=nothing, timeout_ms=nothing)
        desc = tf.EagerOp("QueueDequeueV2")
        tf.add_input(desc, handle_)
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if timeout_ms !== nothing
            desc["timeout_ms"] = Base.Int(timeout_ms)
        end
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_rms_prop_parameters(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_rms_prop_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingRMSPropParameters") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingRMSPropParameters")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_rms_prop_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingRMSPropParameters")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     transpose(x, perm)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function transpose(x_, perm_; name=nothing)
            local desc
            tf.with_op_name(name, "Transpose") do 
                desc = tf.NodeDescription("Transpose")
                x_ = convert(Tensor{Any}, x_)
                perm_ = convert(Tensor{Int32}, perm_)
                (perm_,) = tf.tf_promote(perm_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
                tf.add_input(desc, perm_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function transpose(x_::tf.TensorHandle, perm_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Transpose")
        tf.add_input(desc, x_)
        tf.add_input(desc, perm_)
        desc["T"] = tf.data_type(x_)
        desc["Tperm"] = tf.data_type(perm_)
        (tf.execute(desc))[1]
    end
end


"""
     ifft(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ifft(input_; name=nothing)
            local desc
            tf.with_op_name(name, "IFFT") do 
                desc = tf.NodeDescription("IFFT")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ifft(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IFFT")
        tf.add_input(desc, input_)
        desc["Tcomplex"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_segment_sum_with_num_segments(data, indices, segment_ids, num_segments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_segment_sum_with_num_segments(data_, indices_, segment_ids_, num_segments_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSegmentSumWithNumSegments") do 
                desc = tf.NodeDescription("SparseSegmentSumWithNumSegments")
                data_ = convert(Tensor{Any}, data_)
                indices_ = convert(Tensor{Int32}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                segment_ids_ = convert(Tensor{Int32}, segment_ids_)
                num_segments_ = convert(Tensor{Int32}, num_segments_)
                (num_segments_,) = tf.tf_promote(num_segments_)
                (data_,) = tf.tf_promote(data_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, data_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, segment_ids_)
                tf.add_input(desc, num_segments_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_segment_sum_with_num_segments(data_::tf.TensorHandle, indices_::tf.TensorHandle, segment_ids_::tf.TensorHandle, num_segments_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSegmentSumWithNumSegments")
        tf.add_input(desc, data_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, segment_ids_)
        tf.add_input(desc, num_segments_)
        desc["T"] = tf.data_type(data_)
        desc["Tidx"] = tf.data_type(indices_)
        desc["Tnumsegments"] = tf.data_type(num_segments_)
        (tf.execute(desc))[1]
    end
end


"""
     queue_is_closed_v2(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_is_closed_v2(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "QueueIsClosedV2") do 
                desc = tf.NodeDescription("QueueIsClosedV2")
                handle_ = convert(Tensor{Any}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_is_closed_v2(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("QueueIsClosedV2")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     parameterized_truncated_normal(shape, means, stdevs, minvals, maxvals; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function parameterized_truncated_normal(shape_, means_, stdevs_, minvals_, maxvals_; name=nothing, seed=nothing, seed2=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "ParameterizedTruncatedNormal") do 
                desc = tf.NodeDescription("ParameterizedTruncatedNormal")
                shape_ = convert(Tensor{Any}, shape_)
                means_ = convert(Tensor{Any}, means_)
                stdevs_ = convert(Tensor{Any}, stdevs_)
                minvals_ = convert(Tensor{Any}, minvals_)
                maxvals_ = convert(Tensor{Any}, maxvals_)
                (means_, stdevs_, minvals_, maxvals_) = tf.tf_promote(means_, stdevs_, minvals_, maxvals_)
                (shape_,) = tf.tf_promote(shape_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, means_)
                tf.add_input(desc, stdevs_)
                tf.add_input(desc, minvals_)
                tf.add_input(desc, maxvals_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function parameterized_truncated_normal(shape_::tf.TensorHandle, means_::tf.TensorHandle, stdevs_::tf.TensorHandle, minvals_::tf.TensorHandle, maxvals_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing, dtype=nothing)
        desc = tf.EagerOp("ParameterizedTruncatedNormal")
        tf.add_input(desc, shape_)
        tf.add_input(desc, means_)
        tf.add_input(desc, stdevs_)
        tf.add_input(desc, minvals_)
        tf.add_input(desc, maxvals_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["T"] = tf.data_type(shape_)
        desc["dtype"] = tf.data_type(means_)
        desc["dtype"] = tf.data_type(stdevs_)
        desc["dtype"] = tf.data_type(minvals_)
        desc["dtype"] = tf.data_type(maxvals_)
        (tf.execute(desc))[1]
    end
end


"""
     diag_part(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function diag_part(input_; name=nothing)
            local desc
            tf.with_op_name(name, "DiagPart") do 
                desc = tf.NodeDescription("DiagPart")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function diag_part(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DiagPart")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     kmeans_plus_plus_initialization(points, num_to_sample, seed, num_retries_per_sample)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function kmeans_plus_plus_initialization(points_, num_to_sample_, seed_, num_retries_per_sample_; name=nothing)
            local desc
            tf.with_op_name(name, "KmeansPlusPlusInitialization") do 
                desc = tf.NodeDescription("KmeansPlusPlusInitialization")
                points_ = convert(Tensor{Float32}, points_)
                num_to_sample_ = convert(Tensor{Int64}, num_to_sample_)
                seed_ = convert(Tensor{Int64}, seed_)
                num_retries_per_sample_ = convert(Tensor{Int64}, num_retries_per_sample_)
                tf.add_input(desc, points_)
                tf.add_input(desc, num_to_sample_)
                tf.add_input(desc, seed_)
                tf.add_input(desc, num_retries_per_sample_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function kmeans_plus_plus_initialization(points_::tf.TensorHandle, num_to_sample_::tf.TensorHandle, seed_::tf.TensorHandle, num_retries_per_sample_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("KmeansPlusPlusInitialization")
        tf.add_input(desc, points_)
        tf.add_input(desc, num_to_sample_)
        tf.add_input(desc, seed_)
        tf.add_input(desc, num_retries_per_sample_)
        (tf.execute(desc))[1]
    end
end


"""
     regex_replace(input, pattern, rewrite; replace_global=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function regex_replace(input_, pattern_, rewrite_; name=nothing, replace_global=nothing)
            local desc
            tf.with_op_name(name, "RegexReplace") do 
                desc = tf.NodeDescription("RegexReplace")
                input_ = convert(Tensor{String}, input_)
                pattern_ = convert(Tensor{String}, pattern_)
                rewrite_ = convert(Tensor{String}, rewrite_)
                tf.add_input(desc, input_)
                tf.add_input(desc, pattern_)
                tf.add_input(desc, rewrite_)
                if replace_global !== nothing
                    desc["replace_global"] = Base.Bool(replace_global)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function regex_replace(input_::tf.TensorHandle, pattern_::tf.TensorHandle, rewrite_::tf.TensorHandle; name=nothing, replace_global=nothing)
        desc = tf.EagerOp("RegexReplace")
        tf.add_input(desc, input_)
        tf.add_input(desc, pattern_)
        tf.add_input(desc, rewrite_)
        if replace_global !== nothing
            desc["replace_global"] = Base.Bool(replace_global)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_tensor_dense_mat_mul(a_indices, a_values, a_shape, b; adjoint_a=false, adjoint_b=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_tensor_dense_mat_mul(a_indices_, a_values_, a_shape_, b_; name=nothing, adjoint_a=nothing, adjoint_b=nothing)
            local desc
            tf.with_op_name(name, "SparseTensorDenseMatMul") do 
                desc = tf.NodeDescription("SparseTensorDenseMatMul")
                a_indices_ = convert(Tensor{Int64}, a_indices_)
                a_indices_ = a_indices_ - convert(tf.Tensor{eltype(a_indices_)}, 1)
                a_values_ = convert(Tensor{Any}, a_values_)
                a_shape_ = convert(Tensor{Int64}, a_shape_)
                b_ = convert(Tensor{Any}, b_)
                (a_values_, b_) = tf.tf_promote(a_values_, b_)
                (a_indices_,) = tf.tf_promote(a_indices_)
                tf.add_input(desc, a_indices_)
                tf.add_input(desc, a_values_)
                tf.add_input(desc, a_shape_)
                tf.add_input(desc, b_)
                if adjoint_a !== nothing
                    desc["adjoint_a"] = Base.Bool(adjoint_a)
                end
                if adjoint_b !== nothing
                    desc["adjoint_b"] = Base.Bool(adjoint_b)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_tensor_dense_mat_mul(a_indices_::tf.TensorHandle, a_values_::tf.TensorHandle, a_shape_::tf.TensorHandle, b_::tf.TensorHandle; name=nothing, adjoint_a=nothing, adjoint_b=nothing)
        desc = tf.EagerOp("SparseTensorDenseMatMul")
        tf.add_input(desc, a_indices_)
        tf.add_input(desc, a_values_)
        tf.add_input(desc, a_shape_)
        tf.add_input(desc, b_)
        if adjoint_a !== nothing
            desc["adjoint_a"] = Base.Bool(adjoint_a)
        end
        if adjoint_b !== nothing
            desc["adjoint_b"] = Base.Bool(adjoint_b)
        end
        desc["Tindices"] = tf.data_type(a_indices_)
        desc["T"] = tf.data_type(a_values_)
        desc["T"] = tf.data_type(b_)
        (tf.execute(desc))[1]
    end
end


"""
     map_defun(arguments, captured_inputs; Tcaptured=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function map_defun(arguments_, captured_inputs_; name=nothing, Targuments=nothing, Tcaptured=nothing, output_types=nothing, output_shapes=nothing, f=nothing)
            local desc
            tf.with_op_name(name, "MapDefun") do 
                desc = tf.NodeDescription("MapDefun")
                arguments_ = [convert(Tensor{Any}, x) for x = arguments_]
                captured_inputs_ = [convert(Tensor{Any}, x) for x = captured_inputs_]
                tf.add_input(desc, arguments_)
                tf.add_input(desc, captured_inputs_)
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if Tcaptured !== nothing
                    desc["Tcaptured"] = map(Base.identity, Tcaptured)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function map_defun(arguments_::tf.TensorHandle, captured_inputs_::tf.TensorHandle; name=nothing, Targuments=nothing, Tcaptured=nothing, output_types=nothing, output_shapes=nothing, f=nothing)
        desc = tf.EagerOp("MapDefun")
        tf.add_input(desc, arguments_)
        tf.add_input(desc, captured_inputs_)
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if Tcaptured !== nothing
            desc["Tcaptured"] = map(Base.identity, Tcaptured)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        (tf.execute(desc))[1]
    end
end


"""
     thread_unsafe_unigram_candidate_sampler(true_classes; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function thread_unsafe_unigram_candidate_sampler(true_classes_; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, range_max=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "ThreadUnsafeUnigramCandidateSampler") do 
                desc = tf.NodeDescription("ThreadUnsafeUnigramCandidateSampler")
                true_classes_ = convert(Tensor{Int64}, true_classes_)
                tf.add_input(desc, true_classes_)
                if num_true !== nothing
                    desc["num_true"] = Base.Int(num_true)
                end
                if num_sampled !== nothing
                    desc["num_sampled"] = Base.Int(num_sampled)
                end
                if unique !== nothing
                    desc["unique"] = Base.Bool(unique)
                end
                if range_max !== nothing
                    desc["range_max"] = Base.Int(range_max)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function thread_unsafe_unigram_candidate_sampler(true_classes_::tf.TensorHandle; name=nothing, num_true=nothing, num_sampled=nothing, unique=nothing, range_max=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("ThreadUnsafeUnigramCandidateSampler")
        tf.add_input(desc, true_classes_)
        if num_true !== nothing
            desc["num_true"] = Base.Int(num_true)
        end
        if num_sampled !== nothing
            desc["num_sampled"] = Base.Int(num_sampled)
        end
        if unique !== nothing
            desc["unique"] = Base.Bool(unique)
        end
        if range_max !== nothing
            desc["range_max"] = Base.Int(range_max)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        tf.execute(desc)
    end
end


"""
     retrieve_tpu_embedding_adam_parameters_grad_accum_debug(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_adam_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingADAMParametersGradAccumDebug") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingADAMParametersGradAccumDebug")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_adam_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingADAMParametersGradAccumDebug")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     parallel_concat(values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function parallel_concat(values_; name=nothing, N=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "ParallelConcat") do 
                desc = tf.NodeDescription("ParallelConcat")
                values_ = [convert(Tensor{Any}, x) for x = values_]
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, values_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function parallel_concat(values_::tf.TensorHandle; name=nothing, N=nothing, shape=nothing)
        desc = tf.EagerOp("ParallelConcat")
        tf.add_input(desc, values_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        desc["T"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     lookup_table_find_v2(table_handle, keys, default_value)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lookup_table_find_v2(table_handle_, keys_, default_value_; name=nothing)
            local desc
            tf.with_op_name(name, "LookupTableFindV2") do 
                desc = tf.NodeDescription("LookupTableFindV2")
                table_handle_ = convert(Tensor{Any}, table_handle_)
                keys_ = convert(Tensor{Any}, keys_)
                default_value_ = convert(Tensor{Any}, default_value_)
                (keys_,) = tf.tf_promote(keys_)
                (default_value_,) = tf.tf_promote(default_value_)
                tf.add_input(desc, table_handle_)
                tf.add_input(desc, keys_)
                tf.add_input(desc, default_value_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lookup_table_find_v2(table_handle_::tf.TensorHandle, keys_::tf.TensorHandle, default_value_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LookupTableFindV2")
        tf.add_input(desc, table_handle_)
        tf.add_input(desc, keys_)
        tf.add_input(desc, default_value_)
        desc["Tin"] = tf.data_type(keys_)
        desc["Tout"] = tf.data_type(default_value_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_forest_tree_deserialize(tree_handle, tree_config)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_forest_tree_deserialize(tree_handle_, tree_config_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorForestTreeDeserialize") do 
                desc = tf.NodeDescription("TensorForestTreeDeserialize")
                tree_handle_ = convert(Tensor{Any}, tree_handle_)
                tree_config_ = convert(Tensor{String}, tree_config_)
                tf.add_input(desc, tree_handle_)
                tf.add_input(desc, tree_config_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_forest_tree_deserialize(tree_handle_::tf.TensorHandle, tree_config_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorForestTreeDeserialize")
        tf.add_input(desc, tree_handle_)
        tf.add_input(desc, tree_config_)
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_momentum_parameters(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_momentum_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingMomentumParameters") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingMomentumParameters")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_momentum_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingMomentumParameters")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     fake_quant_with_min_max_args(inputs; min=?, max=?, num_bits=8, narrow_range=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fake_quant_with_min_max_args(inputs_; name=nothing, min=nothing, max=nothing, num_bits=nothing, narrow_range=nothing)
            local desc
            tf.with_op_name(name, "FakeQuantWithMinMaxArgs") do 
                desc = tf.NodeDescription("FakeQuantWithMinMaxArgs")
                inputs_ = convert(Tensor{Float32}, inputs_)
                tf.add_input(desc, inputs_)
                if min !== nothing
                    desc["min"] = Base.identity(min)
                end
                if max !== nothing
                    desc["max"] = Base.identity(max)
                end
                if num_bits !== nothing
                    desc["num_bits"] = Base.Int(num_bits)
                end
                if narrow_range !== nothing
                    desc["narrow_range"] = Base.Bool(narrow_range)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fake_quant_with_min_max_args(inputs_::tf.TensorHandle; name=nothing, min=nothing, max=nothing, num_bits=nothing, narrow_range=nothing)
        desc = tf.EagerOp("FakeQuantWithMinMaxArgs")
        tf.add_input(desc, inputs_)
        if min !== nothing
            desc["min"] = Base.identity(min)
        end
        if max !== nothing
            desc["max"] = Base.identity(max)
        end
        if num_bits !== nothing
            desc["num_bits"] = Base.Int(num_bits)
        end
        if narrow_range !== nothing
            desc["narrow_range"] = Base.Bool(narrow_range)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_gradient_descent(var, alpha, delta; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_gradient_descent(var_, alpha_, delta_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyGradientDescent") do 
                desc = tf.NodeDescription("ResourceApplyGradientDescent")
                var_ = convert(Tensor{Any}, var_)
                alpha_ = convert(Tensor{Any}, alpha_)
                delta_ = convert(Tensor{Any}, delta_)
                (alpha_, delta_) = tf.tf_promote(alpha_, delta_)
                tf.add_input(desc, var_)
                tf.add_input(desc, alpha_)
                tf.add_input(desc, delta_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_gradient_descent(var_::tf.TensorHandle, alpha_::tf.TensorHandle, delta_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyGradientDescent")
        tf.add_input(desc, var_)
        tf.add_input(desc, alpha_)
        tf.add_input(desc, delta_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(alpha_)
        desc["T"] = tf.data_type(delta_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_sliding_window_dataset(input_dataset, window_size, window_shift, window_stride)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_sliding_window_dataset(input_dataset_, window_size_, window_shift_, window_stride_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalSlidingWindowDataset") do 
                desc = tf.NodeDescription("ExperimentalSlidingWindowDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                window_size_ = convert(Tensor{Int64}, window_size_)
                window_shift_ = convert(Tensor{Int64}, window_shift_)
                window_stride_ = convert(Tensor{Int64}, window_stride_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, window_size_)
                tf.add_input(desc, window_shift_)
                tf.add_input(desc, window_stride_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_sliding_window_dataset(input_dataset_::tf.TensorHandle, window_size_::tf.TensorHandle, window_shift_::tf.TensorHandle, window_stride_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalSlidingWindowDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, window_size_)
        tf.add_input(desc, window_shift_)
        tf.add_input(desc, window_stride_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     decode_raw(bytes; little_endian=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function decode_raw(bytes_; name=nothing, out_type=nothing, little_endian=nothing)
            local desc
            tf.with_op_name(name, "DecodeRaw") do 
                desc = tf.NodeDescription("DecodeRaw")
                bytes_ = convert(Tensor{String}, bytes_)
                tf.add_input(desc, bytes_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if little_endian !== nothing
                    desc["little_endian"] = Base.Bool(little_endian)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function decode_raw(bytes_::tf.TensorHandle; name=nothing, out_type=nothing, little_endian=nothing)
        desc = tf.EagerOp("DecodeRaw")
        tf.add_input(desc, bytes_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if little_endian !== nothing
            desc["little_endian"] = Base.Bool(little_endian)
        end
        (tf.execute(desc))[1]
    end
end


"""
     fake_quant_with_min_max_vars_per_channel_gradient(gradients, inputs, min, max; num_bits=8, narrow_range=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fake_quant_with_min_max_vars_per_channel_gradient(gradients_, inputs_, min_, max_; name=nothing, num_bits=nothing, narrow_range=nothing)
            local desc
            tf.with_op_name(name, "FakeQuantWithMinMaxVarsPerChannelGradient") do 
                desc = tf.NodeDescription("FakeQuantWithMinMaxVarsPerChannelGradient")
                gradients_ = convert(Tensor{Float32}, gradients_)
                inputs_ = convert(Tensor{Float32}, inputs_)
                min_ = convert(Tensor{Float32}, min_)
                max_ = convert(Tensor{Float32}, max_)
                tf.add_input(desc, gradients_)
                tf.add_input(desc, inputs_)
                tf.add_input(desc, min_)
                tf.add_input(desc, max_)
                if num_bits !== nothing
                    desc["num_bits"] = Base.Int(num_bits)
                end
                if narrow_range !== nothing
                    desc["narrow_range"] = Base.Bool(narrow_range)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function fake_quant_with_min_max_vars_per_channel_gradient(gradients_::tf.TensorHandle, inputs_::tf.TensorHandle, min_::tf.TensorHandle, max_::tf.TensorHandle; name=nothing, num_bits=nothing, narrow_range=nothing)
        desc = tf.EagerOp("FakeQuantWithMinMaxVarsPerChannelGradient")
        tf.add_input(desc, gradients_)
        tf.add_input(desc, inputs_)
        tf.add_input(desc, min_)
        tf.add_input(desc, max_)
        if num_bits !== nothing
            desc["num_bits"] = Base.Int(num_bits)
        end
        if narrow_range !== nothing
            desc["narrow_range"] = Base.Bool(narrow_range)
        end
        tf.execute(desc)
    end
end


"""
     unique_with_counts_v2(x, axis; out_idx=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unique_with_counts_v2(x_, axis_; name=nothing, out_idx=nothing)
            local desc
            tf.with_op_name(name, "UniqueWithCountsV2") do 
                desc = tf.NodeDescription("UniqueWithCountsV2")
                x_ = convert(Tensor{Any}, x_)
                axis_ = convert(Tensor{Int64}, axis_)
                (x_,) = tf.tf_promote(x_)
                (axis_,) = tf.tf_promote(axis_)
                tf.add_input(desc, x_)
                tf.add_input(desc, axis_)
                if out_idx !== nothing
                    desc["out_idx"] = Base.identity(out_idx)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function unique_with_counts_v2(x_::tf.TensorHandle, axis_::tf.TensorHandle; name=nothing, out_idx=nothing)
        desc = tf.EagerOp("UniqueWithCountsV2")
        tf.add_input(desc, x_)
        tf.add_input(desc, axis_)
        if out_idx !== nothing
            desc["out_idx"] = Base.identity(out_idx)
        end
        desc["T"] = tf.data_type(x_)
        desc["Taxis"] = tf.data_type(axis_)
        tf.execute(desc)
    end
end


"""
     experimental_sleep_dataset(input_dataset, sleep_microseconds)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_sleep_dataset(input_dataset_, sleep_microseconds_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalSleepDataset") do 
                desc = tf.NodeDescription("ExperimentalSleepDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                sleep_microseconds_ = convert(Tensor{Int64}, sleep_microseconds_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, sleep_microseconds_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_sleep_dataset(input_dataset_::tf.TensorHandle, sleep_microseconds_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalSleepDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, sleep_microseconds_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tpu_replicated_output(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tpu_replicated_output(input_; name=nothing, num_replicas=nothing)
            local desc
            tf.with_op_name(name, "TPUReplicatedOutput") do 
                desc = tf.NodeDescription("TPUReplicatedOutput")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if num_replicas !== nothing
                    desc["num_replicas"] = Base.Int(num_replicas)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:num_replicas
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function tpu_replicated_output(input_::tf.TensorHandle; name=nothing, num_replicas=nothing)
        desc = tf.EagerOp("TPUReplicatedOutput")
        tf.add_input(desc, input_)
        if num_replicas !== nothing
            desc["num_replicas"] = Base.Int(num_replicas)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     lower_bound(sorted_inputs, values; out_type=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lower_bound(sorted_inputs_, values_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "LowerBound") do 
                desc = tf.NodeDescription("LowerBound")
                sorted_inputs_ = convert(Tensor{Any}, sorted_inputs_)
                values_ = convert(Tensor{Any}, values_)
                (sorted_inputs_, values_) = tf.tf_promote(sorted_inputs_, values_)
                tf.add_input(desc, sorted_inputs_)
                tf.add_input(desc, values_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lower_bound(sorted_inputs_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("LowerBound")
        tf.add_input(desc, sorted_inputs_)
        tf.add_input(desc, values_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["T"] = tf.data_type(sorted_inputs_)
        desc["T"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     tan(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tan(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Tan") do 
                desc = tf.NodeDescription("Tan")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tan(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Tan")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     enter(data; is_constant=false, parallel_iterations=10)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function enter(data_; name=nothing, frame_name=nothing, is_constant=nothing, parallel_iterations=nothing)
            local desc
            tf.with_op_name(name, "Enter") do 
                desc = tf.NodeDescription("Enter")
                data_ = convert(Tensor{Any}, data_)
                (data_,) = tf.tf_promote(data_)
                tf.add_input(desc, data_)
                if frame_name !== nothing
                    desc["frame_name"] = Base.String(frame_name)
                end
                if is_constant !== nothing
                    desc["is_constant"] = Base.Bool(is_constant)
                end
                if parallel_iterations !== nothing
                    desc["parallel_iterations"] = Base.Int(parallel_iterations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function enter(data_::tf.TensorHandle; name=nothing, frame_name=nothing, is_constant=nothing, parallel_iterations=nothing)
        desc = tf.EagerOp("Enter")
        tf.add_input(desc, data_)
        if frame_name !== nothing
            desc["frame_name"] = Base.String(frame_name)
        end
        if is_constant !== nothing
            desc["is_constant"] = Base.Bool(is_constant)
        end
        if parallel_iterations !== nothing
            desc["parallel_iterations"] = Base.Int(parallel_iterations)
        end
        desc["T"] = tf.data_type(data_)
        (tf.execute(desc))[1]
    end
end


"""
     infeed_enqueue_tuple(inputs; layouts=Int64[], device_ordinal=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function infeed_enqueue_tuple(inputs_; name=nothing, dtypes=nothing, shapes=nothing, layouts=nothing, device_ordinal=nothing)
            local desc
            tf.with_op_name(name, "InfeedEnqueueTuple") do 
                desc = tf.NodeDescription("InfeedEnqueueTuple")
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                tf.add_input(desc, inputs_)
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if layouts !== nothing
                    desc["layouts"] = map(Base.identity, layouts)
                end
                if device_ordinal !== nothing
                    desc["device_ordinal"] = Base.Int(device_ordinal)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function infeed_enqueue_tuple(inputs_::tf.TensorHandle; name=nothing, dtypes=nothing, shapes=nothing, layouts=nothing, device_ordinal=nothing)
        desc = tf.EagerOp("InfeedEnqueueTuple")
        tf.add_input(desc, inputs_)
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if layouts !== nothing
            desc["layouts"] = map(Base.identity, layouts)
        end
        if device_ordinal !== nothing
            desc["device_ordinal"] = Base.Int(device_ordinal)
        end
        (tf.execute(desc))[1]
    end
end


"""
     _set_global_tpu_array(topology)

An op that informs a host of the global ids of all the of TPUs in the
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _set_global_tpu_array(topology_; name=nothing)
            local desc
            tf.with_op_name(name, "_SetGlobalTPUArray") do 
                desc = tf.NodeDescription("_SetGlobalTPUArray")
                topology_ = convert(Tensor{String}, topology_)
                tf.add_input(desc, topology_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _set_global_tpu_array(topology_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("_SetGlobalTPUArray")
        tf.add_input(desc, topology_)
        (tf.execute(desc))[1]
    end
end


"""
     square(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function square(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Square") do 
                desc = tf.NodeDescription("Square")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function square(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Square")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     debug_gradient_ref_identity(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function debug_gradient_ref_identity(input_; name=nothing)
            local desc
            tf.with_op_name(name, "DebugGradientRefIdentity") do 
                desc = tf.NodeDescription("DebugGradientRefIdentity")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function debug_gradient_ref_identity(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("DebugGradientRefIdentity")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     apply_adadelta(var, accum, accum_update, lr, rho, epsilon, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_adadelta(var_, accum_, accum_update_, lr_, rho_, epsilon_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyAdadelta") do 
                desc = tf.NodeDescription("ApplyAdadelta")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                accum_update_ = convert(Tensor{Any}, accum_update_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                (var_, accum_, accum_update_, lr_, rho_, epsilon_, grad_) = tf.tf_promote(var_, accum_, accum_update_, lr_, rho_, epsilon_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, accum_update_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_adadelta(var_::tf.TensorHandle, accum_::tf.TensorHandle, accum_update_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyAdadelta")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, accum_update_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(accum_update_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_group_by_window_dataset(input_dataset, key_func_other_arguments, reduce_func_other_arguments, window_size_func_other_arguments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_group_by_window_dataset(input_dataset_, key_func_other_arguments_, reduce_func_other_arguments_, window_size_func_other_arguments_; name=nothing, key_func=nothing, reduce_func=nothing, window_size_func=nothing, Tkey_func_other_arguments=nothing, Treduce_func_other_arguments=nothing, Twindow_size_func_other_arguments=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalGroupByWindowDataset") do 
                desc = tf.NodeDescription("ExperimentalGroupByWindowDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                key_func_other_arguments_ = [convert(Tensor{Any}, x) for x = key_func_other_arguments_]
                reduce_func_other_arguments_ = [convert(Tensor{Any}, x) for x = reduce_func_other_arguments_]
                window_size_func_other_arguments_ = [convert(Tensor{Any}, x) for x = window_size_func_other_arguments_]
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, key_func_other_arguments_)
                tf.add_input(desc, reduce_func_other_arguments_)
                tf.add_input(desc, window_size_func_other_arguments_)
                if key_func !== nothing
                    desc["key_func"] = Base.identity(key_func)
                end
                if reduce_func !== nothing
                    desc["reduce_func"] = Base.identity(reduce_func)
                end
                if window_size_func !== nothing
                    desc["window_size_func"] = Base.identity(window_size_func)
                end
                if Tkey_func_other_arguments !== nothing
                    desc["Tkey_func_other_arguments"] = map(Base.identity, Tkey_func_other_arguments)
                end
                if Treduce_func_other_arguments !== nothing
                    desc["Treduce_func_other_arguments"] = map(Base.identity, Treduce_func_other_arguments)
                end
                if Twindow_size_func_other_arguments !== nothing
                    desc["Twindow_size_func_other_arguments"] = map(Base.identity, Twindow_size_func_other_arguments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_group_by_window_dataset(input_dataset_::tf.TensorHandle, key_func_other_arguments_::tf.TensorHandle, reduce_func_other_arguments_::tf.TensorHandle, window_size_func_other_arguments_::tf.TensorHandle; name=nothing, key_func=nothing, reduce_func=nothing, window_size_func=nothing, Tkey_func_other_arguments=nothing, Treduce_func_other_arguments=nothing, Twindow_size_func_other_arguments=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalGroupByWindowDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, key_func_other_arguments_)
        tf.add_input(desc, reduce_func_other_arguments_)
        tf.add_input(desc, window_size_func_other_arguments_)
        if key_func !== nothing
            desc["key_func"] = Base.identity(key_func)
        end
        if reduce_func !== nothing
            desc["reduce_func"] = Base.identity(reduce_func)
        end
        if window_size_func !== nothing
            desc["window_size_func"] = Base.identity(window_size_func)
        end
        if Tkey_func_other_arguments !== nothing
            desc["Tkey_func_other_arguments"] = map(Base.identity, Tkey_func_other_arguments)
        end
        if Treduce_func_other_arguments !== nothing
            desc["Treduce_func_other_arguments"] = map(Base.identity, Treduce_func_other_arguments)
        end
        if Twindow_size_func_other_arguments !== nothing
            desc["Twindow_size_func_other_arguments"] = map(Base.identity, Twindow_size_func_other_arguments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     audio_summary(tag, tensor; max_outputs=3)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function audio_summary(tag_, tensor_; name=nothing, sample_rate=nothing, max_outputs=nothing)
            local desc
            tf.with_op_name(name, "AudioSummary") do 
                desc = tf.NodeDescription("AudioSummary")
                tag_ = convert(Tensor{String}, tag_)
                tensor_ = convert(Tensor{Float32}, tensor_)
                tf.add_input(desc, tag_)
                tf.add_input(desc, tensor_)
                if sample_rate !== nothing
                    desc["sample_rate"] = Base.identity(sample_rate)
                end
                if max_outputs !== nothing
                    desc["max_outputs"] = Base.Int(max_outputs)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function audio_summary(tag_::tf.TensorHandle, tensor_::tf.TensorHandle; name=nothing, sample_rate=nothing, max_outputs=nothing)
        desc = tf.EagerOp("AudioSummary")
        tf.add_input(desc, tag_)
        tf.add_input(desc, tensor_)
        if sample_rate !== nothing
            desc["sample_rate"] = Base.identity(sample_rate)
        end
        if max_outputs !== nothing
            desc["max_outputs"] = Base.Int(max_outputs)
        end
        (tf.execute(desc))[1]
    end
end


"""
     squared_difference(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function squared_difference(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "SquaredDifference") do 
                desc = tf.NodeDescription("SquaredDifference")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function squared_difference(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SquaredDifference")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_take_while_dataset(input_dataset, other_arguments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_take_while_dataset(input_dataset_, other_arguments_; name=nothing, predicate=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalTakeWhileDataset") do 
                desc = tf.NodeDescription("ExperimentalTakeWhileDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, other_arguments_)
                if predicate !== nothing
                    desc["predicate"] = Base.identity(predicate)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_take_while_dataset(input_dataset_::tf.TensorHandle, other_arguments_::tf.TensorHandle; name=nothing, predicate=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalTakeWhileDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, other_arguments_)
        if predicate !== nothing
            desc["predicate"] = Base.identity(predicate)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     scatter_nd_update(ref, indices, updates; use_locking=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_nd_update(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ScatterNdUpdate") do 
                desc = tf.NodeDescription("ScatterNdUpdate")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (ref_, updates_) = tf.tf_promote(ref_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_nd_update(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ScatterNdUpdate")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     dynamic_stitch(indices, data)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function dynamic_stitch(indices_, data_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "DynamicStitch") do 
                desc = tf.NodeDescription("DynamicStitch")
                indices_ = [convert(Tensor{Int32}, x) for x = indices_]
                data_ = [convert(Tensor{Any}, x) for x = data_]
                (data_,) = tf.tf_promote(data_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, data_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function dynamic_stitch(indices_::tf.TensorHandle, data_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("DynamicStitch")
        tf.add_input(desc, indices_)
        tf.add_input(desc, data_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        desc["T"] = tf.data_type(data_)
        (tf.execute(desc))[1]
    end
end


"""
     ones_like(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ones_like(x_; name=nothing)
            local desc
            tf.with_op_name(name, "OnesLike") do 
                desc = tf.NodeDescription("OnesLike")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ones_like(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("OnesLike")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     fractional_max_pool_grad(orig_input, orig_output, out_backprop, row_pooling_sequence, col_pooling_sequence; overlapping=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fractional_max_pool_grad(orig_input_, orig_output_, out_backprop_, row_pooling_sequence_, col_pooling_sequence_; name=nothing, overlapping=nothing)
            local desc
            tf.with_op_name(name, "FractionalMaxPoolGrad") do 
                desc = tf.NodeDescription("FractionalMaxPoolGrad")
                orig_input_ = convert(Tensor{Any}, orig_input_)
                orig_output_ = convert(Tensor{Any}, orig_output_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                row_pooling_sequence_ = convert(Tensor{Int64}, row_pooling_sequence_)
                col_pooling_sequence_ = convert(Tensor{Int64}, col_pooling_sequence_)
                (orig_input_, orig_output_, out_backprop_) = tf.tf_promote(orig_input_, orig_output_, out_backprop_)
                tf.add_input(desc, orig_input_)
                tf.add_input(desc, orig_output_)
                tf.add_input(desc, out_backprop_)
                tf.add_input(desc, row_pooling_sequence_)
                tf.add_input(desc, col_pooling_sequence_)
                if overlapping !== nothing
                    desc["overlapping"] = Base.Bool(overlapping)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fractional_max_pool_grad(orig_input_::tf.TensorHandle, orig_output_::tf.TensorHandle, out_backprop_::tf.TensorHandle, row_pooling_sequence_::tf.TensorHandle, col_pooling_sequence_::tf.TensorHandle; name=nothing, overlapping=nothing)
        desc = tf.EagerOp("FractionalMaxPoolGrad")
        tf.add_input(desc, orig_input_)
        tf.add_input(desc, orig_output_)
        tf.add_input(desc, out_backprop_)
        tf.add_input(desc, row_pooling_sequence_)
        tf.add_input(desc, col_pooling_sequence_)
        if overlapping !== nothing
            desc["overlapping"] = Base.Bool(overlapping)
        end
        desc["T"] = tf.data_type(orig_input_)
        desc["T"] = tf.data_type(orig_output_)
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     remote_call(target, args)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function remote_call(target_, args_; name=nothing, Tin=nothing, Tout=nothing, f=nothing)
            local desc
            tf.with_op_name(name, "RemoteCall") do 
                desc = tf.NodeDescription("RemoteCall")
                target_ = convert(Tensor{String}, target_)
                args_ = [convert(Tensor{Any}, x) for x = args_]
                tf.add_input(desc, target_)
                tf.add_input(desc, args_)
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function remote_call(target_::tf.TensorHandle, args_::tf.TensorHandle; name=nothing, Tin=nothing, Tout=nothing, f=nothing)
        desc = tf.EagerOp("RemoteCall")
        tf.add_input(desc, target_)
        tf.add_input(desc, args_)
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        (tf.execute(desc))[1]
    end
end


"""
     gather(params, indices; validate_indices=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function gather(params_, indices_; name=nothing, validate_indices=nothing)
            local desc
            tf.with_op_name(name, "Gather") do 
                desc = tf.NodeDescription("Gather")
                params_ = convert(Tensor{Any}, params_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (params_,) = tf.tf_promote(params_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, params_)
                tf.add_input(desc, indices_)
                if validate_indices !== nothing
                    desc["validate_indices"] = Base.Bool(validate_indices)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function gather(params_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, validate_indices=nothing)
        desc = tf.EagerOp("Gather")
        tf.add_input(desc, params_)
        tf.add_input(desc, indices_)
        if validate_indices !== nothing
            desc["validate_indices"] = Base.Bool(validate_indices)
        end
        desc["Tparams"] = tf.data_type(params_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_mat_mul(a, b, min_a, max_a, min_b, max_b; transpose_a=false, transpose_b=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_mat_mul(a_, b_, min_a_, max_a_, min_b_, max_b_; name=nothing, transpose_a=nothing, transpose_b=nothing)
            local desc
            tf.with_op_name(name, "QuantizedMatMul") do 
                desc = tf.NodeDescription("QuantizedMatMul")
                a_ = convert(Tensor{Any}, a_)
                b_ = convert(Tensor{Any}, b_)
                min_a_ = convert(Tensor{Float32}, min_a_)
                max_a_ = convert(Tensor{Float32}, max_a_)
                min_b_ = convert(Tensor{Float32}, min_b_)
                max_b_ = convert(Tensor{Float32}, max_b_)
                (a_,) = tf.tf_promote(a_)
                (b_,) = tf.tf_promote(b_)
                tf.add_input(desc, a_)
                tf.add_input(desc, b_)
                tf.add_input(desc, min_a_)
                tf.add_input(desc, max_a_)
                tf.add_input(desc, min_b_)
                tf.add_input(desc, max_b_)
                if transpose_a !== nothing
                    desc["transpose_a"] = Base.Bool(transpose_a)
                end
                if transpose_b !== nothing
                    desc["transpose_b"] = Base.Bool(transpose_b)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_mat_mul(a_::tf.TensorHandle, b_::tf.TensorHandle, min_a_::tf.TensorHandle, max_a_::tf.TensorHandle, min_b_::tf.TensorHandle, max_b_::tf.TensorHandle; name=nothing, transpose_a=nothing, transpose_b=nothing)
        desc = tf.EagerOp("QuantizedMatMul")
        tf.add_input(desc, a_)
        tf.add_input(desc, b_)
        tf.add_input(desc, min_a_)
        tf.add_input(desc, max_a_)
        tf.add_input(desc, min_b_)
        tf.add_input(desc, max_b_)
        if transpose_a !== nothing
            desc["transpose_a"] = Base.Bool(transpose_a)
        end
        if transpose_b !== nothing
            desc["transpose_b"] = Base.Bool(transpose_b)
        end
        desc["T1"] = tf.data_type(a_)
        desc["T2"] = tf.data_type(b_)
        tf.execute(desc)
    end
end


"""
     unicode_decode_with_offsets(input; errors=replace, replacement_char=65533, replace_control_characters=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unicode_decode_with_offsets(input_; name=nothing, input_encoding=nothing, errors=nothing, replacement_char=nothing, replace_control_characters=nothing)
            local desc
            tf.with_op_name(name, "UnicodeDecodeWithOffsets") do 
                desc = tf.NodeDescription("UnicodeDecodeWithOffsets")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
                if input_encoding !== nothing
                    desc["input_encoding"] = Base.String(input_encoding)
                end
                if errors !== nothing
                    desc["errors"] = Base.String(errors)
                end
                if replacement_char !== nothing
                    desc["replacement_char"] = Base.Int(replacement_char)
                end
                if replace_control_characters !== nothing
                    desc["replace_control_characters"] = Base.Bool(replace_control_characters)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function unicode_decode_with_offsets(input_::tf.TensorHandle; name=nothing, input_encoding=nothing, errors=nothing, replacement_char=nothing, replace_control_characters=nothing)
        desc = tf.EagerOp("UnicodeDecodeWithOffsets")
        tf.add_input(desc, input_)
        if input_encoding !== nothing
            desc["input_encoding"] = Base.String(input_encoding)
        end
        if errors !== nothing
            desc["errors"] = Base.String(errors)
        end
        if replacement_char !== nothing
            desc["replacement_char"] = Base.Int(replacement_char)
        end
        if replace_control_characters !== nothing
            desc["replace_control_characters"] = Base.Bool(replace_control_characters)
        end
        tf.execute(desc)
    end
end


"""
     enqueue_tpu_embedding_sparse_tensor_batch(sample_indices, embedding_indices, aggregation_weights, mode_override; device_ordinal=-1, combiners=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function enqueue_tpu_embedding_sparse_tensor_batch(sample_indices_, embedding_indices_, aggregation_weights_, mode_override_; name=nothing, N=nothing, device_ordinal=nothing, combiners=nothing, table_ids=nothing)
            local desc
            tf.with_op_name(name, "EnqueueTPUEmbeddingSparseTensorBatch") do 
                desc = tf.NodeDescription("EnqueueTPUEmbeddingSparseTensorBatch")
                sample_indices_ = [convert(Tensor{Int32}, x) for x = sample_indices_]
                embedding_indices_ = [convert(Tensor{Int32}, x) for x = embedding_indices_]
                aggregation_weights_ = [convert(Tensor{Float32}, x) for x = aggregation_weights_]
                mode_override_ = convert(Tensor{String}, mode_override_)
                tf.add_input(desc, sample_indices_)
                tf.add_input(desc, embedding_indices_)
                tf.add_input(desc, aggregation_weights_)
                tf.add_input(desc, mode_override_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if device_ordinal !== nothing
                    desc["device_ordinal"] = Base.Int(device_ordinal)
                end
                if combiners !== nothing
                    desc["combiners"] = map(Base.identity, combiners)
                end
                if table_ids !== nothing
                    desc["table_ids"] = map(Base.identity, table_ids)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function enqueue_tpu_embedding_sparse_tensor_batch(sample_indices_::tf.TensorHandle, embedding_indices_::tf.TensorHandle, aggregation_weights_::tf.TensorHandle, mode_override_::tf.TensorHandle; name=nothing, N=nothing, device_ordinal=nothing, combiners=nothing, table_ids=nothing)
        desc = tf.EagerOp("EnqueueTPUEmbeddingSparseTensorBatch")
        tf.add_input(desc, sample_indices_)
        tf.add_input(desc, embedding_indices_)
        tf.add_input(desc, aggregation_weights_)
        tf.add_input(desc, mode_override_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if device_ordinal !== nothing
            desc["device_ordinal"] = Base.Int(device_ordinal)
        end
        if combiners !== nothing
            desc["combiners"] = map(Base.identity, combiners)
        end
        if table_ids !== nothing
            desc["table_ids"] = map(Base.identity, table_ids)
        end
        (tf.execute(desc))[1]
    end
end


"""
     accumulator_apply_gradient(handle, local_step, gradient)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function accumulator_apply_gradient(handle_, local_step_, gradient_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "AccumulatorApplyGradient") do 
                desc = tf.NodeDescription("AccumulatorApplyGradient")
                handle_ = convert(Tensor{String}, handle_)
                local_step_ = convert(Tensor{Int64}, local_step_)
                gradient_ = convert(Tensor{Any}, gradient_)
                (gradient_,) = tf.tf_promote(gradient_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, local_step_)
                tf.add_input(desc, gradient_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function accumulator_apply_gradient(handle_::tf.TensorHandle, local_step_::tf.TensorHandle, gradient_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("AccumulatorApplyGradient")
        tf.add_input(desc, handle_)
        tf.add_input(desc, local_step_)
        tf.add_input(desc, gradient_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["dtype"] = tf.data_type(gradient_)
        (tf.execute(desc))[1]
    end
end


"""
     write_summary(writer, step, tensor, tag, summary_metadata)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function write_summary(writer_, step_, tensor_, tag_, summary_metadata_; name=nothing)
            local desc
            tf.with_op_name(name, "WriteSummary") do 
                desc = tf.NodeDescription("WriteSummary")
                writer_ = convert(Tensor{Any}, writer_)
                step_ = convert(Tensor{Int64}, step_)
                tensor_ = convert(Tensor{Any}, tensor_)
                tag_ = convert(Tensor{String}, tag_)
                summary_metadata_ = convert(Tensor{String}, summary_metadata_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, writer_)
                tf.add_input(desc, step_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, tag_)
                tf.add_input(desc, summary_metadata_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function write_summary(writer_::tf.TensorHandle, step_::tf.TensorHandle, tensor_::tf.TensorHandle, tag_::tf.TensorHandle, summary_metadata_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("WriteSummary")
        tf.add_input(desc, writer_)
        tf.add_input(desc, step_)
        tf.add_input(desc, tensor_)
        tf.add_input(desc, tag_)
        tf.add_input(desc, summary_metadata_)
        desc["T"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_conv2d(input, filter, min_input, max_input, min_filter, max_filter; out_type=Float32, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_conv2d(input_, filter_, min_input_, max_input_, min_filter_, max_filter_; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConv2D") do 
                desc = tf.NodeDescription("QuantizedConv2D")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_filter_ = convert(Tensor{Float32}, min_filter_)
                max_filter_ = convert(Tensor{Float32}, max_filter_)
                (filter_,) = tf.tf_promote(filter_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_filter_)
                tf.add_input(desc, max_filter_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_conv2d(input_::tf.TensorHandle, filter_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_filter_::tf.TensorHandle, max_filter_::tf.TensorHandle; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("QuantizedConv2D")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_filter_)
        tf.add_input(desc, max_filter_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tinput"] = tf.data_type(input_)
        desc["Tfilter"] = tf.data_type(filter_)
        tf.execute(desc)
    end
end


"""
     resource_apply_momentum(var, accum, lr, grad, momentum; use_locking=false, use_nesterov=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_momentum(var_, accum_, lr_, grad_, momentum_; name=nothing, use_locking=nothing, use_nesterov=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyMomentum") do 
                desc = tf.NodeDescription("ResourceApplyMomentum")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                grad_ = convert(Tensor{Any}, grad_)
                momentum_ = convert(Tensor{Any}, momentum_)
                (lr_, grad_, momentum_) = tf.tf_promote(lr_, grad_, momentum_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, momentum_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if use_nesterov !== nothing
                    desc["use_nesterov"] = Base.Bool(use_nesterov)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_momentum(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, grad_::tf.TensorHandle, momentum_::tf.TensorHandle; name=nothing, use_locking=nothing, use_nesterov=nothing)
        desc = tf.EagerOp("ResourceApplyMomentum")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, momentum_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if use_nesterov !== nothing
            desc["use_nesterov"] = Base.Bool(use_nesterov)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(grad_)
        desc["T"] = tf.data_type(momentum_)
        (tf.execute(desc))[1]
    end
end


"""
     log1p(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function log1p(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Log1p") do 
                desc = tf.NodeDescription("Log1p")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function log1p(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Log1p")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     ordered_map_clear(; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ordered_map_clear(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "OrderedMapClear") do 
                desc = tf.NodeDescription("OrderedMapClear")
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ordered_map_clear(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("OrderedMapClear")
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_scatter_update(resource, indices, updates)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_scatter_update(resource_, indices_, updates_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "ResourceScatterUpdate") do 
                desc = tf.NodeDescription("ResourceScatterUpdate")
                resource_ = convert(Tensor{Any}, resource_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (updates_,) = tf.tf_promote(updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_scatter_update(resource_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("ResourceScatterUpdate")
        tf.add_input(desc, resource_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["Tindices"] = tf.data_type(indices_)
        desc["dtype"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     barrier_take_many(handle, num_elements; allow_small_batch=false, wait_for_incomplete=false, timeout_ms=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function barrier_take_many(handle_, num_elements_; name=nothing, component_types=nothing, allow_small_batch=nothing, wait_for_incomplete=nothing, timeout_ms=nothing)
            local desc
            tf.with_op_name(name, "BarrierTakeMany") do 
                desc = tf.NodeDescription("BarrierTakeMany")
                handle_ = convert(Tensor{String}, handle_)
                num_elements_ = convert(Tensor{Int32}, num_elements_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, num_elements_)
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if allow_small_batch !== nothing
                    desc["allow_small_batch"] = Base.Bool(allow_small_batch)
                end
                if wait_for_incomplete !== nothing
                    desc["wait_for_incomplete"] = Base.Bool(wait_for_incomplete)
                end
                if timeout_ms !== nothing
                    desc["timeout_ms"] = Base.Int(timeout_ms)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function barrier_take_many(handle_::tf.TensorHandle, num_elements_::tf.TensorHandle; name=nothing, component_types=nothing, allow_small_batch=nothing, wait_for_incomplete=nothing, timeout_ms=nothing)
        desc = tf.EagerOp("BarrierTakeMany")
        tf.add_input(desc, handle_)
        tf.add_input(desc, num_elements_)
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if allow_small_batch !== nothing
            desc["allow_small_batch"] = Base.Bool(allow_small_batch)
        end
        if wait_for_incomplete !== nothing
            desc["wait_for_incomplete"] = Base.Bool(wait_for_incomplete)
        end
        if timeout_ms !== nothing
            desc["timeout_ms"] = Base.Int(timeout_ms)
        end
        tf.execute(desc)
    end
end


"""
     resource_apply_keras_momentum(var, accum, lr, grad, momentum; use_locking=false, use_nesterov=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_keras_momentum(var_, accum_, lr_, grad_, momentum_; name=nothing, use_locking=nothing, use_nesterov=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyKerasMomentum") do 
                desc = tf.NodeDescription("ResourceApplyKerasMomentum")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                grad_ = convert(Tensor{Any}, grad_)
                momentum_ = convert(Tensor{Any}, momentum_)
                (lr_, grad_, momentum_) = tf.tf_promote(lr_, grad_, momentum_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, momentum_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if use_nesterov !== nothing
                    desc["use_nesterov"] = Base.Bool(use_nesterov)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_keras_momentum(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, grad_::tf.TensorHandle, momentum_::tf.TensorHandle; name=nothing, use_locking=nothing, use_nesterov=nothing)
        desc = tf.EagerOp("ResourceApplyKerasMomentum")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, momentum_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if use_nesterov !== nothing
            desc["use_nesterov"] = Base.Bool(use_nesterov)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(grad_)
        desc["T"] = tf.data_type(momentum_)
        (tf.execute(desc))[1]
    end
end


"""
     generate_big_query_reader_partitions(; test_end_point=)

Generates serialized partition messages suitable for batch reads.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function generate_big_query_reader_partitions(; name=nothing, project_id=nothing, dataset_id=nothing, table_id=nothing, columns=nothing, timestamp_millis=nothing, num_partitions=nothing, test_end_point=nothing)
            local desc
            tf.with_op_name(name, "GenerateBigQueryReaderPartitions") do 
                desc = tf.NodeDescription("GenerateBigQueryReaderPartitions")
                if project_id !== nothing
                    desc["project_id"] = Base.String(project_id)
                end
                if dataset_id !== nothing
                    desc["dataset_id"] = Base.String(dataset_id)
                end
                if table_id !== nothing
                    desc["table_id"] = Base.String(table_id)
                end
                if columns !== nothing
                    desc["columns"] = map(Base.identity, columns)
                end
                if timestamp_millis !== nothing
                    desc["timestamp_millis"] = Base.Int(timestamp_millis)
                end
                if num_partitions !== nothing
                    desc["num_partitions"] = Base.Int(num_partitions)
                end
                if test_end_point !== nothing
                    desc["test_end_point"] = Base.String(test_end_point)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function generate_big_query_reader_partitions(; name=nothing, project_id=nothing, dataset_id=nothing, table_id=nothing, columns=nothing, timestamp_millis=nothing, num_partitions=nothing, test_end_point=nothing)
        desc = tf.EagerOp("GenerateBigQueryReaderPartitions")
        if project_id !== nothing
            desc["project_id"] = Base.String(project_id)
        end
        if dataset_id !== nothing
            desc["dataset_id"] = Base.String(dataset_id)
        end
        if table_id !== nothing
            desc["table_id"] = Base.String(table_id)
        end
        if columns !== nothing
            desc["columns"] = map(Base.identity, columns)
        end
        if timestamp_millis !== nothing
            desc["timestamp_millis"] = Base.Int(timestamp_millis)
        end
        if num_partitions !== nothing
            desc["num_partitions"] = Base.Int(num_partitions)
        end
        if test_end_point !== nothing
            desc["test_end_point"] = Base.String(test_end_point)
        end
        (tf.execute(desc))[1]
    end
end


"""
     _xla_recv_at_host(dynamic_key)

A placeholder op for multiple values that will be sent to TensorFlow from a
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _xla_recv_at_host(dynamic_key_; name=nothing, Toutputs=nothing, key=nothing, device_ordinal=nothing)
            local desc
            tf.with_op_name(name, "_XlaRecvAtHost") do 
                desc = tf.NodeDescription("_XlaRecvAtHost")
                dynamic_key_ = convert(Tensor{String}, dynamic_key_)
                tf.add_input(desc, dynamic_key_)
                if Toutputs !== nothing
                    desc["Toutputs"] = map(Base.identity, Toutputs)
                end
                if key !== nothing
                    desc["key"] = Base.String(key)
                end
                if device_ordinal !== nothing
                    desc["device_ordinal"] = Base.Int(device_ordinal)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _xla_recv_at_host(dynamic_key_::tf.TensorHandle; name=nothing, Toutputs=nothing, key=nothing, device_ordinal=nothing)
        desc = tf.EagerOp("_XlaRecvAtHost")
        tf.add_input(desc, dynamic_key_)
        if Toutputs !== nothing
            desc["Toutputs"] = map(Base.identity, Toutputs)
        end
        if key !== nothing
            desc["key"] = Base.String(key)
        end
        if device_ordinal !== nothing
            desc["device_ordinal"] = Base.Int(device_ordinal)
        end
        (tf.execute(desc))[1]
    end
end


"""
     quantized_avg_pool(input, min_input, max_input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_avg_pool(input_, min_input_, max_input_; name=nothing, ksize=nothing, strides=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "QuantizedAvgPool") do 
                desc = tf.NodeDescription("QuantizedAvgPool")
                input_ = convert(Tensor{Any}, input_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_avg_pool(input_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing)
        desc = tf.EagerOp("QuantizedAvgPool")
        tf.add_input(desc, input_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     resource_apply_adam_with_amsgrad(var, m, v, vhat, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_adam_with_amsgrad(var_, m_, v_, vhat_, beta1_power_, beta2_power_, lr_, beta1_, beta2_, epsilon_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyAdamWithAmsgrad") do 
                desc = tf.NodeDescription("ResourceApplyAdamWithAmsgrad")
                var_ = convert(Tensor{Any}, var_)
                m_ = convert(Tensor{Any}, m_)
                v_ = convert(Tensor{Any}, v_)
                vhat_ = convert(Tensor{Any}, vhat_)
                beta1_power_ = convert(Tensor{Any}, beta1_power_)
                beta2_power_ = convert(Tensor{Any}, beta2_power_)
                lr_ = convert(Tensor{Any}, lr_)
                beta1_ = convert(Tensor{Any}, beta1_)
                beta2_ = convert(Tensor{Any}, beta2_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                (beta1_power_, beta2_power_, lr_, beta1_, beta2_, epsilon_, grad_) = tf.tf_promote(beta1_power_, beta2_power_, lr_, beta1_, beta2_, epsilon_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, m_)
                tf.add_input(desc, v_)
                tf.add_input(desc, vhat_)
                tf.add_input(desc, beta1_power_)
                tf.add_input(desc, beta2_power_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, beta1_)
                tf.add_input(desc, beta2_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_adam_with_amsgrad(var_::tf.TensorHandle, m_::tf.TensorHandle, v_::tf.TensorHandle, vhat_::tf.TensorHandle, beta1_power_::tf.TensorHandle, beta2_power_::tf.TensorHandle, lr_::tf.TensorHandle, beta1_::tf.TensorHandle, beta2_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyAdamWithAmsgrad")
        tf.add_input(desc, var_)
        tf.add_input(desc, m_)
        tf.add_input(desc, v_)
        tf.add_input(desc, vhat_)
        tf.add_input(desc, beta1_power_)
        tf.add_input(desc, beta2_power_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, beta1_)
        tf.add_input(desc, beta2_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(beta1_power_)
        desc["T"] = tf.data_type(beta2_power_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(beta1_)
        desc["T"] = tf.data_type(beta2_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_resize(input_handle, size)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_resize(input_handle_, size_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorListResize") do 
                desc = tf.NodeDescription("TensorListResize")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                size_ = convert(Tensor{Int32}, size_)
                tf.add_input(desc, input_handle_)
                tf.add_input(desc, size_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_resize(input_handle_::tf.TensorHandle, size_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorListResize")
        tf.add_input(desc, input_handle_)
        tf.add_input(desc, size_)
        (tf.execute(desc))[1]
    end
end


"""
     _host_recv(; client_terminated=false)

Receives the named tensor from send_device on recv_device.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _host_recv(; name=nothing, tensor_type=nothing, tensor_name=nothing, send_device=nothing, send_device_incarnation=nothing, recv_device=nothing, client_terminated=nothing)
            local desc
            tf.with_op_name(name, "_HostRecv") do 
                desc = tf.NodeDescription("_HostRecv")
                if tensor_type !== nothing
                    desc["tensor_type"] = Base.identity(tensor_type)
                end
                if tensor_name !== nothing
                    desc["tensor_name"] = Base.String(tensor_name)
                end
                if send_device !== nothing
                    desc["send_device"] = Base.String(send_device)
                end
                if send_device_incarnation !== nothing
                    desc["send_device_incarnation"] = Base.Int(send_device_incarnation)
                end
                if recv_device !== nothing
                    desc["recv_device"] = Base.String(recv_device)
                end
                if client_terminated !== nothing
                    desc["client_terminated"] = Base.Bool(client_terminated)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _host_recv(; name=nothing, tensor_type=nothing, tensor_name=nothing, send_device=nothing, send_device_incarnation=nothing, recv_device=nothing, client_terminated=nothing)
        desc = tf.EagerOp("_HostRecv")
        if tensor_type !== nothing
            desc["tensor_type"] = Base.identity(tensor_type)
        end
        if tensor_name !== nothing
            desc["tensor_name"] = Base.String(tensor_name)
        end
        if send_device !== nothing
            desc["send_device"] = Base.String(send_device)
        end
        if send_device_incarnation !== nothing
            desc["send_device_incarnation"] = Base.Int(send_device_incarnation)
        end
        if recv_device !== nothing
            desc["recv_device"] = Base.String(recv_device)
        end
        if client_terminated !== nothing
            desc["client_terminated"] = Base.Bool(client_terminated)
        end
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_center_bias(tree_ensemble_handle, mean_gradients, mean_hessians, l1, l2)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_center_bias(tree_ensemble_handle_, mean_gradients_, mean_hessians_, l1_, l2_; name=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesCenterBias") do 
                desc = tf.NodeDescription("BoostedTreesCenterBias")
                tree_ensemble_handle_ = convert(Tensor{Any}, tree_ensemble_handle_)
                mean_gradients_ = convert(Tensor{Float32}, mean_gradients_)
                mean_hessians_ = convert(Tensor{Float32}, mean_hessians_)
                l1_ = convert(Tensor{Float32}, l1_)
                l2_ = convert(Tensor{Float32}, l2_)
                tf.add_input(desc, tree_ensemble_handle_)
                tf.add_input(desc, mean_gradients_)
                tf.add_input(desc, mean_hessians_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_center_bias(tree_ensemble_handle_::tf.TensorHandle, mean_gradients_::tf.TensorHandle, mean_hessians_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BoostedTreesCenterBias")
        tf.add_input(desc, tree_ensemble_handle_)
        tf.add_input(desc, mean_gradients_)
        tf.add_input(desc, mean_hessians_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        (tf.execute(desc))[1]
    end
end


"""
     lookup_table_size_v2(table_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lookup_table_size_v2(table_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "LookupTableSizeV2") do 
                desc = tf.NodeDescription("LookupTableSizeV2")
                table_handle_ = convert(Tensor{Any}, table_handle_)
                tf.add_input(desc, table_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lookup_table_size_v2(table_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LookupTableSizeV2")
        tf.add_input(desc, table_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     irfft(input, fft_length)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function irfft(input_, fft_length_; name=nothing)
            local desc
            tf.with_op_name(name, "IRFFT") do 
                desc = tf.NodeDescription("IRFFT")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                fft_length_ = convert(Tensor{Int32}, fft_length_)
                tf.add_input(desc, input_)
                tf.add_input(desc, fft_length_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function irfft(input_::tf.TensorHandle, fft_length_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IRFFT")
        tf.add_input(desc, input_)
        tf.add_input(desc, fft_length_)
        (tf.execute(desc))[1]
    end
end


"""
     inplace_add(x, i, v)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function inplace_add(x_, i_, v_; name=nothing)
            local desc
            tf.with_op_name(name, "InplaceAdd") do 
                desc = tf.NodeDescription("InplaceAdd")
                x_ = convert(Tensor{Any}, x_)
                i_ = convert(Tensor{Int32}, i_)
                v_ = convert(Tensor{Any}, v_)
                (x_, v_) = tf.tf_promote(x_, v_)
                tf.add_input(desc, x_)
                tf.add_input(desc, i_)
                tf.add_input(desc, v_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function inplace_add(x_::tf.TensorHandle, i_::tf.TensorHandle, v_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("InplaceAdd")
        tf.add_input(desc, x_)
        tf.add_input(desc, i_)
        tf.add_input(desc, v_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(v_)
        (tf.execute(desc))[1]
    end
end


"""
     bias_add(value, bias; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function bias_add(value_, bias_; name=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "BiasAdd") do 
                desc = tf.NodeDescription("BiasAdd")
                value_ = convert(Tensor{Any}, value_)
                bias_ = convert(Tensor{Any}, bias_)
                (value_, bias_) = tf.tf_promote(value_, bias_)
                tf.add_input(desc, value_)
                tf.add_input(desc, bias_)
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function bias_add(value_::tf.TensorHandle, bias_::tf.TensorHandle; name=nothing, data_format=nothing)
        desc = tf.EagerOp("BiasAdd")
        tf.add_input(desc, value_)
        tf.add_input(desc, bias_)
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(value_)
        desc["T"] = tf.data_type(bias_)
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_adam_parameters_grad_accum_debug(parameters, momenta, velocities, gradient_accumulators; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_adam_parameters_grad_accum_debug(parameters_, momenta_, velocities_, gradient_accumulators_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingADAMParametersGradAccumDebug") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingADAMParametersGradAccumDebug")
                parameters_ = convert(Tensor{Float32}, parameters_)
                momenta_ = convert(Tensor{Float32}, momenta_)
                velocities_ = convert(Tensor{Float32}, velocities_)
                gradient_accumulators_ = convert(Tensor{Float32}, gradient_accumulators_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, momenta_)
                tf.add_input(desc, velocities_)
                tf.add_input(desc, gradient_accumulators_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_adam_parameters_grad_accum_debug(parameters_::tf.TensorHandle, momenta_::tf.TensorHandle, velocities_::tf.TensorHandle, gradient_accumulators_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingADAMParametersGradAccumDebug")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, momenta_)
        tf.add_input(desc, velocities_)
        tf.add_input(desc, gradient_accumulators_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     _disconnect_host_from_distributed_tpu_system()

An op that disconnects the TPUs on a host from a running distributed
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _disconnect_host_from_distributed_tpu_system(; name=nothing)
            local desc
            tf.with_op_name(name, "_DisconnectHostFromDistributedTPUSystem") do 
                desc
                tf.NodeDescription("_DisconnectHostFromDistributedTPUSystem")
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _disconnect_host_from_distributed_tpu_system(; name=nothing)
        desc = tf.EagerOp("_DisconnectHostFromDistributedTPUSystem")
        (tf.execute(desc))[1]
    end
end


"""
     ragged_range(starts, limits, deltas)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ragged_range(starts_, limits_, deltas_; name=nothing)
            local desc
            tf.with_op_name(name, "RaggedRange") do 
                desc = tf.NodeDescription("RaggedRange")
                starts_ = convert(Tensor{Int32}, starts_)
                limits_ = convert(Tensor{Int32}, limits_)
                deltas_ = convert(Tensor{Int32}, deltas_)
                (starts_, limits_, deltas_) = tf.tf_promote(starts_, limits_, deltas_)
                tf.add_input(desc, starts_)
                tf.add_input(desc, limits_)
                tf.add_input(desc, deltas_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function ragged_range(starts_::tf.TensorHandle, limits_::tf.TensorHandle, deltas_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RaggedRange")
        tf.add_input(desc, starts_)
        tf.add_input(desc, limits_)
        tf.add_input(desc, deltas_)
        desc["T"] = tf.data_type(starts_)
        desc["T"] = tf.data_type(limits_)
        desc["T"] = tf.data_type(deltas_)
        tf.execute(desc)
    end
end


"""
     window_dataset(input_dataset, size, shift, stride, drop_remainder)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function window_dataset(input_dataset_, size_, shift_, stride_, drop_remainder_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "WindowDataset") do 
                desc = tf.NodeDescription("WindowDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                size_ = convert(Tensor{Int64}, size_)
                shift_ = convert(Tensor{Int64}, shift_)
                stride_ = convert(Tensor{Int64}, stride_)
                drop_remainder_ = convert(Tensor{Bool}, drop_remainder_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, size_)
                tf.add_input(desc, shift_)
                tf.add_input(desc, stride_)
                tf.add_input(desc, drop_remainder_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function window_dataset(input_dataset_::tf.TensorHandle, size_::tf.TensorHandle, shift_::tf.TensorHandle, stride_::tf.TensorHandle, drop_remainder_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("WindowDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, size_)
        tf.add_input(desc, shift_)
        tf.add_input(desc, stride_)
        tf.add_input(desc, drop_remainder_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     diag(diagonal)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function diag(diagonal_; name=nothing)
            local desc
            tf.with_op_name(name, "Diag") do 
                desc = tf.NodeDescription("Diag")
                diagonal_ = convert(Tensor{Any}, diagonal_)
                (diagonal_,) = tf.tf_promote(diagonal_)
                tf.add_input(desc, diagonal_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function diag(diagonal_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Diag")
        tf.add_input(desc, diagonal_)
        desc["T"] = tf.data_type(diagonal_)
        (tf.execute(desc))[1]
    end
end


"""
     infeed_dequeue()


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function infeed_dequeue(; name=nothing, dtype=nothing, shape=nothing)
            local desc
            tf.with_op_name(name, "InfeedDequeue") do 
                desc = tf.NodeDescription("InfeedDequeue")
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function infeed_dequeue(; name=nothing, dtype=nothing, shape=nothing)
        desc = tf.EagerOp("InfeedDequeue")
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     experimental_latency_stats_dataset(input_dataset, tag)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_latency_stats_dataset(input_dataset_, tag_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalLatencyStatsDataset") do 
                desc = tf.NodeDescription("ExperimentalLatencyStatsDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                tag_ = convert(Tensor{String}, tag_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, tag_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_latency_stats_dataset(input_dataset_::tf.TensorHandle, tag_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalLatencyStatsDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, tag_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     add_sparse_to_tensors_map(sparse_indices, sparse_values, sparse_shape; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function add_sparse_to_tensors_map(sparse_indices_, sparse_values_, sparse_shape_; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "AddSparseToTensorsMap") do 
                desc = tf.NodeDescription("AddSparseToTensorsMap")
                sparse_indices_ = convert(Tensor{Int64}, sparse_indices_)
                sparse_values_ = convert(Tensor{Any}, sparse_values_)
                sparse_shape_ = convert(Tensor{Int64}, sparse_shape_)
                (sparse_values_,) = tf.tf_promote(sparse_values_)
                tf.add_input(desc, sparse_indices_)
                tf.add_input(desc, sparse_values_)
                tf.add_input(desc, sparse_shape_)
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function add_sparse_to_tensors_map(sparse_indices_::tf.TensorHandle, sparse_values_::tf.TensorHandle, sparse_shape_::tf.TensorHandle; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("AddSparseToTensorsMap")
        tf.add_input(desc, sparse_indices_)
        tf.add_input(desc, sparse_values_)
        tf.add_input(desc, sparse_shape_)
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        desc["T"] = tf.data_type(sparse_values_)
        (tf.execute(desc))[1]
    end
end


"""
     ragged_gather(params_nested_splits, params_dense_values, indices)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ragged_gather(params_nested_splits_, params_dense_values_, indices_; name=nothing, PARAMS_RAGGED_RANK=nothing, OUTPUT_RAGGED_RANK=nothing)
            local desc
            tf.with_op_name(name, "RaggedGather") do 
                desc = tf.NodeDescription("RaggedGather")
                params_nested_splits_ = [convert(Tensor{Int64}, x) for x = params_nested_splits_]
                params_dense_values_ = convert(Tensor{Any}, params_dense_values_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (indices_,) = tf.tf_promote(indices_)
                (params_dense_values_,) = tf.tf_promote(params_dense_values_)
                tf.add_input(desc, params_nested_splits_)
                tf.add_input(desc, params_dense_values_)
                tf.add_input(desc, indices_)
                if PARAMS_RAGGED_RANK !== nothing
                    desc["PARAMS_RAGGED_RANK"] = Base.Int(PARAMS_RAGGED_RANK)
                end
                if OUTPUT_RAGGED_RANK !== nothing
                    desc["OUTPUT_RAGGED_RANK"] = Base.Int(OUTPUT_RAGGED_RANK)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function ragged_gather(params_nested_splits_::tf.TensorHandle, params_dense_values_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, PARAMS_RAGGED_RANK=nothing, OUTPUT_RAGGED_RANK=nothing)
        desc = tf.EagerOp("RaggedGather")
        tf.add_input(desc, params_nested_splits_)
        tf.add_input(desc, params_dense_values_)
        tf.add_input(desc, indices_)
        if PARAMS_RAGGED_RANK !== nothing
            desc["PARAMS_RAGGED_RANK"] = Base.Int(PARAMS_RAGGED_RANK)
        end
        if OUTPUT_RAGGED_RANK !== nothing
            desc["OUTPUT_RAGGED_RANK"] = Base.Int(OUTPUT_RAGGED_RANK)
        end
        desc["Tvalues"] = tf.data_type(params_dense_values_)
        desc["Tindices"] = tf.data_type(indices_)
        tf.execute(desc)
    end
end


"""
     rgb_to_hsv(images)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function rgb_to_hsv(images_; name=nothing)
            local desc
            tf.with_op_name(name, "RGBToHSV") do 
                desc = tf.NodeDescription("RGBToHSV")
                images_ = convert(Tensor{Float32}, images_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function rgb_to_hsv(images_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RGBToHSV")
        tf.add_input(desc, images_)
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     multi_device_iterator_to_string_handle(multi_device_iterator)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function multi_device_iterator_to_string_handle(multi_device_iterator_; name=nothing)
            local desc
            tf.with_op_name(name, "MultiDeviceIteratorToStringHandle") do 
                desc = tf.NodeDescription("MultiDeviceIteratorToStringHandle")
                multi_device_iterator_ = convert(Tensor{Any}, multi_device_iterator_)
                tf.add_input(desc, multi_device_iterator_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function multi_device_iterator_to_string_handle(multi_device_iterator_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MultiDeviceIteratorToStringHandle")
        tf.add_input(desc, multi_device_iterator_)
        (tf.execute(desc))[1]
    end
end


"""
     for_(start, limit, delta, input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function for_(start_, limit_, delta_, input_; name=nothing, T=nothing, body=nothing)
            local desc
            tf.with_op_name(name, "For") do 
                desc = tf.NodeDescription("For")
                start_ = convert(Tensor{Int32}, start_)
                limit_ = convert(Tensor{Int32}, limit_)
                delta_ = convert(Tensor{Int32}, delta_)
                input_ = [convert(Tensor{Any}, x) for x = input_]
                tf.add_input(desc, start_)
                tf.add_input(desc, limit_)
                tf.add_input(desc, delta_)
                tf.add_input(desc, input_)
                if T !== nothing
                    desc["T"] = map(Base.identity, T)
                end
                if body !== nothing
                    desc["body"] = Base.identity(body)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function for_(start_::tf.TensorHandle, limit_::tf.TensorHandle, delta_::tf.TensorHandle, input_::tf.TensorHandle; name=nothing, T=nothing, body=nothing)
        desc = tf.EagerOp("For")
        tf.add_input(desc, start_)
        tf.add_input(desc, limit_)
        tf.add_input(desc, delta_)
        tf.add_input(desc, input_)
        if T !== nothing
            desc["T"] = map(Base.identity, T)
        end
        if body !== nothing
            desc["body"] = Base.identity(body)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_reduce_max_sparse(input_indices, input_values, input_shape, reduction_axes; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_reduce_max_sparse(input_indices_, input_values_, input_shape_, reduction_axes_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "SparseReduceMaxSparse") do 
                desc = tf.NodeDescription("SparseReduceMaxSparse")
                input_indices_ = convert(Tensor{Int64}, input_indices_)
                input_values_ = convert(Tensor{Any}, input_values_)
                input_shape_ = convert(Tensor{Int64}, input_shape_)
                reduction_axes_ = convert(Tensor{Int32}, reduction_axes_)
                (input_values_,) = tf.tf_promote(input_values_)
                tf.add_input(desc, input_indices_)
                tf.add_input(desc, input_values_)
                tf.add_input(desc, input_shape_)
                tf.add_input(desc, reduction_axes_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_reduce_max_sparse(input_indices_::tf.TensorHandle, input_values_::tf.TensorHandle, input_shape_::tf.TensorHandle, reduction_axes_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("SparseReduceMaxSparse")
        tf.add_input(desc, input_indices_)
        tf.add_input(desc, input_values_)
        tf.add_input(desc, input_shape_)
        tf.add_input(desc, reduction_axes_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["T"] = tf.data_type(input_values_)
        tf.execute(desc)
    end
end


"""
     concat_offset(concat_dim, shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function concat_offset(concat_dim_, shape_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "ConcatOffset") do 
                desc = tf.NodeDescription("ConcatOffset")
                concat_dim_ = convert(Tensor{Int32}, concat_dim_)
                shape_ = [convert(Tensor{Int32}, x) for x = shape_]
                tf.add_input(desc, concat_dim_)
                tf.add_input(desc, shape_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:N
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function concat_offset(concat_dim_::tf.TensorHandle, shape_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("ConcatOffset")
        tf.add_input(desc, concat_dim_)
        tf.add_input(desc, shape_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        tf.execute(desc)
    end
end


"""
     stage(values; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stage(values_; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "Stage") do 
                desc = tf.NodeDescription("Stage")
                values_ = [convert(Tensor{Any}, x) for x = values_]
                tf.add_input(desc, values_)
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stage(values_::tf.TensorHandle; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("Stage")
        tf.add_input(desc, values_)
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     switch(data, pred)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function switch(data_, pred_; name=nothing)
            local desc
            tf.with_op_name(name, "Switch") do 
                desc = tf.NodeDescription("Switch")
                data_ = convert(Tensor{Any}, data_)
                pred_ = convert(Tensor{Bool}, pred_)
                (data_,) = tf.tf_promote(data_)
                tf.add_input(desc, data_)
                tf.add_input(desc, pred_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function switch(data_::tf.TensorHandle, pred_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Switch")
        tf.add_input(desc, data_)
        tf.add_input(desc, pred_)
        desc["T"] = tf.data_type(data_)
        tf.execute(desc)
    end
end


"""
     queue_dequeue_many_v2(handle, n; timeout_ms=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_dequeue_many_v2(handle_, n_; name=nothing, component_types=nothing, timeout_ms=nothing)
            local desc
            tf.with_op_name(name, "QueueDequeueManyV2") do 
                desc = tf.NodeDescription("QueueDequeueManyV2")
                handle_ = convert(Tensor{Any}, handle_)
                n_ = convert(Tensor{Int32}, n_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, n_)
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if timeout_ms !== nothing
                    desc["timeout_ms"] = Base.Int(timeout_ms)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_dequeue_many_v2(handle_::tf.TensorHandle, n_::tf.TensorHandle; name=nothing, component_types=nothing, timeout_ms=nothing)
        desc = tf.EagerOp("QueueDequeueManyV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, n_)
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if timeout_ms !== nothing
            desc["timeout_ms"] = Base.Int(timeout_ms)
        end
        (tf.execute(desc))[1]
    end
end


"""
     segment_prod(data, segment_ids)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function segment_prod(data_, segment_ids_; name=nothing)
            local desc
            tf.with_op_name(name, "SegmentProd") do 
                desc = tf.NodeDescription("SegmentProd")
                data_ = convert(Tensor{Any}, data_)
                segment_ids_ = convert(Tensor{Any}, segment_ids_)
                segment_ids_ = segment_ids_ - convert(tf.Tensor{eltype(segment_ids_)}, 1)
                (data_,) = tf.tf_promote(data_)
                (segment_ids_,) = tf.tf_promote(segment_ids_)
                tf.add_input(desc, data_)
                tf.add_input(desc, segment_ids_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function segment_prod(data_::tf.TensorHandle, segment_ids_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SegmentProd")
        tf.add_input(desc, data_)
        tf.add_input(desc, segment_ids_)
        desc["T"] = tf.data_type(data_)
        desc["Tindices"] = tf.data_type(segment_ids_)
        (tf.execute(desc))[1]
    end
end


"""
     approximate_equal(x, y; tolerance=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function approximate_equal(x_, y_; name=nothing, tolerance=nothing)
            local desc
            tf.with_op_name(name, "ApproximateEqual") do 
                desc = tf.NodeDescription("ApproximateEqual")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
                if tolerance !== nothing
                    desc["tolerance"] = Base.identity(tolerance)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function approximate_equal(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing, tolerance=nothing)
        desc = tf.EagerOp("ApproximateEqual")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        if tolerance !== nothing
            desc["tolerance"] = Base.identity(tolerance)
        end
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     conv2d(input, filter; use_cudnn_on_gpu=true, explicit_paddings=Int64[], data_format=NHWC, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function conv2d(input_, filter_; name=nothing, strides=nothing, use_cudnn_on_gpu=nothing, padding=nothing, explicit_paddings=nothing, data_format=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "Conv2D") do 
                desc = tf.NodeDescription("Conv2D")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                (input_, filter_) = tf.tf_promote(input_, filter_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if use_cudnn_on_gpu !== nothing
                    desc["use_cudnn_on_gpu"] = Base.Bool(use_cudnn_on_gpu)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if explicit_paddings !== nothing
                    desc["explicit_paddings"] = map(Base.identity, explicit_paddings)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function conv2d(input_::tf.TensorHandle, filter_::tf.TensorHandle; name=nothing, strides=nothing, use_cudnn_on_gpu=nothing, padding=nothing, explicit_paddings=nothing, data_format=nothing, dilations=nothing)
        desc = tf.EagerOp("Conv2D")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if use_cudnn_on_gpu !== nothing
            desc["use_cudnn_on_gpu"] = Base.Bool(use_cudnn_on_gpu)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if explicit_paddings !== nothing
            desc["explicit_paddings"] = map(Base.identity, explicit_paddings)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(filter_)
        (tf.execute(desc))[1]
    end
end


"""
     cross_replica_sum(input, group_assignment)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cross_replica_sum(input_, group_assignment_; name=nothing)
            local desc
            tf.with_op_name(name, "CrossReplicaSum") do 
                desc = tf.NodeDescription("CrossReplicaSum")
                input_ = convert(Tensor{Any}, input_)
                group_assignment_ = convert(Tensor{Int32}, group_assignment_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, group_assignment_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cross_replica_sum(input_::tf.TensorHandle, group_assignment_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("CrossReplicaSum")
        tf.add_input(desc, input_)
        tf.add_input(desc, group_assignment_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_mat_mul(a, b; transpose_a=false, transpose_b=false, a_is_sparse=false, b_is_sparse=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_mat_mul(a_, b_; name=nothing, transpose_a=nothing, transpose_b=nothing, a_is_sparse=nothing, b_is_sparse=nothing)
            local desc
            tf.with_op_name(name, "SparseMatMul") do 
                desc = tf.NodeDescription("SparseMatMul")
                a_ = convert(Tensor{Float32}, a_)
                b_ = convert(Tensor{Float32}, b_)
                (b_,) = tf.tf_promote(b_)
                (a_,) = tf.tf_promote(a_)
                tf.add_input(desc, a_)
                tf.add_input(desc, b_)
                if transpose_a !== nothing
                    desc["transpose_a"] = Base.Bool(transpose_a)
                end
                if transpose_b !== nothing
                    desc["transpose_b"] = Base.Bool(transpose_b)
                end
                if a_is_sparse !== nothing
                    desc["a_is_sparse"] = Base.Bool(a_is_sparse)
                end
                if b_is_sparse !== nothing
                    desc["b_is_sparse"] = Base.Bool(b_is_sparse)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_mat_mul(a_::tf.TensorHandle, b_::tf.TensorHandle; name=nothing, transpose_a=nothing, transpose_b=nothing, a_is_sparse=nothing, b_is_sparse=nothing)
        desc = tf.EagerOp("SparseMatMul")
        tf.add_input(desc, a_)
        tf.add_input(desc, b_)
        if transpose_a !== nothing
            desc["transpose_a"] = Base.Bool(transpose_a)
        end
        if transpose_b !== nothing
            desc["transpose_b"] = Base.Bool(transpose_b)
        end
        if a_is_sparse !== nothing
            desc["a_is_sparse"] = Base.Bool(a_is_sparse)
        end
        if b_is_sparse !== nothing
            desc["b_is_sparse"] = Base.Bool(b_is_sparse)
        end
        desc["Ta"] = tf.data_type(a_)
        desc["Tb"] = tf.data_type(b_)
        (tf.execute(desc))[1]
    end
end


"""
     _scoped_allocator_split(concat, split)

Acts roughly like a SplitV Op that splits one tensor into multiple tensors
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _scoped_allocator_split(concat_, split_; name=nothing, sa_name=nothing, id=nothing, N=nothing, shapes=nothing)
            local desc
            tf.with_op_name(name, "_ScopedAllocatorSplit") do 
                desc = tf.NodeDescription("_ScopedAllocatorSplit")
                concat_ = convert(Tensor{Any}, concat_)
                split_ = [convert(Tensor{Any}, x) for x = split_]
                (concat_, split_) = tf.tf_promote(concat_, split_)
                tf.add_input(desc, concat_)
                tf.add_input(desc, split_)
                if sa_name !== nothing
                    desc["sa_name"] = Base.String(sa_name)
                end
                if id !== nothing
                    desc["id"] = Base.Int(id)
                end
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:N
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function _scoped_allocator_split(concat_::tf.TensorHandle, split_::tf.TensorHandle; name=nothing, sa_name=nothing, id=nothing, N=nothing, shapes=nothing)
        desc = tf.EagerOp("_ScopedAllocatorSplit")
        tf.add_input(desc, concat_)
        tf.add_input(desc, split_)
        if sa_name !== nothing
            desc["sa_name"] = Base.String(sa_name)
        end
        if id !== nothing
            desc["id"] = Base.Int(id)
        end
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        desc["T"] = tf.data_type(concat_)
        desc["T"] = tf.data_type(split_)
        tf.execute(desc)
    end
end


"""
     igammac(a, x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function igammac(a_, x_; name=nothing)
            local desc
            tf.with_op_name(name, "Igammac") do 
                desc = tf.NodeDescription("Igammac")
                a_ = convert(Tensor{Any}, a_)
                x_ = convert(Tensor{Any}, x_)
                (a_, x_) = tf.tf_promote(a_, x_)
                tf.add_input(desc, a_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function igammac(a_::tf.TensorHandle, x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Igammac")
        tf.add_input(desc, a_)
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(a_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_mat_mul(x, y; adj_x=false, adj_y=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_mat_mul(x_, y_; name=nothing, adj_x=nothing, adj_y=nothing)
            local desc
            tf.with_op_name(name, "BatchMatMul") do 
                desc = tf.NodeDescription("BatchMatMul")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
                if adj_x !== nothing
                    desc["adj_x"] = Base.Bool(adj_x)
                end
                if adj_y !== nothing
                    desc["adj_y"] = Base.Bool(adj_y)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_mat_mul(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing, adj_x=nothing, adj_y=nothing)
        desc = tf.EagerOp("BatchMatMul")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        if adj_x !== nothing
            desc["adj_x"] = Base.Bool(adj_x)
        end
        if adj_y !== nothing
            desc["adj_y"] = Base.Bool(adj_y)
        end
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     enqueue_tpu_embedding_sparse_batch(sample_indices, embedding_indices, aggregation_weights, mode_override; device_ordinal=-1, combiners=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function enqueue_tpu_embedding_sparse_batch(sample_indices_, embedding_indices_, aggregation_weights_, mode_override_; name=nothing, N=nothing, device_ordinal=nothing, combiners=nothing)
            local desc
            tf.with_op_name(name, "EnqueueTPUEmbeddingSparseBatch") do 
                desc = tf.NodeDescription("EnqueueTPUEmbeddingSparseBatch")
                sample_indices_ = [convert(Tensor{Int32}, x) for x = sample_indices_]
                embedding_indices_ = [convert(Tensor{Int32}, x) for x = embedding_indices_]
                aggregation_weights_ = [convert(Tensor{Float32}, x) for x = aggregation_weights_]
                mode_override_ = convert(Tensor{String}, mode_override_)
                tf.add_input(desc, sample_indices_)
                tf.add_input(desc, embedding_indices_)
                tf.add_input(desc, aggregation_weights_)
                tf.add_input(desc, mode_override_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if device_ordinal !== nothing
                    desc["device_ordinal"] = Base.Int(device_ordinal)
                end
                if combiners !== nothing
                    desc["combiners"] = map(Base.identity, combiners)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function enqueue_tpu_embedding_sparse_batch(sample_indices_::tf.TensorHandle, embedding_indices_::tf.TensorHandle, aggregation_weights_::tf.TensorHandle, mode_override_::tf.TensorHandle; name=nothing, N=nothing, device_ordinal=nothing, combiners=nothing)
        desc = tf.EagerOp("EnqueueTPUEmbeddingSparseBatch")
        tf.add_input(desc, sample_indices_)
        tf.add_input(desc, embedding_indices_)
        tf.add_input(desc, aggregation_weights_)
        tf.add_input(desc, mode_override_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if device_ordinal !== nothing
            desc["device_ordinal"] = Base.Int(device_ordinal)
        end
        if combiners !== nothing
            desc["combiners"] = map(Base.identity, combiners)
        end
        (tf.execute(desc))[1]
    end
end


"""
     queue_close_v2(handle; cancel_pending_enqueues=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function queue_close_v2(handle_; name=nothing, cancel_pending_enqueues=nothing)
            local desc
            tf.with_op_name(name, "QueueCloseV2") do 
                desc = tf.NodeDescription("QueueCloseV2")
                handle_ = convert(Tensor{Any}, handle_)
                tf.add_input(desc, handle_)
                if cancel_pending_enqueues !== nothing
                    desc["cancel_pending_enqueues"] = Base.Bool(cancel_pending_enqueues)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function queue_close_v2(handle_::tf.TensorHandle; name=nothing, cancel_pending_enqueues=nothing)
        desc = tf.EagerOp("QueueCloseV2")
        tf.add_input(desc, handle_)
        if cancel_pending_enqueues !== nothing
            desc["cancel_pending_enqueues"] = Base.Bool(cancel_pending_enqueues)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_pack(handle, flow_in; element_shape=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_pack(handle_, flow_in_; name=nothing, dtype=nothing, element_shape=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayPack") do 
                desc = tf.NodeDescription("TensorArrayPack")
                handle_ = convert(Tensor{String}, handle_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, flow_in_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if element_shape !== nothing
                    desc["element_shape"] = Base.identity(element_shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_pack(handle_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, dtype=nothing, element_shape=nothing)
        desc = tf.EagerOp("TensorArrayPack")
        tf.add_input(desc, handle_)
        tf.add_input(desc, flow_in_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if element_shape !== nothing
            desc["element_shape"] = Base.identity(element_shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     reader_restore_state(reader_handle, state)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_restore_state(reader_handle_, state_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderRestoreState") do 
                desc = tf.NodeDescription("ReaderRestoreState")
                reader_handle_ = convert(Tensor{String}, reader_handle_)
                state_ = convert(Tensor{String}, state_)
                tf.add_input(desc, reader_handle_)
                tf.add_input(desc, state_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reader_restore_state(reader_handle_::tf.TensorHandle, state_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderRestoreState")
        tf.add_input(desc, reader_handle_)
        tf.add_input(desc, state_)
        (tf.execute(desc))[1]
    end
end


"""
     _fused_conv2d(input, filter, args; data_format=NHWC, dilations=[1, 1, 1, 1], use_cudnn_on_gpu=true, fused_ops=Int64[], epsilon=?)

*NOTE*: Do not invoke this operator directly in Python. Grappler is
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _fused_conv2d(input_, filter_, args_; name=nothing, num_args=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing, use_cudnn_on_gpu=nothing, fused_ops=nothing, epsilon=nothing)
            local desc
            tf.with_op_name(name, "_FusedConv2D") do 
                desc = tf.NodeDescription("_FusedConv2D")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                args_ = [convert(Tensor{Any}, x) for x = args_]
                (input_, filter_, args_) = tf.tf_promote(input_, filter_, args_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, args_)
                if num_args !== nothing
                    desc["num_args"] = Base.Int(num_args)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
                if use_cudnn_on_gpu !== nothing
                    desc["use_cudnn_on_gpu"] = Base.Bool(use_cudnn_on_gpu)
                end
                if fused_ops !== nothing
                    desc["fused_ops"] = map(Base.identity, fused_ops)
                end
                if epsilon !== nothing
                    desc["epsilon"] = Base.identity(epsilon)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _fused_conv2d(input_::tf.TensorHandle, filter_::tf.TensorHandle, args_::tf.TensorHandle; name=nothing, num_args=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing, use_cudnn_on_gpu=nothing, fused_ops=nothing, epsilon=nothing)
        desc = tf.EagerOp("_FusedConv2D")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, args_)
        if num_args !== nothing
            desc["num_args"] = Base.Int(num_args)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        if use_cudnn_on_gpu !== nothing
            desc["use_cudnn_on_gpu"] = Base.Bool(use_cudnn_on_gpu)
        end
        if fused_ops !== nothing
            desc["fused_ops"] = map(Base.identity, fused_ops)
        end
        if epsilon !== nothing
            desc["epsilon"] = Base.identity(epsilon)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(filter_)
        desc["T"] = tf.data_type(args_)
        (tf.execute(desc))[1]
    end
end


"""
     _read_variables_op(resources)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _read_variables_op(resources_; name=nothing, N=nothing, dtypes=nothing)
            local desc
            tf.with_op_name(name, "_ReadVariablesOp") do 
                desc = tf.NodeDescription("_ReadVariablesOp")
                resources_ = [convert(Tensor{Any}, x) for x = resources_]
                tf.add_input(desc, resources_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _read_variables_op(resources_::tf.TensorHandle; name=nothing, N=nothing, dtypes=nothing)
        desc = tf.EagerOp("_ReadVariablesOp")
        tf.add_input(desc, resources_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     mutable_hash_table_of_tensors(; container=, shared_name=, use_node_name_sharing=false, value_shape=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mutable_hash_table_of_tensors(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing, value_shape=nothing)
            local desc
            tf.with_op_name(name, "MutableHashTableOfTensors") do 
                desc = tf.NodeDescription("MutableHashTableOfTensors")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if use_node_name_sharing !== nothing
                    desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
                end
                if key_dtype !== nothing
                    desc["key_dtype"] = Base.identity(key_dtype)
                end
                if value_dtype !== nothing
                    desc["value_dtype"] = Base.identity(value_dtype)
                end
                if value_shape !== nothing
                    desc["value_shape"] = Base.identity(value_shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mutable_hash_table_of_tensors(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing, value_shape=nothing)
        desc = tf.EagerOp("MutableHashTableOfTensors")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if use_node_name_sharing !== nothing
            desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
        end
        if key_dtype !== nothing
            desc["key_dtype"] = Base.identity(key_dtype)
        end
        if value_dtype !== nothing
            desc["value_dtype"] = Base.identity(value_dtype)
        end
        if value_shape !== nothing
            desc["value_shape"] = Base.identity(value_shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     read_file(filename)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function read_file(filename_; name=nothing)
            local desc
            tf.with_op_name(name, "ReadFile") do 
                desc = tf.NodeDescription("ReadFile")
                filename_ = convert(Tensor{String}, filename_)
                tf.add_input(desc, filename_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function read_file(filename_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReadFile")
        tf.add_input(desc, filename_)
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_mdl_adagrad_light_parameters(parameters, accumulators, weights, benefits; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_mdl_adagrad_light_parameters(parameters_, accumulators_, weights_, benefits_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingMDLAdagradLightParameters") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingMDLAdagradLightParameters")
                parameters_ = convert(Tensor{Float32}, parameters_)
                accumulators_ = convert(Tensor{Float32}, accumulators_)
                weights_ = convert(Tensor{Float32}, weights_)
                benefits_ = convert(Tensor{Float32}, benefits_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, accumulators_)
                tf.add_input(desc, weights_)
                tf.add_input(desc, benefits_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_mdl_adagrad_light_parameters(parameters_::tf.TensorHandle, accumulators_::tf.TensorHandle, weights_::tf.TensorHandle, benefits_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingMDLAdagradLightParameters")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, accumulators_)
        tf.add_input(desc, weights_)
        tf.add_input(desc, benefits_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     fractional_avg_pool_grad(orig_input_tensor_shape, out_backprop, row_pooling_sequence, col_pooling_sequence; overlapping=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fractional_avg_pool_grad(orig_input_tensor_shape_, out_backprop_, row_pooling_sequence_, col_pooling_sequence_; name=nothing, overlapping=nothing)
            local desc
            tf.with_op_name(name, "FractionalAvgPoolGrad") do 
                desc = tf.NodeDescription("FractionalAvgPoolGrad")
                orig_input_tensor_shape_ = convert(Tensor{Int64}, orig_input_tensor_shape_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                row_pooling_sequence_ = convert(Tensor{Int64}, row_pooling_sequence_)
                col_pooling_sequence_ = convert(Tensor{Int64}, col_pooling_sequence_)
                (out_backprop_,) = tf.tf_promote(out_backprop_)
                tf.add_input(desc, orig_input_tensor_shape_)
                tf.add_input(desc, out_backprop_)
                tf.add_input(desc, row_pooling_sequence_)
                tf.add_input(desc, col_pooling_sequence_)
                if overlapping !== nothing
                    desc["overlapping"] = Base.Bool(overlapping)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fractional_avg_pool_grad(orig_input_tensor_shape_::tf.TensorHandle, out_backprop_::tf.TensorHandle, row_pooling_sequence_::tf.TensorHandle, col_pooling_sequence_::tf.TensorHandle; name=nothing, overlapping=nothing)
        desc = tf.EagerOp("FractionalAvgPoolGrad")
        tf.add_input(desc, orig_input_tensor_shape_)
        tf.add_input(desc, out_backprop_)
        tf.add_input(desc, row_pooling_sequence_)
        tf.add_input(desc, col_pooling_sequence_)
        if overlapping !== nothing
            desc["overlapping"] = Base.Bool(overlapping)
        end
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_adagrad_parameters_grad_accum_debug(parameters, accumulators, gradient_accumulators; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_adagrad_parameters_grad_accum_debug(parameters_, accumulators_, gradient_accumulators_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingAdagradParametersGradAccumDebug") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingAdagradParametersGradAccumDebug")
                parameters_ = convert(Tensor{Float32}, parameters_)
                accumulators_ = convert(Tensor{Float32}, accumulators_)
                gradient_accumulators_ = convert(Tensor{Float32}, gradient_accumulators_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, accumulators_)
                tf.add_input(desc, gradient_accumulators_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_adagrad_parameters_grad_accum_debug(parameters_::tf.TensorHandle, accumulators_::tf.TensorHandle, gradient_accumulators_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingAdagradParametersGradAccumDebug")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, accumulators_)
        tf.add_input(desc, gradient_accumulators_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     stateful_standard_normal_v2(resource, algorithm, shape; dtype=Float32, shape_dtype=Int64)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stateful_standard_normal_v2(resource_, algorithm_, shape_; name=nothing, dtype=nothing, shape_dtype=nothing)
            local desc
            tf.with_op_name(name, "StatefulStandardNormalV2") do 
                desc = tf.NodeDescription("StatefulStandardNormalV2")
                resource_ = convert(Tensor{Any}, resource_)
                algorithm_ = convert(Tensor{Int64}, algorithm_)
                shape_ = convert(Tensor{Int64}, shape_)
                (shape_,) = tf.tf_promote(shape_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, algorithm_)
                tf.add_input(desc, shape_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape_dtype !== nothing
                    desc["shape_dtype"] = Base.identity(shape_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stateful_standard_normal_v2(resource_::tf.TensorHandle, algorithm_::tf.TensorHandle, shape_::tf.TensorHandle; name=nothing, dtype=nothing, shape_dtype=nothing)
        desc = tf.EagerOp("StatefulStandardNormalV2")
        tf.add_input(desc, resource_)
        tf.add_input(desc, algorithm_)
        tf.add_input(desc, shape_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape_dtype !== nothing
            desc["shape_dtype"] = Base.identity(shape_dtype)
        end
        desc["shape_dtype"] = tf.data_type(shape_)
        (tf.execute(desc))[1]
    end
end


"""
     bincount(arr, size, weights)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function bincount(arr_, size_, weights_; name=nothing)
            local desc
            tf.with_op_name(name, "Bincount") do 
                desc = tf.NodeDescription("Bincount")
                arr_ = convert(Tensor{Int32}, arr_)
                size_ = convert(Tensor{Int32}, size_)
                weights_ = convert(Tensor{Any}, weights_)
                (weights_,) = tf.tf_promote(weights_)
                tf.add_input(desc, arr_)
                tf.add_input(desc, size_)
                tf.add_input(desc, weights_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function bincount(arr_::tf.TensorHandle, size_::tf.TensorHandle, weights_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Bincount")
        tf.add_input(desc, arr_)
        tf.add_input(desc, size_)
        tf.add_input(desc, weights_)
        desc["T"] = tf.data_type(weights_)
        (tf.execute(desc))[1]
    end
end


"""
     inv(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function inv(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Inv") do 
                desc = tf.NodeDescription("Inv")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function inv(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Inv")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     apply_proximal_adagrad(var, accum, lr, l1, l2, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_proximal_adagrad(var_, accum_, lr_, l1_, l2_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyProximalAdagrad") do 
                desc = tf.NodeDescription("ApplyProximalAdagrad")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                grad_ = convert(Tensor{Any}, grad_)
                (var_, accum_, lr_, l1_, l2_, grad_) = tf.tf_promote(var_, accum_, lr_, l1_, l2_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_proximal_adagrad(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyProximalAdagrad")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     gather_v2(params, indices, axis)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function gather_v2(params_, indices_, axis_; name=nothing)
            local desc
            tf.with_op_name(name, "GatherV2") do 
                desc = tf.NodeDescription("GatherV2")
                params_ = convert(Tensor{Any}, params_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                axis_ = convert(Tensor{Any}, axis_)
                (params_,) = tf.tf_promote(params_)
                (indices_,) = tf.tf_promote(indices_)
                (axis_,) = tf.tf_promote(axis_)
                tf.add_input(desc, params_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, axis_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function gather_v2(params_::tf.TensorHandle, indices_::tf.TensorHandle, axis_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("GatherV2")
        tf.add_input(desc, params_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, axis_)
        desc["Tparams"] = tf.data_type(params_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["Taxis"] = tf.data_type(axis_)
        (tf.execute(desc))[1]
    end
end


"""
     write_file(filename, contents)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function write_file(filename_, contents_; name=nothing)
            local desc
            tf.with_op_name(name, "WriteFile") do 
                desc = tf.NodeDescription("WriteFile")
                filename_ = convert(Tensor{String}, filename_)
                contents_ = convert(Tensor{String}, contents_)
                tf.add_input(desc, filename_)
                tf.add_input(desc, contents_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function write_file(filename_::tf.TensorHandle, contents_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("WriteFile")
        tf.add_input(desc, filename_)
        tf.add_input(desc, contents_)
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_get_ensemble_states(tree_ensemble_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_get_ensemble_states(tree_ensemble_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesGetEnsembleStates") do 
                desc = tf.NodeDescription("BoostedTreesGetEnsembleStates")
                tree_ensemble_handle_ = convert(Tensor{Any}, tree_ensemble_handle_)
                tf.add_input(desc, tree_ensemble_handle_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:5
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function boosted_trees_get_ensemble_states(tree_ensemble_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BoostedTreesGetEnsembleStates")
        tf.add_input(desc, tree_ensemble_handle_)
        tf.execute(desc)
    end
end


"""
     resource_gather(resource, indices; validate_indices=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_gather(resource_, indices_; name=nothing, validate_indices=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "ResourceGather") do 
                desc = tf.NodeDescription("ResourceGather")
                resource_ = convert(Tensor{Any}, resource_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, indices_)
                if validate_indices !== nothing
                    desc["validate_indices"] = Base.Bool(validate_indices)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_gather(resource_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, validate_indices=nothing, dtype=nothing)
        desc = tf.EagerOp("ResourceGather")
        tf.add_input(desc, resource_)
        tf.add_input(desc, indices_)
        if validate_indices !== nothing
            desc["validate_indices"] = Base.Bool(validate_indices)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_proximal_gradient_descent(var, alpha, l1, l2, delta; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_proximal_gradient_descent(var_, alpha_, l1_, l2_, delta_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyProximalGradientDescent") do 
                desc = tf.NodeDescription("ResourceApplyProximalGradientDescent")
                var_ = convert(Tensor{Any}, var_)
                alpha_ = convert(Tensor{Any}, alpha_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                delta_ = convert(Tensor{Any}, delta_)
                (alpha_, l1_, l2_, delta_) = tf.tf_promote(alpha_, l1_, l2_, delta_)
                tf.add_input(desc, var_)
                tf.add_input(desc, alpha_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, delta_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_proximal_gradient_descent(var_::tf.TensorHandle, alpha_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, delta_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyProximalGradientDescent")
        tf.add_input(desc, var_)
        tf.add_input(desc, alpha_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, delta_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(alpha_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(delta_)
        (tf.execute(desc))[1]
    end
end


"""
     truncate_mod(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function truncate_mod(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "TruncateMod") do 
                desc = tf.NodeDescription("TruncateMod")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function truncate_mod(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TruncateMod")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     log_matrix_determinant(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function log_matrix_determinant(input_; name=nothing)
            local desc
            tf.with_op_name(name, "LogMatrixDeterminant") do 
                desc = tf.NodeDescription("LogMatrixDeterminant")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function log_matrix_determinant(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LogMatrixDeterminant")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     irfft2d(input, fft_length)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function irfft2d(input_, fft_length_; name=nothing)
            local desc
            tf.with_op_name(name, "IRFFT2D") do 
                desc = tf.NodeDescription("IRFFT2D")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                fft_length_ = convert(Tensor{Int32}, fft_length_)
                tf.add_input(desc, input_)
                tf.add_input(desc, fft_length_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function irfft2d(input_::tf.TensorHandle, fft_length_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IRFFT2D")
        tf.add_input(desc, input_)
        tf.add_input(desc, fft_length_)
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_training_predict(tree_ensemble_handle, cached_tree_ids, cached_node_ids, bucketized_features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_training_predict(tree_ensemble_handle_, cached_tree_ids_, cached_node_ids_, bucketized_features_; name=nothing, num_bucketized_features=nothing, logits_dimension=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesTrainingPredict") do 
                desc = tf.NodeDescription("BoostedTreesTrainingPredict")
                tree_ensemble_handle_ = convert(Tensor{Any}, tree_ensemble_handle_)
                cached_tree_ids_ = convert(Tensor{Int32}, cached_tree_ids_)
                cached_node_ids_ = convert(Tensor{Int32}, cached_node_ids_)
                bucketized_features_ = [convert(Tensor{Int32}, x) for x = bucketized_features_]
                tf.add_input(desc, tree_ensemble_handle_)
                tf.add_input(desc, cached_tree_ids_)
                tf.add_input(desc, cached_node_ids_)
                tf.add_input(desc, bucketized_features_)
                if num_bucketized_features !== nothing
                    desc["num_bucketized_features"] = Base.Int(num_bucketized_features)
                end
                if logits_dimension !== nothing
                    desc["logits_dimension"] = Base.Int(logits_dimension)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function boosted_trees_training_predict(tree_ensemble_handle_::tf.TensorHandle, cached_tree_ids_::tf.TensorHandle, cached_node_ids_::tf.TensorHandle, bucketized_features_::tf.TensorHandle; name=nothing, num_bucketized_features=nothing, logits_dimension=nothing)
        desc = tf.EagerOp("BoostedTreesTrainingPredict")
        tf.add_input(desc, tree_ensemble_handle_)
        tf.add_input(desc, cached_tree_ids_)
        tf.add_input(desc, cached_node_ids_)
        tf.add_input(desc, bucketized_features_)
        if num_bucketized_features !== nothing
            desc["num_bucketized_features"] = Base.Int(num_bucketized_features)
        end
        if logits_dimension !== nothing
            desc["logits_dimension"] = Base.Int(logits_dimension)
        end
        tf.execute(desc)
    end
end


"""
     nearest_neighbors(points, centers, k)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function nearest_neighbors(points_, centers_, k_; name=nothing)
            local desc
            tf.with_op_name(name, "NearestNeighbors") do 
                desc = tf.NodeDescription("NearestNeighbors")
                points_ = convert(Tensor{Float32}, points_)
                centers_ = convert(Tensor{Float32}, centers_)
                k_ = convert(Tensor{Int64}, k_)
                tf.add_input(desc, points_)
                tf.add_input(desc, centers_)
                tf.add_input(desc, k_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function nearest_neighbors(points_::tf.TensorHandle, centers_::tf.TensorHandle, k_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("NearestNeighbors")
        tf.add_input(desc, points_)
        tf.add_input(desc, centers_)
        tf.add_input(desc, k_)
        tf.execute(desc)
    end
end


"""
     floor(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function floor(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Floor") do 
                desc = tf.NodeDescription("Floor")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function floor(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Floor")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(parameters, accumulators, gradient_accumulators; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(parameters_, accumulators_, gradient_accumulators_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingProximalAdagradParametersGradAccumDebug") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingProximalAdagradParametersGradAccumDebug")
                parameters_ = convert(Tensor{Float32}, parameters_)
                accumulators_ = convert(Tensor{Float32}, accumulators_)
                gradient_accumulators_ = convert(Tensor{Float32}, gradient_accumulators_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, accumulators_)
                tf.add_input(desc, gradient_accumulators_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(parameters_::tf.TensorHandle, accumulators_::tf.TensorHandle, gradient_accumulators_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingProximalAdagradParametersGradAccumDebug")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, accumulators_)
        tf.add_input(desc, gradient_accumulators_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     write_image_summary(writer, step, tag, tensor, bad_color; max_images=3)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function write_image_summary(writer_, step_, tag_, tensor_, bad_color_; name=nothing, max_images=nothing)
            local desc
            tf.with_op_name(name, "WriteImageSummary") do 
                desc = tf.NodeDescription("WriteImageSummary")
                writer_ = convert(Tensor{Any}, writer_)
                step_ = convert(Tensor{Int64}, step_)
                tag_ = convert(Tensor{String}, tag_)
                tensor_ = convert(Tensor{Float32}, tensor_)
                bad_color_ = convert(Tensor{UInt8}, bad_color_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, writer_)
                tf.add_input(desc, step_)
                tf.add_input(desc, tag_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, bad_color_)
                if max_images !== nothing
                    desc["max_images"] = Base.Int(max_images)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function write_image_summary(writer_::tf.TensorHandle, step_::tf.TensorHandle, tag_::tf.TensorHandle, tensor_::tf.TensorHandle, bad_color_::tf.TensorHandle; name=nothing, max_images=nothing)
        desc = tf.EagerOp("WriteImageSummary")
        tf.add_input(desc, writer_)
        tf.add_input(desc, step_)
        tf.add_input(desc, tag_)
        tf.add_input(desc, tensor_)
        tf.add_input(desc, bad_color_)
        if max_images !== nothing
            desc["max_images"] = Base.Int(max_images)
        end
        desc["T"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     tile_grad(input, multiples)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tile_grad(input_, multiples_; name=nothing)
            local desc
            tf.with_op_name(name, "TileGrad") do 
                desc = tf.NodeDescription("TileGrad")
                input_ = convert(Tensor{Any}, input_)
                multiples_ = convert(Tensor{Int32}, multiples_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, multiples_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tile_grad(input_::tf.TensorHandle, multiples_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TileGrad")
        tf.add_input(desc, input_)
        tf.add_input(desc, multiples_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_grad_v3(handle, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_grad_v3(handle_, flow_in_; name=nothing, source=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayGradV3") do 
                desc = tf.NodeDescription("TensorArrayGradV3")
                handle_ = convert(Tensor{Any}, handle_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, flow_in_)
                if source !== nothing
                    desc["source"] = Base.String(source)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function tensor_array_grad_v3(handle_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, source=nothing)
        desc = tf.EagerOp("TensorArrayGradV3")
        tf.add_input(desc, handle_)
        tf.add_input(desc, flow_in_)
        if source !== nothing
            desc["source"] = Base.String(source)
        end
        tf.execute(desc)
    end
end


"""
     enqueue_tpu_embedding_integer_batch(batch, mode_override; device_ordinal=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function enqueue_tpu_embedding_integer_batch(batch_, mode_override_; name=nothing, N=nothing, device_ordinal=nothing)
            local desc
            tf.with_op_name(name, "EnqueueTPUEmbeddingIntegerBatch") do 
                desc = tf.NodeDescription("EnqueueTPUEmbeddingIntegerBatch")
                batch_ = [convert(Tensor{Int32}, x) for x = batch_]
                mode_override_ = convert(Tensor{String}, mode_override_)
                tf.add_input(desc, batch_)
                tf.add_input(desc, mode_override_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if device_ordinal !== nothing
                    desc["device_ordinal"] = Base.Int(device_ordinal)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function enqueue_tpu_embedding_integer_batch(batch_::tf.TensorHandle, mode_override_::tf.TensorHandle; name=nothing, N=nothing, device_ordinal=nothing)
        desc = tf.EagerOp("EnqueueTPUEmbeddingIntegerBatch")
        tf.add_input(desc, batch_)
        tf.add_input(desc, mode_override_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if device_ordinal !== nothing
            desc["device_ordinal"] = Base.Int(device_ordinal)
        end
        (tf.execute(desc))[1]
    end
end


"""
     fused_batch_norm(x, scale, offset, mean, variance; epsilon=?, data_format=NHWC, is_training=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fused_batch_norm(x_, scale_, offset_, mean_, variance_; name=nothing, epsilon=nothing, data_format=nothing, is_training=nothing)
            local desc
            tf.with_op_name(name, "FusedBatchNorm") do 
                desc = tf.NodeDescription("FusedBatchNorm")
                x_ = convert(Tensor{Any}, x_)
                scale_ = convert(Tensor{Any}, scale_)
                offset_ = convert(Tensor{Any}, offset_)
                mean_ = convert(Tensor{Any}, mean_)
                variance_ = convert(Tensor{Any}, variance_)
                (x_, scale_, offset_, mean_, variance_) = tf.tf_promote(x_, scale_, offset_, mean_, variance_)
                tf.add_input(desc, x_)
                tf.add_input(desc, scale_)
                tf.add_input(desc, offset_)
                tf.add_input(desc, mean_)
                tf.add_input(desc, variance_)
                if epsilon !== nothing
                    desc["epsilon"] = Base.identity(epsilon)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if is_training !== nothing
                    desc["is_training"] = Base.Bool(is_training)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:5
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function fused_batch_norm(x_::tf.TensorHandle, scale_::tf.TensorHandle, offset_::tf.TensorHandle, mean_::tf.TensorHandle, variance_::tf.TensorHandle; name=nothing, epsilon=nothing, data_format=nothing, is_training=nothing)
        desc = tf.EagerOp("FusedBatchNorm")
        tf.add_input(desc, x_)
        tf.add_input(desc, scale_)
        tf.add_input(desc, offset_)
        tf.add_input(desc, mean_)
        tf.add_input(desc, variance_)
        if epsilon !== nothing
            desc["epsilon"] = Base.identity(epsilon)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if is_training !== nothing
            desc["is_training"] = Base.Bool(is_training)
        end
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(scale_)
        desc["T"] = tf.data_type(offset_)
        desc["T"] = tf.data_type(mean_)
        desc["T"] = tf.data_type(variance_)
        tf.execute(desc)
    end
end


"""
     logical_and(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function logical_and(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "LogicalAnd") do 
                desc = tf.NodeDescription("LogicalAnd")
                x_ = convert(Tensor{Bool}, x_)
                y_ = convert(Tensor{Bool}, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function logical_and(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LogicalAnd")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_scatter_update(tensor, indices, updates)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_scatter_update(tensor_, indices_, updates_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorScatterUpdate") do 
                desc = tf.NodeDescription("TensorScatterUpdate")
                tensor_ = convert(Tensor{Any}, tensor_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (tensor_, updates_) = tf.tf_promote(tensor_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_scatter_update(tensor_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorScatterUpdate")
        tf.add_input(desc, tensor_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        desc["T"] = tf.data_type(tensor_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     text_line_reader_v2(; skip_header_lines=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function text_line_reader_v2(; name=nothing, skip_header_lines=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "TextLineReaderV2") do 
                desc = tf.NodeDescription("TextLineReaderV2")
                if skip_header_lines !== nothing
                    desc["skip_header_lines"] = Base.Int(skip_header_lines)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function text_line_reader_v2(; name=nothing, skip_header_lines=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("TextLineReaderV2")
        if skip_header_lines !== nothing
            desc["skip_header_lines"] = Base.Int(skip_header_lines)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_slice_dataset(components)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_slice_dataset(components_; name=nothing, Toutput_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "TensorSliceDataset") do 
                desc = tf.NodeDescription("TensorSliceDataset")
                components_ = [convert(Tensor{Any}, x) for x = components_]
                tf.add_input(desc, components_)
                if Toutput_types !== nothing
                    desc["Toutput_types"] = map(Base.identity, Toutput_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_slice_dataset(components_::tf.TensorHandle; name=nothing, Toutput_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("TensorSliceDataset")
        tf.add_input(desc, components_)
        if Toutput_types !== nothing
            desc["Toutput_types"] = map(Base.identity, Toutput_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_scatter_v3(handle, indices, value, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_scatter_v3(handle_, indices_, value_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayScatterV3") do 
                desc = tf.NodeDescription("TensorArrayScatterV3")
                handle_ = convert(Tensor{Any}, handle_)
                indices_ = convert(Tensor{Int32}, indices_)
                value_ = convert(Tensor{Any}, value_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, value_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_scatter_v3(handle_::tf.TensorHandle, indices_::tf.TensorHandle, value_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArrayScatterV3")
        tf.add_input(desc, handle_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, value_)
        tf.add_input(desc, flow_in_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     resize_nearest_neighbor_grad(grads, size; align_corners=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resize_nearest_neighbor_grad(grads_, size_; name=nothing, align_corners=nothing)
            local desc
            tf.with_op_name(name, "ResizeNearestNeighborGrad") do 
                desc = tf.NodeDescription("ResizeNearestNeighborGrad")
                grads_ = convert(Tensor{Any}, grads_)
                size_ = convert(Tensor{Int32}, size_)
                (grads_,) = tf.tf_promote(grads_)
                tf.add_input(desc, grads_)
                tf.add_input(desc, size_)
                if align_corners !== nothing
                    desc["align_corners"] = Base.Bool(align_corners)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resize_nearest_neighbor_grad(grads_::tf.TensorHandle, size_::tf.TensorHandle; name=nothing, align_corners=nothing)
        desc = tf.EagerOp("ResizeNearestNeighborGrad")
        tf.add_input(desc, grads_)
        tf.add_input(desc, size_)
        if align_corners !== nothing
            desc["align_corners"] = Base.Bool(align_corners)
        end
        desc["T"] = tf.data_type(grads_)
        (tf.execute(desc))[1]
    end
end


"""
     apply_power_sign(var, m, lr, logbase, sign_decay, beta, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function apply_power_sign(var_, m_, lr_, logbase_, sign_decay_, beta_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ApplyPowerSign") do 
                desc = tf.NodeDescription("ApplyPowerSign")
                var_ = convert(Tensor{Any}, var_)
                m_ = convert(Tensor{Any}, m_)
                lr_ = convert(Tensor{Any}, lr_)
                logbase_ = convert(Tensor{Any}, logbase_)
                sign_decay_ = convert(Tensor{Any}, sign_decay_)
                beta_ = convert(Tensor{Any}, beta_)
                grad_ = convert(Tensor{Any}, grad_)
                (var_, m_, lr_, logbase_, sign_decay_, beta_, grad_) = tf.tf_promote(var_, m_, lr_, logbase_, sign_decay_, beta_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, m_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, logbase_)
                tf.add_input(desc, sign_decay_)
                tf.add_input(desc, beta_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function apply_power_sign(var_::tf.TensorHandle, m_::tf.TensorHandle, lr_::tf.TensorHandle, logbase_::tf.TensorHandle, sign_decay_::tf.TensorHandle, beta_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ApplyPowerSign")
        tf.add_input(desc, var_)
        tf.add_input(desc, m_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, logbase_)
        tf.add_input(desc, sign_decay_)
        tf.add_input(desc, beta_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(m_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(logbase_)
        desc["T"] = tf.data_type(sign_decay_)
        desc["T"] = tf.data_type(beta_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_rebatch_dataset(input_dataset, num_workers)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_rebatch_dataset(input_dataset_, num_workers_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalRebatchDataset") do 
                desc = tf.NodeDescription("ExperimentalRebatchDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                num_workers_ = convert(Tensor{Int64}, num_workers_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, num_workers_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_rebatch_dataset(input_dataset_::tf.TensorHandle, num_workers_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalRebatchDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, num_workers_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     mirror_pad(input, paddings)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mirror_pad(input_, paddings_; name=nothing, mode=nothing)
            local desc
            tf.with_op_name(name, "MirrorPad") do 
                desc = tf.NodeDescription("MirrorPad")
                input_ = convert(Tensor{Any}, input_)
                paddings_ = convert(Tensor{Int32}, paddings_)
                (input_,) = tf.tf_promote(input_)
                (paddings_,) = tf.tf_promote(paddings_)
                tf.add_input(desc, input_)
                tf.add_input(desc, paddings_)
                if mode !== nothing
                    desc["mode"] = Base.String(mode)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mirror_pad(input_::tf.TensorHandle, paddings_::tf.TensorHandle; name=nothing, mode=nothing)
        desc = tf.EagerOp("MirrorPad")
        tf.add_input(desc, input_)
        tf.add_input(desc, paddings_)
        if mode !== nothing
            desc["mode"] = Base.String(mode)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tpaddings"] = tf.data_type(paddings_)
        (tf.execute(desc))[1]
    end
end


"""
     logical_not(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function logical_not(x_; name=nothing)
            local desc
            tf.with_op_name(name, "LogicalNot") do 
                desc = tf.NodeDescription("LogicalNot")
                x_ = convert(Tensor{Bool}, x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function logical_not(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LogicalNot")
        tf.add_input(desc, x_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_ifft(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_ifft(input_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchIFFT") do 
                desc = tf.NodeDescription("BatchIFFT")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_ifft(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchIFFT")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_concat_v2(handle, flow_in; element_shape_except0=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_concat_v2(handle_, flow_in_; name=nothing, dtype=nothing, element_shape_except0=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayConcatV2") do 
                desc = tf.NodeDescription("TensorArrayConcatV2")
                handle_ = convert(Tensor{String}, handle_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, flow_in_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if element_shape_except0 !== nothing
                    desc["element_shape_except0"] = Base.identity(element_shape_except0)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function tensor_array_concat_v2(handle_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, dtype=nothing, element_shape_except0=nothing)
        desc = tf.EagerOp("TensorArrayConcatV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, flow_in_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if element_shape_except0 !== nothing
            desc["element_shape_except0"] = Base.identity(element_shape_except0)
        end
        tf.execute(desc)
    end
end


"""
     sum(input, reduction_indices; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sum(input_, reduction_indices_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "Sum") do 
                desc = tf.NodeDescription("Sum")
                input_ = convert(Tensor{Any}, input_)
                reduction_indices_ = convert(Tensor{Int32}, reduction_indices_)
                reduction_indices_ = reduction_indices_ - convert(tf.Tensor{eltype(reduction_indices_)}, 1)
                (input_,) = tf.tf_promote(input_)
                (reduction_indices_,) = tf.tf_promote(reduction_indices_)
                tf.add_input(desc, input_)
                tf.add_input(desc, reduction_indices_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sum(input_::tf.TensorHandle, reduction_indices_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("Sum")
        tf.add_input(desc, input_)
        tf.add_input(desc, reduction_indices_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tidx"] = tf.data_type(reduction_indices_)
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_predict(tree_ensemble_handle, bucketized_features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_predict(tree_ensemble_handle_, bucketized_features_; name=nothing, num_bucketized_features=nothing, logits_dimension=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesPredict") do 
                desc = tf.NodeDescription("BoostedTreesPredict")
                tree_ensemble_handle_ = convert(Tensor{Any}, tree_ensemble_handle_)
                bucketized_features_ = [convert(Tensor{Int32}, x) for x = bucketized_features_]
                tf.add_input(desc, tree_ensemble_handle_)
                tf.add_input(desc, bucketized_features_)
                if num_bucketized_features !== nothing
                    desc["num_bucketized_features"] = Base.Int(num_bucketized_features)
                end
                if logits_dimension !== nothing
                    desc["logits_dimension"] = Base.Int(logits_dimension)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_predict(tree_ensemble_handle_::tf.TensorHandle, bucketized_features_::tf.TensorHandle; name=nothing, num_bucketized_features=nothing, logits_dimension=nothing)
        desc = tf.EagerOp("BoostedTreesPredict")
        tf.add_input(desc, tree_ensemble_handle_)
        tf.add_input(desc, bucketized_features_)
        if num_bucketized_features !== nothing
            desc["num_bucketized_features"] = Base.Int(num_bucketized_features)
        end
        if logits_dimension !== nothing
            desc["logits_dimension"] = Base.Int(logits_dimension)
        end
        (tf.execute(desc))[1]
    end
end


"""
     quantized_conv2d_with_bias_and_relu_and_requantize(input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output; out_type=Float32, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_conv2d_with_bias_and_relu_and_requantize(input_, filter_, bias_, min_input_, max_input_, min_filter_, max_filter_, min_freezed_output_, max_freezed_output_; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConv2DWithBiasAndReluAndRequantize") do 
                desc = tf.NodeDescription("QuantizedConv2DWithBiasAndReluAndRequantize")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                bias_ = convert(Tensor{Any}, bias_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_filter_ = convert(Tensor{Float32}, min_filter_)
                max_filter_ = convert(Tensor{Float32}, max_filter_)
                min_freezed_output_ = convert(Tensor{Float32}, min_freezed_output_)
                max_freezed_output_ = convert(Tensor{Float32}, max_freezed_output_)
                (filter_,) = tf.tf_promote(filter_)
                (input_,) = tf.tf_promote(input_)
                (bias_,) = tf.tf_promote(bias_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, bias_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_filter_)
                tf.add_input(desc, max_filter_)
                tf.add_input(desc, min_freezed_output_)
                tf.add_input(desc, max_freezed_output_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_conv2d_with_bias_and_relu_and_requantize(input_::tf.TensorHandle, filter_::tf.TensorHandle, bias_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_filter_::tf.TensorHandle, max_filter_::tf.TensorHandle, min_freezed_output_::tf.TensorHandle, max_freezed_output_::tf.TensorHandle; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("QuantizedConv2DWithBiasAndReluAndRequantize")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, bias_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_filter_)
        tf.add_input(desc, max_filter_)
        tf.add_input(desc, min_freezed_output_)
        tf.add_input(desc, max_freezed_output_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tinput"] = tf.data_type(input_)
        desc["Tfilter"] = tf.data_type(filter_)
        desc["Tbias"] = tf.data_type(bias_)
        tf.execute(desc)
    end
end


"""
     resource_sparse_apply_adagrad(var, accum, lr, grad, indices; use_locking=false, update_slots=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_sparse_apply_adagrad(var_, accum_, lr_, grad_, indices_; name=nothing, use_locking=nothing, update_slots=nothing)
            local desc
            tf.with_op_name(name, "ResourceSparseApplyAdagrad") do 
                desc = tf.NodeDescription("ResourceSparseApplyAdagrad")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (lr_, grad_) = tf.tf_promote(lr_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if update_slots !== nothing
                    desc["update_slots"] = Base.Bool(update_slots)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_sparse_apply_adagrad(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing, update_slots=nothing)
        desc = tf.EagerOp("ResourceSparseApplyAdagrad")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if update_slots !== nothing
            desc["update_slots"] = Base.Bool(update_slots)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     leaky_relu_grad(gradients, features; alpha=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function leaky_relu_grad(gradients_, features_; name=nothing, alpha=nothing)
            local desc
            tf.with_op_name(name, "LeakyReluGrad") do 
                desc = tf.NodeDescription("LeakyReluGrad")
                gradients_ = convert(Tensor{Float32}, gradients_)
                features_ = convert(Tensor{Float32}, features_)
                (gradients_, features_) = tf.tf_promote(gradients_, features_)
                tf.add_input(desc, gradients_)
                tf.add_input(desc, features_)
                if alpha !== nothing
                    desc["alpha"] = Base.identity(alpha)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function leaky_relu_grad(gradients_::tf.TensorHandle, features_::tf.TensorHandle; name=nothing, alpha=nothing)
        desc = tf.EagerOp("LeakyReluGrad")
        tf.add_input(desc, gradients_)
        tf.add_input(desc, features_)
        if alpha !== nothing
            desc["alpha"] = Base.identity(alpha)
        end
        desc["T"] = tf.data_type(gradients_)
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     _device_retval(input)

A graph node which represents a return value of a function.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _device_retval(input_; name=nothing, index=nothing)
            local desc
            tf.with_op_name(name, "_DeviceRetval") do 
                desc = tf.NodeDescription("_DeviceRetval")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if index !== nothing
                    desc["index"] = Base.Int(index)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _device_retval(input_::tf.TensorHandle; name=nothing, index=nothing)
        desc = tf.EagerOp("_DeviceRetval")
        tf.add_input(desc, input_)
        if index !== nothing
            desc["index"] = Base.Int(index)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     pad(input, paddings)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function pad(input_, paddings_; name=nothing)
            local desc
            tf.with_op_name(name, "Pad") do 
                desc = tf.NodeDescription("Pad")
                input_ = convert(Tensor{Any}, input_)
                paddings_ = convert(Tensor{Int32}, paddings_)
                (input_,) = tf.tf_promote(input_)
                (paddings_,) = tf.tf_promote(paddings_)
                tf.add_input(desc, input_)
                tf.add_input(desc, paddings_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function pad(input_::tf.TensorHandle, paddings_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Pad")
        tf.add_input(desc, input_)
        tf.add_input(desc, paddings_)
        desc["T"] = tf.data_type(input_)
        desc["Tpaddings"] = tf.data_type(paddings_)
        (tf.execute(desc))[1]
    end
end


"""
     add_many_sparse_to_tensors_map(sparse_indices, sparse_values, sparse_shape; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function add_many_sparse_to_tensors_map(sparse_indices_, sparse_values_, sparse_shape_; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "AddManySparseToTensorsMap") do 
                desc = tf.NodeDescription("AddManySparseToTensorsMap")
                sparse_indices_ = convert(Tensor{Int64}, sparse_indices_)
                sparse_values_ = convert(Tensor{Any}, sparse_values_)
                sparse_shape_ = convert(Tensor{Int64}, sparse_shape_)
                (sparse_values_,) = tf.tf_promote(sparse_values_)
                tf.add_input(desc, sparse_indices_)
                tf.add_input(desc, sparse_values_)
                tf.add_input(desc, sparse_shape_)
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function add_many_sparse_to_tensors_map(sparse_indices_::tf.TensorHandle, sparse_values_::tf.TensorHandle, sparse_shape_::tf.TensorHandle; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("AddManySparseToTensorsMap")
        tf.add_input(desc, sparse_indices_)
        tf.add_input(desc, sparse_values_)
        tf.add_input(desc, sparse_shape_)
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        desc["T"] = tf.data_type(sparse_values_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_reorder(input_indices, input_values, input_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_reorder(input_indices_, input_values_, input_shape_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseReorder") do 
                desc = tf.NodeDescription("SparseReorder")
                input_indices_ = convert(Tensor{Int64}, input_indices_)
                input_values_ = convert(Tensor{Any}, input_values_)
                input_shape_ = convert(Tensor{Int64}, input_shape_)
                (input_values_,) = tf.tf_promote(input_values_)
                tf.add_input(desc, input_indices_)
                tf.add_input(desc, input_values_)
                tf.add_input(desc, input_shape_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_reorder(input_indices_::tf.TensorHandle, input_values_::tf.TensorHandle, input_shape_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseReorder")
        tf.add_input(desc, input_indices_)
        tf.add_input(desc, input_values_)
        tf.add_input(desc, input_shape_)
        desc["T"] = tf.data_type(input_values_)
        tf.execute(desc)
    end
end


"""
     bitwise_xor(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function bitwise_xor(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "BitwiseXor") do 
                desc = tf.NodeDescription("BitwiseXor")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function bitwise_xor(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BitwiseXor")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_matrix_set_diag(input, diagonal)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_matrix_set_diag(input_, diagonal_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchMatrixSetDiag") do 
                desc = tf.NodeDescription("BatchMatrixSetDiag")
                input_ = convert(Tensor{Any}, input_)
                diagonal_ = convert(Tensor{Any}, diagonal_)
                (input_, diagonal_) = tf.tf_promote(input_, diagonal_)
                tf.add_input(desc, input_)
                tf.add_input(desc, diagonal_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_matrix_set_diag(input_::tf.TensorHandle, diagonal_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchMatrixSetDiag")
        tf.add_input(desc, input_)
        tf.add_input(desc, diagonal_)
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(diagonal_)
        (tf.execute(desc))[1]
    end
end


"""
     lookup_table_insert_v2(table_handle, keys, values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lookup_table_insert_v2(table_handle_, keys_, values_; name=nothing)
            local desc
            tf.with_op_name(name, "LookupTableInsertV2") do 
                desc = tf.NodeDescription("LookupTableInsertV2")
                table_handle_ = convert(Tensor{Any}, table_handle_)
                keys_ = convert(Tensor{Any}, keys_)
                values_ = convert(Tensor{Any}, values_)
                (keys_,) = tf.tf_promote(keys_)
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, table_handle_)
                tf.add_input(desc, keys_)
                tf.add_input(desc, values_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lookup_table_insert_v2(table_handle_::tf.TensorHandle, keys_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LookupTableInsertV2")
        tf.add_input(desc, table_handle_)
        tf.add_input(desc, keys_)
        tf.add_input(desc, values_)
        desc["Tin"] = tf.data_type(keys_)
        desc["Tout"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_dense_to_sparse_batch_dataset(input_dataset, batch_size, row_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_dense_to_sparse_batch_dataset(input_dataset_, batch_size_, row_shape_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalDenseToSparseBatchDataset") do 
                desc = tf.NodeDescription("ExperimentalDenseToSparseBatchDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                batch_size_ = convert(Tensor{Int64}, batch_size_)
                row_shape_ = convert(Tensor{Int64}, row_shape_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, batch_size_)
                tf.add_input(desc, row_shape_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_dense_to_sparse_batch_dataset(input_dataset_::tf.TensorHandle, batch_size_::tf.TensorHandle, row_shape_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalDenseToSparseBatchDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, batch_size_)
        tf.add_input(desc, row_shape_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_sparse_apply_rms_prop(var, ms, mom, lr, rho, momentum, epsilon, grad, indices; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_sparse_apply_rms_prop(var_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_, indices_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceSparseApplyRMSProp") do 
                desc = tf.NodeDescription("ResourceSparseApplyRMSProp")
                var_ = convert(Tensor{Any}, var_)
                ms_ = convert(Tensor{Any}, ms_)
                mom_ = convert(Tensor{Any}, mom_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                momentum_ = convert(Tensor{Any}, momentum_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                (lr_, rho_, momentum_, epsilon_, grad_) = tf.tf_promote(lr_, rho_, momentum_, epsilon_, grad_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, ms_)
                tf.add_input(desc, mom_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, momentum_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_sparse_apply_rms_prop(var_::tf.TensorHandle, ms_::tf.TensorHandle, mom_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, momentum_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceSparseApplyRMSProp")
        tf.add_input(desc, var_)
        tf.add_input(desc, ms_)
        tf.add_input(desc, mom_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, momentum_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(momentum_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        (tf.execute(desc))[1]
    end
end


"""
     random_crop(image, size; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function random_crop(image_, size_; name=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "RandomCrop") do 
                desc = tf.NodeDescription("RandomCrop")
                image_ = convert(Tensor{Any}, image_)
                size_ = convert(Tensor{Int64}, size_)
                (image_,) = tf.tf_promote(image_)
                tf.add_input(desc, image_)
                tf.add_input(desc, size_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function random_crop(image_::tf.TensorHandle, size_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("RandomCrop")
        tf.add_input(desc, image_)
        tf.add_input(desc, size_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        desc["T"] = tf.data_type(image_)
        (tf.execute(desc))[1]
    end
end


"""
     lookup_table_import_v2(table_handle, keys, values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lookup_table_import_v2(table_handle_, keys_, values_; name=nothing)
            local desc
            tf.with_op_name(name, "LookupTableImportV2") do 
                desc = tf.NodeDescription("LookupTableImportV2")
                table_handle_ = convert(Tensor{Any}, table_handle_)
                keys_ = convert(Tensor{Any}, keys_)
                values_ = convert(Tensor{Any}, values_)
                (keys_,) = tf.tf_promote(keys_)
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, table_handle_)
                tf.add_input(desc, keys_)
                tf.add_input(desc, values_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lookup_table_import_v2(table_handle_::tf.TensorHandle, keys_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LookupTableImportV2")
        tf.add_input(desc, table_handle_)
        tf.add_input(desc, keys_)
        tf.add_input(desc, values_)
        desc["Tin"] = tf.data_type(keys_)
        desc["Tout"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_scatter_nd_update(ref, indices, updates; use_locking=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_scatter_nd_update(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceScatterNdUpdate") do 
                desc = tf.NodeDescription("ResourceScatterNdUpdate")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (updates_,) = tf.tf_promote(updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_scatter_nd_update(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceScatterNdUpdate")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     static_regex_full_match(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function static_regex_full_match(input_; name=nothing, pattern=nothing)
            local desc
            tf.with_op_name(name, "StaticRegexFullMatch") do 
                desc = tf.NodeDescription("StaticRegexFullMatch")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
                if pattern !== nothing
                    desc["pattern"] = Base.String(pattern)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function static_regex_full_match(input_::tf.TensorHandle; name=nothing, pattern=nothing)
        desc = tf.EagerOp("StaticRegexFullMatch")
        tf.add_input(desc, input_)
        if pattern !== nothing
            desc["pattern"] = Base.String(pattern)
        end
        (tf.execute(desc))[1]
    end
end


"""
     gcs_configure_credentials(json)

Configures the credentials used by the GCS client of the local TF runtime.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function gcs_configure_credentials(json_; name=nothing)
            local desc
            tf.with_op_name(name, "GcsConfigureCredentials") do 
                desc = tf.NodeDescription("GcsConfigureCredentials")
                json_ = convert(Tensor{String}, json_)
                tf.add_input(desc, json_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function gcs_configure_credentials(json_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("GcsConfigureCredentials")
        tf.add_input(desc, json_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_size_v3(handle, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_size_v3(handle_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArraySizeV3") do 
                desc = tf.NodeDescription("TensorArraySizeV3")
                handle_ = convert(Tensor{Any}, handle_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_size_v3(handle_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArraySizeV3")
        tf.add_input(desc, handle_)
        tf.add_input(desc, flow_in_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_segment_sqrt_n_with_num_segments(data, indices, segment_ids, num_segments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_segment_sqrt_n_with_num_segments(data_, indices_, segment_ids_, num_segments_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSegmentSqrtNWithNumSegments") do 
                desc = tf.NodeDescription("SparseSegmentSqrtNWithNumSegments")
                data_ = convert(Tensor{Any}, data_)
                indices_ = convert(Tensor{Int32}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                segment_ids_ = convert(Tensor{Int32}, segment_ids_)
                num_segments_ = convert(Tensor{Int32}, num_segments_)
                (num_segments_,) = tf.tf_promote(num_segments_)
                (data_,) = tf.tf_promote(data_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, data_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, segment_ids_)
                tf.add_input(desc, num_segments_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_segment_sqrt_n_with_num_segments(data_::tf.TensorHandle, indices_::tf.TensorHandle, segment_ids_::tf.TensorHandle, num_segments_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSegmentSqrtNWithNumSegments")
        tf.add_input(desc, data_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, segment_ids_)
        tf.add_input(desc, num_segments_)
        desc["T"] = tf.data_type(data_)
        desc["Tidx"] = tf.data_type(indices_)
        desc["Tnumsegments"] = tf.data_type(num_segments_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_group_by_reducer_dataset(input_dataset, key_func_other_arguments, init_func_other_arguments, reduce_func_other_arguments, finalize_func_other_arguments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_group_by_reducer_dataset(input_dataset_, key_func_other_arguments_, init_func_other_arguments_, reduce_func_other_arguments_, finalize_func_other_arguments_; name=nothing, key_func=nothing, init_func=nothing, reduce_func=nothing, finalize_func=nothing, Tkey_func_other_arguments=nothing, Tinit_func_other_arguments=nothing, Treduce_func_other_arguments=nothing, Tfinalize_func_other_arguments=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalGroupByReducerDataset") do 
                desc = tf.NodeDescription("ExperimentalGroupByReducerDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                key_func_other_arguments_ = [convert(Tensor{Any}, x) for x = key_func_other_arguments_]
                init_func_other_arguments_ = [convert(Tensor{Any}, x) for x = init_func_other_arguments_]
                reduce_func_other_arguments_ = [convert(Tensor{Any}, x) for x = reduce_func_other_arguments_]
                finalize_func_other_arguments_ = [convert(Tensor{Any}, x) for x = finalize_func_other_arguments_]
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, key_func_other_arguments_)
                tf.add_input(desc, init_func_other_arguments_)
                tf.add_input(desc, reduce_func_other_arguments_)
                tf.add_input(desc, finalize_func_other_arguments_)
                if key_func !== nothing
                    desc["key_func"] = Base.identity(key_func)
                end
                if init_func !== nothing
                    desc["init_func"] = Base.identity(init_func)
                end
                if reduce_func !== nothing
                    desc["reduce_func"] = Base.identity(reduce_func)
                end
                if finalize_func !== nothing
                    desc["finalize_func"] = Base.identity(finalize_func)
                end
                if Tkey_func_other_arguments !== nothing
                    desc["Tkey_func_other_arguments"] = map(Base.identity, Tkey_func_other_arguments)
                end
                if Tinit_func_other_arguments !== nothing
                    desc["Tinit_func_other_arguments"] = map(Base.identity, Tinit_func_other_arguments)
                end
                if Treduce_func_other_arguments !== nothing
                    desc["Treduce_func_other_arguments"] = map(Base.identity, Treduce_func_other_arguments)
                end
                if Tfinalize_func_other_arguments !== nothing
                    desc["Tfinalize_func_other_arguments"] = map(Base.identity, Tfinalize_func_other_arguments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_group_by_reducer_dataset(input_dataset_::tf.TensorHandle, key_func_other_arguments_::tf.TensorHandle, init_func_other_arguments_::tf.TensorHandle, reduce_func_other_arguments_::tf.TensorHandle, finalize_func_other_arguments_::tf.TensorHandle; name=nothing, key_func=nothing, init_func=nothing, reduce_func=nothing, finalize_func=nothing, Tkey_func_other_arguments=nothing, Tinit_func_other_arguments=nothing, Treduce_func_other_arguments=nothing, Tfinalize_func_other_arguments=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalGroupByReducerDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, key_func_other_arguments_)
        tf.add_input(desc, init_func_other_arguments_)
        tf.add_input(desc, reduce_func_other_arguments_)
        tf.add_input(desc, finalize_func_other_arguments_)
        if key_func !== nothing
            desc["key_func"] = Base.identity(key_func)
        end
        if init_func !== nothing
            desc["init_func"] = Base.identity(init_func)
        end
        if reduce_func !== nothing
            desc["reduce_func"] = Base.identity(reduce_func)
        end
        if finalize_func !== nothing
            desc["finalize_func"] = Base.identity(finalize_func)
        end
        if Tkey_func_other_arguments !== nothing
            desc["Tkey_func_other_arguments"] = map(Base.identity, Tkey_func_other_arguments)
        end
        if Tinit_func_other_arguments !== nothing
            desc["Tinit_func_other_arguments"] = map(Base.identity, Tinit_func_other_arguments)
        end
        if Treduce_func_other_arguments !== nothing
            desc["Treduce_func_other_arguments"] = map(Base.identity, Treduce_func_other_arguments)
        end
        if Tfinalize_func_other_arguments !== nothing
            desc["Tfinalize_func_other_arguments"] = map(Base.identity, Tfinalize_func_other_arguments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     conv2d_backprop_filter(input, filter_sizes, out_backprop; use_cudnn_on_gpu=true, explicit_paddings=Int64[], data_format=NHWC, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function conv2d_backprop_filter(input_, filter_sizes_, out_backprop_; name=nothing, strides=nothing, use_cudnn_on_gpu=nothing, padding=nothing, explicit_paddings=nothing, data_format=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "Conv2DBackpropFilter") do 
                desc = tf.NodeDescription("Conv2DBackpropFilter")
                input_ = convert(Tensor{Any}, input_)
                filter_sizes_ = convert(Tensor{Int32}, filter_sizes_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                (input_, out_backprop_) = tf.tf_promote(input_, out_backprop_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_sizes_)
                tf.add_input(desc, out_backprop_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if use_cudnn_on_gpu !== nothing
                    desc["use_cudnn_on_gpu"] = Base.Bool(use_cudnn_on_gpu)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if explicit_paddings !== nothing
                    desc["explicit_paddings"] = map(Base.identity, explicit_paddings)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function conv2d_backprop_filter(input_::tf.TensorHandle, filter_sizes_::tf.TensorHandle, out_backprop_::tf.TensorHandle; name=nothing, strides=nothing, use_cudnn_on_gpu=nothing, padding=nothing, explicit_paddings=nothing, data_format=nothing, dilations=nothing)
        desc = tf.EagerOp("Conv2DBackpropFilter")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_sizes_)
        tf.add_input(desc, out_backprop_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if use_cudnn_on_gpu !== nothing
            desc["use_cudnn_on_gpu"] = Base.Bool(use_cudnn_on_gpu)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if explicit_paddings !== nothing
            desc["explicit_paddings"] = map(Base.identity, explicit_paddings)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     max_pool_grad(orig_input, orig_output, grad; data_format=NHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool_grad(orig_input_, orig_output_, grad_; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "MaxPoolGrad") do 
                desc = tf.NodeDescription("MaxPoolGrad")
                orig_input_ = convert(Tensor{Float32}, orig_input_)
                orig_output_ = convert(Tensor{Float32}, orig_output_)
                grad_ = convert(Tensor{Float32}, grad_)
                (orig_input_, orig_output_, grad_) = tf.tf_promote(orig_input_, orig_output_, grad_)
                tf.add_input(desc, orig_input_)
                tf.add_input(desc, orig_output_)
                tf.add_input(desc, grad_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max_pool_grad(orig_input_::tf.TensorHandle, orig_output_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("MaxPoolGrad")
        tf.add_input(desc, orig_input_)
        tf.add_input(desc, orig_output_)
        tf.add_input(desc, grad_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(orig_input_)
        desc["T"] = tf.data_type(orig_output_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     _initialize_host_for_distributed_tpu(input)

An op that connects each chip on the host to a centralized UberDriver to allow
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _initialize_host_for_distributed_tpu(input_; name=nothing)
            local desc
            tf.with_op_name(name, "_InitializeHostForDistributedTPU") do 
                desc = tf.NodeDescription("_InitializeHostForDistributedTPU")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _initialize_host_for_distributed_tpu(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("_InitializeHostForDistributedTPU")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     stage_peek(index; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stage_peek(index_; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "StagePeek") do 
                desc = tf.NodeDescription("StagePeek")
                index_ = convert(Tensor{Int32}, index_)
                tf.add_input(desc, index_)
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stage_peek(index_::tf.TensorHandle; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("StagePeek")
        tf.add_input(desc, index_)
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     pad_v2(input, paddings, constant_values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function pad_v2(input_, paddings_, constant_values_; name=nothing)
            local desc
            tf.with_op_name(name, "PadV2") do 
                desc = tf.NodeDescription("PadV2")
                input_ = convert(Tensor{Any}, input_)
                paddings_ = convert(Tensor{Int32}, paddings_)
                constant_values_ = convert(Tensor{Any}, constant_values_)
                (input_, constant_values_) = tf.tf_promote(input_, constant_values_)
                (paddings_,) = tf.tf_promote(paddings_)
                tf.add_input(desc, input_)
                tf.add_input(desc, paddings_)
                tf.add_input(desc, constant_values_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function pad_v2(input_::tf.TensorHandle, paddings_::tf.TensorHandle, constant_values_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("PadV2")
        tf.add_input(desc, input_)
        tf.add_input(desc, paddings_)
        tf.add_input(desc, constant_values_)
        desc["T"] = tf.data_type(input_)
        desc["Tpaddings"] = tf.data_type(paddings_)
        desc["T"] = tf.data_type(constant_values_)
        (tf.execute(desc))[1]
    end
end


"""
     _parallel_concat_start()

Creates an empty Tensor with shape `shape` and type `dtype`.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _parallel_concat_start(; name=nothing, shape=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "_ParallelConcatStart") do 
                desc = tf.NodeDescription("_ParallelConcatStart")
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _parallel_concat_start(; name=nothing, shape=nothing, dtype=nothing)
        desc = tf.EagerOp("_ParallelConcatStart")
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     print_v2(input; output_stream=stderr)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function print_v2(input_; name=nothing, output_stream=nothing)
            local desc
            tf.with_op_name(name, "PrintV2") do 
                desc = tf.NodeDescription("PrintV2")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
                if output_stream !== nothing
                    desc["output_stream"] = Base.String(output_stream)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function print_v2(input_::tf.TensorHandle; name=nothing, output_stream=nothing)
        desc = tf.EagerOp("PrintV2")
        tf.add_input(desc, input_)
        if output_stream !== nothing
            desc["output_stream"] = Base.String(output_stream)
        end
        (tf.execute(desc))[1]
    end
end


"""
     optional_get_value(optional)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function optional_get_value(optional_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "OptionalGetValue") do 
                desc = tf.NodeDescription("OptionalGetValue")
                optional_ = convert(Tensor{Any}, optional_)
                tf.add_input(desc, optional_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function optional_get_value(optional_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("OptionalGetValue")
        tf.add_input(desc, optional_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     load_tpu_embedding_ftrl_parameters(parameters, accumulators, linears; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_ftrl_parameters(parameters_, accumulators_, linears_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingFTRLParameters") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingFTRLParameters")
                parameters_ = convert(Tensor{Float32}, parameters_)
                accumulators_ = convert(Tensor{Float32}, accumulators_)
                linears_ = convert(Tensor{Float32}, linears_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, accumulators_)
                tf.add_input(desc, linears_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_ftrl_parameters(parameters_::tf.TensorHandle, accumulators_::tf.TensorHandle, linears_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingFTRLParameters")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, accumulators_)
        tf.add_input(desc, linears_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_slice(indices, values, shape, start, size)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_slice(indices_, values_, shape_, start_, size_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSlice") do 
                desc = tf.NodeDescription("SparseSlice")
                indices_ = convert(Tensor{Int64}, indices_)
                values_ = convert(Tensor{Any}, values_)
                shape_ = convert(Tensor{Int64}, shape_)
                start_ = convert(Tensor{Int64}, start_)
                size_ = convert(Tensor{Int64}, size_)
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, values_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, start_)
                tf.add_input(desc, size_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_slice(indices_::tf.TensorHandle, values_::tf.TensorHandle, shape_::tf.TensorHandle, start_::tf.TensorHandle, size_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSlice")
        tf.add_input(desc, indices_)
        tf.add_input(desc, values_)
        tf.add_input(desc, shape_)
        tf.add_input(desc, start_)
        tf.add_input(desc, size_)
        desc["T"] = tf.data_type(values_)
        tf.execute(desc)
    end
end


"""
     boosted_trees_make_quantile_summaries(float_values, example_weights, epsilon)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_make_quantile_summaries(float_values_, example_weights_, epsilon_; name=nothing, num_features=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesMakeQuantileSummaries") do 
                desc = tf.NodeDescription("BoostedTreesMakeQuantileSummaries")
                float_values_ = [convert(Tensor{Float32}, x) for x = float_values_]
                example_weights_ = convert(Tensor{Float32}, example_weights_)
                epsilon_ = convert(Tensor{Float32}, epsilon_)
                tf.add_input(desc, float_values_)
                tf.add_input(desc, example_weights_)
                tf.add_input(desc, epsilon_)
                if num_features !== nothing
                    desc["num_features"] = Base.Int(num_features)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:num_features
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function boosted_trees_make_quantile_summaries(float_values_::tf.TensorHandle, example_weights_::tf.TensorHandle, epsilon_::tf.TensorHandle; name=nothing, num_features=nothing)
        desc = tf.EagerOp("BoostedTreesMakeQuantileSummaries")
        tf.add_input(desc, float_values_)
        tf.add_input(desc, example_weights_)
        tf.add_input(desc, epsilon_)
        if num_features !== nothing
            desc["num_features"] = Base.Int(num_features)
        end
        tf.execute(desc)
    end
end


"""
     matrix_solve(matrix, rhs; adjoint=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_solve(matrix_, rhs_; name=nothing, adjoint=nothing)
            local desc
            tf.with_op_name(name, "MatrixSolve") do 
                desc = tf.NodeDescription("MatrixSolve")
                matrix_ = convert(Tensor{Any}, matrix_)
                rhs_ = convert(Tensor{Any}, rhs_)
                (matrix_, rhs_) = tf.tf_promote(matrix_, rhs_)
                tf.add_input(desc, matrix_)
                tf.add_input(desc, rhs_)
                if adjoint !== nothing
                    desc["adjoint"] = Base.Bool(adjoint)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_solve(matrix_::tf.TensorHandle, rhs_::tf.TensorHandle; name=nothing, adjoint=nothing)
        desc = tf.EagerOp("MatrixSolve")
        tf.add_input(desc, matrix_)
        tf.add_input(desc, rhs_)
        if adjoint !== nothing
            desc["adjoint"] = Base.Bool(adjoint)
        end
        desc["T"] = tf.data_type(matrix_)
        desc["T"] = tf.data_type(rhs_)
        (tf.execute(desc))[1]
    end
end


"""
     _configure_distributed_tpu(inputs)

An op that sets up the centralized structures for a distributed TPU
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _configure_distributed_tpu(inputs_; name=nothing, N=nothing)
            local desc
            tf.with_op_name(name, "_ConfigureDistributedTPU") do 
                desc = tf.NodeDescription("_ConfigureDistributedTPU")
                inputs_ = [convert(Tensor{Int32}, x) for x = inputs_]
                tf.add_input(desc, inputs_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _configure_distributed_tpu(inputs_::tf.TensorHandle; name=nothing, N=nothing)
        desc = tf.EagerOp("_ConfigureDistributedTPU")
        tf.add_input(desc, inputs_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        (tf.execute(desc))[1]
    end
end


"""
     adjust_contrastv2(images, contrast_factor)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function adjust_contrastv2(images_, contrast_factor_; name=nothing)
            local desc
            tf.with_op_name(name, "AdjustContrastv2") do 
                desc = tf.NodeDescription("AdjustContrastv2")
                images_ = convert(Tensor{Float32}, images_)
                contrast_factor_ = convert(Tensor{Float32}, contrast_factor_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                tf.add_input(desc, contrast_factor_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function adjust_contrastv2(images_::tf.TensorHandle, contrast_factor_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("AdjustContrastv2")
        tf.add_input(desc, images_)
        tf.add_input(desc, contrast_factor_)
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     _mkl_maximum(x, y, mkl_x, mkl_y)

Returns the max of x and y (i.e. x > y ? x : y) element-wise.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _mkl_maximum(x_, y_, mkl_x_, mkl_y_; name=nothing)
            local desc
            tf.with_op_name(name, "_MklMaximum") do 
                desc = tf.NodeDescription("_MklMaximum")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                mkl_x_ = convert(Tensor{UInt8}, mkl_x_)
                mkl_y_ = convert(Tensor{UInt8}, mkl_y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
                tf.add_input(desc, mkl_x_)
                tf.add_input(desc, mkl_y_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function _mkl_maximum(x_::tf.TensorHandle, y_::tf.TensorHandle, mkl_x_::tf.TensorHandle, mkl_y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("_MklMaximum")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        tf.add_input(desc, mkl_x_)
        tf.add_input(desc, mkl_y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        tf.execute(desc)
    end
end


"""
     cudnn_rnn_params_size(num_layers, num_units, input_size; rnn_mode=lstm, input_mode=linear_input, direction=unidirectional, dropout=?, seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cudnn_rnn_params_size(num_layers_, num_units_, input_size_; name=nothing, S=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
            local desc
            tf.with_op_name(name, "CudnnRNNParamsSize") do 
                desc = tf.NodeDescription("CudnnRNNParamsSize")
                num_layers_ = convert(Tensor{Int32}, num_layers_)
                num_units_ = convert(Tensor{Int32}, num_units_)
                input_size_ = convert(Tensor{Int32}, input_size_)
                tf.add_input(desc, num_layers_)
                tf.add_input(desc, num_units_)
                tf.add_input(desc, input_size_)
                if S !== nothing
                    desc["S"] = Base.identity(S)
                end
                if rnn_mode !== nothing
                    desc["rnn_mode"] = Base.String(rnn_mode)
                end
                if input_mode !== nothing
                    desc["input_mode"] = Base.String(input_mode)
                end
                if direction !== nothing
                    desc["direction"] = Base.String(direction)
                end
                if dropout !== nothing
                    desc["dropout"] = Base.identity(dropout)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cudnn_rnn_params_size(num_layers_::tf.TensorHandle, num_units_::tf.TensorHandle, input_size_::tf.TensorHandle; name=nothing, S=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing)
        desc = tf.EagerOp("CudnnRNNParamsSize")
        tf.add_input(desc, num_layers_)
        tf.add_input(desc, num_units_)
        tf.add_input(desc, input_size_)
        if S !== nothing
            desc["S"] = Base.identity(S)
        end
        if rnn_mode !== nothing
            desc["rnn_mode"] = Base.String(rnn_mode)
        end
        if input_mode !== nothing
            desc["input_mode"] = Base.String(input_mode)
        end
        if direction !== nothing
            desc["direction"] = Base.String(direction)
        end
        if dropout !== nothing
            desc["dropout"] = Base.identity(dropout)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_quantile_stream_resource_add_summaries(quantile_stream_resource_handle, summaries)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_quantile_stream_resource_add_summaries(quantile_stream_resource_handle_, summaries_; name=nothing, num_features=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesQuantileStreamResourceAddSummaries") do 
                desc = tf.NodeDescription("BoostedTreesQuantileStreamResourceAddSummaries")
                quantile_stream_resource_handle_ = convert(Tensor{Any}, quantile_stream_resource_handle_)
                summaries_ = [convert(Tensor{Float32}, x) for x = summaries_]
                tf.add_input(desc, quantile_stream_resource_handle_)
                tf.add_input(desc, summaries_)
                if num_features !== nothing
                    desc["num_features"] = Base.Int(num_features)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_quantile_stream_resource_add_summaries(quantile_stream_resource_handle_::tf.TensorHandle, summaries_::tf.TensorHandle; name=nothing, num_features=nothing)
        desc = tf.EagerOp("BoostedTreesQuantileStreamResourceAddSummaries")
        tf.add_input(desc, quantile_stream_resource_handle_)
        tf.add_input(desc, summaries_)
        if num_features !== nothing
            desc["num_features"] = Base.Int(num_features)
        end
        (tf.execute(desc))[1]
    end
end


"""
     batch_ifft3d(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_ifft3d(input_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchIFFT3D") do 
                desc = tf.NodeDescription("BatchIFFT3D")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_ifft3d(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchIFFT3D")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     sigmoid(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sigmoid(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Sigmoid") do 
                desc = tf.NodeDescription("Sigmoid")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sigmoid(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Sigmoid")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     segment_mean(data, segment_ids)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function segment_mean(data_, segment_ids_; name=nothing)
            local desc
            tf.with_op_name(name, "SegmentMean") do 
                desc = tf.NodeDescription("SegmentMean")
                data_ = convert(Tensor{Any}, data_)
                segment_ids_ = convert(Tensor{Any}, segment_ids_)
                segment_ids_ = segment_ids_ - convert(tf.Tensor{eltype(segment_ids_)}, 1)
                (data_,) = tf.tf_promote(data_)
                (segment_ids_,) = tf.tf_promote(segment_ids_)
                tf.add_input(desc, data_)
                tf.add_input(desc, segment_ids_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function segment_mean(data_::tf.TensorHandle, segment_ids_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SegmentMean")
        tf.add_input(desc, data_)
        tf.add_input(desc, segment_ids_)
        desc["T"] = tf.data_type(data_)
        desc["Tindices"] = tf.data_type(segment_ids_)
        (tf.execute(desc))[1]
    end
end


"""
     is_boosted_trees_ensemble_initialized(tree_ensemble_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function is_boosted_trees_ensemble_initialized(tree_ensemble_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "IsBoostedTreesEnsembleInitialized") do 
                desc = tf.NodeDescription("IsBoostedTreesEnsembleInitialized")
                tree_ensemble_handle_ = convert(Tensor{Any}, tree_ensemble_handle_)
                tf.add_input(desc, tree_ensemble_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function is_boosted_trees_ensemble_initialized(tree_ensemble_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IsBoostedTreesEnsembleInitialized")
        tf.add_input(desc, tree_ensemble_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_size_v2(handle, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_size_v2(handle_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArraySizeV2") do 
                desc = tf.NodeDescription("TensorArraySizeV2")
                handle_ = convert(Tensor{String}, handle_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_size_v2(handle_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArraySizeV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, flow_in_)
        (tf.execute(desc))[1]
    end
end


"""
     _mkl_sub(x, y, mkl_x, mkl_y)

Returns x - y element-wise.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _mkl_sub(x_, y_, mkl_x_, mkl_y_; name=nothing)
            local desc
            tf.with_op_name(name, "_MklSub") do 
                desc = tf.NodeDescription("_MklSub")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                mkl_x_ = convert(Tensor{UInt8}, mkl_x_)
                mkl_y_ = convert(Tensor{UInt8}, mkl_y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
                tf.add_input(desc, mkl_x_)
                tf.add_input(desc, mkl_y_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function _mkl_sub(x_::tf.TensorHandle, y_::tf.TensorHandle, mkl_x_::tf.TensorHandle, mkl_y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("_MklSub")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        tf.add_input(desc, mkl_x_)
        tf.add_input(desc, mkl_y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        tf.execute(desc)
    end
end


"""
     send_tpu_embedding_gradients(inputs, learning_rates; NN=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function send_tpu_embedding_gradients(inputs_, learning_rates_; name=nothing, N=nothing, NN=nothing, config=nothing)
            local desc
            tf.with_op_name(name, "SendTPUEmbeddingGradients") do 
                desc = tf.NodeDescription("SendTPUEmbeddingGradients")
                inputs_ = [convert(Tensor{Float32}, x) for x = inputs_]
                learning_rates_ = [convert(Tensor{Float32}, x) for x = learning_rates_]
                tf.add_input(desc, inputs_)
                tf.add_input(desc, learning_rates_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if NN !== nothing
                    desc["NN"] = Base.Int(NN)
                end
                if config !== nothing
                    desc["config"] = Base.String(config)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function send_tpu_embedding_gradients(inputs_::tf.TensorHandle, learning_rates_::tf.TensorHandle; name=nothing, N=nothing, NN=nothing, config=nothing)
        desc = tf.EagerOp("SendTPUEmbeddingGradients")
        tf.add_input(desc, inputs_)
        tf.add_input(desc, learning_rates_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if NN !== nothing
            desc["NN"] = Base.Int(NN)
        end
        if config !== nothing
            desc["config"] = Base.String(config)
        end
        (tf.execute(desc))[1]
    end
end


"""
     max_pool3d(input; data_format=NDHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool3d(input_; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "MaxPool3D") do 
                desc = tf.NodeDescription("MaxPool3D")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max_pool3d(input_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("MaxPool3D")
        tf.add_input(desc, input_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     prod(input, reduction_indices; keep_dims=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function prod(input_, reduction_indices_; name=nothing, keep_dims=nothing)
            local desc
            tf.with_op_name(name, "Prod") do 
                desc = tf.NodeDescription("Prod")
                input_ = convert(Tensor{Any}, input_)
                reduction_indices_ = convert(Tensor{Int32}, reduction_indices_)
                reduction_indices_ = reduction_indices_ - convert(tf.Tensor{eltype(reduction_indices_)}, 1)
                (input_,) = tf.tf_promote(input_)
                (reduction_indices_,) = tf.tf_promote(reduction_indices_)
                tf.add_input(desc, input_)
                tf.add_input(desc, reduction_indices_)
                if keep_dims !== nothing
                    desc["keep_dims"] = Base.Bool(keep_dims)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function prod(input_::tf.TensorHandle, reduction_indices_::tf.TensorHandle; name=nothing, keep_dims=nothing)
        desc = tf.EagerOp("Prod")
        tf.add_input(desc, input_)
        tf.add_input(desc, reduction_indices_)
        if keep_dims !== nothing
            desc["keep_dims"] = Base.Bool(keep_dims)
        end
        desc["T"] = tf.data_type(input_)
        desc["Tidx"] = tf.data_type(reduction_indices_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_identity_indexed_dataset(size)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_identity_indexed_dataset(size_; name=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalIdentityIndexedDataset") do 
                desc = tf.NodeDescription("ExperimentalIdentityIndexedDataset")
                size_ = convert(Tensor{Any}, size_)
                tf.add_input(desc, size_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_identity_indexed_dataset(size_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ExperimentalIdentityIndexedDataset")
        tf.add_input(desc, size_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_push_back(input_handle, tensor)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_push_back(input_handle_, tensor_; name=nothing, element_dtype=nothing)
            local desc
            tf.with_op_name(name, "TensorListPushBack") do 
                desc = tf.NodeDescription("TensorListPushBack")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                tensor_ = convert(Tensor{Any}, tensor_)
                (tensor_,) = tf.tf_promote(tensor_)
                tf.add_input(desc, input_handle_)
                tf.add_input(desc, tensor_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_push_back(input_handle_::tf.TensorHandle, tensor_::tf.TensorHandle; name=nothing, element_dtype=nothing)
        desc = tf.EagerOp("TensorListPushBack")
        tf.add_input(desc, input_handle_)
        tf.add_input(desc, tensor_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        desc["element_dtype"] = tf.data_type(tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_function(in_tensors, captured_tensors; max_enqueued_batches=10, allowed_batch_sizes=Int64[], container=, shared_name=, batching_queue=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_function(in_tensors_, captured_tensors_; name=nothing, f=nothing, num_batch_threads=nothing, max_batch_size=nothing, batch_timeout_micros=nothing, max_enqueued_batches=nothing, allowed_batch_sizes=nothing, container=nothing, shared_name=nothing, batching_queue=nothing, Tin=nothing, Tcaptured=nothing, Tout=nothing)
            local desc
            tf.with_op_name(name, "BatchFunction") do 
                desc = tf.NodeDescription("BatchFunction")
                in_tensors_ = [convert(Tensor{Any}, x) for x = in_tensors_]
                captured_tensors_ = [convert(Tensor{Any}, x) for x = captured_tensors_]
                tf.add_input(desc, in_tensors_)
                tf.add_input(desc, captured_tensors_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if num_batch_threads !== nothing
                    desc["num_batch_threads"] = Base.Int(num_batch_threads)
                end
                if max_batch_size !== nothing
                    desc["max_batch_size"] = Base.Int(max_batch_size)
                end
                if batch_timeout_micros !== nothing
                    desc["batch_timeout_micros"] = Base.Int(batch_timeout_micros)
                end
                if max_enqueued_batches !== nothing
                    desc["max_enqueued_batches"] = Base.Int(max_enqueued_batches)
                end
                if allowed_batch_sizes !== nothing
                    desc["allowed_batch_sizes"] = map(Base.identity, allowed_batch_sizes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if batching_queue !== nothing
                    desc["batching_queue"] = Base.String(batching_queue)
                end
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tcaptured !== nothing
                    desc["Tcaptured"] = map(Base.identity, Tcaptured)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_function(in_tensors_::tf.TensorHandle, captured_tensors_::tf.TensorHandle; name=nothing, f=nothing, num_batch_threads=nothing, max_batch_size=nothing, batch_timeout_micros=nothing, max_enqueued_batches=nothing, allowed_batch_sizes=nothing, container=nothing, shared_name=nothing, batching_queue=nothing, Tin=nothing, Tcaptured=nothing, Tout=nothing)
        desc = tf.EagerOp("BatchFunction")
        tf.add_input(desc, in_tensors_)
        tf.add_input(desc, captured_tensors_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if num_batch_threads !== nothing
            desc["num_batch_threads"] = Base.Int(num_batch_threads)
        end
        if max_batch_size !== nothing
            desc["max_batch_size"] = Base.Int(max_batch_size)
        end
        if batch_timeout_micros !== nothing
            desc["batch_timeout_micros"] = Base.Int(batch_timeout_micros)
        end
        if max_enqueued_batches !== nothing
            desc["max_enqueued_batches"] = Base.Int(max_enqueued_batches)
        end
        if allowed_batch_sizes !== nothing
            desc["allowed_batch_sizes"] = map(Base.identity, allowed_batch_sizes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if batching_queue !== nothing
            desc["batching_queue"] = Base.String(batching_queue)
        end
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tcaptured !== nothing
            desc["Tcaptured"] = map(Base.identity, Tcaptured)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_fill_empty_rows(indices, values, dense_shape, default_value)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_fill_empty_rows(indices_, values_, dense_shape_, default_value_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseFillEmptyRows") do 
                desc = tf.NodeDescription("SparseFillEmptyRows")
                indices_ = convert(Tensor{Int64}, indices_)
                values_ = convert(Tensor{Any}, values_)
                dense_shape_ = convert(Tensor{Int64}, dense_shape_)
                default_value_ = convert(Tensor{Any}, default_value_)
                (values_, default_value_) = tf.tf_promote(values_, default_value_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, values_)
                tf.add_input(desc, dense_shape_)
                tf.add_input(desc, default_value_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:4
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_fill_empty_rows(indices_::tf.TensorHandle, values_::tf.TensorHandle, dense_shape_::tf.TensorHandle, default_value_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseFillEmptyRows")
        tf.add_input(desc, indices_)
        tf.add_input(desc, values_)
        tf.add_input(desc, dense_shape_)
        tf.add_input(desc, default_value_)
        desc["T"] = tf.data_type(values_)
        desc["T"] = tf.data_type(default_value_)
        tf.execute(desc)
    end
end


"""
     self_adjoint_eig_v2(input; compute_v=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function self_adjoint_eig_v2(input_; name=nothing, compute_v=nothing)
            local desc
            tf.with_op_name(name, "SelfAdjointEigV2") do 
                desc = tf.NodeDescription("SelfAdjointEigV2")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if compute_v !== nothing
                    desc["compute_v"] = Base.Bool(compute_v)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function self_adjoint_eig_v2(input_::tf.TensorHandle; name=nothing, compute_v=nothing)
        desc = tf.EagerOp("SelfAdjointEigV2")
        tf.add_input(desc, input_)
        if compute_v !== nothing
            desc["compute_v"] = Base.Bool(compute_v)
        end
        desc["T"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     retrieve_tpu_embedding_ftrl_parameters(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_ftrl_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingFTRLParameters") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingFTRLParameters")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_ftrl_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingFTRLParameters")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     resource_sparse_apply_adagrad_da(var, gradient_accumulator, gradient_squared_accumulator, grad, indices, lr, l1, l2, global_step; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_sparse_apply_adagrad_da(var_, gradient_accumulator_, gradient_squared_accumulator_, grad_, indices_, lr_, l1_, l2_, global_step_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceSparseApplyAdagradDA") do 
                desc = tf.NodeDescription("ResourceSparseApplyAdagradDA")
                var_ = convert(Tensor{Any}, var_)
                gradient_accumulator_ = convert(Tensor{Any}, gradient_accumulator_)
                gradient_squared_accumulator_ = convert(Tensor{Any}, gradient_squared_accumulator_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                global_step_ = convert(Tensor{Int64}, global_step_)
                (grad_, lr_, l1_, l2_) = tf.tf_promote(grad_, lr_, l1_, l2_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, gradient_accumulator_)
                tf.add_input(desc, gradient_squared_accumulator_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, global_step_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_sparse_apply_adagrad_da(var_::tf.TensorHandle, gradient_accumulator_::tf.TensorHandle, gradient_squared_accumulator_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, global_step_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceSparseApplyAdagradDA")
        tf.add_input(desc, var_)
        tf.add_input(desc, gradient_accumulator_)
        tf.add_input(desc, gradient_squared_accumulator_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, global_step_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        (tf.execute(desc))[1]
    end
end


"""
     temporary_variable(; var_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function temporary_variable(; name=nothing, shape=nothing, dtype=nothing, var_name=nothing)
            local desc
            tf.with_op_name(name, "TemporaryVariable") do 
                desc = tf.NodeDescription("TemporaryVariable")
                if shape !== nothing
                    desc["shape"] = Base.identity(shape)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if var_name !== nothing
                    desc["var_name"] = Base.String(var_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function temporary_variable(; name=nothing, shape=nothing, dtype=nothing, var_name=nothing)
        desc = tf.EagerOp("TemporaryVariable")
        if shape !== nothing
            desc["shape"] = Base.identity(shape)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if var_name !== nothing
            desc["var_name"] = Base.String(var_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_add_sign(var, m, lr, alpha, sign_decay, beta, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_add_sign(var_, m_, lr_, alpha_, sign_decay_, beta_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyAddSign") do 
                desc = tf.NodeDescription("ResourceApplyAddSign")
                var_ = convert(Tensor{Any}, var_)
                m_ = convert(Tensor{Any}, m_)
                lr_ = convert(Tensor{Any}, lr_)
                alpha_ = convert(Tensor{Any}, alpha_)
                sign_decay_ = convert(Tensor{Any}, sign_decay_)
                beta_ = convert(Tensor{Any}, beta_)
                grad_ = convert(Tensor{Any}, grad_)
                (lr_, alpha_, sign_decay_, beta_, grad_) = tf.tf_promote(lr_, alpha_, sign_decay_, beta_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, m_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, alpha_)
                tf.add_input(desc, sign_decay_)
                tf.add_input(desc, beta_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_add_sign(var_::tf.TensorHandle, m_::tf.TensorHandle, lr_::tf.TensorHandle, alpha_::tf.TensorHandle, sign_decay_::tf.TensorHandle, beta_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyAddSign")
        tf.add_input(desc, var_)
        tf.add_input(desc, m_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, alpha_)
        tf.add_input(desc, sign_decay_)
        tf.add_input(desc, beta_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(alpha_)
        desc["T"] = tf.data_type(sign_decay_)
        desc["T"] = tf.data_type(beta_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     roll(input, shift, axis)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function roll(input_, shift_, axis_; name=nothing)
            local desc
            tf.with_op_name(name, "Roll") do 
                desc = tf.NodeDescription("Roll")
                input_ = convert(Tensor{Any}, input_)
                shift_ = convert(Tensor{Any}, shift_)
                axis_ = convert(Tensor{Any}, axis_)
                (input_,) = tf.tf_promote(input_)
                (shift_,) = tf.tf_promote(shift_)
                (axis_,) = tf.tf_promote(axis_)
                tf.add_input(desc, input_)
                tf.add_input(desc, shift_)
                tf.add_input(desc, axis_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function roll(input_::tf.TensorHandle, shift_::tf.TensorHandle, axis_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Roll")
        tf.add_input(desc, input_)
        tf.add_input(desc, shift_)
        tf.add_input(desc, axis_)
        desc["T"] = tf.data_type(input_)
        desc["Tshift"] = tf.data_type(shift_)
        desc["Taxis"] = tf.data_type(axis_)
        (tf.execute(desc))[1]
    end
end


"""
     xdivy(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function xdivy(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Xdivy") do 
                desc = tf.NodeDescription("Xdivy")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function xdivy(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Xdivy")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     max_pool3d_grad_grad(orig_input, orig_output, grad; data_format=NDHWC)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool3d_grad_grad(orig_input_, orig_output_, grad_; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
            local desc
            tf.with_op_name(name, "MaxPool3DGradGrad") do 
                desc = tf.NodeDescription("MaxPool3DGradGrad")
                orig_input_ = convert(Tensor{Any}, orig_input_)
                orig_output_ = convert(Tensor{Any}, orig_output_)
                grad_ = convert(Tensor{Any}, grad_)
                (orig_input_, orig_output_, grad_) = tf.tf_promote(orig_input_, orig_output_, grad_)
                tf.add_input(desc, orig_input_)
                tf.add_input(desc, orig_output_)
                tf.add_input(desc, grad_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max_pool3d_grad_grad(orig_input_::tf.TensorHandle, orig_output_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing, data_format=nothing)
        desc = tf.EagerOp("MaxPool3DGradGrad")
        tf.add_input(desc, orig_input_)
        tf.add_input(desc, orig_output_)
        tf.add_input(desc, grad_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        desc["T"] = tf.data_type(orig_input_)
        desc["T"] = tf.data_type(orig_output_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     crop_and_resize(image, boxes, box_ind, crop_size; method=bilinear, extrapolation_value=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function crop_and_resize(image_, boxes_, box_ind_, crop_size_; name=nothing, method=nothing, extrapolation_value=nothing)
            local desc
            tf.with_op_name(name, "CropAndResize") do 
                desc = tf.NodeDescription("CropAndResize")
                image_ = convert(Tensor{Any}, image_)
                boxes_ = convert(Tensor{Float32}, boxes_)
                box_ind_ = convert(Tensor{Int32}, box_ind_)
                crop_size_ = convert(Tensor{Int32}, crop_size_)
                (image_,) = tf.tf_promote(image_)
                tf.add_input(desc, image_)
                tf.add_input(desc, boxes_)
                tf.add_input(desc, box_ind_)
                tf.add_input(desc, crop_size_)
                if method !== nothing
                    desc["method"] = Base.String(method)
                end
                if extrapolation_value !== nothing
                    desc["extrapolation_value"] = Base.identity(extrapolation_value)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function crop_and_resize(image_::tf.TensorHandle, boxes_::tf.TensorHandle, box_ind_::tf.TensorHandle, crop_size_::tf.TensorHandle; name=nothing, method=nothing, extrapolation_value=nothing)
        desc = tf.EagerOp("CropAndResize")
        tf.add_input(desc, image_)
        tf.add_input(desc, boxes_)
        tf.add_input(desc, box_ind_)
        tf.add_input(desc, crop_size_)
        if method !== nothing
            desc["method"] = Base.String(method)
        end
        if extrapolation_value !== nothing
            desc["extrapolation_value"] = Base.identity(extrapolation_value)
        end
        desc["T"] = tf.data_type(image_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_bias_add(input, bias, min_input, max_input, min_bias, max_bias)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_bias_add(input_, bias_, min_input_, max_input_, min_bias_, max_bias_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "QuantizedBiasAdd") do 
                desc = tf.NodeDescription("QuantizedBiasAdd")
                input_ = convert(Tensor{Any}, input_)
                bias_ = convert(Tensor{Any}, bias_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_bias_ = convert(Tensor{Float32}, min_bias_)
                max_bias_ = convert(Tensor{Float32}, max_bias_)
                (input_,) = tf.tf_promote(input_)
                (bias_,) = tf.tf_promote(bias_)
                tf.add_input(desc, input_)
                tf.add_input(desc, bias_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_bias_)
                tf.add_input(desc, max_bias_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_bias_add(input_::tf.TensorHandle, bias_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_bias_::tf.TensorHandle, max_bias_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("QuantizedBiasAdd")
        tf.add_input(desc, input_)
        tf.add_input(desc, bias_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_bias_)
        tf.add_input(desc, max_bias_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["T1"] = tf.data_type(input_)
        desc["T2"] = tf.data_type(bias_)
        tf.execute(desc)
    end
end


"""
     kmc2chain_initialization(distances, seed)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function kmc2chain_initialization(distances_, seed_; name=nothing)
            local desc
            tf.with_op_name(name, "KMC2ChainInitialization") do 
                desc = tf.NodeDescription("KMC2ChainInitialization")
                distances_ = convert(Tensor{Float32}, distances_)
                seed_ = convert(Tensor{Int64}, seed_)
                tf.add_input(desc, distances_)
                tf.add_input(desc, seed_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function kmc2chain_initialization(distances_::tf.TensorHandle, seed_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("KMC2ChainInitialization")
        tf.add_input(desc, distances_)
        tf.add_input(desc, seed_)
        (tf.execute(desc))[1]
    end
end


"""
     map_unstage_no_key(indices; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function map_unstage_no_key(indices_; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "MapUnstageNoKey") do 
                desc = tf.NodeDescription("MapUnstageNoKey")
                indices_ = convert(Tensor{Int32}, indices_)
                tf.add_input(desc, indices_)
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function map_unstage_no_key(indices_::tf.TensorHandle; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("MapUnstageNoKey")
        tf.add_input(desc, indices_)
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        tf.execute(desc)
    end
end


"""
     scatter_nd_sub(ref, indices, updates; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_nd_sub(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ScatterNdSub") do 
                desc = tf.NodeDescription("ScatterNdSub")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (ref_, updates_) = tf.tf_promote(ref_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_nd_sub(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ScatterNdSub")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     resize_bilinear(images, size; align_corners=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resize_bilinear(images_, size_; name=nothing, align_corners=nothing)
            local desc
            tf.with_op_name(name, "ResizeBilinear") do 
                desc = tf.NodeDescription("ResizeBilinear")
                images_ = convert(Tensor{Any}, images_)
                size_ = convert(Tensor{Int32}, size_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                tf.add_input(desc, size_)
                if align_corners !== nothing
                    desc["align_corners"] = Base.Bool(align_corners)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resize_bilinear(images_::tf.TensorHandle, size_::tf.TensorHandle; name=nothing, align_corners=nothing)
        desc = tf.EagerOp("ResizeBilinear")
        tf.add_input(desc, images_)
        tf.add_input(desc, size_)
        if align_corners !== nothing
            desc["align_corners"] = Base.Bool(align_corners)
        end
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     ordered_map_peek(key, indices; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ordered_map_peek(key_, indices_; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "OrderedMapPeek") do 
                desc = tf.NodeDescription("OrderedMapPeek")
                key_ = convert(Tensor{Int64}, key_)
                indices_ = convert(Tensor{Int32}, indices_)
                tf.add_input(desc, key_)
                tf.add_input(desc, indices_)
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ordered_map_peek(key_::tf.TensorHandle, indices_::tf.TensorHandle; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("OrderedMapPeek")
        tf.add_input(desc, key_)
        tf.add_input(desc, indices_)
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array(size; dynamic_size=false, clear_after_read=true, tensor_array_name=, element_shape=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array(size_; name=nothing, dtype=nothing, dynamic_size=nothing, clear_after_read=nothing, tensor_array_name=nothing, element_shape=nothing)
            local desc
            tf.with_op_name(name, "TensorArray") do 
                desc = tf.NodeDescription("TensorArray")
                size_ = convert(Tensor{Int32}, size_)
                tf.add_input(desc, size_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if dynamic_size !== nothing
                    desc["dynamic_size"] = Base.Bool(dynamic_size)
                end
                if clear_after_read !== nothing
                    desc["clear_after_read"] = Base.Bool(clear_after_read)
                end
                if tensor_array_name !== nothing
                    desc["tensor_array_name"] = Base.String(tensor_array_name)
                end
                if element_shape !== nothing
                    desc["element_shape"] = Base.identity(element_shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array(size_::tf.TensorHandle; name=nothing, dtype=nothing, dynamic_size=nothing, clear_after_read=nothing, tensor_array_name=nothing, element_shape=nothing)
        desc = tf.EagerOp("TensorArray")
        tf.add_input(desc, size_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if dynamic_size !== nothing
            desc["dynamic_size"] = Base.Bool(dynamic_size)
        end
        if clear_after_read !== nothing
            desc["clear_after_read"] = Base.Bool(clear_after_read)
        end
        if tensor_array_name !== nothing
            desc["tensor_array_name"] = Base.String(tensor_array_name)
        end
        if element_shape !== nothing
            desc["element_shape"] = Base.identity(element_shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     inplace_sub(x, i, v)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function inplace_sub(x_, i_, v_; name=nothing)
            local desc
            tf.with_op_name(name, "InplaceSub") do 
                desc = tf.NodeDescription("InplaceSub")
                x_ = convert(Tensor{Any}, x_)
                i_ = convert(Tensor{Int32}, i_)
                v_ = convert(Tensor{Any}, v_)
                (x_, v_) = tf.tf_promote(x_, v_)
                tf.add_input(desc, x_)
                tf.add_input(desc, i_)
                tf.add_input(desc, v_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function inplace_sub(x_::tf.TensorHandle, i_::tf.TensorHandle, v_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("InplaceSub")
        tf.add_input(desc, x_)
        tf.add_input(desc, i_)
        tf.add_input(desc, v_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(v_)
        (tf.execute(desc))[1]
    end
end


"""
     pow(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function pow(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Pow") do 
                desc = tf.NodeDescription("Pow")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function pow(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Pow")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     stateful_standard_normal(resource, shape; dtype=Float32, shape_dtype=Int64)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stateful_standard_normal(resource_, shape_; name=nothing, dtype=nothing, shape_dtype=nothing)
            local desc
            tf.with_op_name(name, "StatefulStandardNormal") do 
                desc = tf.NodeDescription("StatefulStandardNormal")
                resource_ = convert(Tensor{Any}, resource_)
                shape_ = convert(Tensor{Int64}, shape_)
                (shape_,) = tf.tf_promote(shape_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, shape_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if shape_dtype !== nothing
                    desc["shape_dtype"] = Base.identity(shape_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stateful_standard_normal(resource_::tf.TensorHandle, shape_::tf.TensorHandle; name=nothing, dtype=nothing, shape_dtype=nothing)
        desc = tf.EagerOp("StatefulStandardNormal")
        tf.add_input(desc, resource_)
        tf.add_input(desc, shape_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if shape_dtype !== nothing
            desc["shape_dtype"] = Base.identity(shape_dtype)
        end
        desc["shape_dtype"] = tf.data_type(shape_)
        (tf.execute(desc))[1]
    end
end


"""
     ref_next_iteration(data)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function ref_next_iteration(data_; name=nothing)
            local desc
            tf.with_op_name(name, "RefNextIteration") do 
                desc = tf.NodeDescription("RefNextIteration")
                data_ = convert(Tensor{Any}, data_)
                (data_,) = tf.tf_promote(data_)
                tf.add_input(desc, data_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function ref_next_iteration(data_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RefNextIteration")
        tf.add_input(desc, data_)
        desc["T"] = tf.data_type(data_)
        (tf.execute(desc))[1]
    end
end


"""
     scalar_summary(tags, values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scalar_summary(tags_, values_; name=nothing)
            local desc
            tf.with_op_name(name, "ScalarSummary") do 
                desc = tf.NodeDescription("ScalarSummary")
                tags_ = convert(Tensor{String}, tags_)
                values_ = convert(Tensor{Any}, values_)
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, tags_)
                tf.add_input(desc, values_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scalar_summary(tags_::tf.TensorHandle, values_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ScalarSummary")
        tf.add_input(desc, tags_)
        tf.add_input(desc, values_)
        desc["T"] = tf.data_type(values_)
        (tf.execute(desc))[1]
    end
end


"""
     string_split_v2(input, sep; maxsplit=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function string_split_v2(input_, sep_; name=nothing, maxsplit=nothing)
            local desc
            tf.with_op_name(name, "StringSplitV2") do 
                desc = tf.NodeDescription("StringSplitV2")
                input_ = convert(Tensor{String}, input_)
                sep_ = convert(Tensor{String}, sep_)
                tf.add_input(desc, input_)
                tf.add_input(desc, sep_)
                if maxsplit !== nothing
                    desc["maxsplit"] = Base.Int(maxsplit)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function string_split_v2(input_::tf.TensorHandle, sep_::tf.TensorHandle; name=nothing, maxsplit=nothing)
        desc = tf.EagerOp("StringSplitV2")
        tf.add_input(desc, input_)
        tf.add_input(desc, sep_)
        if maxsplit !== nothing
            desc["maxsplit"] = Base.Int(maxsplit)
        end
        tf.execute(desc)
    end
end


"""
     bessel_i0e(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function bessel_i0e(x_; name=nothing)
            local desc
            tf.with_op_name(name, "BesselI0e") do 
                desc = tf.NodeDescription("BesselI0e")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function bessel_i0e(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BesselI0e")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     unique(x; out_idx=Int32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unique(x_; name=nothing, out_idx=nothing)
            local desc
            tf.with_op_name(name, "Unique") do 
                desc = tf.NodeDescription("Unique")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
                if out_idx !== nothing
                    desc["out_idx"] = Base.identity(out_idx)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function unique(x_::tf.TensorHandle; name=nothing, out_idx=nothing)
        desc = tf.EagerOp("Unique")
        tf.add_input(desc, x_)
        if out_idx !== nothing
            desc["out_idx"] = Base.identity(out_idx)
        end
        desc["T"] = tf.data_type(x_)
        tf.execute(desc)
    end
end


"""
     load_tpu_embedding_rms_prop_parameters(parameters, ms, mom; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function load_tpu_embedding_rms_prop_parameters(parameters_, ms_, mom_; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "LoadTPUEmbeddingRMSPropParameters") do 
                desc = tf.NodeDescription("LoadTPUEmbeddingRMSPropParameters")
                parameters_ = convert(Tensor{Float32}, parameters_)
                ms_ = convert(Tensor{Float32}, ms_)
                mom_ = convert(Tensor{Float32}, mom_)
                tf.add_input(desc, parameters_)
                tf.add_input(desc, ms_)
                tf.add_input(desc, mom_)
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function load_tpu_embedding_rms_prop_parameters(parameters_::tf.TensorHandle, ms_::tf.TensorHandle, mom_::tf.TensorHandle; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("LoadTPUEmbeddingRMSPropParameters")
        tf.add_input(desc, parameters_)
        tf.add_input(desc, ms_)
        tf.add_input(desc, mom_)
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        (tf.execute(desc))[1]
    end
end


"""
     whole_file_reader_v2(; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function whole_file_reader_v2(; name=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "WholeFileReaderV2") do 
                desc = tf.NodeDescription("WholeFileReaderV2")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function whole_file_reader_v2(; name=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("WholeFileReaderV2")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     eager_py_func(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function eager_py_func(input_; name=nothing, token=nothing, Tin=nothing, Tout=nothing)
            local desc
            tf.with_op_name(name, "EagerPyFunc") do 
                desc = tf.NodeDescription("EagerPyFunc")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                tf.add_input(desc, input_)
                if token !== nothing
                    desc["token"] = Base.String(token)
                end
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function eager_py_func(input_::tf.TensorHandle; name=nothing, token=nothing, Tin=nothing, Tout=nothing)
        desc = tf.EagerOp("EagerPyFunc")
        tf.add_input(desc, input_)
        if token !== nothing
            desc["token"] = Base.String(token)
        end
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        (tf.execute(desc))[1]
    end
end


"""
     next_iteration(data)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function next_iteration(data_; name=nothing)
            local desc
            tf.with_op_name(name, "NextIteration") do 
                desc = tf.NodeDescription("NextIteration")
                data_ = convert(Tensor{Any}, data_)
                (data_,) = tf.tf_promote(data_)
                tf.add_input(desc, data_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function next_iteration(data_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("NextIteration")
        tf.add_input(desc, data_)
        desc["T"] = tf.data_type(data_)
        (tf.execute(desc))[1]
    end
end


"""
     case(branch_index, input; output_shapes=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function case(branch_index_, input_; name=nothing, Tin=nothing, Tout=nothing, branches=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "Case") do 
                desc = tf.NodeDescription("Case")
                branch_index_ = convert(Tensor{Int32}, branch_index_)
                input_ = [convert(Tensor{Any}, x) for x = input_]
                tf.add_input(desc, branch_index_)
                tf.add_input(desc, input_)
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
                if branches !== nothing
                    desc["branches"] = map(Base.identity, branches)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function case(branch_index_::tf.TensorHandle, input_::tf.TensorHandle; name=nothing, Tin=nothing, Tout=nothing, branches=nothing, output_shapes=nothing)
        desc = tf.EagerOp("Case")
        tf.add_input(desc, branch_index_)
        tf.add_input(desc, input_)
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        if branches !== nothing
            desc["branches"] = map(Base.identity, branches)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_scatter_sub(tensor, indices, updates)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_scatter_sub(tensor_, indices_, updates_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorScatterSub") do 
                desc = tf.NodeDescription("TensorScatterSub")
                tensor_ = convert(Tensor{Any}, tensor_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (tensor_, updates_) = tf.tf_promote(tensor_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_scatter_sub(tensor_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorScatterSub")
        tf.add_input(desc, tensor_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        desc["T"] = tf.data_type(tensor_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     scatter_max(ref, indices, updates; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_max(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ScatterMax") do 
                desc = tf.NodeDescription("ScatterMax")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (ref_, updates_) = tf.tf_promote(ref_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_max(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ScatterMax")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     sqrt(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sqrt(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Sqrt") do 
                desc = tf.NodeDescription("Sqrt")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sqrt(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Sqrt")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     accumulator_take_gradient(handle, num_required)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function accumulator_take_gradient(handle_, num_required_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "AccumulatorTakeGradient") do 
                desc = tf.NodeDescription("AccumulatorTakeGradient")
                handle_ = convert(Tensor{String}, handle_)
                num_required_ = convert(Tensor{Int32}, num_required_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, num_required_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function accumulator_take_gradient(handle_::tf.TensorHandle, num_required_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("AccumulatorTakeGradient")
        tf.add_input(desc, handle_)
        tf.add_input(desc, num_required_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     _mkl_add(x, y, mkl_x, mkl_y)

Returns x + y element-wise.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _mkl_add(x_, y_, mkl_x_, mkl_y_; name=nothing)
            local desc
            tf.with_op_name(name, "_MklAdd") do 
                desc = tf.NodeDescription("_MklAdd")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                mkl_x_ = convert(Tensor{UInt8}, mkl_x_)
                mkl_y_ = convert(Tensor{UInt8}, mkl_y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
                tf.add_input(desc, mkl_x_)
                tf.add_input(desc, mkl_y_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function _mkl_add(x_::tf.TensorHandle, y_::tf.TensorHandle, mkl_x_::tf.TensorHandle, mkl_y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("_MklAdd")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        tf.add_input(desc, mkl_x_)
        tf.add_input(desc, mkl_y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        tf.execute(desc)
    end
end


"""
     reciprocal(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reciprocal(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Reciprocal") do 
                desc = tf.NodeDescription("Reciprocal")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reciprocal(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Reciprocal")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     outfeed_enqueue_tuple(inputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function outfeed_enqueue_tuple(inputs_; name=nothing, dtypes=nothing)
            local desc
            tf.with_op_name(name, "OutfeedEnqueueTuple") do 
                desc = tf.NodeDescription("OutfeedEnqueueTuple")
                inputs_ = [convert(Tensor{Any}, x) for x = inputs_]
                tf.add_input(desc, inputs_)
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function outfeed_enqueue_tuple(inputs_::tf.TensorHandle; name=nothing, dtypes=nothing)
        desc = tf.EagerOp("OutfeedEnqueueTuple")
        tf.add_input(desc, inputs_)
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     string_strip(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function string_strip(input_; name=nothing)
            local desc
            tf.with_op_name(name, "StringStrip") do 
                desc = tf.NodeDescription("StringStrip")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function string_strip(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("StringStrip")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     fake_quant_with_min_max_vars_per_channel(inputs, min, max; num_bits=8, narrow_range=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fake_quant_with_min_max_vars_per_channel(inputs_, min_, max_; name=nothing, num_bits=nothing, narrow_range=nothing)
            local desc
            tf.with_op_name(name, "FakeQuantWithMinMaxVarsPerChannel") do 
                desc = tf.NodeDescription("FakeQuantWithMinMaxVarsPerChannel")
                inputs_ = convert(Tensor{Float32}, inputs_)
                min_ = convert(Tensor{Float32}, min_)
                max_ = convert(Tensor{Float32}, max_)
                tf.add_input(desc, inputs_)
                tf.add_input(desc, min_)
                tf.add_input(desc, max_)
                if num_bits !== nothing
                    desc["num_bits"] = Base.Int(num_bits)
                end
                if narrow_range !== nothing
                    desc["narrow_range"] = Base.Bool(narrow_range)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fake_quant_with_min_max_vars_per_channel(inputs_::tf.TensorHandle, min_::tf.TensorHandle, max_::tf.TensorHandle; name=nothing, num_bits=nothing, narrow_range=nothing)
        desc = tf.EagerOp("FakeQuantWithMinMaxVarsPerChannel")
        tf.add_input(desc, inputs_)
        tf.add_input(desc, min_)
        tf.add_input(desc, max_)
        if num_bits !== nothing
            desc["num_bits"] = Base.Int(num_bits)
        end
        if narrow_range !== nothing
            desc["narrow_range"] = Base.Bool(narrow_range)
        end
        (tf.execute(desc))[1]
    end
end


"""
     barrier_ready_size(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function barrier_ready_size(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "BarrierReadySize") do 
                desc = tf.NodeDescription("BarrierReadySize")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function barrier_ready_size(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BarrierReadySize")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     string_to_hash_bucket(string_tensor)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function string_to_hash_bucket(string_tensor_; name=nothing, num_buckets=nothing)
            local desc
            tf.with_op_name(name, "StringToHashBucket") do 
                desc = tf.NodeDescription("StringToHashBucket")
                string_tensor_ = convert(Tensor{String}, string_tensor_)
                tf.add_input(desc, string_tensor_)
                if num_buckets !== nothing
                    desc["num_buckets"] = Base.Int(num_buckets)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function string_to_hash_bucket(string_tensor_::tf.TensorHandle; name=nothing, num_buckets=nothing)
        desc = tf.EagerOp("StringToHashBucket")
        tf.add_input(desc, string_tensor_)
        if num_buckets !== nothing
            desc["num_buckets"] = Base.Int(num_buckets)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_concat(handle, flow_in; element_shape_except0=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_concat(handle_, flow_in_; name=nothing, dtype=nothing, element_shape_except0=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayConcat") do 
                desc = tf.NodeDescription("TensorArrayConcat")
                handle_ = convert(Tensor{String}, handle_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, flow_in_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if element_shape_except0 !== nothing
                    desc["element_shape_except0"] = Base.identity(element_shape_except0)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function tensor_array_concat(handle_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, dtype=nothing, element_shape_except0=nothing)
        desc = tf.EagerOp("TensorArrayConcat")
        tf.add_input(desc, handle_)
        tf.add_input(desc, flow_in_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if element_shape_except0 !== nothing
            desc["element_shape_except0"] = Base.identity(element_shape_except0)
        end
        tf.execute(desc)
    end
end


"""
     sharded_filename(basename, shard, num_shards)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sharded_filename(basename_, shard_, num_shards_; name=nothing)
            local desc
            tf.with_op_name(name, "ShardedFilename") do 
                desc = tf.NodeDescription("ShardedFilename")
                basename_ = convert(Tensor{String}, basename_)
                shard_ = convert(Tensor{Int32}, shard_)
                num_shards_ = convert(Tensor{Int32}, num_shards_)
                tf.add_input(desc, basename_)
                tf.add_input(desc, shard_)
                tf.add_input(desc, num_shards_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sharded_filename(basename_::tf.TensorHandle, shard_::tf.TensorHandle, num_shards_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ShardedFilename")
        tf.add_input(desc, basename_)
        tf.add_input(desc, shard_)
        tf.add_input(desc, num_shards_)
        (tf.execute(desc))[1]
    end
end


"""
     py_func(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function py_func(input_; name=nothing, token=nothing, Tin=nothing, Tout=nothing)
            local desc
            tf.with_op_name(name, "PyFunc") do 
                desc = tf.NodeDescription("PyFunc")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                tf.add_input(desc, input_)
                if token !== nothing
                    desc["token"] = Base.String(token)
                end
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function py_func(input_::tf.TensorHandle; name=nothing, token=nothing, Tin=nothing, Tout=nothing)
        desc = tf.EagerOp("PyFunc")
        tf.add_input(desc, input_)
        if token !== nothing
            desc["token"] = Base.String(token)
        end
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        (tf.execute(desc))[1]
    end
end


"""
     unsorted_segment_prod(data, segment_ids, num_segments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unsorted_segment_prod(data_, segment_ids_, num_segments_; name=nothing)
            local desc
            tf.with_op_name(name, "UnsortedSegmentProd") do 
                desc = tf.NodeDescription("UnsortedSegmentProd")
                data_ = convert(Tensor{Any}, data_)
                segment_ids_ = convert(Tensor{Any}, segment_ids_)
                segment_ids_ = segment_ids_ - convert(tf.Tensor{eltype(segment_ids_)}, 1)
                num_segments_ = convert(Tensor{Int32}, num_segments_)
                (num_segments_,) = tf.tf_promote(num_segments_)
                (data_,) = tf.tf_promote(data_)
                (segment_ids_,) = tf.tf_promote(segment_ids_)
                tf.add_input(desc, data_)
                tf.add_input(desc, segment_ids_)
                tf.add_input(desc, num_segments_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unsorted_segment_prod(data_::tf.TensorHandle, segment_ids_::tf.TensorHandle, num_segments_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("UnsortedSegmentProd")
        tf.add_input(desc, data_)
        tf.add_input(desc, segment_ids_)
        tf.add_input(desc, num_segments_)
        desc["T"] = tf.data_type(data_)
        desc["Tindices"] = tf.data_type(segment_ids_)
        desc["Tnumsegments"] = tf.data_type(num_segments_)
        (tf.execute(desc))[1]
    end
end


"""
     count_up_to(ref)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function count_up_to(ref_; name=nothing, limit=nothing)
            local desc
            tf.with_op_name(name, "CountUpTo") do 
                desc = tf.NodeDescription("CountUpTo")
                ref_ = convert(Tensor{Any}, ref_)
                (ref_,) = tf.tf_promote(ref_)
                tf.add_input(desc, ref_)
                if limit !== nothing
                    desc["limit"] = Base.Int(limit)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function count_up_to(ref_::tf.TensorHandle; name=nothing, limit=nothing)
        desc = tf.EagerOp("CountUpTo")
        tf.add_input(desc, ref_)
        if limit !== nothing
            desc["limit"] = Base.Int(limit)
        end
        desc["T"] = tf.data_type(ref_)
        (tf.execute(desc))[1]
    end
end


"""
     random_gamma(shape, alpha; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function random_gamma(shape_, alpha_; name=nothing, seed=nothing, seed2=nothing, S=nothing)
            local desc
            tf.with_op_name(name, "RandomGamma") do 
                desc = tf.NodeDescription("RandomGamma")
                shape_ = convert(Tensor{Any}, shape_)
                alpha_ = convert(Tensor{Any}, alpha_)
                (shape_,) = tf.tf_promote(shape_)
                (alpha_,) = tf.tf_promote(alpha_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, alpha_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if S !== nothing
                    desc["S"] = Base.identity(S)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function random_gamma(shape_::tf.TensorHandle, alpha_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing, S=nothing)
        desc = tf.EagerOp("RandomGamma")
        tf.add_input(desc, shape_)
        tf.add_input(desc, alpha_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if S !== nothing
            desc["S"] = Base.identity(S)
        end
        desc["S"] = tf.data_type(shape_)
        desc["T"] = tf.data_type(alpha_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_grad(handle, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_grad(handle_, flow_in_; name=nothing, source=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayGrad") do 
                desc = tf.NodeDescription("TensorArrayGrad")
                handle_ = convert(Tensor{String}, handle_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, flow_in_)
                if source !== nothing
                    desc["source"] = Base.String(source)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_grad(handle_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, source=nothing)
        desc = tf.EagerOp("TensorArrayGrad")
        tf.add_input(desc, handle_)
        tf.add_input(desc, flow_in_)
        if source !== nothing
            desc["source"] = Base.String(source)
        end
        (tf.execute(desc))[1]
    end
end


"""
     dilation2d(input, filter)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function dilation2d(input_, filter_; name=nothing, strides=nothing, rates=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "Dilation2D") do 
                desc = tf.NodeDescription("Dilation2D")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                (input_, filter_) = tf.tf_promote(input_, filter_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if rates !== nothing
                    desc["rates"] = map(Base.identity, rates)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function dilation2d(input_::tf.TensorHandle, filter_::tf.TensorHandle; name=nothing, strides=nothing, rates=nothing, padding=nothing)
        desc = tf.EagerOp("Dilation2D")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if rates !== nothing
            desc["rates"] = map(Base.identity, rates)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(filter_)
        (tf.execute(desc))[1]
    end
end


"""
     unbatch(batched_tensor, batch_index, id; container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unbatch(batched_tensor_, batch_index_, id_; name=nothing, timeout_micros=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "Unbatch") do 
                desc = tf.NodeDescription("Unbatch")
                batched_tensor_ = convert(Tensor{Any}, batched_tensor_)
                batch_index_ = convert(Tensor{Int64}, batch_index_)
                id_ = convert(Tensor{Int64}, id_)
                (batched_tensor_,) = tf.tf_promote(batched_tensor_)
                tf.add_input(desc, batched_tensor_)
                tf.add_input(desc, batch_index_)
                tf.add_input(desc, id_)
                if timeout_micros !== nothing
                    desc["timeout_micros"] = Base.Int(timeout_micros)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unbatch(batched_tensor_::tf.TensorHandle, batch_index_::tf.TensorHandle, id_::tf.TensorHandle; name=nothing, timeout_micros=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("Unbatch")
        tf.add_input(desc, batched_tensor_)
        tf.add_input(desc, batch_index_)
        tf.add_input(desc, id_)
        if timeout_micros !== nothing
            desc["timeout_micros"] = Base.Int(timeout_micros)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        desc["T"] = tf.data_type(batched_tensor_)
        (tf.execute(desc))[1]
    end
end


"""
     get_session_handle(value)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function get_session_handle(value_; name=nothing)
            local desc
            tf.with_op_name(name, "GetSessionHandle") do 
                desc = tf.NodeDescription("GetSessionHandle")
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, value_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function get_session_handle(value_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("GetSessionHandle")
        tf.add_input(desc, value_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_adam_parameters(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_adam_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingADAMParameters") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingADAMParameters")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_adam_parameters(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingADAMParameters")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     mutable_hash_table_of_tensors_v2(; container=, shared_name=, use_node_name_sharing=false, value_shape=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mutable_hash_table_of_tensors_v2(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing, value_shape=nothing)
            local desc
            tf.with_op_name(name, "MutableHashTableOfTensorsV2") do 
                desc = tf.NodeDescription("MutableHashTableOfTensorsV2")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if use_node_name_sharing !== nothing
                    desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
                end
                if key_dtype !== nothing
                    desc["key_dtype"] = Base.identity(key_dtype)
                end
                if value_dtype !== nothing
                    desc["value_dtype"] = Base.identity(value_dtype)
                end
                if value_shape !== nothing
                    desc["value_shape"] = Base.identity(value_shape)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mutable_hash_table_of_tensors_v2(; name=nothing, container=nothing, shared_name=nothing, use_node_name_sharing=nothing, key_dtype=nothing, value_dtype=nothing, value_shape=nothing)
        desc = tf.EagerOp("MutableHashTableOfTensorsV2")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if use_node_name_sharing !== nothing
            desc["use_node_name_sharing"] = Base.Bool(use_node_name_sharing)
        end
        if key_dtype !== nothing
            desc["key_dtype"] = Base.identity(key_dtype)
        end
        if value_dtype !== nothing
            desc["value_dtype"] = Base.identity(value_dtype)
        end
        if value_shape !== nothing
            desc["value_shape"] = Base.identity(value_shape)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_apply_ftrl(var, accum, linear, grad, indices, lr, l1, l2, lr_power; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_apply_ftrl(var_, accum_, linear_, grad_, indices_, lr_, l1_, l2_, lr_power_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "SparseApplyFtrl") do 
                desc = tf.NodeDescription("SparseApplyFtrl")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                linear_ = convert(Tensor{Any}, linear_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                lr_ = convert(Tensor{Any}, lr_)
                l1_ = convert(Tensor{Any}, l1_)
                l2_ = convert(Tensor{Any}, l2_)
                lr_power_ = convert(Tensor{Any}, lr_power_)
                (var_, accum_, linear_, grad_, lr_, l1_, l2_, lr_power_) = tf.tf_promote(var_, accum_, linear_, grad_, lr_, l1_, l2_, lr_power_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, linear_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, l1_)
                tf.add_input(desc, l2_)
                tf.add_input(desc, lr_power_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_apply_ftrl(var_::tf.TensorHandle, accum_::tf.TensorHandle, linear_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle, lr_::tf.TensorHandle, l1_::tf.TensorHandle, l2_::tf.TensorHandle, lr_power_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("SparseApplyFtrl")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, linear_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, l1_)
        tf.add_input(desc, l2_)
        tf.add_input(desc, lr_power_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(var_)
        desc["T"] = tf.data_type(accum_)
        desc["T"] = tf.data_type(linear_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(l1_)
        desc["T"] = tf.data_type(l2_)
        desc["T"] = tf.data_type(lr_power_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_dataset_v2(input_dataset, batch_size, drop_remainder)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_dataset_v2(input_dataset_, batch_size_, drop_remainder_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "BatchDatasetV2") do 
                desc = tf.NodeDescription("BatchDatasetV2")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                batch_size_ = convert(Tensor{Int64}, batch_size_)
                drop_remainder_ = convert(Tensor{Bool}, drop_remainder_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, batch_size_)
                tf.add_input(desc, drop_remainder_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_dataset_v2(input_dataset_::tf.TensorHandle, batch_size_::tf.TensorHandle, drop_remainder_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("BatchDatasetV2")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, batch_size_)
        tf.add_input(desc, drop_remainder_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_sparse_minimum(a_indices, a_values, a_shape, b_indices, b_values, b_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_sparse_minimum(a_indices_, a_values_, a_shape_, b_indices_, b_values_, b_shape_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSparseMinimum") do 
                desc = tf.NodeDescription("SparseSparseMinimum")
                a_indices_ = convert(Tensor{Int64}, a_indices_)
                a_values_ = convert(Tensor{Any}, a_values_)
                a_shape_ = convert(Tensor{Int64}, a_shape_)
                b_indices_ = convert(Tensor{Int64}, b_indices_)
                b_values_ = convert(Tensor{Any}, b_values_)
                b_shape_ = convert(Tensor{Int64}, b_shape_)
                (a_values_, b_values_) = tf.tf_promote(a_values_, b_values_)
                tf.add_input(desc, a_indices_)
                tf.add_input(desc, a_values_)
                tf.add_input(desc, a_shape_)
                tf.add_input(desc, b_indices_)
                tf.add_input(desc, b_values_)
                tf.add_input(desc, b_shape_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_sparse_minimum(a_indices_::tf.TensorHandle, a_values_::tf.TensorHandle, a_shape_::tf.TensorHandle, b_indices_::tf.TensorHandle, b_values_::tf.TensorHandle, b_shape_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSparseMinimum")
        tf.add_input(desc, a_indices_)
        tf.add_input(desc, a_values_)
        tf.add_input(desc, a_shape_)
        tf.add_input(desc, b_indices_)
        tf.add_input(desc, b_values_)
        tf.add_input(desc, b_shape_)
        desc["T"] = tf.data_type(a_values_)
        desc["T"] = tf.data_type(b_values_)
        tf.execute(desc)
    end
end


"""
     reverse_v2(tensor, axis)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reverse_v2(tensor_, axis_; name=nothing)
            local desc
            tf.with_op_name(name, "ReverseV2") do 
                desc = tf.NodeDescription("ReverseV2")
                tensor_ = convert(Tensor{Any}, tensor_)
                axis_ = convert(Tensor{Int32}, axis_)
                axis_ = axis_ - convert(tf.Tensor{eltype(axis_)}, 1)
                (tensor_,) = tf.tf_promote(tensor_)
                (axis_,) = tf.tf_promote(axis_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, axis_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function reverse_v2(tensor_::tf.TensorHandle, axis_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReverseV2")
        tf.add_input(desc, tensor_)
        tf.add_input(desc, axis_)
        desc["T"] = tf.data_type(tensor_)
        desc["Tidx"] = tf.data_type(axis_)
        (tf.execute(desc))[1]
    end
end


"""
     strided_slice(input, begin, end, strides; begin_mask=0, end_mask=0, ellipsis_mask=0, new_axis_mask=0, shrink_axis_mask=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function strided_slice(input_, begin_, end_, strides_; name=nothing, Index=nothing, begin_mask=nothing, end_mask=nothing, ellipsis_mask=nothing, new_axis_mask=nothing, shrink_axis_mask=nothing)
            local desc
            tf.with_op_name(name, "StridedSlice") do 
                desc = tf.NodeDescription("StridedSlice")
                input_ = convert(Tensor{Any}, input_)
                begin_ = convert(Tensor{Any}, begin_)
                begin_ = begin_ - convert(tf.Tensor{eltype(begin_)}, 1)
                end_ = convert(Tensor{Any}, end_)
                end_ = end_ - convert(tf.Tensor{eltype(end_)}, 1)
                strides_ = convert(Tensor{Any}, strides_)
                strides_ = strides_ - convert(tf.Tensor{eltype(strides_)}, 1)
                (input_,) = tf.tf_promote(input_)
                (begin_, end_, strides_) = tf.tf_promote(begin_, end_, strides_)
                tf.add_input(desc, input_)
                tf.add_input(desc, begin_)
                tf.add_input(desc, end_)
                tf.add_input(desc, strides_)
                if Index !== nothing
                    desc["Index"] = Base.identity(Index)
                end
                if begin_mask !== nothing
                    begin_mask = Base.Int(begin_mask) - 1
                end
                if begin_mask !== nothing
                    desc["begin_mask"] = Base.Int(begin_mask)
                end
                if end_mask !== nothing
                    end_mask = Base.Int(end_mask) - 1
                end
                if end_mask !== nothing
                    desc["end_mask"] = Base.Int(end_mask)
                end
                if ellipsis_mask !== nothing
                    ellipsis_mask = Base.Int(ellipsis_mask) - 1
                end
                if ellipsis_mask !== nothing
                    desc["ellipsis_mask"] = Base.Int(ellipsis_mask)
                end
                if new_axis_mask !== nothing
                    new_axis_mask = Base.Int(new_axis_mask) - 1
                end
                if new_axis_mask !== nothing
                    desc["new_axis_mask"] = Base.Int(new_axis_mask)
                end
                if shrink_axis_mask !== nothing
                    shrink_axis_mask = Base.Int(shrink_axis_mask) - 1
                end
                if shrink_axis_mask !== nothing
                    desc["shrink_axis_mask"] = Base.Int(shrink_axis_mask)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function strided_slice(input_::tf.TensorHandle, begin_::tf.TensorHandle, end_::tf.TensorHandle, strides_::tf.TensorHandle; name=nothing, Index=nothing, begin_mask=nothing, end_mask=nothing, ellipsis_mask=nothing, new_axis_mask=nothing, shrink_axis_mask=nothing)
        desc = tf.EagerOp("StridedSlice")
        tf.add_input(desc, input_)
        tf.add_input(desc, begin_)
        tf.add_input(desc, end_)
        tf.add_input(desc, strides_)
        if Index !== nothing
            desc["Index"] = Base.identity(Index)
        end
        if begin_mask !== nothing
            begin_mask = Base.Int(begin_mask) - 1
        end
        if begin_mask !== nothing
            desc["begin_mask"] = Base.Int(begin_mask)
        end
        if end_mask !== nothing
            end_mask = Base.Int(end_mask) - 1
        end
        if end_mask !== nothing
            desc["end_mask"] = Base.Int(end_mask)
        end
        if ellipsis_mask !== nothing
            ellipsis_mask = Base.Int(ellipsis_mask) - 1
        end
        if ellipsis_mask !== nothing
            desc["ellipsis_mask"] = Base.Int(ellipsis_mask)
        end
        if new_axis_mask !== nothing
            new_axis_mask = Base.Int(new_axis_mask) - 1
        end
        if new_axis_mask !== nothing
            desc["new_axis_mask"] = Base.Int(new_axis_mask)
        end
        if shrink_axis_mask !== nothing
            shrink_axis_mask = Base.Int(shrink_axis_mask) - 1
        end
        if shrink_axis_mask !== nothing
            desc["shrink_axis_mask"] = Base.Int(shrink_axis_mask)
        end
        desc["T"] = tf.data_type(input_)
        desc["Index"] = tf.data_type(begin_)
        desc["Index"] = tf.data_type(end_)
        desc["Index"] = tf.data_type(strides_)
        (tf.execute(desc))[1]
    end
end


"""
     matching_files(pattern)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matching_files(pattern_; name=nothing)
            local desc
            tf.with_op_name(name, "MatchingFiles") do 
                desc = tf.NodeDescription("MatchingFiles")
                pattern_ = convert(Tensor{String}, pattern_)
                tf.add_input(desc, pattern_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matching_files(pattern_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("MatchingFiles")
        tf.add_input(desc, pattern_)
        (tf.execute(desc))[1]
    end
end


"""
     encode_base64(input; pad=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function encode_base64(input_; name=nothing, pad=nothing)
            local desc
            tf.with_op_name(name, "EncodeBase64") do 
                desc = tf.NodeDescription("EncodeBase64")
                input_ = convert(Tensor{String}, input_)
                tf.add_input(desc, input_)
                if pad !== nothing
                    desc["pad"] = Base.Bool(pad)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function encode_base64(input_::tf.TensorHandle; name=nothing, pad=nothing)
        desc = tf.EagerOp("EncodeBase64")
        tf.add_input(desc, input_)
        if pad !== nothing
            desc["pad"] = Base.Bool(pad)
        end
        (tf.execute(desc))[1]
    end
end


"""
     iterator_get_next_as_optional(iterator)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function iterator_get_next_as_optional(iterator_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "IteratorGetNextAsOptional") do 
                desc = tf.NodeDescription("IteratorGetNextAsOptional")
                iterator_ = convert(Tensor{Any}, iterator_)
                tf.add_input(desc, iterator_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function iterator_get_next_as_optional(iterator_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("IteratorGetNextAsOptional")
        tf.add_input(desc, iterator_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     padding_fifo_queue(; shapes=Int64[], capacity=-1, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function padding_fifo_queue(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "PaddingFIFOQueue") do 
                desc = tf.NodeDescription("PaddingFIFOQueue")
                if component_types !== nothing
                    desc["component_types"] = map(Base.identity, component_types)
                end
                if shapes !== nothing
                    desc["shapes"] = map(Base.identity, shapes)
                end
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function padding_fifo_queue(; name=nothing, component_types=nothing, shapes=nothing, capacity=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("PaddingFIFOQueue")
        if component_types !== nothing
            desc["component_types"] = map(Base.identity, component_types)
        end
        if shapes !== nothing
            desc["shapes"] = map(Base.identity, shapes)
        end
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     iterator_to_string_handle(resource_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function iterator_to_string_handle(resource_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "IteratorToStringHandle") do 
                desc = tf.NodeDescription("IteratorToStringHandle")
                resource_handle_ = convert(Tensor{Any}, resource_handle_)
                tf.add_input(desc, resource_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function iterator_to_string_handle(resource_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IteratorToStringHandle")
        tf.add_input(desc, resource_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     max_pool_grad_grad_with_argmax(input, grad, argmax)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function max_pool_grad_grad_with_argmax(input_, grad_, argmax_; name=nothing, ksize=nothing, strides=nothing, padding=nothing)
            local desc
            tf.with_op_name(name, "MaxPoolGradGradWithArgmax") do 
                desc = tf.NodeDescription("MaxPoolGradGradWithArgmax")
                input_ = convert(Tensor{Any}, input_)
                grad_ = convert(Tensor{Any}, grad_)
                argmax_ = convert(Tensor{Any}, argmax_)
                (argmax_,) = tf.tf_promote(argmax_)
                (input_, grad_) = tf.tf_promote(input_, grad_)
                tf.add_input(desc, input_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, argmax_)
                if ksize !== nothing
                    desc["ksize"] = map(Base.identity, ksize)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function max_pool_grad_grad_with_argmax(input_::tf.TensorHandle, grad_::tf.TensorHandle, argmax_::tf.TensorHandle; name=nothing, ksize=nothing, strides=nothing, padding=nothing)
        desc = tf.EagerOp("MaxPoolGradGradWithArgmax")
        tf.add_input(desc, input_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, argmax_)
        if ksize !== nothing
            desc["ksize"] = map(Base.identity, ksize)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(grad_)
        desc["Targmax"] = tf.data_type(argmax_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_gather(input_handle, indices, element_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_gather(input_handle_, indices_, element_shape_; name=nothing, element_dtype=nothing)
            local desc
            tf.with_op_name(name, "TensorListGather") do 
                desc = tf.NodeDescription("TensorListGather")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                indices_ = convert(Tensor{Int32}, indices_)
                element_shape_ = convert(Tensor{Int32}, element_shape_)
                tf.add_input(desc, input_handle_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, element_shape_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_gather(input_handle_::tf.TensorHandle, indices_::tf.TensorHandle, element_shape_::tf.TensorHandle; name=nothing, element_dtype=nothing)
        desc = tf.EagerOp("TensorListGather")
        tf.add_input(desc, input_handle_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, element_shape_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     multinomial(logits, num_samples; seed=0, seed2=0, output_dtype=Int64)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function multinomial(logits_, num_samples_; name=nothing, seed=nothing, seed2=nothing, output_dtype=nothing)
            local desc
            tf.with_op_name(name, "Multinomial") do 
                desc = tf.NodeDescription("Multinomial")
                logits_ = convert(Tensor{Any}, logits_)
                num_samples_ = convert(Tensor{Int32}, num_samples_)
                (logits_,) = tf.tf_promote(logits_)
                tf.add_input(desc, logits_)
                tf.add_input(desc, num_samples_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if output_dtype !== nothing
                    desc["output_dtype"] = Base.identity(output_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function multinomial(logits_::tf.TensorHandle, num_samples_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing, output_dtype=nothing)
        desc = tf.EagerOp("Multinomial")
        tf.add_input(desc, logits_)
        tf.add_input(desc, num_samples_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if output_dtype !== nothing
            desc["output_dtype"] = Base.identity(output_dtype)
        end
        desc["T"] = tf.data_type(logits_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_read(handle, index, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_read(handle_, index_, flow_in_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayRead") do 
                desc = tf.NodeDescription("TensorArrayRead")
                handle_ = convert(Tensor{String}, handle_)
                index_ = convert(Tensor{Int32}, index_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, index_)
                tf.add_input(desc, flow_in_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_read(handle_::tf.TensorHandle, index_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("TensorArrayRead")
        tf.add_input(desc, handle_)
        tf.add_input(desc, index_)
        tf.add_input(desc, flow_in_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     experimental_indexed_dataset_get(materialized, index)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_indexed_dataset_get(materialized_, index_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalIndexedDatasetGet") do 
                desc = tf.NodeDescription("ExperimentalIndexedDatasetGet")
                materialized_ = convert(Tensor{Any}, materialized_)
                index_ = convert(Tensor{Any}, index_)
                tf.add_input(desc, materialized_)
                tf.add_input(desc, index_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_indexed_dataset_get(materialized_::tf.TensorHandle, index_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalIndexedDatasetGet")
        tf.add_input(desc, materialized_)
        tf.add_input(desc, index_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tpu_partitioned_call(args, device_ordinal)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tpu_partitioned_call(args_, device_ordinal_; name=nothing, Tin=nothing, Tout=nothing, f=nothing)
            local desc
            tf.with_op_name(name, "TPUPartitionedCall") do 
                desc = tf.NodeDescription("TPUPartitionedCall")
                args_ = [convert(Tensor{Any}, x) for x = args_]
                device_ordinal_ = convert(Tensor{Int32}, device_ordinal_)
                tf.add_input(desc, args_)
                tf.add_input(desc, device_ordinal_)
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tpu_partitioned_call(args_::tf.TensorHandle, device_ordinal_::tf.TensorHandle; name=nothing, Tin=nothing, Tout=nothing, f=nothing)
        desc = tf.EagerOp("TPUPartitionedCall")
        tf.add_input(desc, args_)
        tf.add_input(desc, device_ordinal_)
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        (tf.execute(desc))[1]
    end
end


"""
     quantized_conv2d_and_relu_and_requantize(input, filter, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output; out_type=Float32, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_conv2d_and_relu_and_requantize(input_, filter_, min_input_, max_input_, min_filter_, max_filter_, min_freezed_output_, max_freezed_output_; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConv2DAndReluAndRequantize") do 
                desc = tf.NodeDescription("QuantizedConv2DAndReluAndRequantize")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_filter_ = convert(Tensor{Float32}, min_filter_)
                max_filter_ = convert(Tensor{Float32}, max_filter_)
                min_freezed_output_ = convert(Tensor{Float32}, min_freezed_output_)
                max_freezed_output_ = convert(Tensor{Float32}, max_freezed_output_)
                (filter_,) = tf.tf_promote(filter_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_filter_)
                tf.add_input(desc, max_filter_)
                tf.add_input(desc, min_freezed_output_)
                tf.add_input(desc, max_freezed_output_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_conv2d_and_relu_and_requantize(input_::tf.TensorHandle, filter_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_filter_::tf.TensorHandle, max_filter_::tf.TensorHandle, min_freezed_output_::tf.TensorHandle, max_freezed_output_::tf.TensorHandle; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("QuantizedConv2DAndReluAndRequantize")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_filter_)
        tf.add_input(desc, max_filter_)
        tf.add_input(desc, min_freezed_output_)
        tf.add_input(desc, max_freezed_output_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tinput"] = tf.data_type(input_)
        desc["Tfilter"] = tf.data_type(filter_)
        tf.execute(desc)
    end
end


"""
     iterator_from_string_handle_v2(string_handle; output_types=Int64[], output_shapes=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function iterator_from_string_handle_v2(string_handle_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "IteratorFromStringHandleV2") do 
                desc = tf.NodeDescription("IteratorFromStringHandleV2")
                string_handle_ = convert(Tensor{String}, string_handle_)
                tf.add_input(desc, string_handle_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function iterator_from_string_handle_v2(string_handle_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("IteratorFromStringHandleV2")
        tf.add_input(desc, string_handle_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     bitwise_or(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function bitwise_or(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "BitwiseOr") do 
                desc = tf.NodeDescription("BitwiseOr")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function bitwise_or(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BitwiseOr")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     unsorted_segment_max(data, segment_ids, num_segments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unsorted_segment_max(data_, segment_ids_, num_segments_; name=nothing)
            local desc
            tf.with_op_name(name, "UnsortedSegmentMax") do 
                desc = tf.NodeDescription("UnsortedSegmentMax")
                data_ = convert(Tensor{Any}, data_)
                segment_ids_ = convert(Tensor{Any}, segment_ids_)
                segment_ids_ = segment_ids_ - convert(tf.Tensor{eltype(segment_ids_)}, 1)
                num_segments_ = convert(Tensor{Int32}, num_segments_)
                (num_segments_,) = tf.tf_promote(num_segments_)
                (data_,) = tf.tf_promote(data_)
                (segment_ids_,) = tf.tf_promote(segment_ids_)
                tf.add_input(desc, data_)
                tf.add_input(desc, segment_ids_)
                tf.add_input(desc, num_segments_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unsorted_segment_max(data_::tf.TensorHandle, segment_ids_::tf.TensorHandle, num_segments_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("UnsortedSegmentMax")
        tf.add_input(desc, data_)
        tf.add_input(desc, segment_ids_)
        tf.add_input(desc, num_segments_)
        desc["T"] = tf.data_type(data_)
        desc["Tindices"] = tf.data_type(segment_ids_)
        desc["Tnumsegments"] = tf.data_type(num_segments_)
        (tf.execute(desc))[1]
    end
end


"""
     _mkl_squared_difference(x, y, mkl_x, mkl_y)

Returns (x - y)(x - y) element-wise.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _mkl_squared_difference(x_, y_, mkl_x_, mkl_y_; name=nothing)
            local desc
            tf.with_op_name(name, "_MklSquaredDifference") do 
                desc = tf.NodeDescription("_MklSquaredDifference")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                mkl_x_ = convert(Tensor{UInt8}, mkl_x_)
                mkl_y_ = convert(Tensor{UInt8}, mkl_y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
                tf.add_input(desc, mkl_x_)
                tf.add_input(desc, mkl_y_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function _mkl_squared_difference(x_::tf.TensorHandle, y_::tf.TensorHandle, mkl_x_::tf.TensorHandle, mkl_y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("_MklSquaredDifference")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        tf.add_input(desc, mkl_x_)
        tf.add_input(desc, mkl_y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        tf.execute(desc)
    end
end


"""
     conv3d_backprop_filter(input, filter, out_backprop; dilations=[1, 1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function conv3d_backprop_filter(input_, filter_, out_backprop_; name=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "Conv3DBackpropFilter") do 
                desc = tf.NodeDescription("Conv3DBackpropFilter")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                (input_, filter_, out_backprop_) = tf.tf_promote(input_, filter_, out_backprop_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, out_backprop_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function conv3d_backprop_filter(input_::tf.TensorHandle, filter_::tf.TensorHandle, out_backprop_::tf.TensorHandle; name=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("Conv3DBackpropFilter")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, out_backprop_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(filter_)
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     if_(cond, input; output_shapes=Int64[])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function if_(cond_, input_; name=nothing, Tin=nothing, Tout=nothing, then_branch=nothing, else_branch=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "If") do 
                desc = tf.NodeDescription("If")
                cond_ = convert(Tensor{Any}, cond_)
                input_ = [convert(Tensor{Any}, x) for x = input_]
                (cond_,) = tf.tf_promote(cond_)
                tf.add_input(desc, cond_)
                tf.add_input(desc, input_)
                if Tin !== nothing
                    desc["Tin"] = map(Base.identity, Tin)
                end
                if Tout !== nothing
                    desc["Tout"] = map(Base.identity, Tout)
                end
                if then_branch !== nothing
                    desc["then_branch"] = Base.identity(then_branch)
                end
                if else_branch !== nothing
                    desc["else_branch"] = Base.identity(else_branch)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function if_(cond_::tf.TensorHandle, input_::tf.TensorHandle; name=nothing, Tin=nothing, Tout=nothing, then_branch=nothing, else_branch=nothing, output_shapes=nothing)
        desc = tf.EagerOp("If")
        tf.add_input(desc, cond_)
        tf.add_input(desc, input_)
        if Tin !== nothing
            desc["Tin"] = map(Base.identity, Tin)
        end
        if Tout !== nothing
            desc["Tout"] = map(Base.identity, Tout)
        end
        if then_branch !== nothing
            desc["then_branch"] = Base.identity(then_branch)
        end
        if else_branch !== nothing
            desc["else_branch"] = Base.identity(else_branch)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        desc["Tcond"] = tf.data_type(cond_)
        (tf.execute(desc))[1]
    end
end


"""
     flat_map_dataset(input_dataset, other_arguments)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function flat_map_dataset(input_dataset_, other_arguments_; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "FlatMapDataset") do 
                desc = tf.NodeDescription("FlatMapDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, other_arguments_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function flat_map_dataset(input_dataset_::tf.TensorHandle, other_arguments_::tf.TensorHandle; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("FlatMapDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, other_arguments_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_scatter(tensor, indices, element_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_scatter(tensor_, indices_, element_shape_; name=nothing, element_dtype=nothing, shape_type=nothing)
            local desc
            tf.with_op_name(name, "TensorListScatter") do 
                desc = tf.NodeDescription("TensorListScatter")
                tensor_ = convert(Tensor{Any}, tensor_)
                indices_ = convert(Tensor{Int32}, indices_)
                element_shape_ = convert(Tensor{Any}, element_shape_)
                (tensor_,) = tf.tf_promote(tensor_)
                (element_shape_,) = tf.tf_promote(element_shape_)
                tf.add_input(desc, tensor_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, element_shape_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
                if shape_type !== nothing
                    desc["shape_type"] = Base.identity(shape_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_scatter(tensor_::tf.TensorHandle, indices_::tf.TensorHandle, element_shape_::tf.TensorHandle; name=nothing, element_dtype=nothing, shape_type=nothing)
        desc = tf.EagerOp("TensorListScatter")
        tf.add_input(desc, tensor_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, element_shape_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        if shape_type !== nothing
            desc["shape_type"] = Base.identity(shape_type)
        end
        desc["element_dtype"] = tf.data_type(tensor_)
        desc["shape_type"] = tf.data_type(element_shape_)
        (tf.execute(desc))[1]
    end
end


"""
     softsign_grad(gradients, features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function softsign_grad(gradients_, features_; name=nothing)
            local desc
            tf.with_op_name(name, "SoftsignGrad") do 
                desc = tf.NodeDescription("SoftsignGrad")
                gradients_ = convert(Tensor{Any}, gradients_)
                features_ = convert(Tensor{Any}, features_)
                (gradients_, features_) = tf.tf_promote(gradients_, features_)
                tf.add_input(desc, gradients_)
                tf.add_input(desc, features_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function softsign_grad(gradients_::tf.TensorHandle, features_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SoftsignGrad")
        tf.add_input(desc, gradients_)
        tf.add_input(desc, features_)
        desc["T"] = tf.data_type(gradients_)
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     copy_host(input; tensor_name=, debug_ops_spec=Int64[])

Copy Host Op.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function copy_host(input_; name=nothing, tensor_name=nothing, debug_ops_spec=nothing)
            local desc
            tf.with_op_name(name, "CopyHost") do 
                desc = tf.NodeDescription("CopyHost")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if tensor_name !== nothing
                    desc["tensor_name"] = Base.String(tensor_name)
                end
                if debug_ops_spec !== nothing
                    desc["debug_ops_spec"] = map(Base.identity, debug_ops_spec)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function copy_host(input_::tf.TensorHandle; name=nothing, tensor_name=nothing, debug_ops_spec=nothing)
        desc = tf.EagerOp("CopyHost")
        tf.add_input(desc, input_)
        if tensor_name !== nothing
            desc["tensor_name"] = Base.String(tensor_name)
        end
        if debug_ops_spec !== nothing
            desc["debug_ops_spec"] = map(Base.identity, debug_ops_spec)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     lin_space(start, stop, num)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lin_space(start_, stop_, num_; name=nothing)
            local desc
            tf.with_op_name(name, "LinSpace") do 
                desc = tf.NodeDescription("LinSpace")
                start_ = convert(Tensor{Any}, start_)
                stop_ = convert(Tensor{Any}, stop_)
                num_ = convert(Tensor{Int32}, num_)
                num_ = num_ - convert(tf.Tensor{eltype(num_)}, 1)
                (start_, stop_) = tf.tf_promote(start_, stop_)
                (num_,) = tf.tf_promote(num_)
                tf.add_input(desc, start_)
                tf.add_input(desc, stop_)
                tf.add_input(desc, num_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function lin_space(start_::tf.TensorHandle, stop_::tf.TensorHandle, num_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LinSpace")
        tf.add_input(desc, start_)
        tf.add_input(desc, stop_)
        tf.add_input(desc, num_)
        desc["T"] = tf.data_type(start_)
        desc["T"] = tf.data_type(stop_)
        desc["Tidx"] = tf.data_type(num_)
        (tf.execute(desc))[1]
    end
end


"""
     _parallel_concat_update(value, update)

Updates input `value` at `loc` with `update`.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _parallel_concat_update(value_, update_; name=nothing, loc=nothing)
            local desc
            tf.with_op_name(name, "_ParallelConcatUpdate") do 
                desc = tf.NodeDescription("_ParallelConcatUpdate")
                value_ = convert(Tensor{Any}, value_)
                update_ = convert(Tensor{Any}, update_)
                (value_, update_) = tf.tf_promote(value_, update_)
                tf.add_input(desc, value_)
                tf.add_input(desc, update_)
                if loc !== nothing
                    desc["loc"] = Base.Int(loc)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _parallel_concat_update(value_::tf.TensorHandle, update_::tf.TensorHandle; name=nothing, loc=nothing)
        desc = tf.EagerOp("_ParallelConcatUpdate")
        tf.add_input(desc, value_)
        tf.add_input(desc, update_)
        if loc !== nothing
            desc["loc"] = Base.Int(loc)
        end
        desc["T"] = tf.data_type(value_)
        desc["T"] = tf.data_type(update_)
        (tf.execute(desc))[1]
    end
end


"""
     stack(; stack_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stack(; name=nothing, elem_type=nothing, stack_name=nothing)
            local desc
            tf.with_op_name(name, "Stack") do 
                desc = tf.NodeDescription("Stack")
                if elem_type !== nothing
                    desc["elem_type"] = Base.identity(elem_type)
                end
                if stack_name !== nothing
                    desc["stack_name"] = Base.String(stack_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stack(; name=nothing, elem_type=nothing, stack_name=nothing)
        desc = tf.EagerOp("Stack")
        if elem_type !== nothing
            desc["elem_type"] = Base.identity(elem_type)
        end
        if stack_name !== nothing
            desc["stack_name"] = Base.String(stack_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     stack_push_v2(handle, elem; swap_memory=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stack_push_v2(handle_, elem_; name=nothing, swap_memory=nothing)
            local desc
            tf.with_op_name(name, "StackPushV2") do 
                desc = tf.NodeDescription("StackPushV2")
                handle_ = convert(Tensor{Any}, handle_)
                elem_ = convert(Tensor{Any}, elem_)
                (elem_,) = tf.tf_promote(elem_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, elem_)
                if swap_memory !== nothing
                    desc["swap_memory"] = Base.Bool(swap_memory)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stack_push_v2(handle_::tf.TensorHandle, elem_::tf.TensorHandle; name=nothing, swap_memory=nothing)
        desc = tf.EagerOp("StackPushV2")
        tf.add_input(desc, handle_)
        tf.add_input(desc, elem_)
        if swap_memory !== nothing
            desc["swap_memory"] = Base.Bool(swap_memory)
        end
        desc["T"] = tf.data_type(elem_)
        (tf.execute(desc))[1]
    end
end


"""
     assign_variable_op(resource, value)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function assign_variable_op(resource_, value_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "AssignVariableOp") do 
                desc = tf.NodeDescription("AssignVariableOp")
                resource_ = convert(Tensor{Any}, resource_)
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, value_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function assign_variable_op(resource_::tf.TensorHandle, value_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("AssignVariableOp")
        tf.add_input(desc, resource_)
        tf.add_input(desc, value_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["dtype"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_split(split_dim, indices, values, shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_split(split_dim_, indices_, values_, shape_; name=nothing, num_split=nothing)
            local desc
            tf.with_op_name(name, "SparseSplit") do 
                desc = tf.NodeDescription("SparseSplit")
                split_dim_ = convert(Tensor{Int64}, split_dim_)
                split_dim_ = split_dim_ - convert(tf.Tensor{eltype(split_dim_)}, 1)
                indices_ = convert(Tensor{Int64}, indices_)
                values_ = convert(Tensor{Any}, values_)
                shape_ = convert(Tensor{Int64}, shape_)
                (values_,) = tf.tf_promote(values_)
                tf.add_input(desc, split_dim_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, values_)
                tf.add_input(desc, shape_)
                if num_split !== nothing
                    desc["num_split"] = Base.Int(num_split)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_split(split_dim_::tf.TensorHandle, indices_::tf.TensorHandle, values_::tf.TensorHandle, shape_::tf.TensorHandle; name=nothing, num_split=nothing)
        desc = tf.EagerOp("SparseSplit")
        tf.add_input(desc, split_dim_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, values_)
        tf.add_input(desc, shape_)
        if num_split !== nothing
            desc["num_split"] = Base.Int(num_split)
        end
        desc["T"] = tf.data_type(values_)
        tf.execute(desc)
    end
end


"""
     tensor_array_unpack(handle, value, flow_in)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_unpack(handle_, value_, flow_in_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayUnpack") do 
                desc = tf.NodeDescription("TensorArrayUnpack")
                handle_ = convert(Tensor{String}, handle_)
                value_ = convert(Tensor{Any}, value_)
                flow_in_ = convert(Tensor{Float32}, flow_in_)
                (value_,) = tf.tf_promote(value_)
                tf.add_input(desc, handle_)
                tf.add_input(desc, value_)
                tf.add_input(desc, flow_in_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_unpack(handle_::tf.TensorHandle, value_::tf.TensorHandle, flow_in_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArrayUnpack")
        tf.add_input(desc, handle_)
        tf.add_input(desc, value_)
        tf.add_input(desc, flow_in_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_stack(input_handle, element_shape; num_elements=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_stack(input_handle_, element_shape_; name=nothing, element_dtype=nothing, num_elements=nothing)
            local desc
            tf.with_op_name(name, "TensorListStack") do 
                desc = tf.NodeDescription("TensorListStack")
                input_handle_ = convert(Tensor{Any}, input_handle_)
                element_shape_ = convert(Tensor{Int32}, element_shape_)
                tf.add_input(desc, input_handle_)
                tf.add_input(desc, element_shape_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
                if num_elements !== nothing
                    desc["num_elements"] = Base.Int(num_elements)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_stack(input_handle_::tf.TensorHandle, element_shape_::tf.TensorHandle; name=nothing, element_dtype=nothing, num_elements=nothing)
        desc = tf.EagerOp("TensorListStack")
        tf.add_input(desc, input_handle_)
        tf.add_input(desc, element_shape_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        if num_elements !== nothing
            desc["num_elements"] = Base.Int(num_elements)
        end
        (tf.execute(desc))[1]
    end
end


"""
     barrier_incomplete_size(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function barrier_incomplete_size(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "BarrierIncompleteSize") do 
                desc = tf.NodeDescription("BarrierIncompleteSize")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function barrier_incomplete_size(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BarrierIncompleteSize")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     restore(file_pattern, tensor_name; preferred_shard=-1)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function restore(file_pattern_, tensor_name_; name=nothing, dt=nothing, preferred_shard=nothing)
            local desc
            tf.with_op_name(name, "Restore") do 
                desc = tf.NodeDescription("Restore")
                file_pattern_ = convert(Tensor{String}, file_pattern_)
                tensor_name_ = convert(Tensor{String}, tensor_name_)
                tf.add_input(desc, file_pattern_)
                tf.add_input(desc, tensor_name_)
                if dt !== nothing
                    desc["dt"] = Base.identity(dt)
                end
                if preferred_shard !== nothing
                    desc["preferred_shard"] = Base.Int(preferred_shard)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function restore(file_pattern_::tf.TensorHandle, tensor_name_::tf.TensorHandle; name=nothing, dt=nothing, preferred_shard=nothing)
        desc = tf.EagerOp("Restore")
        tf.add_input(desc, file_pattern_)
        tf.add_input(desc, tensor_name_)
        if dt !== nothing
            desc["dt"] = Base.identity(dt)
        end
        if preferred_shard !== nothing
            desc["preferred_shard"] = Base.Int(preferred_shard)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_v3(size; element_shape=?, dynamic_size=false, clear_after_read=true, identical_element_shapes=false, tensor_array_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_v3(size_; name=nothing, dtype=nothing, element_shape=nothing, dynamic_size=nothing, clear_after_read=nothing, identical_element_shapes=nothing, tensor_array_name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayV3") do 
                desc = tf.NodeDescription("TensorArrayV3")
                size_ = convert(Tensor{Int32}, size_)
                tf.add_input(desc, size_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
                if element_shape !== nothing
                    desc["element_shape"] = Base.identity(element_shape)
                end
                if dynamic_size !== nothing
                    desc["dynamic_size"] = Base.Bool(dynamic_size)
                end
                if clear_after_read !== nothing
                    desc["clear_after_read"] = Base.Bool(clear_after_read)
                end
                if identical_element_shapes !== nothing
                    desc["identical_element_shapes"] = Base.Bool(identical_element_shapes)
                end
                if tensor_array_name !== nothing
                    desc["tensor_array_name"] = Base.String(tensor_array_name)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function tensor_array_v3(size_::tf.TensorHandle; name=nothing, dtype=nothing, element_shape=nothing, dynamic_size=nothing, clear_after_read=nothing, identical_element_shapes=nothing, tensor_array_name=nothing)
        desc = tf.EagerOp("TensorArrayV3")
        tf.add_input(desc, size_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        if element_shape !== nothing
            desc["element_shape"] = Base.identity(element_shape)
        end
        if dynamic_size !== nothing
            desc["dynamic_size"] = Base.Bool(dynamic_size)
        end
        if clear_after_read !== nothing
            desc["clear_after_read"] = Base.Bool(clear_after_read)
        end
        if identical_element_shapes !== nothing
            desc["identical_element_shapes"] = Base.Bool(identical_element_shapes)
        end
        if tensor_array_name !== nothing
            desc["tensor_array_name"] = Base.String(tensor_array_name)
        end
        tf.execute(desc)
    end
end


"""
     experimental_assert_next_dataset(input_dataset, transformations)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_assert_next_dataset(input_dataset_, transformations_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalAssertNextDataset") do 
                desc = tf.NodeDescription("ExperimentalAssertNextDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                transformations_ = convert(Tensor{String}, transformations_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, transformations_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_assert_next_dataset(input_dataset_::tf.TensorHandle, transformations_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalAssertNextDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, transformations_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     in_top_k(predictions, targets)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function in_top_k(predictions_, targets_; name=nothing, k=nothing)
            local desc
            tf.with_op_name(name, "InTopK") do 
                desc = tf.NodeDescription("InTopK")
                predictions_ = convert(Tensor{Float32}, predictions_)
                targets_ = convert(Tensor{Int32}, targets_)
                (targets_,) = tf.tf_promote(targets_)
                tf.add_input(desc, predictions_)
                tf.add_input(desc, targets_)
                if k !== nothing
                    desc["k"] = Base.Int(k)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function in_top_k(predictions_::tf.TensorHandle, targets_::tf.TensorHandle; name=nothing, k=nothing)
        desc = tf.EagerOp("InTopK")
        tf.add_input(desc, predictions_)
        tf.add_input(desc, targets_)
        if k !== nothing
            desc["k"] = Base.Int(k)
        end
        desc["T"] = tf.data_type(targets_)
        (tf.execute(desc))[1]
    end
end


"""
     scatter_sub(ref, indices, updates; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_sub(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ScatterSub") do 
                desc = tf.NodeDescription("ScatterSub")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (ref_, updates_) = tf.tf_promote(ref_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_sub(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ScatterSub")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     acosh(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function acosh(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Acosh") do 
                desc = tf.NodeDescription("Acosh")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function acosh(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Acosh")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     depthwise_conv2d_native_backprop_filter(input, filter_sizes, out_backprop; data_format=NHWC, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function depthwise_conv2d_native_backprop_filter(input_, filter_sizes_, out_backprop_; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "DepthwiseConv2dNativeBackpropFilter") do 
                desc = tf.NodeDescription("DepthwiseConv2dNativeBackpropFilter")
                input_ = convert(Tensor{Any}, input_)
                filter_sizes_ = convert(Tensor{Int32}, filter_sizes_)
                out_backprop_ = convert(Tensor{Any}, out_backprop_)
                (input_, out_backprop_) = tf.tf_promote(input_, out_backprop_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_sizes_)
                tf.add_input(desc, out_backprop_)
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if data_format !== nothing
                    desc["data_format"] = Base.String(data_format)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function depthwise_conv2d_native_backprop_filter(input_::tf.TensorHandle, filter_sizes_::tf.TensorHandle, out_backprop_::tf.TensorHandle; name=nothing, strides=nothing, padding=nothing, data_format=nothing, dilations=nothing)
        desc = tf.EagerOp("DepthwiseConv2dNativeBackpropFilter")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_sizes_)
        tf.add_input(desc, out_backprop_)
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if data_format !== nothing
            desc["data_format"] = Base.String(data_format)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(out_backprop_)
        (tf.execute(desc))[1]
    end
end


"""
     cast(x; Truncate=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cast(x_; name=nothing, SrcT=nothing, DstT=nothing, Truncate=nothing)
            local desc
            tf.with_op_name(name, "Cast") do 
                desc = tf.NodeDescription("Cast")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
                if SrcT !== nothing
                    desc["SrcT"] = Base.identity(SrcT)
                end
                if DstT !== nothing
                    desc["DstT"] = Base.identity(DstT)
                end
                if Truncate !== nothing
                    desc["Truncate"] = Base.Bool(Truncate)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cast(x_::tf.TensorHandle; name=nothing, SrcT=nothing, DstT=nothing, Truncate=nothing)
        desc = tf.EagerOp("Cast")
        tf.add_input(desc, x_)
        if SrcT !== nothing
            desc["SrcT"] = Base.identity(SrcT)
        end
        if DstT !== nothing
            desc["DstT"] = Base.identity(DstT)
        end
        if Truncate !== nothing
            desc["Truncate"] = Base.Bool(Truncate)
        end
        desc["SrcT"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     quantize_v2(input, min_range, max_range; mode=MIN_COMBINED, round_mode=HALF_AWAY_FROM_ZERO)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantize_v2(input_, min_range_, max_range_; name=nothing, mode=nothing, round_mode=nothing)
            local desc
            tf.with_op_name(name, "QuantizeV2") do 
                desc = tf.NodeDescription("QuantizeV2")
                input_ = convert(Tensor{Float32}, input_)
                min_range_ = convert(Tensor{Float32}, min_range_)
                max_range_ = convert(Tensor{Float32}, max_range_)
                tf.add_input(desc, input_)
                tf.add_input(desc, min_range_)
                tf.add_input(desc, max_range_)
                if mode !== nothing
                    desc["mode"] = Base.String(mode)
                end
                if round_mode !== nothing
                    desc["round_mode"] = Base.String(round_mode)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantize_v2(input_::tf.TensorHandle, min_range_::tf.TensorHandle, max_range_::tf.TensorHandle; name=nothing, mode=nothing, round_mode=nothing)
        desc = tf.EagerOp("QuantizeV2")
        tf.add_input(desc, input_)
        tf.add_input(desc, min_range_)
        tf.add_input(desc, max_range_)
        if mode !== nothing
            desc["mode"] = Base.String(mode)
        end
        if round_mode !== nothing
            desc["round_mode"] = Base.String(round_mode)
        end
        tf.execute(desc)
    end
end


"""
     generator_dataset(init_func_other_args, next_func_other_args, finalize_func_other_args)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function generator_dataset(init_func_other_args_, next_func_other_args_, finalize_func_other_args_; name=nothing, init_func=nothing, next_func=nothing, finalize_func=nothing, Tinit_func_args=nothing, Tnext_func_args=nothing, Tfinalize_func_args=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "GeneratorDataset") do 
                desc = tf.NodeDescription("GeneratorDataset")
                init_func_other_args_ = [convert(Tensor{Any}, x) for x = init_func_other_args_]
                next_func_other_args_ = [convert(Tensor{Any}, x) for x = next_func_other_args_]
                finalize_func_other_args_ = [convert(Tensor{Any}, x) for x = finalize_func_other_args_]
                tf.add_input(desc, init_func_other_args_)
                tf.add_input(desc, next_func_other_args_)
                tf.add_input(desc, finalize_func_other_args_)
                if init_func !== nothing
                    desc["init_func"] = Base.identity(init_func)
                end
                if next_func !== nothing
                    desc["next_func"] = Base.identity(next_func)
                end
                if finalize_func !== nothing
                    desc["finalize_func"] = Base.identity(finalize_func)
                end
                if Tinit_func_args !== nothing
                    desc["Tinit_func_args"] = map(Base.identity, Tinit_func_args)
                end
                if Tnext_func_args !== nothing
                    desc["Tnext_func_args"] = map(Base.identity, Tnext_func_args)
                end
                if Tfinalize_func_args !== nothing
                    desc["Tfinalize_func_args"] = map(Base.identity, Tfinalize_func_args)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function generator_dataset(init_func_other_args_::tf.TensorHandle, next_func_other_args_::tf.TensorHandle, finalize_func_other_args_::tf.TensorHandle; name=nothing, init_func=nothing, next_func=nothing, finalize_func=nothing, Tinit_func_args=nothing, Tnext_func_args=nothing, Tfinalize_func_args=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("GeneratorDataset")
        tf.add_input(desc, init_func_other_args_)
        tf.add_input(desc, next_func_other_args_)
        tf.add_input(desc, finalize_func_other_args_)
        if init_func !== nothing
            desc["init_func"] = Base.identity(init_func)
        end
        if next_func !== nothing
            desc["next_func"] = Base.identity(next_func)
        end
        if finalize_func !== nothing
            desc["finalize_func"] = Base.identity(finalize_func)
        end
        if Tinit_func_args !== nothing
            desc["Tinit_func_args"] = map(Base.identity, Tinit_func_args)
        end
        if Tnext_func_args !== nothing
            desc["Tnext_func_args"] = map(Base.identity, Tnext_func_args)
        end
        if Tfinalize_func_args !== nothing
            desc["Tfinalize_func_args"] = map(Base.identity, Tfinalize_func_args)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     tensor_forest_tree_serialize(tree_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_forest_tree_serialize(tree_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorForestTreeSerialize") do 
                desc = tf.NodeDescription("TensorForestTreeSerialize")
                tree_handle_ = convert(Tensor{Any}, tree_handle_)
                tf.add_input(desc, tree_handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_forest_tree_serialize(tree_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorForestTreeSerialize")
        tf.add_input(desc, tree_handle_)
        (tf.execute(desc))[1]
    end
end


"""
     next_after(x1, x2)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function next_after(x1_, x2_; name=nothing)
            local desc
            tf.with_op_name(name, "NextAfter") do 
                desc = tf.NodeDescription("NextAfter")
                x1_ = convert(Tensor{Float32}, x1_)
                x2_ = convert(Tensor{Float32}, x2_)
                (x1_, x2_) = tf.tf_promote(x1_, x2_)
                tf.add_input(desc, x1_)
                tf.add_input(desc, x2_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function next_after(x1_::tf.TensorHandle, x2_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("NextAfter")
        tf.add_input(desc, x1_)
        tf.add_input(desc, x2_)
        desc["T"] = tf.data_type(x1_)
        desc["T"] = tf.data_type(x2_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_array_close_v2(handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_array_close_v2(handle_; name=nothing)
            local desc
            tf.with_op_name(name, "TensorArrayCloseV2") do 
                desc = tf.NodeDescription("TensorArrayCloseV2")
                handle_ = convert(Tensor{String}, handle_)
                tf.add_input(desc, handle_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_array_close_v2(handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("TensorArrayCloseV2")
        tf.add_input(desc, handle_)
        (tf.execute(desc))[1]
    end
end


"""
     big_query_reader(; container=, shared_name=, test_end_point=)

A Reader that outputs rows from a BigQuery table as tensorflow Examples.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function big_query_reader(; name=nothing, container=nothing, shared_name=nothing, project_id=nothing, dataset_id=nothing, table_id=nothing, columns=nothing, timestamp_millis=nothing, test_end_point=nothing)
            local desc
            tf.with_op_name(name, "BigQueryReader") do 
                desc = tf.NodeDescription("BigQueryReader")
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
                if project_id !== nothing
                    desc["project_id"] = Base.String(project_id)
                end
                if dataset_id !== nothing
                    desc["dataset_id"] = Base.String(dataset_id)
                end
                if table_id !== nothing
                    desc["table_id"] = Base.String(table_id)
                end
                if columns !== nothing
                    desc["columns"] = map(Base.identity, columns)
                end
                if timestamp_millis !== nothing
                    desc["timestamp_millis"] = Base.Int(timestamp_millis)
                end
                if test_end_point !== nothing
                    desc["test_end_point"] = Base.String(test_end_point)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function big_query_reader(; name=nothing, container=nothing, shared_name=nothing, project_id=nothing, dataset_id=nothing, table_id=nothing, columns=nothing, timestamp_millis=nothing, test_end_point=nothing)
        desc = tf.EagerOp("BigQueryReader")
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        if project_id !== nothing
            desc["project_id"] = Base.String(project_id)
        end
        if dataset_id !== nothing
            desc["dataset_id"] = Base.String(dataset_id)
        end
        if table_id !== nothing
            desc["table_id"] = Base.String(table_id)
        end
        if columns !== nothing
            desc["columns"] = map(Base.identity, columns)
        end
        if timestamp_millis !== nothing
            desc["timestamp_millis"] = Base.Int(timestamp_millis)
        end
        if test_end_point !== nothing
            desc["test_end_point"] = Base.String(test_end_point)
        end
        (tf.execute(desc))[1]
    end
end


"""
     reader_read_v2(reader_handle, queue_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function reader_read_v2(reader_handle_, queue_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "ReaderReadV2") do 
                desc = tf.NodeDescription("ReaderReadV2")
                reader_handle_ = convert(Tensor{Any}, reader_handle_)
                queue_handle_ = convert(Tensor{Any}, queue_handle_)
                tf.add_input(desc, reader_handle_)
                tf.add_input(desc, queue_handle_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function reader_read_v2(reader_handle_::tf.TensorHandle, queue_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ReaderReadV2")
        tf.add_input(desc, reader_handle_)
        tf.add_input(desc, queue_handle_)
        tf.execute(desc)
    end
end


"""
     mod(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function mod(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "Mod") do 
                desc = tf.NodeDescription("Mod")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function mod(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Mod")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     add_v2(x, y)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function add_v2(x_, y_; name=nothing)
            local desc
            tf.with_op_name(name, "AddV2") do 
                desc = tf.NodeDescription("AddV2")
                x_ = convert(Tensor{Any}, x_)
                y_ = convert(Tensor{Any}, y_)
                (x_, y_) = tf.tf_promote(x_, y_)
                tf.add_input(desc, x_)
                tf.add_input(desc, y_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function add_v2(x_::tf.TensorHandle, y_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("AddV2")
        tf.add_input(desc, x_)
        tf.add_input(desc, y_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(y_)
        (tf.execute(desc))[1]
    end
end


"""
     stateless_random_normal(shape, seed; dtype=Float32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function stateless_random_normal(shape_, seed_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "StatelessRandomNormal") do 
                desc = tf.NodeDescription("StatelessRandomNormal")
                shape_ = convert(Tensor{Int32}, shape_)
                seed_ = convert(Tensor{Int64}, seed_)
                (shape_,) = tf.tf_promote(shape_)
                (seed_,) = tf.tf_promote(seed_)
                tf.add_input(desc, shape_)
                tf.add_input(desc, seed_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function stateless_random_normal(shape_::tf.TensorHandle, seed_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("StatelessRandomNormal")
        tf.add_input(desc, shape_)
        tf.add_input(desc, seed_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["T"] = tf.data_type(shape_)
        desc["Tseed"] = tf.data_type(seed_)
        (tf.execute(desc))[1]
    end
end


"""
     strided_slice_assign(ref, begin, end, strides, value; begin_mask=0, end_mask=0, ellipsis_mask=0, new_axis_mask=0, shrink_axis_mask=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function strided_slice_assign(ref_, begin_, end_, strides_, value_; name=nothing, Index=nothing, begin_mask=nothing, end_mask=nothing, ellipsis_mask=nothing, new_axis_mask=nothing, shrink_axis_mask=nothing)
            local desc
            tf.with_op_name(name, "StridedSliceAssign") do 
                desc = tf.NodeDescription("StridedSliceAssign")
                ref_ = convert(Tensor{Any}, ref_)
                begin_ = convert(Tensor{Any}, begin_)
                begin_ = begin_ - convert(tf.Tensor{eltype(begin_)}, 1)
                end_ = convert(Tensor{Any}, end_)
                end_ = end_ - convert(tf.Tensor{eltype(end_)}, 1)
                strides_ = convert(Tensor{Any}, strides_)
                strides_ = strides_ - convert(tf.Tensor{eltype(strides_)}, 1)
                value_ = convert(Tensor{Any}, value_)
                (ref_, value_) = tf.tf_promote(ref_, value_)
                (begin_, end_, strides_) = tf.tf_promote(begin_, end_, strides_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, begin_)
                tf.add_input(desc, end_)
                tf.add_input(desc, strides_)
                tf.add_input(desc, value_)
                if Index !== nothing
                    desc["Index"] = Base.identity(Index)
                end
                if begin_mask !== nothing
                    begin_mask = Base.Int(begin_mask) - 1
                end
                if begin_mask !== nothing
                    desc["begin_mask"] = Base.Int(begin_mask)
                end
                if end_mask !== nothing
                    end_mask = Base.Int(end_mask) - 1
                end
                if end_mask !== nothing
                    desc["end_mask"] = Base.Int(end_mask)
                end
                if ellipsis_mask !== nothing
                    ellipsis_mask = Base.Int(ellipsis_mask) - 1
                end
                if ellipsis_mask !== nothing
                    desc["ellipsis_mask"] = Base.Int(ellipsis_mask)
                end
                if new_axis_mask !== nothing
                    new_axis_mask = Base.Int(new_axis_mask) - 1
                end
                if new_axis_mask !== nothing
                    desc["new_axis_mask"] = Base.Int(new_axis_mask)
                end
                if shrink_axis_mask !== nothing
                    shrink_axis_mask = Base.Int(shrink_axis_mask) - 1
                end
                if shrink_axis_mask !== nothing
                    desc["shrink_axis_mask"] = Base.Int(shrink_axis_mask)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function strided_slice_assign(ref_::tf.TensorHandle, begin_::tf.TensorHandle, end_::tf.TensorHandle, strides_::tf.TensorHandle, value_::tf.TensorHandle; name=nothing, Index=nothing, begin_mask=nothing, end_mask=nothing, ellipsis_mask=nothing, new_axis_mask=nothing, shrink_axis_mask=nothing)
        desc = tf.EagerOp("StridedSliceAssign")
        tf.add_input(desc, ref_)
        tf.add_input(desc, begin_)
        tf.add_input(desc, end_)
        tf.add_input(desc, strides_)
        tf.add_input(desc, value_)
        if Index !== nothing
            desc["Index"] = Base.identity(Index)
        end
        if begin_mask !== nothing
            begin_mask = Base.Int(begin_mask) - 1
        end
        if begin_mask !== nothing
            desc["begin_mask"] = Base.Int(begin_mask)
        end
        if end_mask !== nothing
            end_mask = Base.Int(end_mask) - 1
        end
        if end_mask !== nothing
            desc["end_mask"] = Base.Int(end_mask)
        end
        if ellipsis_mask !== nothing
            ellipsis_mask = Base.Int(ellipsis_mask) - 1
        end
        if ellipsis_mask !== nothing
            desc["ellipsis_mask"] = Base.Int(ellipsis_mask)
        end
        if new_axis_mask !== nothing
            new_axis_mask = Base.Int(new_axis_mask) - 1
        end
        if new_axis_mask !== nothing
            desc["new_axis_mask"] = Base.Int(new_axis_mask)
        end
        if shrink_axis_mask !== nothing
            shrink_axis_mask = Base.Int(shrink_axis_mask) - 1
        end
        if shrink_axis_mask !== nothing
            desc["shrink_axis_mask"] = Base.Int(shrink_axis_mask)
        end
        desc["T"] = tf.data_type(ref_)
        desc["Index"] = tf.data_type(begin_)
        desc["Index"] = tf.data_type(end_)
        desc["Index"] = tf.data_type(strides_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     scatter_min(ref, indices, updates; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scatter_min(ref_, indices_, updates_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ScatterMin") do 
                desc = tf.NodeDescription("ScatterMin")
                ref_ = convert(Tensor{Any}, ref_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (ref_, updates_) = tf.tf_promote(ref_, updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scatter_min(ref_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ScatterMin")
        tf.add_input(desc, ref_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(ref_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_strided_slice_assign(ref, begin, end, strides, value; begin_mask=0, end_mask=0, ellipsis_mask=0, new_axis_mask=0, shrink_axis_mask=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_strided_slice_assign(ref_, begin_, end_, strides_, value_; name=nothing, Index=nothing, begin_mask=nothing, end_mask=nothing, ellipsis_mask=nothing, new_axis_mask=nothing, shrink_axis_mask=nothing)
            local desc
            tf.with_op_name(name, "ResourceStridedSliceAssign") do 
                desc = tf.NodeDescription("ResourceStridedSliceAssign")
                ref_ = convert(Tensor{Any}, ref_)
                begin_ = convert(Tensor{Any}, begin_)
                begin_ = begin_ - convert(tf.Tensor{eltype(begin_)}, 1)
                end_ = convert(Tensor{Any}, end_)
                end_ = end_ - convert(tf.Tensor{eltype(end_)}, 1)
                strides_ = convert(Tensor{Any}, strides_)
                strides_ = strides_ - convert(tf.Tensor{eltype(strides_)}, 1)
                value_ = convert(Tensor{Any}, value_)
                (value_,) = tf.tf_promote(value_)
                (begin_, end_, strides_) = tf.tf_promote(begin_, end_, strides_)
                tf.add_input(desc, ref_)
                tf.add_input(desc, begin_)
                tf.add_input(desc, end_)
                tf.add_input(desc, strides_)
                tf.add_input(desc, value_)
                if Index !== nothing
                    desc["Index"] = Base.identity(Index)
                end
                if begin_mask !== nothing
                    begin_mask = Base.Int(begin_mask) - 1
                end
                if begin_mask !== nothing
                    desc["begin_mask"] = Base.Int(begin_mask)
                end
                if end_mask !== nothing
                    end_mask = Base.Int(end_mask) - 1
                end
                if end_mask !== nothing
                    desc["end_mask"] = Base.Int(end_mask)
                end
                if ellipsis_mask !== nothing
                    ellipsis_mask = Base.Int(ellipsis_mask) - 1
                end
                if ellipsis_mask !== nothing
                    desc["ellipsis_mask"] = Base.Int(ellipsis_mask)
                end
                if new_axis_mask !== nothing
                    new_axis_mask = Base.Int(new_axis_mask) - 1
                end
                if new_axis_mask !== nothing
                    desc["new_axis_mask"] = Base.Int(new_axis_mask)
                end
                if shrink_axis_mask !== nothing
                    shrink_axis_mask = Base.Int(shrink_axis_mask) - 1
                end
                if shrink_axis_mask !== nothing
                    desc["shrink_axis_mask"] = Base.Int(shrink_axis_mask)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_strided_slice_assign(ref_::tf.TensorHandle, begin_::tf.TensorHandle, end_::tf.TensorHandle, strides_::tf.TensorHandle, value_::tf.TensorHandle; name=nothing, Index=nothing, begin_mask=nothing, end_mask=nothing, ellipsis_mask=nothing, new_axis_mask=nothing, shrink_axis_mask=nothing)
        desc = tf.EagerOp("ResourceStridedSliceAssign")
        tf.add_input(desc, ref_)
        tf.add_input(desc, begin_)
        tf.add_input(desc, end_)
        tf.add_input(desc, strides_)
        tf.add_input(desc, value_)
        if Index !== nothing
            desc["Index"] = Base.identity(Index)
        end
        if begin_mask !== nothing
            begin_mask = Base.Int(begin_mask) - 1
        end
        if begin_mask !== nothing
            desc["begin_mask"] = Base.Int(begin_mask)
        end
        if end_mask !== nothing
            end_mask = Base.Int(end_mask) - 1
        end
        if end_mask !== nothing
            desc["end_mask"] = Base.Int(end_mask)
        end
        if ellipsis_mask !== nothing
            ellipsis_mask = Base.Int(ellipsis_mask) - 1
        end
        if ellipsis_mask !== nothing
            desc["ellipsis_mask"] = Base.Int(ellipsis_mask)
        end
        if new_axis_mask !== nothing
            new_axis_mask = Base.Int(new_axis_mask) - 1
        end
        if new_axis_mask !== nothing
            desc["new_axis_mask"] = Base.Int(new_axis_mask)
        end
        if shrink_axis_mask !== nothing
            shrink_axis_mask = Base.Int(shrink_axis_mask) - 1
        end
        if shrink_axis_mask !== nothing
            desc["shrink_axis_mask"] = Base.Int(shrink_axis_mask)
        end
        desc["Index"] = tf.data_type(begin_)
        desc["Index"] = tf.data_type(end_)
        desc["Index"] = tf.data_type(strides_)
        desc["T"] = tf.data_type(value_)
        (tf.execute(desc))[1]
    end
end


"""
     random_gamma_grad(alpha, sample)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function random_gamma_grad(alpha_, sample_; name=nothing)
            local desc
            tf.with_op_name(name, "RandomGammaGrad") do 
                desc = tf.NodeDescription("RandomGammaGrad")
                alpha_ = convert(Tensor{Any}, alpha_)
                sample_ = convert(Tensor{Any}, sample_)
                (alpha_, sample_) = tf.tf_promote(alpha_, sample_)
                tf.add_input(desc, alpha_)
                tf.add_input(desc, sample_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function random_gamma_grad(alpha_::tf.TensorHandle, sample_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("RandomGammaGrad")
        tf.add_input(desc, alpha_)
        tf.add_input(desc, sample_)
        desc["T"] = tf.data_type(alpha_)
        desc["T"] = tf.data_type(sample_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_sparse_apply_keras_momentum(var, accum, lr, grad, indices, momentum; use_locking=false, use_nesterov=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_sparse_apply_keras_momentum(var_, accum_, lr_, grad_, indices_, momentum_; name=nothing, use_locking=nothing, use_nesterov=nothing)
            local desc
            tf.with_op_name(name, "ResourceSparseApplyKerasMomentum") do 
                desc = tf.NodeDescription("ResourceSparseApplyKerasMomentum")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                grad_ = convert(Tensor{Any}, grad_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                momentum_ = convert(Tensor{Any}, momentum_)
                (lr_, grad_, momentum_) = tf.tf_promote(lr_, grad_, momentum_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, grad_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, momentum_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if use_nesterov !== nothing
                    desc["use_nesterov"] = Base.Bool(use_nesterov)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_sparse_apply_keras_momentum(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, grad_::tf.TensorHandle, indices_::tf.TensorHandle, momentum_::tf.TensorHandle; name=nothing, use_locking=nothing, use_nesterov=nothing)
        desc = tf.EagerOp("ResourceSparseApplyKerasMomentum")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, grad_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, momentum_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if use_nesterov !== nothing
            desc["use_nesterov"] = Base.Bool(use_nesterov)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(grad_)
        desc["Tindices"] = tf.data_type(indices_)
        desc["T"] = tf.data_type(momentum_)
        (tf.execute(desc))[1]
    end
end


"""
     boosted_trees_create_quantile_stream_resource(quantile_stream_resource_handle, epsilon, num_streams; max_elements=1099511627776)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function boosted_trees_create_quantile_stream_resource(quantile_stream_resource_handle_, epsilon_, num_streams_; name=nothing, max_elements=nothing)
            local desc
            tf.with_op_name(name, "BoostedTreesCreateQuantileStreamResource") do 
                desc = tf.NodeDescription("BoostedTreesCreateQuantileStreamResource")
                quantile_stream_resource_handle_ = convert(Tensor{Any}, quantile_stream_resource_handle_)
                epsilon_ = convert(Tensor{Float32}, epsilon_)
                num_streams_ = convert(Tensor{Int64}, num_streams_)
                tf.add_input(desc, quantile_stream_resource_handle_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, num_streams_)
                if max_elements !== nothing
                    desc["max_elements"] = Base.Int(max_elements)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function boosted_trees_create_quantile_stream_resource(quantile_stream_resource_handle_::tf.TensorHandle, epsilon_::tf.TensorHandle, num_streams_::tf.TensorHandle; name=nothing, max_elements=nothing)
        desc = tf.EagerOp("BoostedTreesCreateQuantileStreamResource")
        tf.add_input(desc, quantile_stream_resource_handle_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, num_streams_)
        if max_elements !== nothing
            desc["max_elements"] = Base.Int(max_elements)
        end
        (tf.execute(desc))[1]
    end
end


"""
     quantized_relu6(features, min_features, max_features; out_type=Float32)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_relu6(features_, min_features_, max_features_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "QuantizedRelu6") do 
                desc = tf.NodeDescription("QuantizedRelu6")
                features_ = convert(Tensor{Any}, features_)
                min_features_ = convert(Tensor{Float32}, min_features_)
                max_features_ = convert(Tensor{Float32}, max_features_)
                (features_,) = tf.tf_promote(features_)
                tf.add_input(desc, features_)
                tf.add_input(desc, min_features_)
                tf.add_input(desc, max_features_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_relu6(features_::tf.TensorHandle, min_features_::tf.TensorHandle, max_features_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("QuantizedRelu6")
        tf.add_input(desc, features_)
        tf.add_input(desc, min_features_)
        tf.add_input(desc, max_features_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["Tinput"] = tf.data_type(features_)
        tf.execute(desc)
    end
end


"""
     sparse_sparse_maximum(a_indices, a_values, a_shape, b_indices, b_values, b_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_sparse_maximum(a_indices_, a_values_, a_shape_, b_indices_, b_values_, b_shape_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSparseMaximum") do 
                desc = tf.NodeDescription("SparseSparseMaximum")
                a_indices_ = convert(Tensor{Int64}, a_indices_)
                a_values_ = convert(Tensor{Any}, a_values_)
                a_shape_ = convert(Tensor{Int64}, a_shape_)
                b_indices_ = convert(Tensor{Int64}, b_indices_)
                b_values_ = convert(Tensor{Any}, b_values_)
                b_shape_ = convert(Tensor{Int64}, b_shape_)
                (a_values_, b_values_) = tf.tf_promote(a_values_, b_values_)
                tf.add_input(desc, a_indices_)
                tf.add_input(desc, a_values_)
                tf.add_input(desc, a_shape_)
                tf.add_input(desc, b_indices_)
                tf.add_input(desc, b_values_)
                tf.add_input(desc, b_shape_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_sparse_maximum(a_indices_::tf.TensorHandle, a_values_::tf.TensorHandle, a_shape_::tf.TensorHandle, b_indices_::tf.TensorHandle, b_values_::tf.TensorHandle, b_shape_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSparseMaximum")
        tf.add_input(desc, a_indices_)
        tf.add_input(desc, a_values_)
        tf.add_input(desc, a_shape_)
        tf.add_input(desc, b_indices_)
        tf.add_input(desc, b_values_)
        tf.add_input(desc, b_shape_)
        desc["T"] = tf.data_type(a_values_)
        desc["T"] = tf.data_type(b_values_)
        tf.execute(desc)
    end
end


"""
     batch_norm_with_global_normalization(t, m, v, beta, gamma)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_norm_with_global_normalization(t_, m_, v_, beta_, gamma_; name=nothing, variance_epsilon=nothing, scale_after_normalization=nothing)
            local desc
            tf.with_op_name(name, "BatchNormWithGlobalNormalization") do 
                desc = tf.NodeDescription("BatchNormWithGlobalNormalization")
                t_ = convert(Tensor{Any}, t_)
                m_ = convert(Tensor{Any}, m_)
                v_ = convert(Tensor{Any}, v_)
                beta_ = convert(Tensor{Any}, beta_)
                gamma_ = convert(Tensor{Any}, gamma_)
                (t_, m_, v_, beta_, gamma_) = tf.tf_promote(t_, m_, v_, beta_, gamma_)
                tf.add_input(desc, t_)
                tf.add_input(desc, m_)
                tf.add_input(desc, v_)
                tf.add_input(desc, beta_)
                tf.add_input(desc, gamma_)
                if variance_epsilon !== nothing
                    desc["variance_epsilon"] = Base.identity(variance_epsilon)
                end
                if scale_after_normalization !== nothing
                    desc["scale_after_normalization"] = Base.Bool(scale_after_normalization)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_norm_with_global_normalization(t_::tf.TensorHandle, m_::tf.TensorHandle, v_::tf.TensorHandle, beta_::tf.TensorHandle, gamma_::tf.TensorHandle; name=nothing, variance_epsilon=nothing, scale_after_normalization=nothing)
        desc = tf.EagerOp("BatchNormWithGlobalNormalization")
        tf.add_input(desc, t_)
        tf.add_input(desc, m_)
        tf.add_input(desc, v_)
        tf.add_input(desc, beta_)
        tf.add_input(desc, gamma_)
        if variance_epsilon !== nothing
            desc["variance_epsilon"] = Base.identity(variance_epsilon)
        end
        if scale_after_normalization !== nothing
            desc["scale_after_normalization"] = Base.Bool(scale_after_normalization)
        end
        desc["T"] = tf.data_type(t_)
        desc["T"] = tf.data_type(m_)
        desc["T"] = tf.data_type(v_)
        desc["T"] = tf.data_type(beta_)
        desc["T"] = tf.data_type(gamma_)
        (tf.execute(desc))[1]
    end
end


"""
     in_top_kv2(predictions, targets, k)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function in_top_kv2(predictions_, targets_, k_; name=nothing)
            local desc
            tf.with_op_name(name, "InTopKV2") do 
                desc = tf.NodeDescription("InTopKV2")
                predictions_ = convert(Tensor{Float32}, predictions_)
                targets_ = convert(Tensor{Int32}, targets_)
                k_ = convert(Tensor{Int32}, k_)
                (targets_, k_) = tf.tf_promote(targets_, k_)
                tf.add_input(desc, predictions_)
                tf.add_input(desc, targets_)
                tf.add_input(desc, k_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function in_top_kv2(predictions_::tf.TensorHandle, targets_::tf.TensorHandle, k_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("InTopKV2")
        tf.add_input(desc, predictions_)
        tf.add_input(desc, targets_)
        tf.add_input(desc, k_)
        desc["T"] = tf.data_type(targets_)
        desc["T"] = tf.data_type(k_)
        (tf.execute(desc))[1]
    end
end


"""
     cholesky(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cholesky(input_; name=nothing)
            local desc
            tf.with_op_name(name, "Cholesky") do 
                desc = tf.NodeDescription("Cholesky")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function cholesky(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Cholesky")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_centered_rms_prop(var, mg, ms, mom, lr, rho, momentum, epsilon, grad; use_locking=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_centered_rms_prop(var_, mg_, ms_, mom_, lr_, rho_, momentum_, epsilon_, grad_; name=nothing, use_locking=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyCenteredRMSProp") do 
                desc = tf.NodeDescription("ResourceApplyCenteredRMSProp")
                var_ = convert(Tensor{Any}, var_)
                mg_ = convert(Tensor{Any}, mg_)
                ms_ = convert(Tensor{Any}, ms_)
                mom_ = convert(Tensor{Any}, mom_)
                lr_ = convert(Tensor{Any}, lr_)
                rho_ = convert(Tensor{Any}, rho_)
                momentum_ = convert(Tensor{Any}, momentum_)
                epsilon_ = convert(Tensor{Any}, epsilon_)
                grad_ = convert(Tensor{Any}, grad_)
                (lr_, rho_, momentum_, epsilon_, grad_) = tf.tf_promote(lr_, rho_, momentum_, epsilon_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, mg_)
                tf.add_input(desc, ms_)
                tf.add_input(desc, mom_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, rho_)
                tf.add_input(desc, momentum_)
                tf.add_input(desc, epsilon_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_centered_rms_prop(var_::tf.TensorHandle, mg_::tf.TensorHandle, ms_::tf.TensorHandle, mom_::tf.TensorHandle, lr_::tf.TensorHandle, rho_::tf.TensorHandle, momentum_::tf.TensorHandle, epsilon_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing)
        desc = tf.EagerOp("ResourceApplyCenteredRMSProp")
        tf.add_input(desc, var_)
        tf.add_input(desc, mg_)
        tf.add_input(desc, ms_)
        tf.add_input(desc, mom_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, rho_)
        tf.add_input(desc, momentum_)
        tf.add_input(desc, epsilon_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(rho_)
        desc["T"] = tf.data_type(momentum_)
        desc["T"] = tf.data_type(epsilon_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_apply_adagrad(var, accum, lr, grad; use_locking=false, update_slots=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_apply_adagrad(var_, accum_, lr_, grad_; name=nothing, use_locking=nothing, update_slots=nothing)
            local desc
            tf.with_op_name(name, "ResourceApplyAdagrad") do 
                desc = tf.NodeDescription("ResourceApplyAdagrad")
                var_ = convert(Tensor{Any}, var_)
                accum_ = convert(Tensor{Any}, accum_)
                lr_ = convert(Tensor{Any}, lr_)
                grad_ = convert(Tensor{Any}, grad_)
                (lr_, grad_) = tf.tf_promote(lr_, grad_)
                tf.add_input(desc, var_)
                tf.add_input(desc, accum_)
                tf.add_input(desc, lr_)
                tf.add_input(desc, grad_)
                if use_locking !== nothing
                    desc["use_locking"] = Base.Bool(use_locking)
                end
                if update_slots !== nothing
                    desc["update_slots"] = Base.Bool(update_slots)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_apply_adagrad(var_::tf.TensorHandle, accum_::tf.TensorHandle, lr_::tf.TensorHandle, grad_::tf.TensorHandle; name=nothing, use_locking=nothing, update_slots=nothing)
        desc = tf.EagerOp("ResourceApplyAdagrad")
        tf.add_input(desc, var_)
        tf.add_input(desc, accum_)
        tf.add_input(desc, lr_)
        tf.add_input(desc, grad_)
        if use_locking !== nothing
            desc["use_locking"] = Base.Bool(use_locking)
        end
        if update_slots !== nothing
            desc["update_slots"] = Base.Bool(update_slots)
        end
        desc["T"] = tf.data_type(lr_)
        desc["T"] = tf.data_type(grad_)
        (tf.execute(desc))[1]
    end
end


"""
     experimental_parallel_interleave_dataset(input_dataset, other_arguments, cycle_length, block_length, sloppy, buffer_output_elements, prefetch_input_elements)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function experimental_parallel_interleave_dataset(input_dataset_, other_arguments_, cycle_length_, block_length_, sloppy_, buffer_output_elements_, prefetch_input_elements_; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "ExperimentalParallelInterleaveDataset") do 
                desc = tf.NodeDescription("ExperimentalParallelInterleaveDataset")
                input_dataset_ = convert(Tensor{Any}, input_dataset_)
                other_arguments_ = [convert(Tensor{Any}, x) for x = other_arguments_]
                cycle_length_ = convert(Tensor{Int64}, cycle_length_)
                block_length_ = convert(Tensor{Int64}, block_length_)
                sloppy_ = convert(Tensor{Bool}, sloppy_)
                buffer_output_elements_ = convert(Tensor{Int64}, buffer_output_elements_)
                prefetch_input_elements_ = convert(Tensor{Int64}, prefetch_input_elements_)
                tf.add_input(desc, input_dataset_)
                tf.add_input(desc, other_arguments_)
                tf.add_input(desc, cycle_length_)
                tf.add_input(desc, block_length_)
                tf.add_input(desc, sloppy_)
                tf.add_input(desc, buffer_output_elements_)
                tf.add_input(desc, prefetch_input_elements_)
                if f !== nothing
                    desc["f"] = Base.identity(f)
                end
                if Targuments !== nothing
                    desc["Targuments"] = map(Base.identity, Targuments)
                end
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function experimental_parallel_interleave_dataset(input_dataset_::tf.TensorHandle, other_arguments_::tf.TensorHandle, cycle_length_::tf.TensorHandle, block_length_::tf.TensorHandle, sloppy_::tf.TensorHandle, buffer_output_elements_::tf.TensorHandle, prefetch_input_elements_::tf.TensorHandle; name=nothing, f=nothing, Targuments=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("ExperimentalParallelInterleaveDataset")
        tf.add_input(desc, input_dataset_)
        tf.add_input(desc, other_arguments_)
        tf.add_input(desc, cycle_length_)
        tf.add_input(desc, block_length_)
        tf.add_input(desc, sloppy_)
        tf.add_input(desc, buffer_output_elements_)
        tf.add_input(desc, prefetch_input_elements_)
        if f !== nothing
            desc["f"] = Base.identity(f)
        end
        if Targuments !== nothing
            desc["Targuments"] = map(Base.identity, Targuments)
        end
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     resize_bicubic_grad(grads, original_image; align_corners=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resize_bicubic_grad(grads_, original_image_; name=nothing, align_corners=nothing)
            local desc
            tf.with_op_name(name, "ResizeBicubicGrad") do 
                desc = tf.NodeDescription("ResizeBicubicGrad")
                grads_ = convert(Tensor{Float32}, grads_)
                original_image_ = convert(Tensor{Any}, original_image_)
                (original_image_,) = tf.tf_promote(original_image_)
                tf.add_input(desc, grads_)
                tf.add_input(desc, original_image_)
                if align_corners !== nothing
                    desc["align_corners"] = Base.Bool(align_corners)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resize_bicubic_grad(grads_::tf.TensorHandle, original_image_::tf.TensorHandle; name=nothing, align_corners=nothing)
        desc = tf.EagerOp("ResizeBicubicGrad")
        tf.add_input(desc, grads_)
        tf.add_input(desc, original_image_)
        if align_corners !== nothing
            desc["align_corners"] = Base.Bool(align_corners)
        end
        desc["T"] = tf.data_type(original_image_)
        (tf.execute(desc))[1]
    end
end


"""
     batch_self_adjoint_eig(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_self_adjoint_eig(input_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchSelfAdjointEig") do 
                desc = tf.NodeDescription("BatchSelfAdjointEig")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_self_adjoint_eig(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchSelfAdjointEig")
        tf.add_input(desc, input_)
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_softmax(sp_indices, sp_values, sp_shape)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_softmax(sp_indices_, sp_values_, sp_shape_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseSoftmax") do 
                desc = tf.NodeDescription("SparseSoftmax")
                sp_indices_ = convert(Tensor{Int64}, sp_indices_)
                sp_values_ = convert(Tensor{Any}, sp_values_)
                sp_shape_ = convert(Tensor{Int64}, sp_shape_)
                (sp_values_,) = tf.tf_promote(sp_values_)
                tf.add_input(desc, sp_indices_)
                tf.add_input(desc, sp_values_)
                tf.add_input(desc, sp_shape_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_softmax(sp_indices_::tf.TensorHandle, sp_values_::tf.TensorHandle, sp_shape_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseSoftmax")
        tf.add_input(desc, sp_indices_)
        tf.add_input(desc, sp_values_)
        tf.add_input(desc, sp_shape_)
        desc["T"] = tf.data_type(sp_values_)
        (tf.execute(desc))[1]
    end
end


"""
     asinh(x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function asinh(x_; name=nothing)
            local desc
            tf.with_op_name(name, "Asinh") do 
                desc = tf.NodeDescription("Asinh")
                x_ = convert(Tensor{Any}, x_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function asinh(x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Asinh")
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     quantized_conv2d_and_relu(input, filter, min_input, max_input, min_filter, max_filter; out_type=Float32, dilations=[1, 1, 1, 1])


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function quantized_conv2d_and_relu(input_, filter_, min_input_, max_input_, min_filter_, max_filter_; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
            local desc
            tf.with_op_name(name, "QuantizedConv2DAndRelu") do 
                desc = tf.NodeDescription("QuantizedConv2DAndRelu")
                input_ = convert(Tensor{Any}, input_)
                filter_ = convert(Tensor{Any}, filter_)
                min_input_ = convert(Tensor{Float32}, min_input_)
                max_input_ = convert(Tensor{Float32}, max_input_)
                min_filter_ = convert(Tensor{Float32}, min_filter_)
                max_filter_ = convert(Tensor{Float32}, max_filter_)
                (filter_,) = tf.tf_promote(filter_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, filter_)
                tf.add_input(desc, min_input_)
                tf.add_input(desc, max_input_)
                tf.add_input(desc, min_filter_)
                tf.add_input(desc, max_filter_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if strides !== nothing
                    desc["strides"] = map(Base.identity, strides)
                end
                if padding !== nothing
                    desc["padding"] = Base.String(padding)
                end
                if dilations !== nothing
                    desc["dilations"] = map(Base.identity, dilations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function quantized_conv2d_and_relu(input_::tf.TensorHandle, filter_::tf.TensorHandle, min_input_::tf.TensorHandle, max_input_::tf.TensorHandle, min_filter_::tf.TensorHandle, max_filter_::tf.TensorHandle; name=nothing, out_type=nothing, strides=nothing, padding=nothing, dilations=nothing)
        desc = tf.EagerOp("QuantizedConv2DAndRelu")
        tf.add_input(desc, input_)
        tf.add_input(desc, filter_)
        tf.add_input(desc, min_input_)
        tf.add_input(desc, max_input_)
        tf.add_input(desc, min_filter_)
        tf.add_input(desc, max_filter_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if strides !== nothing
            desc["strides"] = map(Base.identity, strides)
        end
        if padding !== nothing
            desc["padding"] = Base.String(padding)
        end
        if dilations !== nothing
            desc["dilations"] = map(Base.identity, dilations)
        end
        desc["Tinput"] = tf.data_type(input_)
        desc["Tfilter"] = tf.data_type(filter_)
        tf.execute(desc)
    end
end


"""
     matrix_inverse(input; adjoint=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function matrix_inverse(input_; name=nothing, adjoint=nothing)
            local desc
            tf.with_op_name(name, "MatrixInverse") do 
                desc = tf.NodeDescription("MatrixInverse")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if adjoint !== nothing
                    desc["adjoint"] = Base.Bool(adjoint)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function matrix_inverse(input_::tf.TensorHandle; name=nothing, adjoint=nothing)
        desc = tf.EagerOp("MatrixInverse")
        tf.add_input(desc, input_)
        if adjoint !== nothing
            desc["adjoint"] = Base.Bool(adjoint)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     tensor_list_concat_lists(input_a, input_b)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function tensor_list_concat_lists(input_a_, input_b_; name=nothing, element_dtype=nothing)
            local desc
            tf.with_op_name(name, "TensorListConcatLists") do 
                desc = tf.NodeDescription("TensorListConcatLists")
                input_a_ = convert(Tensor{Any}, input_a_)
                input_b_ = convert(Tensor{Any}, input_b_)
                tf.add_input(desc, input_a_)
                tf.add_input(desc, input_b_)
                if element_dtype !== nothing
                    desc["element_dtype"] = Base.identity(element_dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function tensor_list_concat_lists(input_a_::tf.TensorHandle, input_b_::tf.TensorHandle; name=nothing, element_dtype=nothing)
        desc = tf.EagerOp("TensorListConcatLists")
        tf.add_input(desc, input_a_)
        tf.add_input(desc, input_b_)
        if element_dtype !== nothing
            desc["element_dtype"] = Base.identity(element_dtype)
        end
        (tf.execute(desc))[1]
    end
end


"""
     requantize(input, input_min, input_max, requested_output_min, requested_output_max)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function requantize(input_, input_min_, input_max_, requested_output_min_, requested_output_max_; name=nothing, out_type=nothing)
            local desc
            tf.with_op_name(name, "Requantize") do 
                desc = tf.NodeDescription("Requantize")
                input_ = convert(Tensor{Any}, input_)
                input_min_ = convert(Tensor{Float32}, input_min_)
                input_max_ = convert(Tensor{Float32}, input_max_)
                requested_output_min_ = convert(Tensor{Float32}, requested_output_min_)
                requested_output_max_ = convert(Tensor{Float32}, requested_output_max_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_min_)
                tf.add_input(desc, input_max_)
                tf.add_input(desc, requested_output_min_)
                tf.add_input(desc, requested_output_max_)
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function requantize(input_::tf.TensorHandle, input_min_::tf.TensorHandle, input_max_::tf.TensorHandle, requested_output_min_::tf.TensorHandle, requested_output_max_::tf.TensorHandle; name=nothing, out_type=nothing)
        desc = tf.EagerOp("Requantize")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_min_)
        tf.add_input(desc, input_max_)
        tf.add_input(desc, requested_output_min_)
        tf.add_input(desc, requested_output_max_)
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        desc["Tinput"] = tf.data_type(input_)
        tf.execute(desc)
    end
end


"""
     fft(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function fft(input_; name=nothing)
            local desc
            tf.with_op_name(name, "FFT") do 
                desc = tf.NodeDescription("FFT")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function fft(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("FFT")
        tf.add_input(desc, input_)
        desc["Tcomplex"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     conjugate_transpose(x, perm)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function conjugate_transpose(x_, perm_; name=nothing)
            local desc
            tf.with_op_name(name, "ConjugateTranspose") do 
                desc = tf.NodeDescription("ConjugateTranspose")
                x_ = convert(Tensor{Any}, x_)
                perm_ = convert(Tensor{Int32}, perm_)
                (perm_,) = tf.tf_promote(perm_)
                (x_,) = tf.tf_promote(x_)
                tf.add_input(desc, x_)
                tf.add_input(desc, perm_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function conjugate_transpose(x_::tf.TensorHandle, perm_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ConjugateTranspose")
        tf.add_input(desc, x_)
        tf.add_input(desc, perm_)
        desc["T"] = tf.data_type(x_)
        desc["Tperm"] = tf.data_type(perm_)
        (tf.execute(desc))[1]
    end
end


"""
     unstage(; capacity=0, memory_limit=0, container=, shared_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function unstage(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
            local desc
            tf.with_op_name(name, "Unstage") do 
                desc = tf.NodeDescription("Unstage")
                if capacity !== nothing
                    desc["capacity"] = Base.Int(capacity)
                end
                if memory_limit !== nothing
                    desc["memory_limit"] = Base.Int(memory_limit)
                end
                if dtypes !== nothing
                    desc["dtypes"] = map(Base.identity, dtypes)
                end
                if container !== nothing
                    desc["container"] = Base.String(container)
                end
                if shared_name !== nothing
                    desc["shared_name"] = Base.String(shared_name)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function unstage(; name=nothing, capacity=nothing, memory_limit=nothing, dtypes=nothing, container=nothing, shared_name=nothing)
        desc = tf.EagerOp("Unstage")
        if capacity !== nothing
            desc["capacity"] = Base.Int(capacity)
        end
        if memory_limit !== nothing
            desc["memory_limit"] = Base.Int(memory_limit)
        end
        if dtypes !== nothing
            desc["dtypes"] = map(Base.identity, dtypes)
        end
        if container !== nothing
            desc["container"] = Base.String(container)
        end
        if shared_name !== nothing
            desc["shared_name"] = Base.String(shared_name)
        end
        (tf.execute(desc))[1]
    end
end


"""
     relu6grad(gradients, features)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function relu6grad(gradients_, features_; name=nothing)
            local desc
            tf.with_op_name(name, "Relu6Grad") do 
                desc = tf.NodeDescription("Relu6Grad")
                gradients_ = convert(Tensor{Any}, gradients_)
                features_ = convert(Tensor{Any}, features_)
                (gradients_, features_) = tf.tf_promote(gradients_, features_)
                tf.add_input(desc, gradients_)
                tf.add_input(desc, features_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function relu6grad(gradients_::tf.TensorHandle, features_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Relu6Grad")
        tf.add_input(desc, gradients_)
        tf.add_input(desc, features_)
        desc["T"] = tf.data_type(gradients_)
        desc["T"] = tf.data_type(features_)
        (tf.execute(desc))[1]
    end
end


"""
     scale_and_translate_grad(grads, original_image, scale, translation; kernel_type=lanczos3)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function scale_and_translate_grad(grads_, original_image_, scale_, translation_; name=nothing, kernel_type=nothing)
            local desc
            tf.with_op_name(name, "ScaleAndTranslateGrad") do 
                desc = tf.NodeDescription("ScaleAndTranslateGrad")
                grads_ = convert(Tensor{Any}, grads_)
                original_image_ = convert(Tensor{Any}, original_image_)
                scale_ = convert(Tensor{Float32}, scale_)
                translation_ = convert(Tensor{Float32}, translation_)
                (grads_, original_image_) = tf.tf_promote(grads_, original_image_)
                tf.add_input(desc, grads_)
                tf.add_input(desc, original_image_)
                tf.add_input(desc, scale_)
                tf.add_input(desc, translation_)
                if kernel_type !== nothing
                    desc["kernel_type"] = Base.String(kernel_type)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function scale_and_translate_grad(grads_::tf.TensorHandle, original_image_::tf.TensorHandle, scale_::tf.TensorHandle, translation_::tf.TensorHandle; name=nothing, kernel_type=nothing)
        desc = tf.EagerOp("ScaleAndTranslateGrad")
        tf.add_input(desc, grads_)
        tf.add_input(desc, original_image_)
        tf.add_input(desc, scale_)
        tf.add_input(desc, translation_)
        if kernel_type !== nothing
            desc["kernel_type"] = Base.String(kernel_type)
        end
        desc["T"] = tf.data_type(grads_)
        desc["T"] = tf.data_type(original_image_)
        (tf.execute(desc))[1]
    end
end


"""
     _array_to_list(input)

Converts an array of tensors to a list of tensors.
"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function _array_to_list(input_; name=nothing, N=nothing, out_types=nothing)
            local desc
            tf.with_op_name(name, "_ArrayToList") do 
                desc = tf.NodeDescription("_ArrayToList")
                input_ = [convert(Tensor{Any}, x) for x = input_]
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if out_types !== nothing
                    desc["out_types"] = map(Base.identity, out_types)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function _array_to_list(input_::tf.TensorHandle; name=nothing, N=nothing, out_types=nothing)
        desc = tf.EagerOp("_ArrayToList")
        tf.add_input(desc, input_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if out_types !== nothing
            desc["out_types"] = map(Base.identity, out_types)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     cudnn_rnnv3(input, input_h, input_c, params, sequence_lengths; rnn_mode=lstm, input_mode=linear_input, direction=unidirectional, dropout=?, seed=0, seed2=0, is_training=true)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function cudnn_rnnv3(input_, input_h_, input_c_, params_, sequence_lengths_; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing, is_training=nothing)
            local desc
            tf.with_op_name(name, "CudnnRNNV3") do 
                desc = tf.NodeDescription("CudnnRNNV3")
                input_ = convert(Tensor{Any}, input_)
                input_h_ = convert(Tensor{Any}, input_h_)
                input_c_ = convert(Tensor{Any}, input_c_)
                params_ = convert(Tensor{Any}, params_)
                sequence_lengths_ = convert(Tensor{Int32}, sequence_lengths_)
                (input_, input_h_, input_c_, params_) = tf.tf_promote(input_, input_h_, input_c_, params_)
                tf.add_input(desc, input_)
                tf.add_input(desc, input_h_)
                tf.add_input(desc, input_c_)
                tf.add_input(desc, params_)
                tf.add_input(desc, sequence_lengths_)
                if rnn_mode !== nothing
                    desc["rnn_mode"] = Base.String(rnn_mode)
                end
                if input_mode !== nothing
                    desc["input_mode"] = Base.String(input_mode)
                end
                if direction !== nothing
                    desc["direction"] = Base.String(direction)
                end
                if dropout !== nothing
                    desc["dropout"] = Base.identity(dropout)
                end
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if is_training !== nothing
                    desc["is_training"] = Base.Bool(is_training)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:5
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function cudnn_rnnv3(input_::tf.TensorHandle, input_h_::tf.TensorHandle, input_c_::tf.TensorHandle, params_::tf.TensorHandle, sequence_lengths_::tf.TensorHandle; name=nothing, rnn_mode=nothing, input_mode=nothing, direction=nothing, dropout=nothing, seed=nothing, seed2=nothing, is_training=nothing)
        desc = tf.EagerOp("CudnnRNNV3")
        tf.add_input(desc, input_)
        tf.add_input(desc, input_h_)
        tf.add_input(desc, input_c_)
        tf.add_input(desc, params_)
        tf.add_input(desc, sequence_lengths_)
        if rnn_mode !== nothing
            desc["rnn_mode"] = Base.String(rnn_mode)
        end
        if input_mode !== nothing
            desc["input_mode"] = Base.String(input_mode)
        end
        if direction !== nothing
            desc["direction"] = Base.String(direction)
        end
        if dropout !== nothing
            desc["dropout"] = Base.identity(dropout)
        end
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if is_training !== nothing
            desc["is_training"] = Base.Bool(is_training)
        end
        desc["T"] = tf.data_type(input_)
        desc["T"] = tf.data_type(input_h_)
        desc["T"] = tf.data_type(input_c_)
        desc["T"] = tf.data_type(params_)
        tf.execute(desc)
    end
end


"""
     expand_dims(input, dim)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function expand_dims(input_, dim_; name=nothing)
            local desc
            tf.with_op_name(name, "ExpandDims") do 
                desc = tf.NodeDescription("ExpandDims")
                input_ = convert(Tensor{Any}, input_)
                dim_ = convert(Tensor{Int32}, dim_)
                dim_ = dim_ - convert(tf.Tensor{eltype(dim_)}, 1)
                (input_,) = tf.tf_promote(input_)
                (dim_,) = tf.tf_promote(dim_)
                tf.add_input(desc, input_)
                tf.add_input(desc, dim_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function expand_dims(input_::tf.TensorHandle, dim_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("ExpandDims")
        tf.add_input(desc, input_)
        tf.add_input(desc, dim_)
        desc["T"] = tf.data_type(input_)
        desc["Tdim"] = tf.data_type(dim_)
        (tf.execute(desc))[1]
    end
end


"""
     inv_grad(y, dy)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function inv_grad(y_, dy_; name=nothing)
            local desc
            tf.with_op_name(name, "InvGrad") do 
                desc = tf.NodeDescription("InvGrad")
                y_ = convert(Tensor{Any}, y_)
                dy_ = convert(Tensor{Any}, dy_)
                (y_, dy_) = tf.tf_promote(y_, dy_)
                tf.add_input(desc, y_)
                tf.add_input(desc, dy_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function inv_grad(y_::tf.TensorHandle, dy_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("InvGrad")
        tf.add_input(desc, y_)
        tf.add_input(desc, dy_)
        desc["T"] = tf.data_type(y_)
        desc["T"] = tf.data_type(dy_)
        (tf.execute(desc))[1]
    end
end


"""
     non_max_suppression(boxes, scores, max_output_size; iou_threshold=?)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function non_max_suppression(boxes_, scores_, max_output_size_; name=nothing, iou_threshold=nothing)
            local desc
            tf.with_op_name(name, "NonMaxSuppression") do 
                desc = tf.NodeDescription("NonMaxSuppression")
                boxes_ = convert(Tensor{Float32}, boxes_)
                scores_ = convert(Tensor{Float32}, scores_)
                max_output_size_ = convert(Tensor{Int32}, max_output_size_)
                tf.add_input(desc, boxes_)
                tf.add_input(desc, scores_)
                tf.add_input(desc, max_output_size_)
                if iou_threshold !== nothing
                    desc["iou_threshold"] = Base.identity(iou_threshold)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function non_max_suppression(boxes_::tf.TensorHandle, scores_::tf.TensorHandle, max_output_size_::tf.TensorHandle; name=nothing, iou_threshold=nothing)
        desc = tf.EagerOp("NonMaxSuppression")
        tf.add_input(desc, boxes_)
        tf.add_input(desc, scores_)
        tf.add_input(desc, max_output_size_)
        if iou_threshold !== nothing
            desc["iou_threshold"] = Base.identity(iou_threshold)
        end
        (tf.execute(desc))[1]
    end
end


"""
     l2loss(t)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function l2loss(t_; name=nothing)
            local desc
            tf.with_op_name(name, "L2Loss") do 
                desc = tf.NodeDescription("L2Loss")
                t_ = convert(Tensor{Any}, t_)
                (t_,) = tf.tf_promote(t_)
                tf.add_input(desc, t_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function l2loss(t_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("L2Loss")
        tf.add_input(desc, t_)
        desc["T"] = tf.data_type(t_)
        (tf.execute(desc))[1]
    end
end


"""
     resize_area(images, size; align_corners=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resize_area(images_, size_; name=nothing, align_corners=nothing)
            local desc
            tf.with_op_name(name, "ResizeArea") do 
                desc = tf.NodeDescription("ResizeArea")
                images_ = convert(Tensor{Any}, images_)
                size_ = convert(Tensor{Int32}, size_)
                (images_,) = tf.tf_promote(images_)
                tf.add_input(desc, images_)
                tf.add_input(desc, size_)
                if align_corners !== nothing
                    desc["align_corners"] = Base.Bool(align_corners)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resize_area(images_::tf.TensorHandle, size_::tf.TensorHandle; name=nothing, align_corners=nothing)
        desc = tf.EagerOp("ResizeArea")
        tf.add_input(desc, images_)
        tf.add_input(desc, size_)
        if align_corners !== nothing
            desc["align_corners"] = Base.Bool(align_corners)
        end
        desc["T"] = tf.data_type(images_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_cross(indices, values, shapes, dense_inputs)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_cross(indices_, values_, shapes_, dense_inputs_; name=nothing, N=nothing, hashed_output=nothing, num_buckets=nothing, hash_key=nothing, sparse_types=nothing, dense_types=nothing, out_type=nothing, internal_type=nothing)
            local desc
            tf.with_op_name(name, "SparseCross") do 
                desc = tf.NodeDescription("SparseCross")
                indices_ = [convert(Tensor{Int64}, x) for x = indices_]
                values_ = [convert(Tensor{Any}, x) for x = values_]
                shapes_ = [convert(Tensor{Int64}, x) for x = shapes_]
                dense_inputs_ = [convert(Tensor{Any}, x) for x = dense_inputs_]
                tf.add_input(desc, indices_)
                tf.add_input(desc, values_)
                tf.add_input(desc, shapes_)
                tf.add_input(desc, dense_inputs_)
                if N !== nothing
                    desc["N"] = Base.Int(N)
                end
                if hashed_output !== nothing
                    desc["hashed_output"] = Base.Bool(hashed_output)
                end
                if num_buckets !== nothing
                    desc["num_buckets"] = Base.Int(num_buckets)
                end
                if hash_key !== nothing
                    desc["hash_key"] = Base.Int(hash_key)
                end
                if sparse_types !== nothing
                    desc["sparse_types"] = map(Base.identity, sparse_types)
                end
                if dense_types !== nothing
                    desc["dense_types"] = map(Base.identity, dense_types)
                end
                if out_type !== nothing
                    desc["out_type"] = Base.identity(out_type)
                end
                if internal_type !== nothing
                    desc["internal_type"] = Base.identity(internal_type)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_cross(indices_::tf.TensorHandle, values_::tf.TensorHandle, shapes_::tf.TensorHandle, dense_inputs_::tf.TensorHandle; name=nothing, N=nothing, hashed_output=nothing, num_buckets=nothing, hash_key=nothing, sparse_types=nothing, dense_types=nothing, out_type=nothing, internal_type=nothing)
        desc = tf.EagerOp("SparseCross")
        tf.add_input(desc, indices_)
        tf.add_input(desc, values_)
        tf.add_input(desc, shapes_)
        tf.add_input(desc, dense_inputs_)
        if N !== nothing
            desc["N"] = Base.Int(N)
        end
        if hashed_output !== nothing
            desc["hashed_output"] = Base.Bool(hashed_output)
        end
        if num_buckets !== nothing
            desc["num_buckets"] = Base.Int(num_buckets)
        end
        if hash_key !== nothing
            desc["hash_key"] = Base.Int(hash_key)
        end
        if sparse_types !== nothing
            desc["sparse_types"] = map(Base.identity, sparse_types)
        end
        if dense_types !== nothing
            desc["dense_types"] = map(Base.identity, dense_types)
        end
        if out_type !== nothing
            desc["out_type"] = Base.identity(out_type)
        end
        if internal_type !== nothing
            desc["internal_type"] = Base.identity(internal_type)
        end
        tf.execute(desc)
    end
end


"""
     batch_fft3d(input)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function batch_fft3d(input_; name=nothing)
            local desc
            tf.with_op_name(name, "BatchFFT3D") do 
                desc = tf.NodeDescription("BatchFFT3D")
                input_ = convert(Tensor{Complex{Float32}}, input_)
                tf.add_input(desc, input_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function batch_fft3d(input_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("BatchFFT3D")
        tf.add_input(desc, input_)
        (tf.execute(desc))[1]
    end
end


"""
     random_standard_normal(shape; seed=0, seed2=0)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function random_standard_normal(shape_; name=nothing, seed=nothing, seed2=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "RandomStandardNormal") do 
                desc = tf.NodeDescription("RandomStandardNormal")
                shape_ = convert(Tensor{Any}, shape_)
                (shape_,) = tf.tf_promote(shape_)
                tf.add_input(desc, shape_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function random_standard_normal(shape_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing, dtype=nothing)
        desc = tf.EagerOp("RandomStandardNormal")
        tf.add_input(desc, shape_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["T"] = tf.data_type(shape_)
        (tf.execute(desc))[1]
    end
end


"""
     resource_scatter_mul(resource, indices, updates)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function resource_scatter_mul(resource_, indices_, updates_; name=nothing, dtype=nothing)
            local desc
            tf.with_op_name(name, "ResourceScatterMul") do 
                desc = tf.NodeDescription("ResourceScatterMul")
                resource_ = convert(Tensor{Any}, resource_)
                indices_ = convert(Tensor{Any}, indices_)
                indices_ = indices_ - convert(tf.Tensor{eltype(indices_)}, 1)
                updates_ = convert(Tensor{Any}, updates_)
                (updates_,) = tf.tf_promote(updates_)
                (indices_,) = tf.tf_promote(indices_)
                tf.add_input(desc, resource_)
                tf.add_input(desc, indices_)
                tf.add_input(desc, updates_)
                if dtype !== nothing
                    desc["dtype"] = Base.identity(dtype)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function resource_scatter_mul(resource_::tf.TensorHandle, indices_::tf.TensorHandle, updates_::tf.TensorHandle; name=nothing, dtype=nothing)
        desc = tf.EagerOp("ResourceScatterMul")
        tf.add_input(desc, resource_)
        tf.add_input(desc, indices_)
        tf.add_input(desc, updates_)
        if dtype !== nothing
            desc["dtype"] = Base.identity(dtype)
        end
        desc["Tindices"] = tf.data_type(indices_)
        desc["dtype"] = tf.data_type(updates_)
        (tf.execute(desc))[1]
    end
end


"""
     sdca_optimizer(sparse_example_indices, sparse_feature_indices, sparse_feature_values, dense_features, example_weights, example_labels, sparse_indices, sparse_weights, dense_weights, example_state_data; adaptative=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sdca_optimizer(sparse_example_indices_, sparse_feature_indices_, sparse_feature_values_, dense_features_, example_weights_, example_labels_, sparse_indices_, sparse_weights_, dense_weights_, example_state_data_; name=nothing, loss_type=nothing, adaptative=nothing, num_sparse_features=nothing, num_sparse_features_with_values=nothing, num_dense_features=nothing, l1=nothing, l2=nothing, num_loss_partitions=nothing, num_inner_iterations=nothing)
            local desc
            tf.with_op_name(name, "SdcaOptimizer") do 
                desc = tf.NodeDescription("SdcaOptimizer")
                sparse_example_indices_ = [convert(Tensor{Int64}, x) for x = sparse_example_indices_]
                sparse_feature_indices_ = [convert(Tensor{Int64}, x) for x = sparse_feature_indices_]
                sparse_feature_values_ = [convert(Tensor{Float32}, x) for x = sparse_feature_values_]
                dense_features_ = [convert(Tensor{Float32}, x) for x = dense_features_]
                example_weights_ = convert(Tensor{Float32}, example_weights_)
                example_labels_ = convert(Tensor{Float32}, example_labels_)
                sparse_indices_ = [convert(Tensor{Int64}, x) for x = sparse_indices_]
                sparse_weights_ = [convert(Tensor{Float32}, x) for x = sparse_weights_]
                dense_weights_ = [convert(Tensor{Float32}, x) for x = dense_weights_]
                example_state_data_ = convert(Tensor{Float32}, example_state_data_)
                tf.add_input(desc, sparse_example_indices_)
                tf.add_input(desc, sparse_feature_indices_)
                tf.add_input(desc, sparse_feature_values_)
                tf.add_input(desc, dense_features_)
                tf.add_input(desc, example_weights_)
                tf.add_input(desc, example_labels_)
                tf.add_input(desc, sparse_indices_)
                tf.add_input(desc, sparse_weights_)
                tf.add_input(desc, dense_weights_)
                tf.add_input(desc, example_state_data_)
                if loss_type !== nothing
                    desc["loss_type"] = Base.String(loss_type)
                end
                if adaptative !== nothing
                    desc["adaptative"] = Base.Bool(adaptative)
                end
                if num_sparse_features !== nothing
                    desc["num_sparse_features"] = Base.Int(num_sparse_features)
                end
                if num_sparse_features_with_values !== nothing
                    desc["num_sparse_features_with_values"] = Base.Int(num_sparse_features_with_values)
                end
                if num_dense_features !== nothing
                    desc["num_dense_features"] = Base.Int(num_dense_features)
                end
                if l1 !== nothing
                    desc["l1"] = Base.identity(l1)
                end
                if l2 !== nothing
                    desc["l2"] = Base.identity(l2)
                end
                if num_loss_partitions !== nothing
                    desc["num_loss_partitions"] = Base.Int(num_loss_partitions)
                end
                if num_inner_iterations !== nothing
                    desc["num_inner_iterations"] = Base.Int(num_inner_iterations)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sdca_optimizer(sparse_example_indices_::tf.TensorHandle, sparse_feature_indices_::tf.TensorHandle, sparse_feature_values_::tf.TensorHandle, dense_features_::tf.TensorHandle, example_weights_::tf.TensorHandle, example_labels_::tf.TensorHandle, sparse_indices_::tf.TensorHandle, sparse_weights_::tf.TensorHandle, dense_weights_::tf.TensorHandle, example_state_data_::tf.TensorHandle; name=nothing, loss_type=nothing, adaptative=nothing, num_sparse_features=nothing, num_sparse_features_with_values=nothing, num_dense_features=nothing, l1=nothing, l2=nothing, num_loss_partitions=nothing, num_inner_iterations=nothing)
        desc = tf.EagerOp("SdcaOptimizer")
        tf.add_input(desc, sparse_example_indices_)
        tf.add_input(desc, sparse_feature_indices_)
        tf.add_input(desc, sparse_feature_values_)
        tf.add_input(desc, dense_features_)
        tf.add_input(desc, example_weights_)
        tf.add_input(desc, example_labels_)
        tf.add_input(desc, sparse_indices_)
        tf.add_input(desc, sparse_weights_)
        tf.add_input(desc, dense_weights_)
        tf.add_input(desc, example_state_data_)
        if loss_type !== nothing
            desc["loss_type"] = Base.String(loss_type)
        end
        if adaptative !== nothing
            desc["adaptative"] = Base.Bool(adaptative)
        end
        if num_sparse_features !== nothing
            desc["num_sparse_features"] = Base.Int(num_sparse_features)
        end
        if num_sparse_features_with_values !== nothing
            desc["num_sparse_features_with_values"] = Base.Int(num_sparse_features_with_values)
        end
        if num_dense_features !== nothing
            desc["num_dense_features"] = Base.Int(num_dense_features)
        end
        if l1 !== nothing
            desc["l1"] = Base.identity(l1)
        end
        if l2 !== nothing
            desc["l2"] = Base.identity(l2)
        end
        if num_loss_partitions !== nothing
            desc["num_loss_partitions"] = Base.Int(num_loss_partitions)
        end
        if num_inner_iterations !== nothing
            desc["num_inner_iterations"] = Base.Int(num_inner_iterations)
        end
        tf.execute(desc)
    end
end


"""
     zeta(x, q)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function zeta(x_, q_; name=nothing)
            local desc
            tf.with_op_name(name, "Zeta") do 
                desc = tf.NodeDescription("Zeta")
                x_ = convert(Tensor{Any}, x_)
                q_ = convert(Tensor{Any}, q_)
                (x_, q_) = tf.tf_promote(x_, q_)
                tf.add_input(desc, x_)
                tf.add_input(desc, q_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function zeta(x_::tf.TensorHandle, q_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Zeta")
        tf.add_input(desc, x_)
        tf.add_input(desc, q_)
        desc["T"] = tf.data_type(x_)
        desc["T"] = tf.data_type(q_)
        (tf.execute(desc))[1]
    end
end


"""
     sample_distorted_bounding_box(image_size, bounding_boxes; seed=0, seed2=0, min_object_covered=?, aspect_ratio_range=Int64[], area_range=Int64[], max_attempts=100, use_image_if_no_bounding_boxes=false)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sample_distorted_bounding_box(image_size_, bounding_boxes_; name=nothing, seed=nothing, seed2=nothing, min_object_covered=nothing, aspect_ratio_range=nothing, area_range=nothing, max_attempts=nothing, use_image_if_no_bounding_boxes=nothing)
            local desc
            tf.with_op_name(name, "SampleDistortedBoundingBox") do 
                desc = tf.NodeDescription("SampleDistortedBoundingBox")
                image_size_ = convert(Tensor{Any}, image_size_)
                bounding_boxes_ = convert(Tensor{Float32}, bounding_boxes_)
                (image_size_,) = tf.tf_promote(image_size_)
                tf.add_input(desc, image_size_)
                tf.add_input(desc, bounding_boxes_)
                if seed !== nothing
                    desc["seed"] = Base.Int(seed)
                end
                if seed2 !== nothing
                    desc["seed2"] = Base.Int(seed2)
                end
                if min_object_covered !== nothing
                    desc["min_object_covered"] = Base.identity(min_object_covered)
                end
                if aspect_ratio_range !== nothing
                    desc["aspect_ratio_range"] = map(Base.identity, aspect_ratio_range)
                end
                if area_range !== nothing
                    desc["area_range"] = map(Base.identity, area_range)
                end
                if max_attempts !== nothing
                    desc["max_attempts"] = Base.Int(max_attempts)
                end
                if use_image_if_no_bounding_boxes !== nothing
                    desc["use_image_if_no_bounding_boxes"] = Base.Bool(use_image_if_no_bounding_boxes)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sample_distorted_bounding_box(image_size_::tf.TensorHandle, bounding_boxes_::tf.TensorHandle; name=nothing, seed=nothing, seed2=nothing, min_object_covered=nothing, aspect_ratio_range=nothing, area_range=nothing, max_attempts=nothing, use_image_if_no_bounding_boxes=nothing)
        desc = tf.EagerOp("SampleDistortedBoundingBox")
        tf.add_input(desc, image_size_)
        tf.add_input(desc, bounding_boxes_)
        if seed !== nothing
            desc["seed"] = Base.Int(seed)
        end
        if seed2 !== nothing
            desc["seed2"] = Base.Int(seed2)
        end
        if min_object_covered !== nothing
            desc["min_object_covered"] = Base.identity(min_object_covered)
        end
        if aspect_ratio_range !== nothing
            desc["aspect_ratio_range"] = map(Base.identity, aspect_ratio_range)
        end
        if area_range !== nothing
            desc["area_range"] = map(Base.identity, area_range)
        end
        if max_attempts !== nothing
            desc["max_attempts"] = Base.Int(max_attempts)
        end
        if use_image_if_no_bounding_boxes !== nothing
            desc["use_image_if_no_bounding_boxes"] = Base.Bool(use_image_if_no_bounding_boxes)
        end
        desc["T"] = tf.data_type(image_size_)
        tf.execute(desc)
    end
end


"""
     igamma_grad_a(a, x)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function igamma_grad_a(a_, x_; name=nothing)
            local desc
            tf.with_op_name(name, "IgammaGradA") do 
                desc = tf.NodeDescription("IgammaGradA")
                a_ = convert(Tensor{Any}, a_)
                x_ = convert(Tensor{Any}, x_)
                (a_, x_) = tf.tf_promote(a_, x_)
                tf.add_input(desc, a_)
                tf.add_input(desc, x_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function igamma_grad_a(a_::tf.TensorHandle, x_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("IgammaGradA")
        tf.add_input(desc, a_)
        tf.add_input(desc, x_)
        desc["T"] = tf.data_type(a_)
        desc["T"] = tf.data_type(x_)
        (tf.execute(desc))[1]
    end
end


"""
     segment_max(data, segment_ids)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function segment_max(data_, segment_ids_; name=nothing)
            local desc
            tf.with_op_name(name, "SegmentMax") do 
                desc = tf.NodeDescription("SegmentMax")
                data_ = convert(Tensor{Any}, data_)
                segment_ids_ = convert(Tensor{Any}, segment_ids_)
                segment_ids_ = segment_ids_ - convert(tf.Tensor{eltype(segment_ids_)}, 1)
                (data_,) = tf.tf_promote(data_)
                (segment_ids_,) = tf.tf_promote(segment_ids_)
                tf.add_input(desc, data_)
                tf.add_input(desc, segment_ids_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function segment_max(data_::tf.TensorHandle, segment_ids_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SegmentMax")
        tf.add_input(desc, data_)
        tf.add_input(desc, segment_ids_)
        desc["T"] = tf.data_type(data_)
        desc["Tindices"] = tf.data_type(segment_ids_)
        (tf.execute(desc))[1]
    end
end


"""
     range(start, limit, delta)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function range(start_, limit_, delta_; name=nothing)
            local desc
            tf.with_op_name(name, "Range") do 
                desc = tf.NodeDescription("Range")
                start_ = convert(Tensor{Int32}, start_)
                limit_ = convert(Tensor{Int32}, limit_)
                delta_ = convert(Tensor{Int32}, delta_)
                (start_, limit_, delta_) = tf.tf_promote(start_, limit_, delta_)
                tf.add_input(desc, start_)
                tf.add_input(desc, limit_)
                tf.add_input(desc, delta_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function range(start_::tf.TensorHandle, limit_::tf.TensorHandle, delta_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("Range")
        tf.add_input(desc, start_)
        tf.add_input(desc, limit_)
        tf.add_input(desc, delta_)
        desc["Tidx"] = tf.data_type(start_)
        desc["Tidx"] = tf.data_type(limit_)
        desc["Tidx"] = tf.data_type(delta_)
        (tf.execute(desc))[1]
    end
end


"""
     retrieve_tpu_embedding_momentum_parameters_grad_accum_debug(; table_id=-1, table_name=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function retrieve_tpu_embedding_momentum_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
            local desc
            tf.with_op_name(name, "RetrieveTPUEmbeddingMomentumParametersGradAccumDebug") do 
                desc = tf.NodeDescription("RetrieveTPUEmbeddingMomentumParametersGradAccumDebug")
                if table_id !== nothing
                    desc["table_id"] = Base.Int(table_id)
                end
                if table_name !== nothing
                    desc["table_name"] = Base.String(table_name)
                end
                if num_shards !== nothing
                    desc["num_shards"] = Base.Int(num_shards)
                end
                if shard_id !== nothing
                    desc["shard_id"] = Base.Int(shard_id)
                end
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:3
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function retrieve_tpu_embedding_momentum_parameters_grad_accum_debug(; name=nothing, table_id=nothing, table_name=nothing, num_shards=nothing, shard_id=nothing)
        desc = tf.EagerOp("RetrieveTPUEmbeddingMomentumParametersGradAccumDebug")
        if table_id !== nothing
            desc["table_id"] = Base.Int(table_id)
        end
        if table_name !== nothing
            desc["table_name"] = Base.String(table_name)
        end
        if num_shards !== nothing
            desc["num_shards"] = Base.Int(num_shards)
        end
        if shard_id !== nothing
            desc["shard_id"] = Base.Int(shard_id)
        end
        tf.execute(desc)
    end
end


"""
     flush_summary_writer(writer)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function flush_summary_writer(writer_; name=nothing)
            local desc
            tf.with_op_name(name, "FlushSummaryWriter") do 
                desc = tf.NodeDescription("FlushSummaryWriter")
                writer_ = convert(Tensor{Any}, writer_)
                tf.add_input(desc, writer_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function flush_summary_writer(writer_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("FlushSummaryWriter")
        tf.add_input(desc, writer_)
        (tf.execute(desc))[1]
    end
end


"""
     dequantize(input, min_range, max_range; mode=MIN_COMBINED)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function dequantize(input_, min_range_, max_range_; name=nothing, mode=nothing)
            local desc
            tf.with_op_name(name, "Dequantize") do 
                desc = tf.NodeDescription("Dequantize")
                input_ = convert(Tensor{Any}, input_)
                min_range_ = convert(Tensor{Float32}, min_range_)
                max_range_ = convert(Tensor{Float32}, max_range_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                tf.add_input(desc, min_range_)
                tf.add_input(desc, max_range_)
                if mode !== nothing
                    desc["mode"] = Base.String(mode)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function dequantize(input_::tf.TensorHandle, min_range_::tf.TensorHandle, max_range_::tf.TensorHandle; name=nothing, mode=nothing)
        desc = tf.EagerOp("Dequantize")
        tf.add_input(desc, input_)
        tf.add_input(desc, min_range_)
        tf.add_input(desc, max_range_)
        if mode !== nothing
            desc["mode"] = Base.String(mode)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     sparse_fill_empty_rows_grad(reverse_index_map, grad_values)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_fill_empty_rows_grad(reverse_index_map_, grad_values_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseFillEmptyRowsGrad") do 
                desc = tf.NodeDescription("SparseFillEmptyRowsGrad")
                reverse_index_map_ = convert(Tensor{Int64}, reverse_index_map_)
                grad_values_ = convert(Tensor{Any}, grad_values_)
                (grad_values_,) = tf.tf_promote(grad_values_)
                tf.add_input(desc, reverse_index_map_)
                tf.add_input(desc, grad_values_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function sparse_fill_empty_rows_grad(reverse_index_map_::tf.TensorHandle, grad_values_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseFillEmptyRowsGrad")
        tf.add_input(desc, reverse_index_map_)
        tf.add_input(desc, grad_values_)
        desc["T"] = tf.data_type(grad_values_)
        tf.execute(desc)
    end
end


"""
     iterator_get_next(iterator)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function iterator_get_next(iterator_; name=nothing, output_types=nothing, output_shapes=nothing)
            local desc
            tf.with_op_name(name, "IteratorGetNext") do 
                desc = tf.NodeDescription("IteratorGetNext")
                iterator_ = convert(Tensor{Any}, iterator_)
                tf.add_input(desc, iterator_)
                if output_types !== nothing
                    desc["output_types"] = map(Base.identity, output_types)
                end
                if output_shapes !== nothing
                    desc["output_shapes"] = map(Base.identity, output_shapes)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function iterator_get_next(iterator_::tf.TensorHandle; name=nothing, output_types=nothing, output_shapes=nothing)
        desc = tf.EagerOp("IteratorGetNext")
        tf.add_input(desc, iterator_)
        if output_types !== nothing
            desc["output_types"] = map(Base.identity, output_types)
        end
        if output_shapes !== nothing
            desc["output_shapes"] = map(Base.identity, output_shapes)
        end
        (tf.execute(desc))[1]
    end
end


"""
     sparse_tensor_dense_add(a_indices, a_values, a_shape, b)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function sparse_tensor_dense_add(a_indices_, a_values_, a_shape_, b_; name=nothing)
            local desc
            tf.with_op_name(name, "SparseTensorDenseAdd") do 
                desc = tf.NodeDescription("SparseTensorDenseAdd")
                a_indices_ = convert(Tensor{Any}, a_indices_)
                a_indices_ = a_indices_ - convert(tf.Tensor{eltype(a_indices_)}, 1)
                a_values_ = convert(Tensor{Any}, a_values_)
                a_shape_ = convert(Tensor{Any}, a_shape_)
                a_shape_ = a_shape_ - convert(tf.Tensor{eltype(a_shape_)}, 1)
                b_ = convert(Tensor{Any}, b_)
                (a_values_, b_) = tf.tf_promote(a_values_, b_)
                (a_indices_, a_shape_) = tf.tf_promote(a_indices_, a_shape_)
                tf.add_input(desc, a_indices_)
                tf.add_input(desc, a_values_)
                tf.add_input(desc, a_shape_)
                tf.add_input(desc, b_)
            end
            tf.Tensor(tf.Operation(desc))
        end
    function sparse_tensor_dense_add(a_indices_::tf.TensorHandle, a_values_::tf.TensorHandle, a_shape_::tf.TensorHandle, b_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("SparseTensorDenseAdd")
        tf.add_input(desc, a_indices_)
        tf.add_input(desc, a_values_)
        tf.add_input(desc, a_shape_)
        tf.add_input(desc, b_)
        desc["Tindices"] = tf.data_type(a_indices_)
        desc["T"] = tf.data_type(a_values_)
        desc["Tindices"] = tf.data_type(a_shape_)
        desc["T"] = tf.data_type(b_)
        (tf.execute(desc))[1]
    end
end


"""
     prevent_gradient(input; message=)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function prevent_gradient(input_; name=nothing, message=nothing)
            local desc
            tf.with_op_name(name, "PreventGradient") do 
                desc = tf.NodeDescription("PreventGradient")
                input_ = convert(Tensor{Any}, input_)
                (input_,) = tf.tf_promote(input_)
                tf.add_input(desc, input_)
                if message !== nothing
                    desc["message"] = Base.String(message)
                end
            end
            tf.Tensor(tf.Operation(desc))
        end
    function prevent_gradient(input_::tf.TensorHandle; name=nothing, message=nothing)
        desc = tf.EagerOp("PreventGradient")
        tf.add_input(desc, input_)
        if message !== nothing
            desc["message"] = Base.String(message)
        end
        desc["T"] = tf.data_type(input_)
        (tf.execute(desc))[1]
    end
end


"""
     lookup_table_export(table_handle)


"""
begin
    #= /Users/malmaud/.julia/dev/TensorFlow/src/generate_ops.jl:227 =# tf.@op function lookup_table_export(table_handle_; name=nothing)
            local desc
            tf.with_op_name(name, "LookupTableExport") do 
                desc = tf.NodeDescription("LookupTableExport")
                table_handle_ = convert(Tensor{String}, table_handle_)
                tf.add_input(desc, table_handle_)
            end
            out = tf.Tensor[]
            op = tf.Operation(desc)
            for out_idx = 1:2
                push!(out, tf.Tensor(op, out_idx))
            end
            out
        end
    function lookup_table_export(table_handle_::tf.TensorHandle; name=nothing)
        desc = tf.EagerOp("LookupTableExport")
        tf.add_input(desc, table_handle_)
        tf.execute(desc)
    end
end


end
